#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:3

* README
** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks
   - It contains explanations of how things are organized, of the workflow for
     doing experiments, changes made to the code, and the observed behavior in
     the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Following this, if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch. The /master/ branch is clean from any results, it contains only
     source code and the analysis.
** Experiments workflow:
   1) Create a new branch
   2) Make sure everything is commited
   3) ...
   4) Do the analysis
   5) Add to this file into "* Data" section the entry for the results, using
      the template described below
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote "data" branch
** Example for experimental setup procedure
*** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

*** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

    1. =M-x jupyter-server-list-kernels=
       1. set server URL, e.g. =http://localhost:8889=
       2. set websocket URL, e.g. =http://localhost:8889=
    2. two possibilities
       1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
       2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
          *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    3. In subtree where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. We can customize the output folder using the following variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/figures-jupyter")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/figures-jupyter

** tools used (notes)
*** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
*** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
*** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
*** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

** Example for ...
* Template for data entry:
** exp-#date-#title
*** git:
#+begin_src sh
git log -1
#+end_src

*** System Metadata:
#+NAME: jupyter-python-metadata
#+BEGIN_SRC jupyter-python :var conda_list="true"
  import os

  ramlist = os.popen('free -th').readlines()[-1].split()[1:]

  print('No of CPUs in system:', os.cpu_count())
  print('No of CPUs the current process can use:',
        len(os.sched_getaffinity(0)))
  print('load average:', os.getloadavg())
  print(os.uname())
  print('PID of process:', os.getpid())
  print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
      ramlist[0], ramlist[1], ramlist[2]))

  !echo the current directory: $PWD
  !echo My disk usage:
  !df -h
  if conda_list:
      !conda list
#+END_SRC

**** TODO Add =os.environ=
*** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:
#+NAME: setup-tmux
#+BEGIN_SRC sh :session local
rm ~/.tmux-local-socket-remote-machine
REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
echo $REMOTE_SOCKET
ssh ara -tfN \
    -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
#+END_SRC

#+RESULTS: setup-tmux
| rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
| /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

A script which allows to print the output from the tmux session
in an =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
C-v C-o= when the pointer is inside the tmux block. See [[https://github.com/ahendriksen/ob-tmux/issues/6#issuecomment-613914400][here]].

#+BEGIN_SRC emacs-lisp
  (defun ob-tmux--insert-result ()
    (interactive)
    (let ((info (org-babel-get-src-block-info 'light)))
      (when (and info (string-equal "tmux" (nth 0 info)))
        (let* ((params (nth 2 info))
               (org-session (cdr (assq :session params)))
               (socket (cdr (assq :socket params)))
               (socket (when socket (expand-file-name socket)))
               (ob-session (ob-tmux--from-org-session org-session socket)))
          (org-babel-insert-result
               (ob-tmux--execute-string ob-session
                                        "capture-pane"
                                        "-p" ;; print to stdout
                                        "-S" "-" ;; start at beginning of history
                                        "-t" (ob-tmux--session ob-session))
               '("replace"))))))

  (defun ob-tmux--edit-result ()
    (interactive)
    (pcase (org-babel-get-src-block-info 'light)
      (`(,_ ,_ ,arguments ,_ ,_ ,start ,_)
       (save-excursion
         ;; Go to the results, if there aren't any then run the block.
         (goto-char start)
         (goto-char (or (org-babel-where-is-src-block-result)
                        (progn (org-babel-execute-src-block)
                               (org-babel-where-is-src-block-result))))
         (end-of-line)
         (skip-chars-forward " \r\t\n")
         (org-edit-special)
         (delete-trailing-whitespace)
         (end-of-buffer)
         t))
      (_ nil)))

  (defun ob-tmux--open-src-block-result (orig-fun &rest args)
    (let ((info (org-babel-get-src-block-info 'light)))
      (if (and info (string-equal "tmux" (nth 0 info)))
          (progn
            (ob-tmux--insert-result)
            (ob-tmux--edit-result))
        (apply orig-fun args))))

  (advice-add 'org-babel-open-src-block-result
                 :around #'ob-tmux--open-src-block-result)
#+END_SRC

#+RESULTS:

*** jupyter setup and ssh tunneling

On the compute node of the HPC, the users' environment is managed through module
files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements are needed
because of a jupyter bug which did not let it start. Right now, =ob-tmux= does
not support a =:var= header like normal =org-babel= does. So the =$port=
variable has to be set before calling a block similar to this one:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
export PORT=8889
#+END_SRC

Then call:

#+NAME: jpt-tmux
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
module load tools/python/3.7
export XDG_RUNTIME_DIR=''
export XDG_RUNTIME_DIR=""
jupyter notebook --no-browser --port=$PORT
#+END_SRC

Now this port has to be tunnelled on our local computer. While the tmux session
above keeps running, no matter if Emacs is running or not, this following ssh
tunnel needs to be active locally to connect to the notebook. If Emacs crashes,
it would need to be reestablished.

#+NAME: jpt-tunnel
#+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
#+END_SRC

*** Notes:
    ######################

* Organization of git
** remote/origin/master branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *master* in an *exp###* branch, ### meaning some meaningful descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/exp-###**, except machine
    learning-specific data and metadata from `mlflow` runs, which are saved
    under **data/mlruns** (this allows easily comparing machine learning runs
    with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *exp###* branches are merged here. Afterwards the original branch is
    deleted and on the data branch there is a *Git tag* which shows the merge
    commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

** Git TAGs
*** Stable versions:
*** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
* Organization of code
** scripts:
** src/
*** fluotracify/
**** imports/
**** simulations/
**** training/
**** applications/
**** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

*** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

* Changes in this repository (without "* Data" in this file)
** Changes in LabBook.org (without "* Data")
*** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
*** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
** Changes in src/fluotracify

* DEVELOPMENT TESTING (don't merge in master)
  :LOGBOOK:
  CLOCK: [2020-04-23 Do 13:35]--[2020-04-23 Do 14:57] =>  1:22
  :END:
** configured custom yasnippets,
   - check =yas-describe-tables= for current snippets
   - use =C-c & C-n= to create new snippet (its put in =.emacs.d/snippets/=)

#+BEGIN_SRC sh :session local
  ls -Rl ~/.emacs.d/snippets/
#+END_SRC

#+RESULTS:
| /home/lex/.emacs.d/snippets/:         |     |    |       |                       |
| total                                 |     |    |       |                       |
| drwxr-xr-x                            | Apr | 23 | 15:23 | org-mode              |
| /home/lex/.emacs.d/snippets/org-mode: |     |    |       |                       |
| total                                 |     |    |       |                       |
| -rw-r--r--                            | Apr | 23 | 14:32 | jupyter-python-block  |
| -rw-r--r--                            | Apr | 23 | 14:35 | jupyter-python-header |
| -rw-r--r--                            | Apr | 23 | 15:23 | lmod-srun             |
| -rw-r--r--                            | Apr | 23 | 14:53 | src2                  |
| -rw-r--r--                            | Apr | 23 | 15:00 | tmux                  |

** fix hardlinks of org-files outside =Dokumente/org=
#+BEGIN_SRC sh :session local :results verbatim
  cd Dokumente/org/linkedfiles
  ls -li
  find / -samefile LabBook.org
#+END_SRC

#+RESULTS:
#+begin_example
total 84
4992947 -rw-r--r-- 2 lex lex 11786 Apr 23 14:14 LabBook.org
 404446 -rw-r--r-- 1 lex lex 21544 Apr  4 22:53 LabBook.org~
 404411 -rw-r--r-- 2 lex lex 23355 Apr 20 01:44 lexbn-source.org
4328628 -rw-r--r-- 1 lex lex 20829 Apr 19 14:37 lexbn-source.org~

/home/lex/Dokumente/org/linkedfiles/LabBook.org
/home/lex/Programme/drmed-git/LabBook.org
#+end_example

** connect LabBook to HPC with jupyter etc
   :LOGBOOK:
   CLOCK: [2020-04-23 Do 17:30]--[2020-04-23 Do 17:46] =>  0:16
   CLOCK: [2020-04-23 Do 16:05]--[2020-04-23 Do 16:38] =>  0:33
   CLOCK: [2020-04-23 Do 15:20]--[2020-04-23 Do 15:50] =>  0:30
   CLOCK: [2020-04-23 Do 14:57]--[2020-04-23 Do 15:07] =>  0:10
   :END:
*** connect to compute node
#+BEGIN_SRC sh :session org-ssh :results verbatim
  ssh ara
#+END_SRC

#+RESULTS:
: ssh: Could not resolve hostname ara: Name or service not known

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    48 | mix   | node[003,007-008,023-026,029,031,033-038,040,053,063-064,066-072,075-078,083-085,090-094,117-119,121-125,131,133]                                                                                 |
| b_standard* | up    | 8-08:00:00 |    82 | alloc | node[002,004-006,009-022,027-028,030,032,039,041-045,047-052,054-062,065,073-074,079-082,086-089,095-116,120,126,132,134-136]                                                                     |
| b_standard* | up    | 8-08:00:00 |     1 | idle  | node046                                                                                                                                                                                           |
| gpu_test    | up    |    1:00:00 |     1 | idle  | node127                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | idle  | node130                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     4 | mix   | node[137-140]                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | idle  | node141                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    68 | mix   | node[144,151,162-163,167,169,171-172,177-181,186,191,196-198,200,203-209,212-214,216,218,221-222,224-231,233,235-237,241-249,255,257,259-260,265-268,297,303-304,309-310,315]                     |
| s_standard  | up    | 8-08:00:00 |    83 | alloc | node[142-143,145-150,152-161,164-166,168,170,173-176,182-185,187-190,192-195,199,201-202,210-211,215,217,219-220,223,232,234,238-240,250-254,256,258,261-264,293-296,298-302,305-308,311-314,316] |
| s_fat       | up    | 8-08:00:00 |     3 | mix   | node[269-270,272]                                                                                                                                                                                 |
| s_fat       | up    | 8-08:00:00 |     1 | alloc | node271                                                                                                                                                                                           |

#+BEGIN_SRC sh :session org-ssh
  tmux ls
#+END_SRC

#+RESULTS:
|       0: | 1 | windows | (created | Mon | Apr | 13 | 19:54:44 | 2020 |
| ob-tmux: | 1 | windows | (created | Mon | Apr | 13 | 19:55:21 | 2020 |


#+CALL:setup-tmux

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  echo test
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ echo test
  test
  [ye53nis@login01 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 -
  -pty bash
  [ye53nis@node018 ~]$
#+end_example

*** start and connect to jupyter
:PROPERTIES:
:header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
:END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  export PORT=8889
#+END_SRC

#+CALL: jpt-tmux[:session ob-tmux]

#+RESULTS:
#+begin_example
  [ye53nis@node018 ~]$ export PORT=8889
  [ye53nis@node018 ~]$ module load tools/python/3.7
  [ye53nis@node018 ~]$ export XDG_RUNTIME_DIR=''
  [ye53nis@node018 ~]$ export XDG_RUNTIME_DIR=""
  [ye53nis@node018 ~]$ jupyter notebook --no-browser --port=$PORT
  [I 16:09:30.912 NotebookApp] Serving notebooks from local directory: /home/ye53n
  is
  [I 16:09:30.912 NotebookApp] The Jupyter Notebook is running at:
  [I 16:09:30.912 NotebookApp] http://localhost:8889/?token=8cd6a262f7384ed4780611
  af96fb9cb4db8733a4cf654eaf
  [I 16:09:30.912 NotebookApp] Use Control-C to stop this server and shut down all
   kernels (twice to skip confirmation).
  [C 16:09:30.957 NotebookApp]

      To access the notebook, open this file in a browser:
          file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-50353-open.ht
  ml
      Or copy and paste one of these URLs:
          http://localhost:8889/?token=8cd6a262f7384ed4780611af96fb9cb4db8733a4cf6
  54eaf
#+end_example

#+CALL: jpt-tunnel(port="8889", node="node018")

#+RESULTS:
| sh-5.0$           | sh-5.0$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |    |          |      |      |             |
| ye53nis@node018's | password: |                                      |           |    |          |      |      |             |
| Last              | login:    | Thu                                  | Apr       | 23 | 16:20:50 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           6be3aedd-62d4-4fc2-b816-af41e3986de9   2 minutes ago        starting   0
#+end_example

Passing a boolean value to a variable in =org-babel= was not trivial: you have to
use the infamous *single quote '* from emacs-lisp programming to show that the
expression should be returned as written, not evaluated.

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 48
  No of CPUs the current process can use: 48
  load average: (0.08, 0.03, 0.05)
  posix.uname_result(sysname='Linux', nodename='node018', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 86937
  RAM total: 137G, RAM used: 1.7G, RAM free: 126G
  the current directory: /home/ye53nis
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  4.3G   46G   9% /
  devtmpfs              63G     0   63G   0% /dev
  tmpfs                 63G  559M   63G   1% /dev/shm
  tmpfs                 63G   59M   63G   1% /run
  tmpfs                 63G     0   63G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  nfs01-ib:/home        80T   59T   22T  73% /home
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  3.9G  165G   3% /local
  /dev/sda3            6.0G  481M  5.6G   8% /var
  beegfs_nodev         524T  421T  104T  81% /beegfs
  tmpfs                 13G     0   13G   0% /run/user/67339
#+end_example

** set up mlflow
   :LOGBOOK:
   CLOCK: [2020-04-24 Fr 13:09]--[2020-04-24 Fr 13:52] =>  0:43
   CLOCK: [2020-04-24 Fr 11:07]--[2020-04-24 Fr 11:30] =>  0:23
   CLOCK: [2020-04-23 Do 19:05]--[2020-04-23 Do 19:50] =>  0:45
   CLOCK: [2020-04-23 Do 17:59]--[2020-04-23 Do 18:49] =>  0:50
   CLOCK: [2020-04-23 Do 17:46]--[2020-04-23 Do 17:51] =>  0:05
   :END:
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
   :END:

*** how do I submit mlflow jobs?
- I will need two sessions
  - one *tmux session* for running the jupyter kernel, having a REPL, fast and
    interactive coding. I need tmux bc the connection to the node would break if
    I log out of ssh.
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
      echo tüdelü
    #+END_SRC
  - one *sh ssh session* for sending command line commands. SLURM handles the
    job and outputs files - so it should continue, even if I log out
- alternative solution: tmux windows (*note: after using tmux windows, the
  normal =:session tmux= without window specification doesn't work anymore*)
  - this is window =mlflow= for sending mlflow commands. we have to request some
    computation power by SLURM again
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
      echo pwd
    #+END_SRC
  - this is window =ob1= (name automatically created when you don't specify a
    window name) where our jupyter kernel runs:
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:ob1
      echo testö
    #+END_SRC
**** Failed approaches:
- then jobs are submitted e.g. as bash scripts (this is just an example from the
  wiki):
  #+BEGIN_SRC sh
    #!/bin/bash
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_standard
    #SBATCH --nodes=4
    #SBATCH --ntasks-per-node=36
    #SBATCH --time=1:00
    module purge
    module load tools/python/3.7 mpi/intel/2019-Update5
    srun python intro.py
  #+END_SRC
- test:
  #+NAME: sh-test-script
  #+BEGIN_SRC sh :shebang "#!/bin/bash"
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_test
    #SBATCH --nodes=1
    hostname
  #+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow :noweb yes
  sbatch <<sh-test-script>>
#+END_SRC

  #+BEGIN_SRC sh :session org-ssh :noweb yes :tangle yes
    sbatch <<sh-test-script>>
  #+END_SRC

  #+RESULTS:
  |                                                   |
  | sbatch: error: Unable to open file sh-test-script |

Note: t

**** Note: do it like for jupyter: srun a bash script, then execute mlflow
*** Reading the docs: mlflow
- searched for papers, found [[http://sites.computer.org/debull/A18dec/A18DEC-CD.pdf#page=41][two]] [[https://mlsys.org/Conferences/2019/doc/2019/demo_33.pdf][papers]], but they don't seem very exhaustive.
- took notes [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*<2020-04-16 Do 12:57> =mlflow=][here]]
- shall I keep MLflow files in a folder inside the =data/exp#= folder for each
  experiment or do a central =data/mlflow= folder? → I tend towards the second
  option. MLflow has an environment variable =MLFLOW_EXPERIMENT_NAME= which
  would be the same as =exp#=.
- Inside the folder, should I use "normal" files or a database for saving stuff?
  → I tend towards normal files, since I have no experiments with databases..
- MLflow Tracking Service API might be useful for accessing the results from
  inside org documents.

*** Reading Barredo Arrieta et al: Explainable Artificial Intelligence (XIA)
*** Set up git on HPC
    :LOGBOOK:
    CLOCK: [2020-04-24 Fr 14:35]--[2020-04-24 Fr 17:53] =>  3:18
    CLOCK: [2020-04-24 Fr 13:53]--[2020-04-24 Fr 14:15] =>  0:22
    :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
  git clone https://github.com/aseltmann/fluotracify
#+END_SRC

Wanted to git pull my repository on HPC, noticed that it already exists - and
has uncommited changes. Have to sort that out.

Git runs now on HPC, but had to resolve merge conflicts in code → used *Magit*
and especially Ediff. Watched these resources:
- https://www.youtube.com/watch?v=9S2pMZ6U5Tc&t=715s - short resource on smerge
  and ediff
- https://www.youtube.com/watch?v=j-k-lkilbEs - nice intro to magit in general

*** run mlflow test
**** Use a local tmux session:

#+BEGIN_SRC tmux :session local
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ pwd
  /home/lex
#+end_example

#+BEGIN_SRC tmux :session local
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_EXPERIMENT_ID=0.1
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow run .
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run .
  Specify only one of 'experiment-name' or 'experiment-id' options.
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local2
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  mlflow run /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run /home/lex/Programme/drmed-git/
  2020/04/28 01:17:01 INFO mlflow.projects: === Created directory /tmp/tmp_goyesz7
   for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/28 01:17:01 INFO mlflow.projects: === Running command 'source /home/lex/
  Programme/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114
  b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/tra
  in.py 5 0.2 16384 1e-5 10' in run with ID 'c0f7e64fdda64801860e9805948db29d' ===

  /home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709
  c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_interna
  l.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib
  ; see the module's documentation for alternative uses
    import imp
  2.1.0
  train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set003.csv
  train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set002.csv
  test 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tra
  ces_brightclust_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted time
  steps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-28 01:17:15.293658: I tensorflow/core/platform/cpu_feature_guard.cc:142]
   Your CPU supports instructions that this TensorFlow binary was not compiled to
  use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-28 01:17:15.340845: I tensorflow/core/platform/profile_utils/cpu_utils.c
  c:94] CPU Frequency: 2400500000 Hz
  2020-04-28 01:17:15.342222: I tensorflow/compiler/xla/service/service.cc:168] XL
  A service 0x5654fb291850 initialized for platform Host (this does not guarantee
  that XLA will be used). Devices:
  2020-04-28 01:17:15.342284: I tensorflow/compiler/xla/service/service.cc:176]
  StreamExecutor device (0): Host, Default Version
  2020-04-28 01:17:15.344811: I tensorflow/core/common_runtime/process_util.cc:147
  ] Creating new thread pool with default inter op setting: 2. Tune using inter_op
  _parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 65, in <module>
      with mlflow.start_run():
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 122, in
   start_run
      active_run_obj = MlflowClient().get_run(existing_run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 96, in
  get_run
      return self._tracking_client.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client
  .py", line 49, in get_run
      return self.store.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 423, in get_run
      run_info = self._get_run_info(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 442, in _get_run_info
      databricks_pb2.RESOURCE_DOES_NOT_EXIST)
  mlflow.exceptions.MlflowException: Run 'c0f7e64fdda64801860e9805948db29d' not fo
  und
  Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7fb42c4
  f4440>
  Traceback (most recent call last):
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_
  ops.py", line 3462, in __del__
  AttributeError: 'NoneType' object has no attribute 'device'
  2020/04/28 01:17:16 ERROR mlflow.cli: === Run (ID 'c0f7e64fdda64801860e9805948db
  29d') failed ===
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

**** use remote tmux
#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+RESULTS:
| Permission                           | denied,   | please | try    | again. |          |          |      |                |            |                |    |           |
| ye53nis@ara-login01.rz.uni-jena.de's | password: |        |        |        |          |          |      |                |            |                |    |           |
| Last                                 | failed    | login: | Tue    | Apr    |       28 | 11:05:11 | CEST |           2020 | from       | 10.231.181.150 | on | ssh:notty |
| There                                | was       | 1      | failed | login  |  attempt |    since | the  |           last | successful |         login. |    |           |
| Last                                 | login:    | Tue    | Apr    | 28     | 10:57:34 |     2020 | from | 10.231.181.150 |            |                |    |           |

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    26 | mix   | node[005-006,008,014,018,025-026,029,031,039,043,046,063-064,070-071,085-086,108,110,120,126,132,134-136]                                                                                                         |
| b_standard* | up    | 8-08:00:00 |    96 | alloc | node[002-004,009-013,015-017,019-024,027-028,030,032-037,040-042,045,047-062,065,067-068,072-082,084,087-107,109,111-116,119,121-125,131]                                                                         |
| b_standard* | up    | 8-08:00:00 |     9 | idle  | node[007,038,044,066,069,083,117-118,133]                                                                                                                                                                         |
| gpu_test    | up    |    1:00:00 |     1 | mix   | node127                                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | mix   | node130                                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     2 | mix   | node[139-140]                                                                                                                                                                                                     |
| b_fat       | up    | 8-08:00:00 |     2 | alloc | node[137-138]                                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | alloc | node141                                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    50 | mix   | node[146,151,155,157,162-163,167,169,177,183,186,191,196-200,203,219,224-231,233,235,239,241-246,249,255,257,259-260,265-268,297,303,309-310,315]                                                                 |
| s_standard  | up    | 8-08:00:00 |    97 | alloc | node[142-145,147-150,154,156,158-161,164-166,168,170-176,178-182,184-185,187-190,192-195,201-202,204-218,220-223,232,234,236-238,240,247-248,250-254,256,258,261-264,293-296,298-301,304-305,307-308,311-314,316] |
| s_standard  | up    | 8-08:00:00 |     4 | idle  | node[152-153,302,306]                                                                                                                                                                                             |
| s_fat       | up    | 8-08:00:00 |     4 | alloc | node[269-272]                                                                                                                                                                                                     |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    srun -p b_standard --time=7-08:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
: server version is too old for client

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC emacs-lisp
  (setq org-babel-tmux-location "/usr/local/bin/tmux")
#+END_SRC

#+RESULTS:
: /usr/local/bin/tmux


#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load tools/python/3.7
  module load module-git
  mlflow --version
  git --version
  cd drmed-git
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow --version
  git --version
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  mlflow, version 1.7.0
  [ye53nis@node007 ~]$ git --version
  git version 1.8.3.1
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . --no-conda
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow run . --no-conda
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  2020/04/29 13:31:21 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/04/30 17:56:53 INFO mlflow.projects: === Creating conda environment mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 ===
  Collecting package metadata (repodata.json): done
  Solving environment: done

  Downloading and Extracting Packages
  gorilla-0.3.0        | 11 KB     | ################################################################################################################################################################### | 100%
  pyasn1-0.4.8         | 58 KB     | ################################################################################################################################################################### | 100%
  mako-1.1.2           | 63 KB     | ################################################################################################################################################################### | 100%
  flask-1.1.2          | 74 KB     | ################################################################################################################################################################### | 100%
  tensorboard-2.1.0    | 3.3 MB    | ################################################################################################################################################################### | 100%
  google-auth-1.13.1   | 57 KB     | ################################################################################################################################################################### | 100%
  tensorflow-estimator | 251 KB    | ################################################################################################################################################################### | 100%
  ncurses-6.2          | 817 KB    | ################################################################################################################################################################### | 100%
  intel-openmp-2020.0  | 756 KB    | ################################################################################################################################################################### | 100%
  cloudpickle-1.4.0    | 29 KB     | ################################################################################################################################################################### | 100%
  mlflow-1.8.0         | 3.2 MB    | ################################################################################################################################################################### | 100%
  databricks-cli-0.9.1 | 48 KB     | ################################################################################################################################################################### | 100%
  mkl-service-2.3.0    | 218 KB    | ################################################################################################################################################################### | 100%
  markupsafe-1.1.1     | 29 KB     | ################################################################################################################################################################### | 100%
  libstdcxx-ng-9.1.0   | 3.1 MB    | ################################################################################################################################################################### | 100%
  prometheus_client-0. | 42 KB     | ################################################################################################################################################################### | 100%
  appdirs-1.4.3        | 15 KB     | ################################################################################################################################################################### | 100%
  libprotobuf-3.11.4   | 2.9 MB    | ################################################################################################################################################################### | 100%
  protobuf-3.11.4      | 636 KB    | ################################################################################################################################################################### | 100%
  tensorflow-2.1.0     | 4 KB      | ################################################################################################################################################################### | 100%
  configparser-3.7.4   | 43 KB     | ################################################################################################################################################################### | 100%
  opt_einsum-3.1.0     | 54 KB     | ################################################################################################################################################################### | 100%
  oauthlib-3.1.0       | 88 KB     | ################################################################################################################################################################### | 100%
  python-dateutil-2.8. | 224 KB    | ################################################################################################################################################################### | 100%
  werkzeug-1.0.1       | 240 KB    | ################################################################################################################################################################### | 100%
  tabulate-0.8.3       | 39 KB     | ################################################################################################################################################################### | 100%
  jinja2-2.11.2        | 103 KB    | ################################################################################################################################################################### | 100%
  c-ares-1.15.0        | 89 KB     | ################################################################################################################################################################### | 100%
  requests-oauthlib-1. | 22 KB     | ################################################################################################################################################################### | 100%
  docker-pycreds-0.4.0 | 14 KB     | ################################################################################################################################################################### | 100%
  packaging-20.3       | 36 KB     | ################################################################################################################################################################### | 100%
  keras-preprocessing- | 36 KB     | ################################################################################################################################################################### | 100%
  itsdangerous-1.1.0   | 28 KB     | ################################################################################################################################################################### | 100%
  mkl-2020.0           | 128.9 MB  | ################################################################################################################################################################### | 100%
  keras-applications-1 | 33 KB     | ################################################################################################################################################################### | 100%
  scipy-1.4.1          | 14.5 MB   | ################################################################################################################################################################### | 100%
  blinker-1.4          | 22 KB     | ################################################################################################################################################################### | 100%
  google-auth-oauthlib | 20 KB     | ################################################################################################################################################################### | 100%
  wrapt-1.12.1         | 49 KB     | ################################################################################################################################################################### | 100%
  click-7.1.1          | 71 KB     | ################################################################################################################################################################### | 100%
  h5py-2.10.0          | 1.0 MB    | ################################################################################################################################################################### | 100%
  rsa-4.0              | 29 KB     | ################################################################################################################################################################### | 100%
  pyjwt-1.7.1          | 33 KB     | ################################################################################################################################################################### | 100%
  pyasn1-modules-0.2.7 | 63 KB     | ################################################################################################################################################################### | 100%
  google-pasta-0.2.0   | 44 KB     | ################################################################################################################################################################### | 100%
  mkl_fft-1.0.15       | 154 KB    | ################################################################################################################################################################### | 100%
  alembic-1.4.2        | 117 KB    | ################################################################################################################################################################### | 100%
  backports-1.0        | 139 KB    | ################################################################################################################################################################### | 100%
  entrypoints-0.3      | 12 KB     | ################################################################################################################################################################### | 100%
  pyyaml-5.3.1         | 181 KB    | ################################################################################################################################################################### | 100%
  querystring_parser-1 | 10 KB     | ################################################################################################################################################################### | 100%
  prometheus_flask_exp | 15 KB     | ################################################################################################################################################################### | 100%
  cachetools-3.1.1     | 14 KB     | ################################################################################################################################################################### | 100%
  smmap-3.0.2          | 26 KB     | ################################################################################################################################################################### | 100%
  simplejson-3.17.0    | 101 KB    | ################################################################################################################################################################### | 100%
  pyparsing-2.4.6      | 64 KB     | ################################################################################################################################################################### | 100%
  pytz-2019.3          | 231 KB    | ################################################################################################################################################################### | 100%
  sqlalchemy-1.3.13    | 1.4 MB    | ################################################################################################################################################################### | 100%
  absl-py-0.9.0        | 167 KB    | ################################################################################################################################################################### | 100%
  numpy-base-1.18.1    | 4.2 MB    | ################################################################################################################################################################### | 100%
  mkl_random-1.1.0     | 321 KB    | ################################################################################################################################################################### | 100%
  python-editor-1.0.4  | 11 KB     | ################################################################################################################################################################### | 100%
  gunicorn-20.0.4      | 123 KB    | ################################################################################################################################################################### | 100%
  tensorflow-base-2.1. | 95.2 MB   | ################################################################################################################################################################### | 100%
  markdown-3.1.1       | 118 KB    | ################################################################################################################################################################### | 100%
  astor-0.8.0          | 46 KB     | ################################################################################################################################################################### | 100%
  grpcio-1.27.2        | 1.3 MB    | ################################################################################################################################################################### | 100%
  sqlparse-0.3.1       | 34 KB     | ################################################################################################################################################################### | 100%
  gitdb-4.0.2          | 49 KB     | ################################################################################################################################################################### | 100%
  pandas-1.0.3         | 8.6 MB    | ################################################################################################################################################################### | 100%
  docker-py-4.2.0      | 188 KB    | ################################################################################################################################################################### | 100%
  websocket-client-0.5 | 62 KB     | ################################################################################################################################################################### | 100%
  numpy-1.18.1         | 5 KB      | ################################################################################################################################################################### | 100%
  gitpython-3.1.1      | 328 KB    | ################################################################################################################################################################### | 100%
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/04/30 18:00:02 INFO mlflow.projects: === Created directory /tmp/tmpbcxyzo3m for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/30 18:00:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /home/ye53nis/drmed-git/src 5
  0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '09b669bd51ba4317a6ba4db833a3abb1' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  /home/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-30 18:00:19.551555: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-30 18:00:19.563688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-04-30 18:00:19.566795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b0cba23c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-04-30 18:00:19.566832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-04-30 18:00:19.567000: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='09b669bd51ba4317a6ba4db833a3abb1'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-04-30 18:00:46.639927: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6587 - mean_io_u: 0.4028 - precision: 0.2306 - recall: 0.7511 - val_loss: 1.5574 - val_mean_io_u: 0.3914 - val_precision: 0.1894 - val_recall:
   0.6051
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.6133 - mean_io_u: 0.4082 - precision: 0.2488 - recall: 0.7948/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.6116152, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588262662579). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 107s 3s/step - loss: 1.6042 - mean_io_u: 0.4055 - precision: 0.2566 - recall: 0.7927 - val_loss: 1.6116 - val_mean_io_u: 0.4122 - val_precision: 0.1641 - val_recall:
   0.8504
  Epoch 3/10
  32/32 [==============================] - 107s 3s/step - loss: 1.5036 - mean_io_u: 0.3934 - precision: 0.3298 - recall: 0.8165 - val_loss: 1.6282 - val_mean_io_u: 0.4021 - val_precision: 0.1870 - val_recall:
   0.9343
  Epoch 4/10
  32/32 [==============================] - 105s 3s/step - loss: 1.4783 - mean_io_u: 0.4014 - precision: 0.3343 - recall: 0.8179 - val_loss: 1.6338 - val_mean_io_u: 0.3861 - val_precision: 0.2262 - val_recall:
   0.9908
  Epoch 5/10
  32/32 [==============================] - 106s 3s/step - loss: 1.4398 - mean_io_u: 0.4006 - precision: 0.3735 - recall: 0.8220 - val_loss: 1.7444 - val_mean_io_u: 0.4101 - val_precision: 0.1798 - val_recall:
   0.9999
  Epoch 6/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3941 - mean_io_u: 0.3988 - precision: 0.4144 - recall: 0.8005 - val_loss: 1.8832 - val_mean_io_u: 0.4179 - val_precision: 0.1642 - val_recall:
   0.9999
  Epoch 7/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3660 - mean_io_u: 0.4000 - precision: 0.4544 - recall: 0.8108 - val_loss: 2.0017 - val_mean_io_u: 0.3885 - val_precision: 0.2230 - val_recall:
   0.9999
  Epoch 8/10
  32/32 [==============================] - 106s 3s/step - loss: 1.3169 - mean_io_u: 0.3993 - precision: 0.5203 - recall: 0.8057 - val_loss: 2.5556 - val_mean_io_u: 0.4147 - val_precision: 0.1706 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3050 - mean_io_u: 0.4047 - precision: 0.5429 - recall: 0.8009 - val_loss: 3.0439 - val_mean_io_u: 0.3991 - val_precision: 0.2017 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2911 - mean_io_u: 0.4098 - precision: 0.5691 - recall: 0.7966 - val_loss: 3.6402 - val_mean_io_u: 0.3934 - val_precision: 0.2132 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 843ms/step - loss: 3.5632 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-04-30 18:19:28.557139: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/04/30 18:19:46 INFO mlflow.projects: === Run (ID '09b669bd51ba4317a6ba4db833a3abb1') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Success!!!
** Find solution for large file problem
   :LOGBOOK:
   CLOCK: [2020-05-02 Sa 13:17]--[2020-05-02 Sa 13:43] =>  0:26
   :END:
*** using =git-lfs=
    :LOGBOOK:
    CLOCK: [2020-05-02 Sa 14:41]--[2020-05-02 Sa 16:13] =>  1:32
    :END:
Problem: the deep network =unet.tf= is too big (>300MB) and github only allows a
maximum file size of 100MB. Two possible solutions:
- *Git Large File Storage*: https://git-lfs.github.com/ replace large files with text pointers inside
  Git. Configured with a =.gitattributes= file per project. Git commands stay
  the same
- *Git-annex*: https://git-annex.branchable.com/ own git annex command line
  tool. "stupid filename and metadata tracker".
- See [[file:~/Dokumente/org/04_Digital-und-Technik/software-setup.org::*=git-annex= vs =git-lfs=][here]] for notes

NOTE: *git commands should not be done on compute node, it's easier on login
node via normal ssh*

#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+BEGIN_SRC sh :session org-ssh :results output
  pwd
  git status
#+END_SRC

#+RESULTS:
#+begin_example
/home/ye53nis/drmed-git
# On branch develop
Your branch is ahead of 'origin/develop' by 1 commit.
(use "git push" to publish your local commits)

Untracked files:
(use "git add <file>..." to include in what will be committed)

data/exp-devtest/
nothing added to commit but untracked files present (use "git add" to track)
#+end_example

Encountered problem: git-lfs only syncs files *inside* the repo. The advised way
to save large files on the HPC is to use the dedicated =/beegfs= file system,
which is optimised for that stuff. My current repo is in =/home=
- version 1: migrate git repo to beegfs - effectively abandoning =/home=
- version 2: stay at =/home= and keep track of =/beegfs= using tools like
  =git-annex=

I am trying version 1 now
*** run mlflow model as above, but save everything on =/beegfs=
    :LOGBOOK:
    CLOCK: [2020-05-02 Sa 16:13]--[2020-05-02 Sa 16:15] =>  0:02
    :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ pwd
  /home/ye53nis/drmed-git
  [ye53nis@node007 drmed-git]$ cd /beegfs/ye53nis/drmed-git/
  [ye53nis@node007 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ git status
  # On branch develop
  nothing to commit, working directory clean
  [ye53nis@node007 drmed-git]$ git log -1
  commit 9e6182fbeae831a151342827efa59581e4310ae6
  Author: Alex Seltmann <seltmann@posteo.de>
  Date:   Sat May 2 13:23:42 2020 +0200

      first successful mlflow run without trained net
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  2020/05/02 14:47:02 INFO mlflow.projects: === Created directory /tmp/tmp7uyf926z for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/02 14:47:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src
  5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'cda4eec66a6947c38ec2ee2006563ae5' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  ^[[B^[[B^[[B^[[B^[[B^[[B2.1.0
  /beegfs/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a41791e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-02 14:48:28.731100: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6869 - mean_io_u: 0.4035 - precision: 0.1949 - recall: 0.6740 - val_loss: 1.5778 - val_mean_io_u: 0.4210 - val_precision: 0.1500 - val_recall:
   5.7965e-05
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.5936 - mean_io_u: 0.4047 - precision: 0.2461 - recall: 0.7594/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588423924159). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 106s 3s/step - loss: 1.5935 - mean_io_u: 0.4051 - precision: 0.2456 - recall: 0.7601 - val_loss: 1.5412 - val_mean_io_u: 0.3977 - val_precision: 0.3000 - val_recall:
   8.9508e-05
  Epoch 3/10
  32/32 [==============================] - 108s 3s/step - loss: 1.5357 - mean_io_u: 0.4039 - precision: 0.2901 - recall: 0.8025 - val_loss: 1.5201 - val_mean_io_u: 0.3834 - val_precision: 0.2500 - val_recall:
   6.5409e-05
  Epoch 4/10
  32/32 [==============================] - 109s 3s/step - loss: 1.4929 - mean_io_u: 0.4041 - precision: 0.3227 - recall: 0.8099 - val_loss: 1.5400 - val_mean_io_u: 0.3990 - val_precision: 0.2011 - val_recall:
   0.0535
  Epoch 5/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4589 - mean_io_u: 0.4054 - precision: 0.3445 - recall: 0.7970 - val_loss: 1.5471 - val_mean_io_u: 0.3927 - val_precision: 0.2178 - val_recall:
   0.3854
  Epoch 6/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4293 - mean_io_u: 0.4059 - precision: 0.3692 - recall: 0.7784 - val_loss: 1.6078 - val_mean_io_u: 0.4057 - val_precision: 0.1891 - val_recall:
   0.9730
  Epoch 7/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3821 - mean_io_u: 0.4005 - precision: 0.4276 - recall: 0.7645 - val_loss: 1.7784 - val_mean_io_u: 0.4182 - val_precision: 0.1636 - val_recall:
   0.9998
  Epoch 8/10
  32/32 [==============================] - 109s 3s/step - loss: 1.3219 - mean_io_u: 0.3993 - precision: 0.5042 - recall: 0.8182 - val_loss: 1.9800 - val_mean_io_u: 0.3925 - val_precision: 0.2150 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2852 - mean_io_u: 0.3930 - precision: 0.5602 - recall: 0.7957 - val_loss: 2.5127 - val_mean_io_u: 0.4206 - val_precision: 0.1587 - val_recall:
   1.0000
  Epoch 10/10
  32/32 [==============================] - 108s 3s/step - loss: 1.2926 - mean_io_u: 0.4057 - precision: 0.5469 - recall: 0.8147 - val_loss: 2.9090 - val_mean_io_u: 0.3916 - val_precision: 0.2169 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 865ms/step - loss: 2.9045 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/05/02 15:07:38 INFO mlflow.projects: === Run (ID 'cda4eec66a6947c38ec2ee2006563ae5') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Comparison to run at =/home=:
- some "misformed experiment" warning. Probably bc I tried to rebase the repo on
  the remote, because I committed the big =unet.tf= folder and wanted to redo
  that (it seemed that failed and my first test run got lost)
- same conda env got loaded, and the run seems to have conducted without
  problems, jippieh!

*** checking out mlflow error messages [/]
    :LOGBOOK:
    CLOCK: [2020-05-02 Sa 16:15]--[2020-05-02 Sa 18:06] =>  1:51
    :END:

**** TODO tensorflow: your CPU supports instructions that this TF binary was not compiled to use

#+begin_example
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142]
    Your CPU supports instructions that this TensorFlow binary was not
    compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94]
    CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168]
    XLA service 0x563a41791e20 initialized for platform Host (this does not
    guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]
    StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147]
    Creating new thread pool with default inter op setting: 2.
    Tune using inter_op_parallelism_threads for best performance.

  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319]
    Sets are not currently considered sequences, but this may change in the future,
    so consider avoiding using them.
#+end_example

See [[https://github.com/tensorflow/tensorflow/issues/34369][this Github issue]]: the second part of the error is related to the first one,
and thus can be ignored (or solved following one of the paths below)

See [[https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u][here]]: It's only an issue if you run the code on a CPU!

The mentioned SSE, AVX, FMA etc are extensions from Intel and AMD to
speed up linear algebra computation, e.g. dot-product, matrix multiply,
convolution, etc. AVX and FMA speed them up on a CPU up to 300%. The warning
states that the CPU does support them, but =tensorflow= does not with the
default installation.

If you have a GPU:
- don't care about AVX etc support, because running on a GPU is way better
- you can ignore this warning by:
  #+BEGIN_SRC python
    # Just disables the warning, doesn't enable AVX/FMA
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
  #+END_SRC
  or
  #+BEGIN_SRC sh
    export TF_CPP_MIN_LOG_LEVEL=2
  #+END_SRC

If you don't have a GPU / don't want to use it:
- default tensorflow is intended to be compatible with as many CPUs as possible,
  that's why these libraries are note preinstalled
- *build tensorflow from the source optimized for /your/ CPU* - that's quite
  some additional work... if I should do this, here is TF [[https://www.tensorflow.org/install/source][guide]]
***** TODO Run this code on a GPU node, then decide. Maybe use docker to easily use TF on the nodes
**** TODO mlflow: ABCs from 'collections'

  #+begin_example
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389:
      DeprecationWarning: Using or importing the ABCs from 'collections' instead of from
      'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
      if isinstance(sample_weight_mode, collections.Mapping):
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60:
      DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0,
      use inspect.signature() or inspect.getfullargspec()
  #+end_example

I suspect these will be solved with an =mlflow= update.

**** TODO calling BaseResourceVariable.__init__

#+begin_example
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786:
      calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops)
      with constraint is deprecated and will be removed in a future version.
      Instructions for updating:
      If using Keras pass *_constraint arguments to layers.
    WARNING:tensorflow:Model failed to serialize as JSON.
      Ignoring... Layers with arguments in `__init__` must override `get_config`.

    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552:
      UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` must override `get_config`.
      try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
#+end_example

The =BaseResourceVariable= one seems to be connected to keras' SavedModel
 format and happens in the [[https://www.tensorflow.org/tutorials/keras/save_and_load][official TF keras tutorial]] when using
=model.save('saved_model/my_model')=.

I am still not settled on how to save models anyway. I think I will use
[[https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html#mlflow.tensorflow.save_model][mlflow.tensorflow.save_model()]] or =mlflow.tensorflow.log_model= (not sure what
the difference is). BUT this needs a /serialized/ collection of TF graphs and
variables. Maybe I have to do some more work, see below...

from [[https://www.tensorflow.org/guide/keras/save_and_serialize][TF keras guide]]:
- Saving the architecture (= layers and how these layers are connected) → model
  can be created with freshly initialized state for weights and no compilation
  info
  - Sequential model / functional API model: are explicit graphs of layers,
    config always available in a structured form.
    - =layer.get_config()= or =model.get_config()= will return Python dict
      containing the config of the model
    - Model can be reconstructed
      - Sequential model: =Sequential.from_config(config)=
      - Functional API model: =Model.from_config(config)=
  - Custom objects
    - Models and layers: In order to save/load a model with custom-defined
      layers, or a subclassed model, you should overwrite the =get_config= and
      optionally =from_config= methods. Additionally, you should use register
      the custom object so that Keras is aware of it.
    - Custom functions (e.g. activation loss...) do not need =get_config=,
      function name is sufficient for loading as long as it is registered as a
      custom object
    - defining =Get_config=: should return a JSON-serializable dict in order to
      be compatible with Keras architecture- and model-saving APIs
    - defining =from_config(config)=: should return a new layer or model object
      that is created from the config. Default implementation returns
      =cls(**config)=

See [[https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf][this SO question]]:
- an example for a class which makes =model.save= fail:
  #+BEGIN_SRC python
    class encoder(tf.keras.layers.Layer):

        def __init__(
            self,
            vocab_size, num_layers, units, d_model, num_heads, dropout,
            **kwargs,
        ):
            super().__init__(**kwargs)
            self.vocab_size = vocab_size
            self.num_layers = num_layers
            self.units = units
            self.d_model = d_model
            self.num_heads = num_heads
            self.dropout = dropout

        # Other methods etc.
  #+END_SRC
- and now you need to override this method:
  #+BEGIN_SRC python
        def get_config(self):

            config = super().get_config().copy()
            config.update({
                'vocab_size': self.vocab_size,
                'num_layers': self.num_layers,
                'units': self.units,
                'd_model': self.d_model,
                'num_heads': self.num_heads,
                'dropout': self.dropout,
            })
            return config
  #+END_SRC
- and for =layer.from_config=:
  #+BEGIN_SRC python
        @classmethod
        def from_config(cls, config):
            return cls(**config)
  #+END_SRC
**** TODO Logging to MLflow failed: Changing param values is not allowed

#+BEGIN_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70:
    UserWarning: Logging to MLflow failed:
    Changing param values is not allowed.
    Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'.
    Attempted logging new value 'None'.
  try_mlflow_log(mlflow.log_params, defaults)
#+END_example

Couldn't find anything googling that. Probably has something to do with naming
the variable =batch_size=, which may be a variable the autologging feature
already uses?

**** TODO invalid value tf.Tensor(..., dtype=float32). Please specify value as a valid double

#+begin_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:549:
    UserWarning: Logging to MLflow failed:
    Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss'
    (timestamp=1588423924159). Please specify value as a valid double (64-bit floating point)
  try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
#+end_example

Check out if val_loss got logged in the end. → doesn't seem so. It can be found
under =artifacts/tensorboard_logs= and these are not text files, but some binary
files.

In theory, validation loss and training loss should be logged by mlflow as well
(and custom metrics as well) → check that they are a valid 64-bit integer value.


** TODOs
**** TODO Investigate Error on GPU node
- 2020-04-13 02:45:28.216446: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open
  shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217069: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6:
  cannot open shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217123: W
  tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some
  TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please
  make sure the missing libraries mentioned above are installed properly
**** TODO Export pandas DataFrames as org tables instead of html
- see https://github.com/dzop/emacs-jupyter/issues/88
- see
  https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks
**** TODO Inline-display of plots
**** TODO fix pydot and graphviz to make model plotting work
**** TODO transform ML training ipynb to py files as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
**** TODO check out python module =argparser= as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
*** TODO [#A] Further setup of git branching model
*** PENDING Fix isort and sys.path conflicts
    - State "PENDING"    from "TODO"       [2020-05-02 Sa 13:06] \\
      Waiting for isort 5.0.0 release
See here: https://github.com/timothycrosley/isort/issues/468#issuecomment-570899233
*** TODO Implement talos 1.0 with mlflow, see [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*Querying runs programmatically][here]]
*** TODO [#C] Set up nice package using cookiecutter, poetry, See [[https://stackoverflow.com/questions/49474575/how-to-install-my-own-python-module-package-via-conda-and-watch-its-changes][here]]
* Reconnect
#+CALL: setup-tmux[:session local]

#+RESULTS:
| sh-5.0$                              | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |        |
| Permission                           | denied,                              | please    | try | again. |
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |     |        |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |        |

#+CALL: jpt-tunnel(port="8889", node="node018")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |    |          |      |      |             |
| ye53nis@node018's | password:                            |           |     |    |          |      |      |             |
| Last              | login:                               | Sat       | Apr | 25 | 13:40:36 | 2020 | from | login01.ara |

#+CALL: jupyter-python-metadata(conda_list='False)


#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
#+end_example
