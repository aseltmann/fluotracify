#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:3
#+HTML_HEAD_EXTRA: <style type="text/css">.example {background-color: #FBFBBF;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-emacs-lisp {background-color: #F7ECFB;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-sh {background-color: #F0FBE9;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-tmux {background-color: #E1EED8;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-python {background-color: #E6EDF4;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-jupyter-python {background-color: #FAEAE1;}</style>

* README
** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks. It also contains notes taken
     during the process of setting up this workflow for reproducible research.
   - This file contains explanations of how things are organized, of the
     workflow for doing experiments, changes made to the code, and the observed
     behavior in the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Therefore: if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch of the repository. The /master/ branch is clean from any results, it
     contains only source code and the analysis.
   - This project is my take on [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]]. The idea was postulated in
     a blog post in 2006:
     #+BEGIN_QUOTE
     ... there is a URL to a laboratory notebook that is freely available and
     indexed on common search engines. It does not necessarily have to look like
     a paper notebook but it is essential that all of the information available
     to the researchers to make their conclusions is equally available to the
     rest of the world ---Jean-Claude Bradley
     #+END_QUOTE
   - Proposal on how to deal with truly private data (e.g. notes from a
     confidential meeting with a colleague), which might otherwise be noted in a
     normal Lab notebook: do not include them here. Only notes relevant to the
     current project should be taken
** Code block languages used in this document

   #+BEGIN_SRC sh
     # This is a sh block for shell / bash scripting. In the context of this file,
     # these blocks are mainly used for operations on my local computer.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light green colour (#F0FBE9)
   #+END_SRC

   #+BEGIN_SRC tmux
     # This block can open and access tmux sessions, used for shell scripting on
     # remote computing clusters.
     # In the LabBook.html rendering of this document, these blocks will have a
     # distinct light green colour (#E1EED8)
   #+END_SRC

   #+BEGIN_SRC python
     # This is a python block. In the context of this file, it is seldomly used
     # (only for examplary scripts.)
     # In the LabBook.html rendering of this document, these blocks will have a
     # light blue colour (#E6EDF4)
   #+END_SRC

   #+BEGIN_SRC jupyter-python :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
     # This is a jupyter-python block. The code is sent to a jupyter kernel running
     # on a remote high performance computing cluster. Most of my jupyter code is
     # executed this way.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light orange colour (#FAEAE1)
   #+END_SRC

   #+BEGIN_SRC emacs-lisp
     ;; This is a emacs-lisp block, the language used to customize Emacs, which is
     ;; sometimes necessary, since the reproducible workflow of this LabBook is
     ;; tightly integrated with Emacs and org-mode.
     ;; In the LabBook.html rendering of this document, these blocks will have a
     ;; light violet colour (#F7ECFB)
   #+END_SRC

   #+begin_example
     This is a literal example block. It can be used very flexibly - in the context
     of this document the output of most code blocks is displayed this way.
     In the LabBook.html rendering of this document, these blocks will have a light
     yellow colour (#FBFBBF)
   #+end_example

** Experiments workflow:
   1) Create a new branch from =master=
   2) Print out the git log from the latest commit and the metadata
   3) Call the analysis scripts, follow the principles outlined in
      [[* Organization of code]]
   4) All machine learning runs are saved in =data/mlruns=, all other data in
      =data/#experiment-name=
   5) Add a "** #experiment-name" section to this file under [[* Data]]
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote =data= branch
** Example for experimental setup procedure

*** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

** tools used (notes)
*** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
*** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
*** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
*** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

* Template for data entry and setup notes:
** exp-#date-#title
*** git:

    #+begin_src sh
    git log -1
    #+end_src

*** System Metadata:

    #+NAME: jp-metadata
    #+BEGIN_SRC jupyter-python :var _long="true"
      import os
      import pprint

      ramlist = os.popen('free -th').readlines()[-1].split()[1:]

      print('No of CPUs in system:', os.cpu_count())
      print('No of CPUs the current process can use:',
            len(os.sched_getaffinity(0)))
      print('load average:', os.getloadavg())
      print('os.uname(): ', os.uname())
      print('PID of process:', os.getpid())
      print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
          ramlist[0], ramlist[1], ramlist[2]))

      !echo the current directory: $PWD
      !echo My disk usage:
      !df -h
      if _long:
          !conda list
          pprint.pprint(dict(os.environ), sort_dicts=False)

    #+END_SRC

*** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:

    #+NAME: setup-tmux
    #+BEGIN_SRC sh :session local
    rm ~/.tmux-local-socket-remote-machine
    REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
    echo $REMOTE_SOCKET
    ssh ara -tfN \
        -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
    #+END_SRC

    #+RESULTS: setup-tmux
    | rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
    | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
    | /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
    | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

*** SSH tunneling
    :PROPERTIES:
    :CUSTOM_ID: ssh-tunneling
    :END:

    Different applications can be run on the remote compute node. If I want to
    access them at the local machine, and open them with the browser, I use this
    tunneling script.

    #+NAME: ssh-tunnel
    #+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
    ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
    #+END_SRC

    Apps I use that way:
    - Jupyter lab for running Python 3-Kernels
    - TensorBoard
    - Mlflow ui

*** jupyter scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-jp
    :END:

    Starting a jupyter instance on a server where the necessary libraries are
    installed is easy using this script:

    #+NAME: jpt-tmux
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
    conda activate tensorflow_nightly
    export PORT=8889
    export XDG_RUNTIME_DIR=''
    export XDG_RUNTIME_DIR=""
    jupyter lab --no-browser --port=$PORT
    #+END_SRC

    On the compute node of the HPC, the users' environment is managed through
    module files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements
    are needed because of a jupyter bug which did not let it start. Right now,
    =ob-tmux= does not support a =:var= header like normal =org-babel= does. So
    the =$port= variable has to be set here in the template.

    Now this port has to be tunnelled on our local computer (See
    [[#ssh-tunneling]]). While the tmux session above keeps running, no matter if
    Emacs is running or not, this following ssh tunnel needs to be active
    locally to connect to the notebook. If you close Emacs, it would need to be
    reestablished (see [[* Reconnect]])

** Setup notes
*** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

*** =emacs-jupyter= Setup

    =Emacs-jupyter= aims to be an API for a lot of functionalities of the
    =jupyter= project. The documentation can be found on [[https://github.com/dzop/emacs-jupyter][GitHub]].

    1. For the *whole document*: connect ot a running jupyter instance
       1. =M-x jupyter-server-list-kernels=
          1. set server URL, e.g. =http://localhost:8889=
          2. set websocket URL, e.g. =http://localhost:8889=
       2. two possibilities
          1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
          2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
             *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    2. In the *subtree* where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. customize the output folder using the following org-mode variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/plots
    3. For each *individual block*, the following customizations might be useful
       1. jupyter kernels can return multiple kinds of rich output (images,
          html, ...) or scalar data (plain text, numbers, lists, ...). To force
          a plain output, use =:results scalar=
       2. to change the priority of different rich outputs, use =:display=
          header argument, e.g. =:display text/plain text/html= prioritizes
          plain text over html. All supported mimetypes in default order:
          1. text/org
          2. image/svg+xml, image/jpeg, image/png
          3. text/html
          4. text/markdown
          5. text/latex
          6. text/plain
       3. We can set jupyter to output pandas DataFrames as org tables
          automatically using the source block header argument =:pandoc t=
       4. useful keybindings
          - =M-i= to open the documentation for wherever your pointer is (like
            pressing =Shift-TAB= in Jupyter notebooks)
          - =C-c C-i= to interrupt the kernel, =C-c C-r= to restart the kernel

* Organization of git
** remote/origin/master branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *master* in an *#experiment-name* branch, ### meaning some meaningful
    descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/#experiment-name**, except
    machine learning-specific data and metadata from `mlflow` runs, which are
    saved under **data/mlruns** (this allows easily comparing machine learning
    runs with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *#experiment-name* branches are merged here. Afterwards the original
    branch is deleted and on the data branch there is a *Git tag* which shows
    the merge commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

** Git TAGs
*** Stable versions:
*** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
* Organization of code
** scripts:
** src/
*** fluotracify/
**** imports/
**** simulations/
**** training/
**** applications/
**** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

*** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

* Changes in this repository (without "* Data" in this file)
** Changes in LabBook.org (without "* Data")
*** 2020-05-31
    - extend general documentation in README
    - Add code block examples
    - extend documentation on experiment workflow
    - move setup notes from README to "Template for data entry and setup notes"
    - remove emacs-lisp code for custom tmux block functions (not relevant
      enough)
    - change named "jpt-tmux" from starting a jupyter notebook to starting
      jupyter lab. Load a conda environment instead of using Lmod's =module
      load=
*** 2020-05-07
    - extend documentation on git model
    - extend documentation on jupyter setup
*** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
*** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
** Changes in src/fluotracify
* Data
** exp-310520-unet

*** Connect

**** Tmux on Ara
#+CALL: setup-tmux[:session local]

#+RESULTS:
| sh-5.0$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
| >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

Test:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
#+END_SRC

**** Compute node for script execution
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node171 drmed-git]$
#+end_example

**** Jupyter on Ara
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:749074c4-797a-4e72-957c-f87331800ef8
   :END:

1. Request compute node via tmux
   #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
     srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
   #+END_SRC
2.
#+CALL: jpt-tmux[:session jpmux]

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ jupyter lab --no-browser --port=$PORT
  [I 21:44:33.348 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tensorflow_nightly/lib/python3.8/site-packages/jupyterlab
  [I 21:44:33.348 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tensorflow_nightly/share/jupyter/lab
  [I 21:44:33.353 LabApp] Serving notebooks from local directory: /beegfs/ye53nis/drmed-git
  [I 21:44:33.353 LabApp] The Jupyter Notebook is running at:
  [I 21:44:33.353 LabApp] http://localhost:8889/?token=baceda81f9f1b1ef453aef855e00bc58c338ac8f2efcbf00
  [I 21:44:33.353 LabApp]  or http://127.0.0.1:8889/?token=baceda81f9f1b1ef453aef855e00bc58c338ac8f2efcbf00
  [I 21:44:33.353 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
  [C 21:44:33.668 LabApp]

      To access the notebook, open this file in a browser:
          file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-442384-open.html
      Or copy and paste one of these URLs:
          http://localhost:8889/?token=baceda81f9f1b1ef453aef855e00bc58c338ac8f2efcbf00
       or http://127.0.0.1:8889/?token=baceda81f9f1b1ef453aef855e00bc58c338ac8f2efcbf00
#+end_example

#+CALL: ssh-tunnel(port="8889", node="node146")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |    |          |      |      |             |
| ye53nis@node146's | password:                            |           |     |    |          |      |      |             |
| Last              | login:                               | Mon       | May | 25 | 13:42:48 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           749074c4-797a-4e72-957c-f87331800ef8   a few seconds ago    starting   0
#+end_example

Test:

#+CALL: jp-metadata(_long='True)

#+RESULTS:
#+begin_example
  No of CPUs in system: 72
  No of CPUs the current process can use: 24
  load average: (43.52, 43.44, 43.4)
  os.uname():  posix.uname_result(sysname='Linux', nodename='node171', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 143415
  RAM total: 199G, RAM used: 37G, RAM free: 62G
  the current directory: /home/ye53nis
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  3.2G   47G   7% /
  devtmpfs              94G     0   94G   0% /dev
  tmpfs                 94G  751M   94G   1% /dev/shm
  tmpfs                 94G  219M   94G   1% /run
  tmpfs                 94G     0   94G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs02-ib:/data01      88T   60T   29T  68% /data01
  nfs03-ib:/pool/work  100T   79T   22T  79% /nfsdata
  nfs01-ib:/home        80T   59T   22T  74% /home
  /dev/sda5            2.0G   83M  2.0G   5% /tmp
  /dev/sda3            6.0G  402M  5.6G   7% /var
  /dev/sda6            169G   57M  169G   1% /local
  beegfs_nodev         524T  442T   83T  85% /beegfs
  tmpfs                 19G     0   19G   0% /run/user/68191
  tmpfs                 19G     0   19G   0% /run/user/67339
  /bin/sh: conda: command not found
  {'SLURM_CHECKPOINT_IMAGE_DIR': '/var/slurm/checkpoint',
   'SLURM_NODELIST': 'node171',
   'SLURM_JOB_NAME': 'bash',
   'XDG_SESSION_ID': '8541',
   'SLURMD_NODENAME': 'node171',
   'SLURM_TOPOLOGY_ADDR': 'node171',
   'SLURM_NTASKS_PER_NODE': '24',
   'HOSTNAME': 'login01',
   'SLURM_PRIO_PROCESS': '0',
   'SLURM_SRUN_COMM_PORT': '45585',
   'SHELL': '/bin/bash',
   'TERM': 'xterm-color',
   'SLURM_JOB_QOS': 'qstand',
   'SLURM_PTY_WIN_ROW': '24',
   'HISTSIZE': '1000',
   'TMPDIR': '/tmp',
   'SLURM_TOPOLOGY_ADDR_PATTERN': 'node',
   'SSH_CLIENT': '10.231.190.186 48592 22',
   'CONDA_SHLVL': '2',
   'CONDA_PROMPT_MODIFIER': '(tensorflow_nightly) ',
   'GSETTINGS_SCHEMA_DIR_CONDA_BACKUP': '',
   'WINDOWID': '0',
   'QTDIR': '/usr/lib64/qt-3.3',
   'QTINC': '/usr/lib64/qt-3.3/include',
   'SSH_TTY': '/dev/pts/57',
   'QT_GRAPHICSSYSTEM_CHECKED': '1',
   'SLURM_NNODES': '1',
   'USER': 'ye53nis',
   'http_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
   'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',
   'CONDA_EXE': '/cluster/miniconda3/bin/conda',
   'SLURM_STEP_NUM_NODES': '1',
   'SLURM_JOBID': '386457',
   'SRUN_DEBUG': '3',
   'SLURM_NTASKS': '24',
   'SLURM_LAUNCH_NODE_IPADDR': '192.168.192.5',
   'SLURM_STEP_ID': '0',
   'TMUX': '/tmp/tmux-67339/default,47311,2',
   '_CE_CONDA': '',
   'CONDA_PREFIX_1': '/cluster/miniconda3',
   'SLURM_STEP_LAUNCHER_PORT': '45585',
   'SLURM_TASKS_PER_NODE': '24',
   'MAIL': '/var/spool/mail/ye53nis',
   'PATH': '/home/ye53nis/.conda/envs/tensorflow_nightly/bin:/home/lex/Programme/miniconda3/envs/tensorflow_env/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/home/lex/Programme/miniconda3/bin:/usr/sbin:/home/ye53nis/.local/bin:/home/ye53nis/bin',
   'GSETTINGS_SCHEMA_DIR': '/home/ye53nis/.conda/envs/tensorflow_nightly/share/glib-2.0/schemas',
   'SLURM_WORKING_CLUSTER': 'hpc:192.168.192.1:6817:8448',
   'SLURM_JOB_ID': '386457',
   'CONDA_PREFIX': '/home/ye53nis/.conda/envs/tensorflow_nightly',
   'SLURM_JOB_USER': 'ye53nis',
   'SLURM_STEPID': '0',
   'PWD': '/home/ye53nis',
   'SLURM_SRUN_COMM_HOST': '192.168.192.5',
   'LANG': 'en_US.UTF-8',
   'SLURM_PTY_WIN_COL': '80',
   'SLURM_UMASK': '0022',
   'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles',
   'SLURM_JOB_UID': '67339',
   'LOADEDMODULES': '',
   'SLURM_NODEID': '0',
   'TMUX_PANE': '%2',
   'SLURM_SUBMIT_DIR': '/home/ye53nis',
   'SLURM_TASK_PID': '416264',
   'SLURM_NPROCS': '24',
   'SLURM_CPUS_ON_NODE': '24',
   'SLURM_DISTRIBUTION': 'block',
   'https_proxy': 'https://internet4nzm.rz.uni-jena.de:3128',
   'SLURM_PROCID': '0',
   'HISTCONTROL': 'ignoredups',
   '_CE_M': '',
   'SLURM_JOB_NODELIST': 'node171',
   'SLURM_PTY_PORT': '37693',
   'HOME': '/home/ye53nis',
   'SHLVL': '3',
   'SLURM_LOCALID': '0',
   'SLURM_JOB_GID': '13280',
   'SLURM_JOB_CPUS_PER_NODE': '24',
   'SLURM_CLUSTER_NAME': 'hpc',
   'SLURM_GTIDS': '0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23',
   'SLURM_SUBMIT_HOST': 'login01',
   'SLURM_JOB_PARTITION': 's_standard',
   'MATHEMATICA_HOME': '/cluster/apps/mathematica/11.3',
   'CONDA_PYTHON_EXE': '/cluster/miniconda3/bin/python',
   'LOGNAME': 'ye53nis',
   'SLURM_STEP_NUM_TASKS': '24',
   'QTLIB': '/usr/lib64/qt-3.3/lib',
   'SLURM_JOB_ACCOUNT': 'iaob',
   'SLURM_JOB_NUM_NODES': '1',
   'MODULESHOME': '/usr/share/Modules',
   'CONDA_DEFAULT_ENV': 'tensorflow_nightly',
   'LESSOPEN': '||/usr/bin/lesspipe.sh %s',
   'SLURM_STEP_TASKS_PER_NODE': '24',
   'PORT': '8889',
   'SLURM_STEP_NODELIST': 'node171',
   'DISPLAY': ':0',
   'XDG_RUNTIME_DIR': '',
   'XAUTHORITY': '/tmp/xauth-1000-_0',
   'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\n}',
   '_': '/home/ye53nis/.conda/envs/tensorflow_nightly/bin/jupyter',
   'KERNEL_LAUNCH_TIMEOUT': '40',
   'JPY_PARENT_PID': '417110',
   'CLICOLOR': '1',
   'PAGER': 'cat',
   'GIT_PAGER': 'cat',
   'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'}

  os.environ
   None
#+end_example
**** Tensorboard tunnel, Mlflow ui tunnel
#+CALL: ssh-tunnel[:session local](port="6006", node="node146")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |    |          |      |      |             |
| ye53nis@node146's | password:                            |           |     |    |          |      |      |             |
| Last              | login:                               | Mon       | May | 25 | 13:13:33 | 2020 | from | login01.ara |
*** git

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    git status
    git log -1
    #+END_SRC

    #+RESULTS:
    #+begin_example
    #+end_example
