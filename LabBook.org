#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:4
#+OPTIONS: H:4
#+HTML_HEAD_EXTRA: <style type="text/css">.example {background-color: #FBFBBF;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-emacs-lisp {background-color: #F7ECFB;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-sh {background-color: #F0FBE9;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-tmux {background-color: #E1EED8;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-python {background-color: #E6EDF4;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-jupyter-python {background-color: #FAEAE1;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details {padding: 1em; background-color: #f0f0f0; border-radius: 15px; color: hsl(157 75% 20%); font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em  #00000057;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details:hover {background:pink;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">table {display: block; overflow-x: auto; white-space: nowrap;}</style>


* Technical Notes
** README
*** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks. It also contains notes taken
     during the process of setting up this workflow for reproducible research.
   - This file contains explanations of how things are organized, of the
     workflow for doing experiments, changes made to the code, and the observed
     behavior in the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Therefore: if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch of the repository. The /main/ branch is clean from any results, it
     contains only source code and the analysis.
   - This project is my take on [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]]. The idea was postulated in
     a blog post in 2006:
     #+BEGIN_QUOTE
     ... there is a URL to a laboratory notebook that is freely available and
     indexed on common search engines. It does not necessarily have to look like
     a paper notebook but it is essential that all of the information available
     to the researchers to make their conclusions is equally available to the
     rest of the world ---Jean-Claude Bradley
     #+END_QUOTE
   - Proposal on how to deal with truly private data (e.g. notes from a
     confidential meeting with a colleague), which might otherwise be noted in a
     normal Lab notebook: do not include them here. Only notes relevant to the
     current project should be taken
*** Code block languages used in this document

   #+BEGIN_SRC sh
     # This is a sh block for shell / bash scripting. In the context of this file,
     # these blocks are mainly used for operations on my local computer.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light green colour (#F0FBE9)
   #+END_SRC

   #+BEGIN_SRC tmux
     # This block can open and access tmux sessions, used for shell scripting on
     # remote computing clusters.
     # In the LabBook.html rendering of this document, these blocks will have a
     # distinct light green colour (#E1EED8)
   #+END_SRC

   #+BEGIN_SRC python
     # This is a python block. In the context of this file, it is seldomly used
     # (only for examplary scripts.)
     # In the LabBook.html rendering of this document, these blocks will have a
     # light blue colour (#E6EDF4)
   #+END_SRC

   #+BEGIN_SRC jupyter-python :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
     # This is a jupyter-python block. The code is sent to a jupyter kernel running
     # on a remote high performance computing cluster. Most of my jupyter code is
     # executed this way.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light orange colour (#FAEAE1)
   #+END_SRC

   #+BEGIN_SRC emacs-lisp
     ;; This is a emacs-lisp block, the language used to customize Emacs, which is
     ;; sometimes necessary, since the reproducible workflow of this LabBook is
     ;; tightly integrated with Emacs and org-mode.
     ;; In the LabBook.html rendering of this document, these blocks will have a
     ;; light violet colour (#F7ECFB)
   #+END_SRC

   #+begin_example
     This is a literal example block. It can be used very flexibly - in the context
     of this document the output of most code blocks is displayed this way.
     In the LabBook.html rendering of this document, these blocks will have a light
     yellow colour (#FBFBBF)
   #+end_example

   #+begin_details
   #+begin_example
     This is a literal example block enclosed in a details block. This is useful to
     make the page more readable by collapsing large amounts of output.
     In the Labbook.html rendering of this document, the details block will have a
     light grey colour (#f0f0f0) and a pink color when hovering above it.
   #+end_example
   #+end_details

*** Experiments workflow:
   1) Create a new branch from =main=
   2) Print out the git log from the latest commit and the metadata
   3) Call the analysis scripts, follow the principles outlined in
      [[* Organization of code]]
   4) All machine learning runs are saved in =data/mlruns=, all other data in
      =data/#experiment-name=
   5) Add a ~** exp-<date>-<name>~" section to this file under [[* Data]]
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote =data= branch
*** Example for experimental setup procedure

**** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

*** tools used (notes)
**** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
**** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
**** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
**** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

** Template for data entry and setup notes:
*** exp-#date-#title
**** git:

    #+begin_src sh
    git log -1
    #+end_src

**** System Metadata:

    #+NAME: jp-metadata
    #+BEGIN_SRC jupyter-python :var _long="true"
      import os
      import pprint

      ramlist = os.popen('free -th').readlines()[-1].split()[1:]

      print('No of CPUs in system:', os.cpu_count())
      print('No of CPUs the current process can use:',
            len(os.sched_getaffinity(0)))
      print('load average:', os.getloadavg())
      print('os.uname(): ', os.uname())
      print('PID of process:', os.getpid())
      print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
          ramlist[0], ramlist[1], ramlist[2]))

      !echo the current directory: $PWD
      !echo My disk usage:
      !df -h
      if _long:
          %conda list
          pprint.pprint(dict(os.environ), sort_dicts=False)

    #+END_SRC

**** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:

    #+NAME: setup-tmux
    #+BEGIN_SRC sh :session local
    rm ~/.tmux-local-socket-remote-machine
    REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
    echo $REMOTE_SOCKET
    ssh ara -tfN \
        -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
    #+END_SRC

    #+RESULTS: setup-tmux
    | rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
    | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
    | /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
    | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

**** SSH tunneling
    :PROPERTIES:
    :CUSTOM_ID: ssh-tunneling
    :END:

    Different applications can be run on the remote compute node. If I want to
    access them at the local machine, and open them with the browser, I use this
    tunneling script.

    #+NAME: ssh-tunnel
    #+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
    ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
    #+END_SRC

    Apps I use that way:
    - Jupyter lab for running Python 3-Kernels
    - TensorBoard
    - Mlflow ui

**** jupyter scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-jp
    :END:

    Starting a jupyter instance on a server where the necessary libraries are
    installed is easy using this script:

    #+NAME: jpt-tmux
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
    conda activate tf
    export PORT=8889
    export XDG_RUNTIME_DIR=''
    export XDG_RUNTIME_DIR=""
    jupyter lab --no-browser --port=$PORT
    #+END_SRC

    On the compute node of the HPC, the users' environment is managed through
    module files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements
    are needed because of a jupyter bug which did not let it start. Right now,
    =ob-tmux= does not support a =:var= header like normal =org-babel= does. So
    the =$port= variable has to be set here in the template.

    Now this port has to be tunnelled on our local computer (See
    [[#ssh-tunneling]]). While the tmux session above keeps running, no matter if
    Emacs is running or not, this following ssh tunnel needs to be active
    locally to connect to the notebook. If you close Emacs, it would need to be
    reestablished

*** Setup notes
**** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

**** =emacs-jupyter= Setup

    =Emacs-jupyter= aims to be an API for a lot of functionalities of the
    =jupyter= project. The documentation can be found on [[https://github.com/dzop/emacs-jupyter][GitHub]].

    1. For the *whole document*: connect to a running jupyter instance
       1. =M-x jupyter-server-list-kernels=
          1. set server URL, e.g. =http://localhost:8889=
          2. set websocket URL, e.g. =http://localhost:8889=
       2. two possibilities
          1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
          2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
             *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    2. In the *subtree* where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. customize the output folder using the following org-mode variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/plots
    3. For each *individual block*, the following customizations might be useful
       1. jupyter kernels can return multiple kinds of rich output (images,
          html, ...) or scalar data (plain text, numbers, lists, ...). To force
          a plain output, use =:results scalar=. To show the output in the
          minibuffer only, use =:results silent=
       2. to change the priority of different rich outputs, use =:display=
          header argument, e.g. =:display text/plain text/html= prioritizes
          plain text over html. All supported mimetypes in default order:
          1. text/org
          2. image/svg+xml, image/jpeg, image/png
          3. text/html
          4. text/markdown
          5. text/latex
          6. text/plain
       3. We can set jupyter to output pandas DataFrames as org tables
          automatically using the source block header argument =:pandoc t=
       4. useful keybindings
          - =M-i= to open the documentation for wherever your pointer is (like
            pressing =Shift-TAB= in Jupyter notebooks)
          - =C-c C-i= to interrupt the kernel, =C-c C-r= to restart the kernel

*** Notes on archiving
**** Exporting the LabBook.org to html in a twbs style
     - I am partial to the twitter bootstrap theme of html, since I like it's
       simple design, but clear structure with a nice table of contents at the
       side → the following org mode extension supports a seemless export to
       twitter bootstrap html: https://github.com/marsmining/ox-twbs
     - when installed, the export can be triggered via the command
       =(org-twbs-export-as-html)= or via the keyboard shortcut for export =C-c
       C-e= followed by =w= for Twitter bootstrap and =h= for saving the .html
     - _Things to configure:_
       - in general, there are multiple export options:
         https://orgmode.org/manual/Export-Settings.html
       - E.g. I set 2 =#+OPTIONS= keywords at the begin of the file: =toc:4= and
         =H:4= which make sure that in my export my sidebar table of contents
         will show numbered headings till a depth of 4.
       - I configured my code blocks so that they will not be evaluated when
         exporting (I would recommend this especially if you only export for
         archiving) and that both the code block and the output will be exported
         with the keyword: =#+PROPERTY: header-args :eval never-export :exports
         both=
       - To discriminate between code blocks for different languages I gave each
         of them a distinct colour using =#+HTML_HEAD_EXTRA: <style...= (see
         above)
       - I had to configure a style for =table=, so that the
         - =display: block; overflow-x: auto;= gets the table to be restricted
           to the width of the text and if it is larger, activates scrolling
         - =white-space: nowrap;= makes it that there is no wrap in a column, so
           it might be broader, but better readable if you have scrolling anyway
     - _Things to do before exporting / Troubleshooting while exporting:_
       - when using a dark theme for you emacs, the export of the code blocks
         might show some ugly dark backgrounds from the theme. If this becomes
         an issue, change to a light theme for the export with =M-x
         (load-theme)= and choose =solarized-light=
       - only in the =data= branch you set the git tags after merging. If you
         want to show them here, execute the corresponding function in [[Git TAGs]]
       - make sure your file links work properly! I recommend referencing your
         files relatively (e.g. [ [ f ile:./data/exp-XXXXXX-test/test.png]]
         without spaces). Otherwise there will be errors in your /*Messages*/
         buffer
       - There might be errors with your code blocks
         - e.g. the export function expects you to assign a default variable to
           your functions
         - if you call a function via the =#+CALL= mechanism, it wants you to
           include two parentheses for the function, e.g. =#+CALL: test()=
       - check indentation of code blocks inside lists
       - add a =details= block around large output cells. This makes them
         expandable. I added some =#+HTML_HEAD_EXTRA: <style...= inspired by
         [[https://alhassy.github.io/org-special-block-extras/#Folded-Details][alhassy]]. That's how the =details= block looks like:
         #+begin_example
         #+begin_details

         #+end_details
         #+end_example
       - If you reference a parameter with an underscore in the name, use the
         org markdown tricks to style them like code (~==~ or =~~=), otherwise
         the part after the underscore will be rendered like a subscript:
         =under_score= vs under_score
     - _Things to do after exporting:_
       - In my workflow, the exported =LabBook.html= with the overview of all
         experiments is in the =data= folder. If you move the file, you will
         have to fix the file links for the new location, e.g. via "Find and
         replace" =M-%=:
         - if you move the org file → in the org file find =[[file:./data/= and
           replace with =[[file:./= → then export with =C-c C-e w h=
         - if you export first with =C-c C-e w h= and move the html file to
           =data= → in the html file find =./data= and replace with =.=
** Organization of git

*** remote/origin/main branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
*** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *main* in an *#experiment-name* branch, ### meaning some meaningful
    descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/#experiment-name**, except
    machine learning-specific data and metadata from `mlflow` runs, which are
    saved under **data/mlruns** (this allows easily comparing machine learning
    runs with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
*** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
*** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *#experiment-name* branches are merged here. Afterwards the original
    branch is deleted and on the data branch there is a *Git tag* which shows
    the merge commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

*** Git TAGs
**** Stable versions:
**** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
   : exp-200520-unet Merge branch 'exp-310520-unet' into data
   : exp-200531-unet Merge branch 'heads/exp-310520-unet' into data
   : exp-201231-clustsim exp-201231-clustsim
   : exp-210204-unet Add exp-210204-unet LabBook part 3
   : exp-310520-unet move exp-310520-unet to data branch manually
** Organization of code
*** scripts:
*** src/
**** fluotracify/
***** imports/
***** simulations/
***** training/
***** applications/
***** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

**** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

** Changes in this repository (without "* Data" in this file)
*** Changes in LabBook.org (without "* Data")
**** 2022-02-19
     - Add =#+HTML_HEAD_EXTRA: <style...= for =table= to enable scrolling if the
       table overflows
**** 2021-12-16
     - Add =details= blocks, corresponding =#+HTML_HEAD_EXTRA: <style...= and
       documentation in  [[Notes on archiving]]
**** 2021-08-05
     - Rename =master= branch to =main= branch
**** 2021-04-04
     - Add =#+OPTIONS: H:4= and =#+OPTIONS: toc:4= to show up to 4 levels of
       depth in the html (twbs) export of this LabBook in the table of contents
       at the side
     - I added [[Notes on archiving]]
**** 2020-11-04
    - update "jupyter scripts" in [[Template for data entry and setup notes:]]
      for new conda environment on server (now =conda activate tf-nightly=)
**** 2020-05-31
    - extend general documentation in README
    - Add code block examples
    - extend documentation on experiment workflow
    - move setup notes from README to "Template for data entry and setup notes"
    - remove emacs-lisp code for custom tmux block functions (not relevant
      enough)
    - change named "jpt-tmux" from starting a jupyter notebook to starting
      jupyter lab. Load a conda environment instead of using Lmod's =module
      load=
**** 2020-05-07
    - extend documentation on git model
    - extend documentation on jupyter setup
**** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
**** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
*** Changes in src/fluotracify

* Data
** exp-220227-unet

*** Setup: GPU node on HPC

    1. Setup tmux
       #+CALL: setup-tmux[:session local]

       #+RESULTS:
       | rm:                                         | cannot                                 | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
       | ye53nis@ara-login01.rz.uni-jena.de's        | password:                              |           |                                                |    |      |      |    |           |
       | /home/lex/.tmux-local-socket-remote-machine |                                        |           |                                                |    |      |      |    |           |
       | >                                           | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

    2. first, connect with the GPU node in the high performance cluster
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         cd /
         srun -p gpu_p100 --time=7-10:00:00 --ntasks-per-node=12 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (base) [ye53nis@node128 /]$
       #+end_example

    3. Load CUDA and cuDNN in the version compatible to your tensorflow library
       (see https://www.tensorflow.org/install/source#gpu)
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         module load nvidia/cuda/11.2
         module load nvidia/cudnn/8.1
         module list
       #+END_SRC

       #+RESULTS:
       #+begin_example
         Currently Loaded Modulefiles:
           1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
         (base) [ye53nis@node128 /]$
       #+end_example

    4. Branch out git branch =exp-210807-hparams= from =main= (done via magit)
       and make sure you are on the correct branch

       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         cd /beegfs/ye53nis/drmed-git
         git checkout exp-220227-unet
       #+END_SRC

       #+RESULTS:
       #+begin_example
         Checking out files: 100% (147/147), done.
         M       src/nanosimpy
         Branch exp-220227-unet set up to track remote branch exp-220227-unet from origin.
         Switched to a new branch 'exp-220227-unet'
         (base) [ye53nis@node128 drmed-git]$
       #+end_example

    7. load conda environment, define MLflow environment variables and create log directory
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         conda activate tf
         cd /beegfs/ye53nis/drmed-git
         export MLFLOW_EXPERIMENT_NAME=exp-220227-unet
         export MLFLOW_TRACKING_URI=file:./data/mlruns
         mkdir -p data/exp-220227-unet/jupyter
         mkdir ../tmp
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node128 drmed-git]$
       #+end_example

    8. set output directory for matplotlib plots in jupyter
       #+begin_src emacs-lisp
         (setq org-babel-jupyter-resource-directory "./data/exp-220227-unet/jupyter")
       #+end_src

       #+RESULTS:
       : ./data/exp-220227-unet/jupyter

*** Setup: Jupyter node on HPC
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3
    :END:
    1. Set up tmux (if we haven't done that before) (=#+CALL:
       setup-tmux[:session local]=)
       #+CALL: setup-tmux[:session local2]

       #+RESULTS:
       |         |                                        |           |
       | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
       | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    2. Request compute node
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
         cd /
         srun -p b_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
       #+END_SRC


    3. Start Jupyter Lab (~#+CALL: jpt-tmux[:session jpmux]~)
       #+CALL: jpt-tmux[:session jpmux]

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node005 /]$ jupyter lab --no-browser --port=$PORT
         [I 2023-01-18 11:33:10.992 ServerApp] jupyterlab | extension was successfully linked.
         [I 2023-01-18 11:33:20.469 ServerApp] nbclassic | extension was successfully linked.
         [I 2023-01-18 11:33:20.932 ServerApp] nbclassic | extension was successfully loaded.
         [I 2023-01-18 11:33:20.935 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/jupyterlab
         [I 2023-01-18 11:33:20.935 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf/share/jupyter/lab
         [I 2023-01-18 11:33:20.943 ServerApp] jupyterlab | extension was successfully loaded.
         [I 2023-01-18 11:33:20.945 ServerApp] Serving notebooks from local directory: /
         [I 2023-01-18 11:33:20.945 ServerApp] Jupyter Server 1.13.5 is running at:
         [I 2023-01-18 11:33:20.945 ServerApp] http://localhost:8889/lab?token=f8a5db2d00721ed0a736f6a6fc2a21020172913cc2337ec0
         [I 2023-01-18 11:33:20.945 ServerApp]  or http://127.0.0.1:8889/lab?token=f8a5db2d00721ed0a736f6a6fc2a21020172913cc2337ec0
         [I 2023-01-18 11:33:20.945 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
         [C 2023-01-18 11:33:21.003 ServerApp]

             To access the server, open this file in a browser:
                 file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-183673-open.html
             Or copy and paste one of these URLs:
                 http://localhost:8889/lab?token=f8a5db2d00721ed0a736f6a6fc2a21020172913cc2337ec0
              or http://127.0.0.1:8889/lab?token=f8a5db2d00721ed0a736f6a6fc2a21020172913cc2337ec0

       #+end_example

    4. Create SSH Tunnel for jupyter lab to the local computer (e.g. ~#+CALL:
       ssh-tunnel(port="8889", node="node160")~)
       #+CALL: ssh-tunnel(port="8889", node="node005")
       #+RESULTS:
       |                   |             |                                        |                         |         |    |     |      |    |       |          |
       | sh-5.1$           | sh-5.1$     | ye53nis@ara-login01.rz.uni-jena.de's | password:               |         |    |     |      |    |       |          |
       | Warning:          | Permanently | added                                  | 'node005,192.168.193.5' | (ECDSA) | to | the | list | of | known | hosts. |
       | ye53nis@node005's | password:   |                                        |                         |         |    |     |      |    |       |          |

    5. I started a Python3 kernel using =jupyter-server-list-kernels=. Then I
       added the kernel ID to the =:PROPERTIES:= drawer of this (and following)
       subtrees.
       #+begin_example
       python3           c4f3acce-60c4-489d-922c-407da110fd6a   a few seconds ago    idle       1
       #+end_example

    6. Test (~#+CALL: jp-metadata(_long='True)~) and record metadata:
       #+CALL: jp-metadata(_long='True)

       #+RESULTS:
       #+begin_example
         No of CPUs in system: 48
         No of CPUs the current process can use: 24
         load average: (24.2, 19.65, 11.23)
         os.uname():  posix.uname_result(sysname='Linux', nodename='node034', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
         PID of process: 102013
         RAM total: 137G, RAM used: 34G, RAM free: 64G
         the current directory: /
         My disk usage:
         Filesystem           Size  Used Avail Use% Mounted on
         /dev/sda1             50G  4.9G   46G  10% /
         devtmpfs              63G     0   63G   0% /dev
         tmpfs                 63G  707M   63G   2% /dev/shm
         tmpfs                 63G  107M   63G   1% /run
         tmpfs                 63G     0   63G   0% /sys/fs/cgroup
         nfs01-ib:/home        80T   71T  9.2T  89% /home
         nfs03-ib:/pool/work  100T   72T   29T  72% /nfsdata
         nfs01-ib:/cluster    2.0T  486G  1.6T  24% /cluster
         /dev/sda5            2.0G   34M  2.0G   2% /tmp
         /dev/sda6            169G  4.0G  165G   3% /local
         /dev/sda3            6.0G  438M  5.6G   8% /var
         beegfs_nodev         524T  441T   84T  85% /beegfs
         tmpfs                 13G     0   13G   0% /run/user/67339# packages in environment at /home/ye53nis/.conda/envs/tf:
         #
         # Name                    Version                   Build  Channel
         _libgcc_mutex             0.1                        main
         _openmp_mutex             5.1                       1_gnu
         absl-py                   1.0.0                    pypi_0    pypi
         alembic                   1.7.7                    pypi_0    pypi
         anyio                     3.5.0            py39h06a4308_0
         argon2-cffi               21.3.0             pyhd3eb1b0_0
         argon2-cffi-bindings      21.2.0           py39h7f8727e_0
         asteval                   0.9.26                   pypi_0    pypi
         asttokens                 2.0.5              pyhd3eb1b0_0
         astunparse                1.6.3                    pypi_0    pypi
         attrs                     21.4.0             pyhd3eb1b0_0
         babel                     2.9.1              pyhd3eb1b0_0
         backcall                  0.2.0              pyhd3eb1b0_0
         beautifulsoup4            4.11.1           py39h06a4308_0
         bleach                    4.1.0              pyhd3eb1b0_0
         brotlipy                  0.7.0           py39h27cfd23_1003
         ca-certificates           2022.4.26            h06a4308_0
         cachetools                5.1.0                    pypi_0    pypi
         certifi                   2021.10.8        py39h06a4308_2
         cffi                      1.15.0           py39hd667e15_1
         charset-normalizer        2.0.4              pyhd3eb1b0_0
         click                     8.1.3                    pypi_0    pypi
         cloudpickle               2.0.0                    pypi_0    pypi
         cryptography              37.0.1           py39h9ce1e76_0
         cycler                    0.11.0                   pypi_0    pypi
         cython                    0.29.30                  pypi_0    pypi
         databricks-cli            0.16.6                   pypi_0    pypi
         debugpy                   1.5.1            py39h295c915_0
         decorator                 5.1.1              pyhd3eb1b0_0
         defusedxml                0.7.1              pyhd3eb1b0_0
         docker                    5.0.3                    pypi_0    pypi
         entrypoints               0.4              py39h06a4308_0
         executing                 0.8.3              pyhd3eb1b0_0
         fcsfiles                  2022.2.2                 pypi_0    pypi
         flask                     2.1.2                    pypi_0    pypi
         flatbuffers               1.12                     pypi_0    pypi
         fonttools                 4.33.3                   pypi_0    pypi
         future                    0.18.2                   pypi_0    pypi
         gast                      0.4.0                    pypi_0    pypi
         gitdb                     4.0.9                    pypi_0    pypi
         gitpython                 3.1.27                   pypi_0    pypi
         google-auth               2.6.6                    pypi_0    pypi
         google-auth-oauthlib      0.4.6                    pypi_0    pypi
         google-pasta              0.2.0                    pypi_0    pypi
         greenlet                  1.1.2                    pypi_0    pypi
         grpcio                    1.46.1                   pypi_0    pypi
         gunicorn                  20.1.0                   pypi_0    pypi
         h5py                      3.6.0                    pypi_0    pypi
         idna                      3.3                pyhd3eb1b0_0
         importlib-metadata        4.11.3                   pypi_0    pypi
         ipykernel                 6.9.1            py39h06a4308_0
         ipython                   8.3.0            py39h06a4308_0
         ipython_genutils          0.2.0              pyhd3eb1b0_1
         itsdangerous              2.1.2                    pypi_0    pypi
         jedi                      0.18.1           py39h06a4308_1
         jinja2                    3.0.3              pyhd3eb1b0_0
         joblib                    1.1.0                    pypi_0    pypi
         json5                     0.9.6              pyhd3eb1b0_0
         jsonschema                4.4.0            py39h06a4308_0
         jupyter_client            7.2.2            py39h06a4308_0
         jupyter_core              4.10.0           py39h06a4308_0
         jupyter_server            1.13.5             pyhd3eb1b0_0
         jupyterlab                3.3.2              pyhd3eb1b0_0
         jupyterlab_pygments       0.1.2                      py_0
         jupyterlab_server         2.12.0           py39h06a4308_0
         keras                     2.9.0                    pypi_0    pypi
         keras-preprocessing       1.1.2                    pypi_0    pypi
         kiwisolver                1.4.2                    pypi_0    pypi
         ld_impl_linux-64          2.38                 h1181459_0
         libclang                  14.0.1                   pypi_0    pypi
         libffi                    3.3                  he6710b0_2
         libgcc-ng                 11.2.0               h1234567_0
         libgomp                   11.2.0               h1234567_0
         libsodium                 1.0.18               h7b6447c_0
         libstdcxx-ng              11.2.0               h1234567_0
         lmfit                     1.0.3                    pypi_0    pypi
         mako                      1.2.0                    pypi_0    pypi
         markdown                  3.3.7                    pypi_0    pypi
         markupsafe                2.0.1            py39h27cfd23_0
         matplotlib                3.5.2                    pypi_0    pypi
         matplotlib-inline         0.1.2              pyhd3eb1b0_2
         mistune                   0.8.4           py39h27cfd23_1000
         mlflow                    1.26.0                   pypi_0    pypi
         multipletau               0.3.3                    pypi_0    pypi
         nbclassic                 0.3.5              pyhd3eb1b0_0
         nbclient                  0.5.13           py39h06a4308_0
         nbconvert                 6.4.4            py39h06a4308_0
         nbformat                  5.3.0            py39h06a4308_0
         ncurses                   6.3                  h7f8727e_2
         nest-asyncio              1.5.5            py39h06a4308_0
         notebook                  6.4.11           py39h06a4308_0
         numpy                     1.22.3                   pypi_0    pypi
         oauthlib                  3.2.0                    pypi_0    pypi
         openssl                   1.1.1o               h7f8727e_0
         opt-einsum                3.3.0                    pypi_0    pypi
         packaging                 21.3               pyhd3eb1b0_0
         pandas                    1.4.2                    pypi_0    pypi
         pandocfilters             1.5.0              pyhd3eb1b0_0
         parso                     0.8.3              pyhd3eb1b0_0
         pexpect                   4.8.0              pyhd3eb1b0_3
         pickleshare               0.7.5           pyhd3eb1b0_1003
         pillow                    9.1.1                    pypi_0    pypi
         pip                       21.2.4           py39h06a4308_0
         prometheus-flask-exporter 0.20.1                   pypi_0    pypi
         prometheus_client         0.13.1             pyhd3eb1b0_0
         prompt-toolkit            3.0.20             pyhd3eb1b0_0
         protobuf                  3.20.1                   pypi_0    pypi
         ptyprocess                0.7.0              pyhd3eb1b0_2
         pure_eval                 0.2.2              pyhd3eb1b0_0
         pyasn1                    0.4.8                    pypi_0    pypi
         pyasn1-modules            0.2.8                    pypi_0    pypi
         pycparser                 2.21               pyhd3eb1b0_0
         pygments                  2.11.2             pyhd3eb1b0_0
         pyjwt                     2.4.0                    pypi_0    pypi
         pyopenssl                 22.0.0             pyhd3eb1b0_0
         pyparsing                 3.0.4              pyhd3eb1b0_0
         pyrsistent                0.18.0           py39heee7806_0
         pysocks                   1.7.1            py39h06a4308_0
         python                    3.9.12               h12debd9_0
         python-dateutil           2.8.2              pyhd3eb1b0_0
         python-fastjsonschema     2.15.1             pyhd3eb1b0_0
         pytz                      2021.3             pyhd3eb1b0_0
         pyyaml                    6.0                      pypi_0    pypi
         pyzmq                     22.3.0           py39h295c915_2
         querystring-parser        1.2.4                    pypi_0    pypi
         readline                  8.1.2                h7f8727e_1
         requests                  2.27.1             pyhd3eb1b0_0
         requests-oauthlib         1.3.1                    pypi_0    pypi
         rsa                       4.8                      pypi_0    pypi
         scikit-learn              1.1.0                    pypi_0    pypi
         scipy                     1.8.1                    pypi_0    pypi
         seaborn                   0.11.2                   pypi_0    pypi
         send2trash                1.8.0              pyhd3eb1b0_1
         setuptools                61.2.0           py39h06a4308_0
         six                       1.16.0             pyhd3eb1b0_1
         smmap                     5.0.0                    pypi_0    pypi
         sniffio                   1.2.0            py39h06a4308_1
         soupsieve                 2.3.1              pyhd3eb1b0_0
         sqlalchemy                1.4.36                   pypi_0    pypi
         sqlite                    3.38.3               hc218d9a_0
         sqlparse                  0.4.2                    pypi_0    pypi
         stack_data                0.2.0              pyhd3eb1b0_0
         tabulate                  0.8.9                    pypi_0    pypi
         tensorboard               2.9.0                    pypi_0    pypi
         tensorboard-data-server   0.6.1                    pypi_0    pypi
         tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
         tensorflow                2.9.0                    pypi_0    pypi
         tensorflow-estimator      2.9.0                    pypi_0    pypi
         tensorflow-io-gcs-filesystem 0.26.0                   pypi_0    pypi
         termcolor                 1.1.0                    pypi_0    pypi
         terminado                 0.13.1           py39h06a4308_0
         testpath                  0.5.0              pyhd3eb1b0_0
         threadpoolctl             3.1.0                    pypi_0    pypi
         tk                        8.6.11               h1ccaba5_1
         tornado                   6.1              py39h27cfd23_0
         traitlets                 5.1.1              pyhd3eb1b0_0
         typing-extensions         4.1.1                hd3eb1b0_0
         typing_extensions         4.1.1              pyh06a4308_0
         tzdata                    2022a                hda174b7_0
         uncertainties             3.1.6                    pypi_0    pypi
         urllib3                   1.26.9           py39h06a4308_0
         wcwidth                   0.2.5              pyhd3eb1b0_0
         webencodings              0.5.1            py39h06a4308_1
         websocket-client          0.58.0           py39h06a4308_4
         werkzeug                  2.1.2                    pypi_0    pypi
         wheel                     0.37.1             pyhd3eb1b0_0
         wrapt                     1.14.1                   pypi_0    pypi
         xz                        5.2.5                h7f8727e_1
         zeromq                    4.3.4                h2531618_0
         zipp                      3.8.0                    pypi_0    pypi
         zlib                      1.2.12               h7f8727e_2

         Note: you may need to restart the kernel to use updated packages.
         {'SLURM_CHECKPOINT_IMAGE_DIR': '/var/slurm/checkpoint',
          'SLURM_NODELIST': 'node034',
          'SLURM_JOB_NAME': 'bash',
          'XDG_SESSION_ID': '135386',
          'SLURMD_NODENAME': 'node034',
          'SLURM_TOPOLOGY_ADDR': 'node034',
          'SLURM_NTASKS_PER_NODE': '24',
          'HOSTNAME': 'login01',
          'SLURM_PRIO_PROCESS': '0',
          'SLURM_SRUN_COMM_PORT': '40968',
          'SHELL': '/bin/bash',
          'TERM': 'xterm-color',
          'SLURM_JOB_QOS': 'qstand',
          'SLURM_PTY_WIN_ROW': '48',
          'HISTSIZE': '1000',
          'TMPDIR': '/tmp',
          'SLURM_TOPOLOGY_ADDR_PATTERN': 'node',
          'SSH_CLIENT': '10.231.185.64 42170 22',
          'CONDA_SHLVL': '2',
          'CONDA_PROMPT_MODIFIER': '(tf) ',
          'WINDOWID': '0',
          'QTDIR': '/usr/lib64/qt-3.3',
          'QTINC': '/usr/lib64/qt-3.3/include',
          'SSH_TTY': '/dev/pts/19',
          'NO_PROXY': 'localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001',
          'QT_GRAPHICSSYSTEM_CHECKED': '1',
          'SLURM_NNODES': '1',
          'USER': 'ye53nis',
          'http_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',
          'CONDA_EXE': '/cluster/miniconda3/bin/conda',
          'SLURM_STEP_NUM_NODES': '1',
          'SLURM_JOBID': '1657237',
          'SRUN_DEBUG': '3',
          'FTP_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'ftp_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_NTASKS': '24',
          'SLURM_LAUNCH_NODE_IPADDR': '192.168.192.5',
          'SLURM_STEP_ID': '0',
          'TMUX': '/tmp/tmux-67339/default,14861,2',
          '_CE_CONDA': '',
          'CONDA_PREFIX_1': '/cluster/miniconda3',
          'SLURM_STEP_LAUNCHER_PORT': '40968',
          'SLURM_TASKS_PER_NODE': '24',
          'MAIL': '/var/spool/mail/ye53nis',
          'PATH': '/home/ye53nis/.conda/envs/tf/bin:/home/lex/Programme/miniconda3/envs/tf/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/home/lex/Programme/miniconda3/bin:/usr/sbin:/home/ye53nis/.local/bin:/home/ye53nis/bin',
          'SLURM_WORKING_CLUSTER': 'hpc:192.168.192.1:6817:8448',
          'SLURM_JOB_ID': '1657237',
          'CONDA_PREFIX': '/home/ye53nis/.conda/envs/tf',
          'SLURM_JOB_USER': 'ye53nis',
          'SLURM_STEPID': '0',
          'PWD': '/',
          'SLURM_SRUN_COMM_HOST': '192.168.192.5',
          'LANG': 'en_US.UTF-8',
          'SLURM_PTY_WIN_COL': '236',
          'SLURM_UMASK': '0022',
          'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles',
          'SLURM_JOB_UID': '67339',
          'LOADEDMODULES': '',
          'SLURM_NODEID': '0',
          'TMUX_PANE': '%2',
          'SLURM_SUBMIT_DIR': '/',
          'SLURM_TASK_PID': '100551',
          'SLURM_NPROCS': '24',
          'SLURM_CPUS_ON_NODE': '24',
          'SLURM_DISTRIBUTION': 'block',
          'HTTPS_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'https_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_PROCID': '0',
          'HISTCONTROL': 'ignoredups',
          '_CE_M': '',
          'SLURM_JOB_NODELIST': 'node034',
          'SLURM_PTY_PORT': '43329',
          'HOME': '/home/ye53nis',
          'SHLVL': '3',
          'SLURM_LOCALID': '0',
          'SLURM_JOB_GID': '13280',
          'SLURM_JOB_CPUS_PER_NODE': '24',
          'SLURM_CLUSTER_NAME': 'hpc',
          'no_proxy': 'localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001',
          'SLURM_GTIDS': '0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23',
          'SLURM_SUBMIT_HOST': 'login01',
          'HTTP_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_JOB_PARTITION': 'b_standard',
          'MATHEMATICA_HOME': '/cluster/apps/mathematica/12.3',
          'CONDA_PYTHON_EXE': '/cluster/miniconda3/bin/python',
          'LOGNAME': 'ye53nis',
          'SLURM_STEP_NUM_TASKS': '24',
          'QTLIB': '/usr/lib64/qt-3.3/lib',
          'SLURM_JOB_ACCOUNT': 'iaob',
          'SLURM_JOB_NUM_NODES': '1',
          'MODULESHOME': '/usr/share/Modules',
          'CONDA_DEFAULT_ENV': 'tf',
          'LESSOPEN': '||/usr/bin/lesspipe.sh %s',
          'SLURM_STEP_TASKS_PER_NODE': '24',
          'PORT': '8889',
          'SLURM_STEP_NODELIST': 'node034',
          'DISPLAY': ':0',
          'XDG_RUNTIME_DIR': '',
          'XAUTHORITY': '/home/lex/.Xauthority',
          'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\n}',
          '_': '/home/ye53nis/.conda/envs/tf/bin/jupyter',
          'PYDEVD_USE_FRAME_EVAL': 'NO',
          'JPY_PARENT_PID': '100629',
          'CLICOLOR': '1',
          'PAGER': 'cat',
          'GIT_PAGER': 'cat',
          'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}
       #+end_example
*** Setup: Jupyter on local computer
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
    :END:

   1. on our local machine we don't need tmux. A simple sh command is enough. So
      let's start the conda environment in the sh session =local= and start
      jupterlab there.
      #+begin_src sh :session local
        conda activate tf
        jupyter lab --no-browser --port=8888
      #+end_src

      #+begin_example
      [I 2022-05-22 14:24:33.496 ServerApp] jupyterlab | extension was successfully linked.
      [I 2022-05-22 14:24:33.745 ServerApp] nbclassic | extension was successfully linked.
      [I 2022-05-22 14:24:33.786 LabApp] JupyterLab extension loaded from /home/lex/Programme/miniconda3/envs/tf/lib/python3.9/site-packages/jupyterlab
      [I 2022-05-22 14:24:33.786 LabApp] JupyterLab application directory is /home/lex/Programme/miniconda3/envs/tf/share/jupyter/lab
      [I 2022-05-22 14:24:33.790 ServerApp] jupyterlab | extension was successfully loaded.
      [I 2022-05-22 14:24:33.799 ServerApp] nbclassic | extension was successfully loaded.
      [I 2022-05-22 14:24:33.800 ServerApp] Serving notebooks from local directory: /home/lex/Programme/drmed-git
      [I 2022-05-22 14:24:33.800 ServerApp] Jupyter Server 1.4.1 is running at:
      [I 2022-05-22 14:24:33.800 ServerApp] http://localhost:8888/lab?token=1d0362f7e2280b0060620c901abee258910e16c879bc0870
      [I 2022-05-22 14:24:33.800 ServerApp]  or http://127.0.0.1:8888/lab?token=1d0362f7e2280b0060620c901abee258910e16c879bc0870
      [I 2022-05-22 14:24:33.800 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
      [C 2022-05-22 14:24:33.804 ServerApp]

          To access the server, open this file in a browser:
              file:///home/lex/.local/share/jupyter/runtime/jpserver-1749996-open.html
          Or copy and paste one of these URLs:
              http://localhost:8888/lab?token=1d0362f7e2280b0060620c901abee258910e16c879bc0870
           or http://127.0.0.1:8888/lab?token=1d0362f7e2280b0060620c901abee258910e16c879bc0870

      #+end_example

   2. I started a Python3 kernel using =jupyter-server-list-kernels=. Then I
      added the kernel ID to the =:PROPERTIES:= drawer of this (and following)
      subtrees.

      #+begin_example
      python3           03038b73-b2b5-49ce-a1dc-21afb6247d0f   a few seconds ago    starting   0
      #+end_example

   3. Test: (~#+CALL: jp-metadata(_long='True)~)
      #+CALL: jp-metadata(_long='True)

      #+RESULTS:
      :RESULTS:
      #+begin_example
        No of CPUs in system: 4
        No of CPUs the current process can use: 4
        load average: (0.93115234375, 0.97216796875, 0.5595703125)
        os.uname():  posix.uname_result(sysname='Linux', nodename='Topialex', release='5.15.28-1-MANJARO', version='#1 SMP PREEMPT Fri Mar 11 14:12:57 UTC 2022', machine='x86_64')
        PID of process: 8991
        RAM total: 16Gi, RAM used: 1,8Gi, RAM free: 12Gi
        the current directory: /home/lex/Programme/drmed-git
        My disk usage:
        Filesystem      Size  Used Avail Use% Mounted on
        dev             3,9G     0  3,9G   0% /dev
        run             3,9G  1,5M  3,9G   1% /run
        /dev/sda2       167G  131G   28G  83% /
        tmpfs           3,9G   63M  3,8G   2% /dev/shm
        tmpfs           3,9G  4,2M  3,9G   1% /tmp
        /dev/sda1       300M  264K  300M   1% /boot/efi
        tmpfs           784M   80K  784M   1% /run/user/1000# packages in environment at /home/lex/Programme/miniconda3/envs/tf:
        #
        # Name                    Version                   Build  Channel
        _libgcc_mutex             0.1                        main
        _openmp_mutex             4.5                       1_gnu
        absl-py                   1.0.0                    pypi_0    pypi
        alembic                   1.4.1                    pypi_0    pypi
        anyio                     2.2.0            py39h06a4308_1
        argon2-cffi               20.1.0           py39h27cfd23_1
        asteval                   0.9.25                   pypi_0    pypi
        astroid                   2.9.2                    pypi_0    pypi
        astunparse                1.6.3                    pypi_0    pypi
        async_generator           1.10               pyhd3eb1b0_0
        attrs                     21.2.0             pyhd3eb1b0_0
        babel                     2.9.1              pyhd3eb1b0_0
        backcall                  0.2.0              pyhd3eb1b0_0
        bleach                    4.0.0              pyhd3eb1b0_0
        brotlipy                  0.7.0           py39h27cfd23_1003
        ca-certificates           2021.10.26           h06a4308_2
        cachetools                4.2.4                    pypi_0    pypi
        certifi                   2021.10.8        py39h06a4308_0
        cffi                      1.14.6           py39h400218f_0
        charset-normalizer        2.0.4              pyhd3eb1b0_0
        click                     8.0.3                    pypi_0    pypi
        cloudpickle               2.0.0                    pypi_0    pypi
        cryptography              36.0.0           py39h9ce1e76_0
        cycler                    0.11.0                   pypi_0    pypi
        cython                    0.29.26                  pypi_0    pypi
        databricks-cli            0.16.2                   pypi_0    pypi
        debugpy                   1.5.1            py39h295c915_0
        decorator                 5.1.0              pyhd3eb1b0_0
        defusedxml                0.7.1              pyhd3eb1b0_0
        docker                    5.0.3                    pypi_0    pypi
        entrypoints               0.3              py39h06a4308_0
        fcsfiles                  2021.6.6                 pypi_0    pypi
        flake8                    4.0.1                    pypi_0    pypi
        flask                     2.0.2                    pypi_0    pypi
        flatbuffers               2.0                      pypi_0    pypi
        focuspoint                0.1                      pypi_0    pypi
        fonttools                 4.28.5                   pypi_0    pypi
        future                    0.18.2                   pypi_0    pypi
        gast                      0.4.0                    pypi_0    pypi
        gitdb                     4.0.9                    pypi_0    pypi
        gitpython                 3.1.24                   pypi_0    pypi
        google-auth               2.3.3                    pypi_0    pypi
        google-auth-oauthlib      0.4.6                    pypi_0    pypi
        google-pasta              0.2.0                    pypi_0    pypi
        greenlet                  1.1.2                    pypi_0    pypi
        grpcio                    1.43.0                   pypi_0    pypi
        gunicorn                  20.1.0                   pypi_0    pypi
        h5py                      3.6.0                    pypi_0    pypi
        idna                      3.3                pyhd3eb1b0_0
        importlib-metadata        4.8.2            py39h06a4308_0
        importlib_metadata        4.8.2                hd3eb1b0_0
        ipykernel                 6.4.1            py39h06a4308_1
        ipython                   7.29.0           py39hb070fc8_0
        ipython_genutils          0.2.0              pyhd3eb1b0_1
        isort                     5.10.1                   pypi_0    pypi
        itsdangerous              2.0.1                    pypi_0    pypi
        jedi                      0.18.0           py39h06a4308_1
        jinja2                    3.0.2              pyhd3eb1b0_0
        joblib                    1.1.0                    pypi_0    pypi
        json5                     0.9.6              pyhd3eb1b0_0
        jsonschema                3.2.0              pyhd3eb1b0_2
        jupyter_client            7.1.0              pyhd3eb1b0_0
        jupyter_core              4.9.1            py39h06a4308_0
        jupyter_server            1.4.1            py39h06a4308_0
        jupyterlab                3.2.1              pyhd3eb1b0_1
        jupyterlab_pygments       0.1.2                      py_0
        jupyterlab_server         2.8.2              pyhd3eb1b0_0
        keras                     2.7.0                    pypi_0    pypi
        keras-preprocessing       1.1.2                    pypi_0    pypi
        kiwisolver                1.3.2                    pypi_0    pypi
        lazy-object-proxy         1.7.1                    pypi_0    pypi
        ld_impl_linux-64          2.35.1               h7274673_9
        libclang                  12.0.0                   pypi_0    pypi
        libffi                    3.3                  he6710b0_2
        libgcc-ng                 9.3.0               h5101ec6_17
        libgomp                   9.3.0               h5101ec6_17
        libsodium                 1.0.18               h7b6447c_0
        libstdcxx-ng              9.3.0               hd4cf53a_17
        lmfit                     1.0.3                    pypi_0    pypi
        mako                      1.1.6                    pypi_0    pypi
        markdown                  3.3.6                    pypi_0    pypi
        markupsafe                2.0.1            py39h27cfd23_0
        matplotlib                3.5.1                    pypi_0    pypi
        matplotlib-inline         0.1.2              pyhd3eb1b0_2
        mccabe                    0.6.1                    pypi_0    pypi
        mistune                   0.8.4           py39h27cfd23_1000
        mlflow                    1.22.0                   pypi_0    pypi
        multipletau               0.3.3                    pypi_0    pypi
        mypy                      0.930                    pypi_0    pypi
        mypy-extensions           0.4.3                    pypi_0    pypi
        nbclassic                 0.2.6              pyhd3eb1b0_0
        nbclient                  0.5.3              pyhd3eb1b0_0
        nbconvert                 6.1.0            py39h06a4308_0
        nbformat                  5.1.3              pyhd3eb1b0_0
        ncurses                   6.3                  h7f8727e_2
        nest-asyncio              1.5.1              pyhd3eb1b0_0
        nodeenv                   1.6.0                    pypi_0    pypi
        notebook                  6.4.6            py39h06a4308_0
        numpy                     1.21.5                   pypi_0    pypi
        oauthlib                  3.1.1                    pypi_0    pypi
        openssl                   1.1.1l               h7f8727e_0
        opt-einsum                3.3.0                    pypi_0    pypi
        packaging                 21.3               pyhd3eb1b0_0
        pandas                    1.3.5                    pypi_0    pypi
        pandocfilters             1.4.3            py39h06a4308_1
        parso                     0.8.2              pyhd3eb1b0_0
        pexpect                   4.8.0              pyhd3eb1b0_3
        pickleshare               0.7.5           pyhd3eb1b0_1003
        pillow                    8.4.0                    pypi_0    pypi
        pip                       21.2.4           py39h06a4308_0
        platformdirs              2.4.1                    pypi_0    pypi
        prometheus-flask-exporter 0.18.7                   pypi_0    pypi
        prometheus_client         0.12.0             pyhd3eb1b0_0
        prompt-toolkit            3.0.20             pyhd3eb1b0_0
        protobuf                  3.19.1                   pypi_0    pypi
        ptyprocess                0.7.0              pyhd3eb1b0_2
        pyasn1                    0.4.8                    pypi_0    pypi
        pyasn1-modules            0.2.8                    pypi_0    pypi
        pycodestyle               2.8.0                    pypi_0    pypi
        pycparser                 2.21               pyhd3eb1b0_0
        pydot                     1.4.2                    pypi_0    pypi
        pyflakes                  2.4.0                    pypi_0    pypi
        pygments                  2.10.0             pyhd3eb1b0_0
        pylint                    2.12.2                   pypi_0    pypi
        pyopenssl                 21.0.0             pyhd3eb1b0_1
        pyparsing                 3.0.4              pyhd3eb1b0_0
        pyright                   0.0.13                   pypi_0    pypi
        pyrsistent                0.18.0           py39heee7806_0
        pysocks                   1.7.1            py39h06a4308_0
        python                    3.9.7                h12debd9_1
        python-dateutil           2.8.2              pyhd3eb1b0_0
        python-editor             1.0.4                    pypi_0    pypi
        pytz                      2021.3             pyhd3eb1b0_0
        pyyaml                    6.0                      pypi_0    pypi
        pyzmq                     22.3.0           py39h295c915_2
        querystring-parser        1.2.4                    pypi_0    pypi
        readline                  8.1                  h27cfd23_0
        requests                  2.26.0             pyhd3eb1b0_0
        requests-oauthlib         1.3.0                    pypi_0    pypi
        rsa                       4.8                      pypi_0    pypi
        scikit-learn              1.0.2                    pypi_0    pypi
        scipy                     1.7.3                    pypi_0    pypi
        seaborn                   0.11.2                   pypi_0    pypi
        send2trash                1.8.0              pyhd3eb1b0_1
        setuptools                58.0.4           py39h06a4308_0
        six                       1.16.0             pyhd3eb1b0_0
        smmap                     5.0.0                    pypi_0    pypi
        sniffio                   1.2.0            py39h06a4308_1
        sqlalchemy                1.4.29                   pypi_0    pypi
        sqlite                    3.37.0               hc218d9a_0
        sqlparse                  0.4.2                    pypi_0    pypi
        tabulate                  0.8.9                    pypi_0    pypi
        tensorboard               2.7.0                    pypi_0    pypi
        tensorboard-data-server   0.6.1                    pypi_0    pypi
        tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
        tensorflow                2.7.0                    pypi_0    pypi
        tensorflow-estimator      2.7.0                    pypi_0    pypi
        tensorflow-io-gcs-filesystem 0.23.1                   pypi_0    pypi
        termcolor                 1.1.0                    pypi_0    pypi
        terminado                 0.9.4            py39h06a4308_0
        testpath                  0.5.0              pyhd3eb1b0_0
        threadpoolctl             3.0.0                    pypi_0    pypi
        tk                        8.6.11               h1ccaba5_0
        toml                      0.10.2                   pypi_0    pypi
        tomli                     2.0.0                    pypi_0    pypi
        tornado                   6.1              py39h27cfd23_0
        traitlets                 5.1.1              pyhd3eb1b0_0
        typing-extensions         4.0.1                    pypi_0    pypi
        tzdata                    2021e                hda174b7_0
        uncertainties             3.1.6                    pypi_0    pypi
        urllib3                   1.26.7             pyhd3eb1b0_0
        wcwidth                   0.2.5              pyhd3eb1b0_0
        webencodings              0.5.1            py39h06a4308_1
        websocket-client          1.2.3                    pypi_0    pypi
        werkzeug                  2.0.2                    pypi_0    pypi
        wheel                     0.37.0             pyhd3eb1b0_1
        wrapt                     1.13.3                   pypi_0    pypi
        xz                        5.2.5                h7b6447c_0
        zeromq                    4.3.4                h2531618_0
        zipp                      3.6.0              pyhd3eb1b0_0
        zlib                      1.2.11               h7f8727e_4

        Note: you may need to restart the kernel to use updated packages.
        {'SHELL': '/bin/bash',
         'SESSION_MANAGER': 'local/Topialex:@/tmp/.ICE-unix/878,unix/Topialex:/tmp/.ICE-unix/878',
         'XDG_CONFIG_DIRS': '/home/lex/.config/kdedefaults:/etc/xdg',
         'XDG_SESSION_PATH': '/org/freedesktop/DisplayManager/Session1',
         'CONDA_EXE': '/home/lex/Programme/miniconda3/bin/conda',
         '_CE_M': '',
         'LANGUAGE': 'en_GB',
         'TERMCAP': '',
         'LC_ADDRESS': 'de_DE.UTF-8',
         'LC_NAME': 'de_DE.UTF-8',
         'INSIDE_EMACS': '27.2,comint',
         'DESKTOP_SESSION': 'plasma',
         'LC_MONETARY': 'de_DE.UTF-8',
         'GTK_RC_FILES': '/etc/gtk/gtkrc:/home/lex/.gtkrc:/home/lex/.config/gtkrc',
         'XCURSOR_SIZE': '24',
         'GTK_MODULES': 'canberra-gtk-module',
         'XDG_SEAT': 'seat0',
         'PWD': '/home/lex/Programme/drmed-git',
         'LOGNAME': 'lex',
         'XDG_SESSION_DESKTOP': 'KDE',
         'XDG_SESSION_TYPE': 'x11',
         'CONDA_PREFIX': '/home/lex/Programme/miniconda3/envs/tf',
         'DSSI_PATH': '/home/lex/.dssi:/usr/lib/dssi:/usr/local/lib/dssi',
         'SYSTEMD_EXEC_PID': '768',
         'XAUTHORITY': '/home/lex/.Xauthority',
         'MOTD_SHOWN': 'pam',
         'GTK2_RC_FILES': '/etc/gtk-2.0/gtkrc:/home/lex/.gtkrc-2.0:/home/lex/.config/gtkrc-2.0',
         'HOME': '/home/lex',
         'LANG': 'de_DE.UTF-8',
         'LC_PAPER': 'de_DE.UTF-8',
         'VST_PATH': '/home/lex/.vst:/usr/lib/vst:/usr/local/lib/vst',
         'XDG_CURRENT_DESKTOP': 'KDE',
         'COLUMNS': '80',
         'CONDA_PROMPT_MODIFIER': '',
         'XDG_SEAT_PATH': '/org/freedesktop/DisplayManager/Seat0',
         'KDE_SESSION_UID': '1000',
         'XDG_SESSION_CLASS': 'user',
         'LC_IDENTIFICATION': 'de_DE.UTF-8',
         'TERM': 'xterm-color',
         '_CE_CONDA': '',
         'USER': 'lex',
         'CONDA_SHLVL': '1',
         'KDE_SESSION_VERSION': '5',
         'PAM_KWALLET5_LOGIN': '/run/user/1000/kwallet5.socket',
         'DISPLAY': ':0',
         'SHLVL': '2',
         'LC_TELEPHONE': 'de_DE.UTF-8',
         'LC_MEASUREMENT': 'de_DE.UTF-8',
         'XDG_VTNR': '1',
         'XDG_SESSION_ID': '2',
         'QT_LINUX_ACCESSIBILITY_ALWAYS_ON': '1',
         'CONDA_PYTHON_EXE': '/home/lex/Programme/miniconda3/bin/python',
         'MOZ_PLUGIN_PATH': '/usr/lib/mozilla/plugins',
         'XDG_RUNTIME_DIR': '/run/user/1000',
         'CONDA_DEFAULT_ENV': 'tf',
         'LC_TIME': 'de_DE.UTF-8',
         'QT_AUTO_SCREEN_SCALE_FACTOR': '0',
         'XCURSOR_THEME': 'breeze_cursors',
         'XDG_DATA_DIRS': '/home/lex/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share:/var/lib/snapd/desktop',
         'KDE_FULL_SESSION': 'true',
         'BROWSER': 'vivaldi-stable',
         'PATH': '/home/lex/Programme/miniconda3/envs/tf/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin',
         'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus',
         'LV2_PATH': '/home/lex/.lv2:/usr/lib/lv2:/usr/local/lib/lv2',
        'KDE_APPLICATIONS_AS_SCOPE': '1',
        'MAIL': '/var/spool/mail/lex',
        'LC_NUMERIC': 'de_DE.UTF-8',
        'LADSPA_PATH': '/home/lex/.ladspa:/usr/lib/ladspa:/usr/local/lib/ladspa',
        'CADENCE_AUTO_STARTED': 'true',
        '_': '/home/lex/Programme/miniconda3/envs/tf/bin/jupyter',
        'PYDEVD_USE_FRAME_EVAL': 'NO',
        'JPY_PARENT_PID': '8414',
        'CLICOLOR': '1',
        'PAGER': 'cat',
        'GIT_PAGER': 'cat',
        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}
      #+end_example
      : 5f083adb-6166-4a49-9fa5-08e37046cbfd
      :END:
*** Setup: Node for running Mlflow UI
     1. Create mlflow tmux session and start mlflow ui
        #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session mlflowui
          conda activate tf
          mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
        #+END_SRC

        #+RESULTS:
        #+begin_example
          (tf) [ye53nis@login01 ~]$ mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Starting gunicorn 20.1.0
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Listening at: http://127.0.0.1:5001 (5106)
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Using worker: sync
          [2021-08-08 14:47:33 +0200] [5115] [INFO] Booting worker with pid: 5115
        #+end_example

     2. SHH tunnel the mflow session to the local computer (#+CALL:
        ssh-tunnel[:session local3](port="5001", node="login01"))
        #+CALL: ssh-tunnel[:session local3](port="5001", node="login01")

        #+RESULTS:
        |                   |           |                                        |           |       |          |      |      |               |
        | sh-5.1$           | sh-5.1$   |
ye53nis@ara-login01.rz.uni-jena.de's | password: |       |          |      |      |               |
        | ye53nis@login01's | password: |                                        |           |       |          |      |      |               |
        | bind:             | Address   | already                                | in        | use
 |          |      |      |               |
        | Last              | login:    | Tue                                    | Aug       |    17 | 18:03:52 | 2021 | from | 10.231.188.20 |

*** Setup: Record GPU metadata & git
   1. Current directory, last 10 git commits

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        pwd
        git log -10
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf) [ye53nis@node128 drmed-git]$ pwd
        /beegfs/ye53nis/drmed-git
        (tf) [ye53nis@node128 drmed-git]$ git log -10
        commit 4c2dc79f0483090d3af2591891c2349b0a48115f
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Thu Mar 3 14:10:45 2022 +0100

            Fix normalize() for l1 and l2 in preprocessing

        commit 39baf02076ba8fbcf444bfa11108d302bcb4c45f
        Author: Alex Seltmann <seltmann@posteo.de>
        Date:   Sun Feb 27 22:20:22 2022 +0100

            Add comparison file from exp-210807-hparams

        commit d51b11eda090b9301e783ec35bdfd26c7bf0709c
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Feb 27 18:40:00 2022 +0100

            fix model input_size to None; else to crop_size

        commit c637444d8b798603629f6f0bd72ee55af7f81a5f
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Feb 27 18:39:29 2022 +0100

            Fix function call correlate_and_fit

        commit 291c6619c12bc39d526137a43d976b3cb4881e50
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sat Feb 26 20:04:07 2022 +0100

            Fix scale_trace; simplify tf_pad_trace call

        commit dcca8b9e17909a95b824c8a7b1fec52eeed198c3
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Thu Feb 24 16:11:39 2022 +0100

            test tf_pad_trace

        commit 6cf2da85748ef13f2e752bea8989a6d31549ced3
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

   2. GPU, CPU, RAM, file system, env variables, top info
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        nvcc -V
        echo --------------------
        lscpu
        echo --------------------
        nproc
        echo --------------------
        free -h
        echo --------------------
        df -h
        echo --------------------
        printenv
        echo --------------------
        top -bcn1 -w512 | head -n 15
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf) [ye53nis@node128 drmed-git]$ nvcc -V
        nvcc: NVIDIA (R) Cuda compiler driver
        Copyright (c) 2005-2020 NVIDIA Corporation
        Built on Mon_Nov_30_19:08:53_PST_2020
        Cuda compilation tools, release 11.2, V11.2.67
        Build cuda_11.2.r11.2/compiler.29373293_0
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ lscpu
        Architecture:          x86_64
        CPU op-mode(s):        32-bit, 64-bit
        Byte Order:            Little Endian
        CPU(s):                48
        On-line CPU(s) list:   0-47
        Thread(s) per core:    2
        Core(s) per socket:    12
        Socket(s):             2
        NUMA node(s):          4
        Vendor ID:             GenuineIntel
        CPU family:            6
        Model:                 79
        Model name:            Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
        Stepping:              1
        CPU MHz:               1203.527
        CPU max MHz:           2900.0000
        CPU min MHz:           1200.0000
        BogoMIPS:              4399.79
        Virtualization:        VT-x
        L1d cache:             32K
        L1i cache:             32K
        L2 cache:              256K
        L3 cache:              15360K
        NUMA node0 CPU(s):     0-5,24-29
        NUMA node1 CPU(s):     6-11,30-35
        NUMA node2 CPU(s):     12-17,36-41
        NUMA node3 CPU(s):     18-23,42-47
        Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonst
        op_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cd
        p_l3 intel_ppin intel_pt ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida
        arat pln pts spec_ctrl intel_stibp
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ nproc
        12
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ free -h
                      total        used        free      shared  buff/cache   available
        Mem:           125G        1.1G        116G        230M        8.6G        123G
        Swap:           11G          0B         11G
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ df -h
        Filesystem           Size  Used Avail Use% Mounted on
        /dev/sda1             50G  7.0G   44G  14% /
        devtmpfs              63G     0   63G   0% /dev
        tmpfs                 63G  188M   63G   1% /dev/shm
        tmpfs                 63G   43M   63G   1% /run
        tmpfs                 63G     0   63G   0% /sys/fs/cgroup
        nfs01-ib:/cluster    2.0T  469G  1.6T  23% /cluster
        nfs01-ib:/home        80T   68T   13T  85% /home
        nfs03-ib:/pool/work  100T   71T   29T  71% /nfsdata
        /dev/sda3            6.0G  635M  5.4G  11% /var
        /dev/sda6            169G  354M  169G   1% /local
        /dev/sda5            2.0G   35M  2.0G   2% /tmp
        beegfs_nodev         524T  508T   17T  97% /beegfs
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ printenv
        SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
        SLURM_NODELIST=node128
        CUDA_PATH=/cluster/nvidia/cuda/11.2
        SLURM_JOB_NAME=bash
        CUDA_INC_PATH=/cluster/nvidia/cuda/11.2/include
        XDG_SESSION_ID=44301
        SLURMD_NODENAME=node128
        SLURM_TOPOLOGY_ADDR=node128
        SLURM_NTASKS_PER_NODE=12
        HOSTNAME=login01
        SLURM_PRIO_PROCESS=0
        SLURM_SRUN_COMM_PORT=38740
        SHELL=/bin/bash
        TERM=screen
        MLFLOW_EXPERIMENT_NAME=exp-220227-unet
        SLURM_JOB_QOS=qstand
        SLURM_PTY_WIN_ROW=53
        HISTSIZE=1000
        TMPDIR=/tmp
        SLURM_TOPOLOGY_ADDR_PATTERN=node
        SSH_CLIENT=10.231.181.128 49370 22
        INCLUDEDIR=/cluster/nvidia/cuda/11.2/include
        CONDA_SHLVL=2
        CONDA_PROMPT_MODIFIER=(tf)
        OLDPWD=/beegfs/ye53nis/drmed-git
        QTDIR=/usr/lib64/qt-3.3
        QTINC=/usr/lib64/qt-3.3/include
        SSH_TTY=/dev/pts/79
        NO_PROXY=localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001
        QT_GRAPHICSSYSTEM_CHECKED=1
        SLURM_NNODES=1
        USER=ye53nis
        http_proxy=http://internet4nzm.rz.uni-jena.de:3128
        LD_LIBRARY_PATH=/cluster/nvidia/cuda/11.2/lib64:/cluster/nvidia/cuda/11.2/nvvm/lib64:/cluster/nvidia/cudnn/8.1//lib64
        LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01
        ;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:
        ,*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01
        ;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:
        ,*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;3
        5:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=
        01;36:*.xspf=01;36:
        CONDA_EXE=/cluster/miniconda3/bin/conda
        SLURM_STEP_NUM_NODES=1
        SLURM_JOBID=1615665
        SRUN_DEBUG=3
        FTP_PROXY=http://internet4nzm.rz.uni-jena.de:3128
        ftp_proxy=http://internet4nzm.rz.uni-jena.de:3128
        SLURM_NTASKS=12
        SLURM_LAUNCH_NODE_IPADDR=192.168.192.5
        SLURM_STEP_ID=0
        TMUX=/tmp/tmux-67339/default,20557,7
        _CE_CONDA=
        CONDA_PREFIX_1=/cluster/miniconda3
        MODCUDA=YES
        SLURM_STEP_LAUNCHER_PORT=38740
        SLURM_TASKS_PER_NODE=12
        MAIL=/var/spool/mail/ye53nis
        PATH=/cluster/nvidia/cuda/11.2/bin:/cluster/nvidia/cuda/11.2/nvvm:/cluster/nvidia/cuda/11.2/open64/bin:/cluster/nvidia/cuda/11.2/libnvvp:/home/ye53nis/.conda/envs/tf/bin:/home/lex/Programme/miniconda3/envs/tf-nightly-lab/bin:/home/lex/P
        rogramme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/usr/sbin:/home/ye53nis/.local/bi
        n:/home/ye53nis/bin
        SLURM_WORKING_CLUSTER=hpc:192.168.192.1:6817:8448
        SLURM_JOB_ID=1615665
        LD_RUN_PATH=/cluster/nvidia/cuda/11.2/lib64
        SLURM_STEP_GPUS=0
        CONDA_PREFIX=/home/ye53nis/.conda/envs/tf
        CUDA_LIB_PATH=/cluster/nvidia/cuda/11.2/lib64
        SLURM_JOB_USER=ye53nis
        SLURM_STEPID=0
        PWD=/beegfs/ye53nis/drmed-git
        _LMFILES_=/cluster/modulefiles/nvidia/cuda/11.2:/cluster/modulefiles/nvidia/cudnn/8.1
        CUDA_VISIBLE_DEVICES=0
        SLURM_SRUN_COMM_HOST=192.168.192.5
        LANG=en_US.UTF-8
        SLURM_PTY_WIN_COL=236
        SLURM_UMASK=0022
        MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles
        SLURM_JOB_UID=67339
        LOADEDMODULES=nvidia/cuda/11.2:nvidia/cudnn/8.1
        SLURM_NODEID=0
        TMUX_PANE=%7
        SLURM_SUBMIT_DIR=/
        SLURM_TASK_PID=4042
        SLURM_NPROCS=12
        SLURM_CPUS_ON_NODE=12
        SLURM_DISTRIBUTION=block
        HTTPS_PROXY=http://internet4nzm.rz.uni-jena.de:3128
        https_proxy=http://internet4nzm.rz.uni-jena.de:3128
        SLURM_PROCID=0
        HISTCONTROL=ignoredups
        _CE_M=
        SLURM_JOB_NODELIST=node128
        SLURM_PTY_PORT=37529
        HOME=/home/ye53nis
        SHLVL=3
        SLURM_LOCALID=0
        SLURM_JOB_GID=13280
        SLURM_JOB_CPUS_PER_NODE=12
        SLURM_CLUSTER_NAME=hpc
        no_proxy=localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001
        SLURM_GTIDS=0,1,2,3,4,5,6,7,8,9,10,11
        SLURM_SUBMIT_HOST=login01
        HTTP_PROXY=http://internet4nzm.rz.uni-jena.de:3128
        SLURM_JOB_PARTITION=gpu_p100
        MATHEMATICA_HOME=/cluster/apps/mathematica/11.3
        CONDA_PYTHON_EXE=/cluster/miniconda3/bin/python
        LOGNAME=ye53nis
        SLURM_STEP_NUM_TASKS=12
        QTLIB=/usr/lib64/qt-3.3/lib
        GPU_DEVICE_ORDINAL=0
        SLURM_JOB_ACCOUNT=iaob
        MLFLOW_TRACKING_URI=file:./data/mlruns
        SLURM_JOB_NUM_NODES=1
        MODULESHOME=/usr/share/Modules
        CONDA_DEFAULT_ENV=tf
        LESSOPEN=||/usr/bin/lesspipe.sh %s
        SLURM_STEP_TASKS_PER_NODE=12
        SLURM_STEP_NODELIST=node128
        DISPLAY=:0
        XDG_RUNTIME_DIR=/run/user/67339
        INCLUDE=/cluster/nvidia/cudnn/8.1//include
        XAUTHORITY=/home/lex/.Xauthority
        BASH_FUNC_module()=() {  eval `/usr/bin/modulecmd bash $*`
        }
        _=/bin/printenv
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ top -bcn1 -w512 | head -n 15
        top - 21:21:42 up 72 days,  9:36,  0 users,  load average: 0.00, 0.03, 0.05
        Tasks: 521 total,   1 running, 520 sleeping,   0 stopped,   0 zombie
        %Cpu(s):  0.2 us,  0.2 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
        KiB Mem : 13191630+total, 12171446+free,  1196368 used,  9005476 buff/cache
        KiB Swap: 12582908 total, 12582908 free,        0 used. 12953688+avail Mem

          PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
        13258 ye53nis   20   0  172732   2620   1664 R  11.1  0.0   0:00.03 top -bcn1 -w512
            1 root      20   0   71788   7548   2584 S   0.0  0.0  35:51.03 /usr/lib/systemd/systemd --switched-root --system --deserialize 22
            2 root      20   0       0      0      0 S   0.0  0.0   0:01.65 [kthreadd]
            3 root      20   0       0      0      0 S   0.0  0.0   0:06.95 [ksoftirqd/0]
            5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 [kworker/0:0H]
            8 root      rt   0       0      0      0 S   0.0  0.0   0:06.58 [migration/0]
            9 root      20   0       0      0      0 S   0.0  0.0   0:00.00 [rcu_bh]
           10 root      20   0       0      0      0 S   0.0  0.0  43:01.62 [rcu_sched]
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

   3. print conda list
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        conda list
      #+END_SRC

      #+RESULTS:
      #+begin_example
        # packages in environment at /home/ye53nis/.conda/envs/tf:
        #
        # Name                    Version                   Build  Channel
        _libgcc_mutex             0.1                        main
        _openmp_mutex             4.5                       1_gnu
        absl-py                   1.0.0                    pypi_0    pypi
        alembic                   1.7.6                    pypi_0    pypi
        anyio                     2.2.0            py39h06a4308_1
        argon2-cffi               20.1.0           py39h27cfd23_1
        asteval                   0.9.26                   pypi_0    pypi
        astunparse                1.6.3                    pypi_0    pypi
        async_generator           1.10               pyhd3eb1b0_0
        attrs                     21.4.0             pyhd3eb1b0_0
        babel                     2.9.1              pyhd3eb1b0_0
        backcall                  0.2.0              pyhd3eb1b0_0
        bleach                    4.1.0              pyhd3eb1b0_0
        brotlipy                  0.7.0           py39h27cfd23_1003
        ca-certificates           2021.10.26           h06a4308_2
        cachetools                5.0.0                    pypi_0    pypi
        certifi                   2021.10.8        py39h06a4308_2
        cffi                      1.15.0           py39hd667e15_1
        charset-normalizer        2.0.4              pyhd3eb1b0_0
        click                     8.0.3                    pypi_0    pypi
        cloudpickle               2.0.0                    pypi_0    pypi
        cryptography              36.0.0           py39h9ce1e76_0
        cycler                    0.11.0                   pypi_0    pypi
        cython                    0.29.27                  pypi_0    pypi
        databricks-cli            0.16.4                   pypi_0    pypi
        debugpy                   1.5.1            py39h295c915_0
        decorator                 5.1.1              pyhd3eb1b0_0
        defusedxml                0.7.1              pyhd3eb1b0_0
        docker                    5.0.3                    pypi_0    pypi
        entrypoints               0.3              py39h06a4308_0
        fcsfiles                  2022.2.2                 pypi_0    pypi
        flask                     2.0.2                    pypi_0    pypi
        flatbuffers               2.0                      pypi_0    pypi
        fonttools                 4.29.1                   pypi_0    pypi
        future                    0.18.2                   pypi_0    pypi
        gast                      0.5.3                    pypi_0    pypi
        gitdb                     4.0.9                    pypi_0    pypi
        gitpython                 3.1.26                   pypi_0    pypi
        google-auth               2.6.0                    pypi_0    pypi
        google-auth-oauthlib      0.4.6                    pypi_0    pypi
        google-pasta              0.2.0                    pypi_0    pypi
        greenlet                  1.1.2                    pypi_0    pypi
        grpcio                    1.43.0                   pypi_0    pypi
        gunicorn                  20.1.0                   pypi_0    pypi
        h5py                      3.6.0                    pypi_0    pypi
        idna                      3.3                pyhd3eb1b0_0
        importlib-metadata        4.8.2            py39h06a4308_0
        importlib_metadata        4.8.2                hd3eb1b0_0
        ipykernel                 6.4.1            py39h06a4308_1
        ipython                   7.31.1           py39h06a4308_0
        ipython_genutils          0.2.0              pyhd3eb1b0_1
        itsdangerous              2.0.1                    pypi_0    pypi
        jedi                      0.18.1           py39h06a4308_1
        jinja2                    3.0.2              pyhd3eb1b0_0
        joblib                    1.1.0                    pypi_0    pypi
        json5                     0.9.6              pyhd3eb1b0_0
        jsonschema                3.2.0              pyhd3eb1b0_2
        jupyter_client            7.1.2              pyhd3eb1b0_0
        jupyter_core              4.9.1            py39h06a4308_0
        jupyter_server            1.4.1            py39h06a4308_0
        jupyterlab                3.2.1              pyhd3eb1b0_1
        jupyterlab_pygments       0.1.2                      py_0
        jupyterlab_server         2.10.2             pyhd3eb1b0_1
        keras                     2.8.0                    pypi_0    pypi
        keras-preprocessing       1.1.2                    pypi_0    pypi
        kiwisolver                1.3.2                    pypi_0    pypi
        ld_impl_linux-64          2.35.1               h7274673_9
        libclang                  13.0.0                   pypi_0    pypi
        libffi                    3.3                  he6710b0_2
        libgcc-ng                 9.3.0               h5101ec6_17
        libgomp                   9.3.0               h5101ec6_17
        libsodium                 1.0.18               h7b6447c_0
        libstdcxx-ng              9.3.0               hd4cf53a_17
        lmfit                     1.0.3                    pypi_0    pypi
        mako                      1.1.6                    pypi_0    pypi
        markdown                  3.3.6                    pypi_0    pypi
        markupsafe                2.0.1            py39h27cfd23_0
        matplotlib                3.5.1                    pypi_0    pypi
        matplotlib-inline         0.1.2              pyhd3eb1b0_2
        mistune                   0.8.4           py39h27cfd23_1000
        mlflow                    1.23.1                   pypi_0    pypi
        multipletau               0.3.3                    pypi_0    pypi
        nbclassic                 0.2.6              pyhd3eb1b0_0
        nbclient                  0.5.3              pyhd3eb1b0_0
        nbconvert                 6.3.0            py39h06a4308_0
        nbformat                  5.1.3              pyhd3eb1b0_0
        ncurses                   6.3                  h7f8727e_2
        nest-asyncio              1.5.1              pyhd3eb1b0_0
        notebook                  6.4.6            py39h06a4308_0
        numpy                     1.22.2                   pypi_0    pypi
        oauthlib                  3.2.0                    pypi_0    pypi
        openssl                   1.1.1m               h7f8727e_0
        opt-einsum                3.3.0                    pypi_0    pypi
        packaging                 21.3               pyhd3eb1b0_0
        pandas                    1.4.0                    pypi_0    pypi
        pandocfilters             1.5.0              pyhd3eb1b0_0
        parso                     0.8.3              pyhd3eb1b0_0
        pexpect                   4.8.0              pyhd3eb1b0_3
        pickleshare               0.7.5           pyhd3eb1b0_1003
        pillow                    9.0.1                    pypi_0    pypi
        pip                       21.2.4           py39h06a4308_0
        prometheus-flask-exporter 0.18.7                   pypi_0    pypi
        prometheus_client         0.13.1             pyhd3eb1b0_0
        prompt-toolkit            3.0.20             pyhd3eb1b0_0
        protobuf                  3.19.4                   pypi_0    pypi
        ptyprocess                0.7.0              pyhd3eb1b0_2
        pyasn1                    0.4.8                    pypi_0    pypi
        pyasn1-modules            0.2.8                    pypi_0    pypi
        pycparser                 2.21               pyhd3eb1b0_0
        pygments                  2.11.2             pyhd3eb1b0_0
        pyopenssl                 22.0.0             pyhd3eb1b0_0
        pyparsing                 3.0.4              pyhd3eb1b0_0
        pyrsistent                0.18.0           py39heee7806_0
        pysocks                   1.7.1            py39h06a4308_0
        python                    3.9.7                h12debd9_1
        python-dateutil           2.8.2              pyhd3eb1b0_0
        pytz                      2021.3             pyhd3eb1b0_0
        pyyaml                    6.0                      pypi_0    pypi
        pyzmq                     22.3.0           py39h295c915_2
        querystring-parser        1.2.4                    pypi_0    pypi
        readline                  8.1.2                h7f8727e_1
        requests                  2.27.1             pyhd3eb1b0_0
        requests-oauthlib         1.3.1                    pypi_0    pypi
        rsa                       4.8                      pypi_0    pypi
        scikit-learn              1.0.2                    pypi_0    pypi
        scipy                     1.8.0                    pypi_0    pypi
        seaborn                   0.11.2                   pypi_0    pypi
        send2trash                1.8.0              pyhd3eb1b0_1
        setuptools                58.0.4           py39h06a4308_0
        six                       1.16.0             pyhd3eb1b0_0
        smmap                     5.0.0                    pypi_0    pypi
        sniffio                   1.2.0            py39h06a4308_1
        sqlalchemy                1.4.31                   pypi_0    pypi
        sqlite                    3.37.2               hc218d9a_0
        sqlparse                  0.4.2                    pypi_0    pypi
        tabulate                  0.8.9                    pypi_0    pypi
        tensorboard               2.8.0                    pypi_0    pypi
        tensorboard-data-server   0.6.1                    pypi_0    pypi
        tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
        tensorflow                2.8.0                    pypi_0    pypi
        tensorflow-io-gcs-filesystem 0.24.0                   pypi_0    pypi
        termcolor                 1.1.0                    pypi_0    pypi
        terminado                 0.9.4            py39h06a4308_0
        testpath                  0.5.0              pyhd3eb1b0_0
        tf-estimator-nightly      2.8.0.dev2021122109          pypi_0    pypi
        threadpoolctl             3.1.0                    pypi_0    pypi
        tk                        8.6.11               h1ccaba5_0
        tornado                   6.1              py39h27cfd23_0
        traitlets                 5.1.1              pyhd3eb1b0_0
        typing-extensions         4.0.1                    pypi_0    pypi
        tzdata                    2021e                hda174b7_0
        uncertainties             3.1.6                    pypi_0    pypi
        urllib3                   1.26.8             pyhd3eb1b0_0
        wcwidth                   0.2.5              pyhd3eb1b0_0
        webencodings              0.5.1            py39h06a4308_1
        websocket-client          1.2.3                    pypi_0    pypi
        werkzeug                  2.0.3                    pypi_0    pypi
        wheel                     0.37.1             pyhd3eb1b0_0
        wrapt                     1.13.3                   pypi_0    pypi
        xz                        5.2.5                h7b6447c_0
        zeromq                    4.3.4                h2531618_0
        zipp                      3.7.0              pyhd3eb1b0_0
        zlib                      1.2.11               h7f8727e_4
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

   4. Show tree of input files used.
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        tree ../saves/firstartifact_Nov2020_train_max2sets
        echo --------------------
        tree ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
        echo --------------------
        tree ../saves/firstartifact_Nov2020_test
      #+END_SRC

      #+RESULTS:
      #+begin_example

        (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_train_max2sets
        ../saves/firstartifact_Nov2020_train_max2sets
        ├── 0.069
        │   ├── 0.01
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D0.069_set002.csv
        │   │   └── traces_brightclust_Nov2020_D0.069_set003.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.069_set009.csv
        ├── 0.08
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.08_set007.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D0.08_set002.csv
        │   │   └── traces_brightclust_Nov2020_D0.08_set006.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D0.08_set004.csv
        │       └── traces_brightclust_Nov2020_D0.08_set009.csv
        ├── 0.1
        │   ├── 0.01
        │   │   ├── traces_brightclust_Nov2020_D0.1_set004.csv
        │   │   └── traces_brightclust_Nov2020_D0.1_set006.csv
        │   ├── 0.1
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D0.1_set003.csv
        │       └── traces_brightclust_Nov2020_D0.1_set007.csv
        ├── 0.2
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.2_set003.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D0.2_set001.csv
        │   │   └── traces_brightclust_Nov2020_D0.2_set004.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D0.2_set009.csv
        │       └── traces_brightclust_Nov2020_D0.2_set010.csv
        ├── 0.4
        │   ├── 0.01
        │   │   ├── traces_brightclust_Nov2020_D0.4_set004.csv
        │   │   └── traces_brightclust_Nov2020_D0.4_set010.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D0.4_set002.csv
        │   │   └── traces_brightclust_Nov2020_D0.4_set003.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D0.4_set006.csv
        │       └── traces_brightclust_Nov2020_D0.4_set007.csv
        ├── 0.6
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.6_set010.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D0.6_set004.csv
        │   │   └── traces_brightclust_Nov2020_D0.6_set005.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D0.6_set001.csv
        │       └── traces_brightclust_Nov2020_D0.6_set002.csv
        ├── 10
        │   ├── 0.01
        │   │   ├── traces_brightclust_Nov2020_D10_set003.csv
        │   │   └── traces_brightclust_Nov2020_D10_set004.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D10_set006.csv
        │   │   └── traces_brightclust_Nov2020_D10_set007.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D10_set010.csv
        ├── 1.0
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D1.0_set010.csv
        │   ├── 0.1
        │   │   ├── traces_brightclust_Nov2020_D1.0_set004.csv
        │   │   └── traces_brightclust_Nov2020_D1.0_set007.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D1.0_set001.csv
        │       └── traces_brightclust_Nov2020_D1.0_set002.csv
        ├── 3.0
        │   ├── 0.01
        │   │   ├── traces_brightclust_Nov2020_D3.0_set005.csv
        │   │   └── traces_brightclust_Nov2020_D3.0_set006.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D3.0_set010.csv
        │   └── 1.0
        │       ├── traces_brightclust_Nov2020_D3.0_set001.csv
        │       └── traces_brightclust_Nov2020_D3.0_set003.csv
        └── 50
            ├── 0.01
            │   └── traces_brightclust_Nov2020_D50_set006.csv
            ├── 0.1
            │   ├── traces_brightclust_Nov2020_D50_set009.csv
            │   └── traces_brightclust_Nov2020_D50_set010.csv
            └── 1.0
                ├── traces_brightclust_Nov2020_D50_set004.csv
                └── traces_brightclust_Nov2020_D50_set005.csv

        40 directories, 48 files
        (tf) [ye53nis@node128 drmed-git]$ echo --------------------
        --------------------
        (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
        ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
        ├── 0.069
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.069_set006.csv
        │   └── 1.0
        ├── 0.08
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.08_set008.csv
        │   └── 1.0
        ├── 0.1
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.1_set008.csv
        │   ├── 0.1
        │   └── 1.0
        ├── 0.2
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.2_set006.csv
        │   └── 1.0
        ├── 0.4
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.4_set009.csv
        │   └── 1.0
        ├── 0.6
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.6_set006.csv
        │   └── 1.0
        ├── 10
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D10_set008.csv
        │   ├── 0.1
        │   └── 1.0
        ├── 1.0
        │   ├── 0.01
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D1.0_set009.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D1.0_set008.csv
        ├── 3.0
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D3.0_set008.csv
        │   ├── 0.1
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D3.0_set009.csv
        └── 50
            ├── 0.01
            ├── 0.1
            └── 1.0
                └── traces_brightclust_Nov2020_D50_set007.csv

        40 directories, 12 files
        (tf) [ye53nis@node128 drmed-git]$ echo --------------------
        --------------------

        (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_test
        ../saves/firstartifact_Nov2020_test
        ├── 0.069
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.069_set005.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.069_set001.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.069_set010.csv
        ├── 0.08
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.08_set005.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.08_set003.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.08_set001.csv
        ├── 0.1
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.1_set002.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.1_set005.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.1_set001.csv
        ├── 0.2
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.2_set002.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.2_set007.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.2_set005.csv
        ├── 0.4
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.4_set008.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.4_set001.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.4_set005.csv
        ├── 0.6
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D0.6_set008.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D0.6_set003.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D0.6_set009.csv
        ├── 10
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D10_set002.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D10_set001.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D10_set005.csv
        ├── 1.0
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D1.0_set006.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D1.0_set003.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D1.0_set005.csv
        ├── 3.0
        │   ├── 0.01
        │   │   └── traces_brightclust_Nov2020_D3.0_set004.csv
        │   ├── 0.1
        │   │   └── traces_brightclust_Nov2020_D3.0_set007.csv
        │   └── 1.0
        │       └── traces_brightclust_Nov2020_D3.0_set002.csv
        └── 50
            ├── 0.01
            │   └── traces_brightclust_Nov2020_D50_set002.csv
            ├── 0.1
            │   └── traces_brightclust_Nov2020_D50_set003.csv
            └── 1.0
                └── traces_brightclust_Nov2020_D50_set001.csv

        40 directories, 30 files
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example
*** Setup: Show all hyperparameters that worked in =exp-210807-hparams=
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
   :END:
   1. get the comparison data of all runs from =exp-210807-hparams= via =git
      restore=
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        git show 04e9dc3:./data/exp-210807-hparams/mlflow/run1-2_comparison.csv > ./data/exp-220227-unet/mlflow/exp-210807-hparams_comparison.csv
      #+END_SRC

   2. open the file in jupyter, do some processing to only find the best runs,
      and display the relevant hparams (see =exp-210807-hparams= section
      =4. Analyze run 1 and 2= for explanations on the processing)
      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
        import numpy as np
        import pandas as pd
      #+END_SRC

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git

      #+NAME: get-hparam-comparison
      #+BEGIN_SRC jupyter-python
        run1_2 = pd.read_csv('data/exp-220227-unet/mlflow/exp-210807-hparams_comparison.csv', index_col=0)
        run1_2_valauc = run1_2.loc['val_auc'].astype(float)
        singles_ls = ['5441e71efe0f4dae868648e7cc795c65']

        run1_2_singles = run1_2.loc[:, singles_ls]
        run1_2_singles.iloc[35:, :] = run1_2_singles.iloc[35:, :].astype(np.float64)
        run1_2 = run1_2.drop(columns=singles_ls)

        assert len(run1_2.iloc[35:, :].columns) % 2 == 0

        run1_2_doubleparams = pd.DataFrame()
        run1_2_doublemetrics = pd.DataFrame()
        double_cols = []
        for left, right in zip(run1_2.iloc[:, ::2].items(), run1_2.iloc[:, 1::2].items()):
            double_cols.append((left[0], right[0]))
            current_metrics = left[1].iloc[35:].combine(other=right[1].iloc[35:],
                                                        func=(lambda x1, x2: (float(x1) + float(x2)) / 2))
            current_params = left[1].iloc[:35].combine(other=right[1].iloc[:35],
                                                       func=(lambda x1, x2: set((x1, x2)) if x1 != x2 else x1))
            run1_2_doubleparams = pd.concat([run1_2_doubleparams, current_params], axis=1)
            run1_2_doublemetrics = pd.concat([run1_2_doublemetrics, current_metrics], axis=1)

        run1_2_doublemetrics = pd.DataFrame(data=run1_2_doublemetrics.to_numpy(),
                                            index=run1_2.iloc[35:, :].index,
                                            columns=double_cols)

        run1_2_doubleparams = pd.DataFrame(data=run1_2_doubleparams.to_numpy(),
                                           index=run1_2.iloc[:35, :].index,
                                           columns=double_cols)

        run1_2_combimetrics = pd.concat([run1_2_doublemetrics, run1_2_singles.iloc[35:, :]], axis=1)
        run1_2_combiparams = pd.concat([run1_2_doubleparams, run1_2_singles.iloc[:35, :]], axis=1)
        run1_2_mymetrics = run1_2_combimetrics.loc[['val_auc', 'val_recall0.5', 'val_precision0.5']]
        run1_2_myparams = run1_2_combiparams.loc[['hp_batch_size', 'hp_first_filters', 'hp_input_size', 'hp_lr_power', 'hp_lr_start', 'hp_n_levels', 'hp_pool_size', 'hp_scaler']]
        run1_2_my = pd.concat([run1_2_mymetrics, run1_2_myparams], axis=0).T
        # cond1 = run1_2_combimetrics.loc[:, 'val_auc'] > 0.95
        cond2 = run1_2_my.loc[:, 'val_recall0.5'] > 0.85
        cond3 = run1_2_my.loc[:, 'val_precision0.5'] > 0.85

        with pd.option_context('display.max_rows', None, 'display.max_columns', None):
            display(run1_2_my.loc[cond2 & cond3])
      #+END_SRC

      #+RESULTS: get-hparam-comparison
      :RESULTS:
      | Run ID:                                                              | val_auc | val_recall0.5 | val_precision0.5 | hp_batch_size | hp_first_filters | hp_input_size | hp_lr_power |        hp_lr_start | hp_n_levels | hp_pool_size | hp_scaler |
      |----------------------------------------------------------------------+---------+---------------+------------------+---------------+------------------+---------------+-------------+--------------------+-------------+--------------+-----------|
      | (9051e32b87d84f3485b980067addec30, 61ff87bdb89b4e2ba64f8dacc774992d) |   0.981 |        0.8975 |            0.918 |            26 |               44 |         16384 |           1 | 0.0136170138242663 |           7 |            2 | standard  |
      | (93b168c0ff7942c8a908a94129daf973, f243b3b742de4dbcb7ccfbd4244706f8) |   0.976 |         0.893 |            0.852 |            15 |               23 |         16384 |           7 | 0.0305060808685107 |           6 |            4 | quant_g   |
      | (a5b8551144ff46e697a39cd1551e1475, 98cf8cdef9c54b5286e277e75e2ab8c1) |   0.984 |         0.916 |            0.909 |            20 |               78 |         16384 |           4 | 0.0584071108418767 |           4 |            4 | standard  |
      | (00f2635d9fa2463c9a066722163405be, d0a8e1748b194f3290d471b6b44f19f8) |   0.987 |         0.929 |           0.9065 |            28 |                6 |         16384 |           1 | 0.0553313915596308 |           5 |            4 | minmax    |
      | (5604d43c1ece461b8e6eaa0dfb65d6dc, 3612536a77f34f22bc83d1d809140aa6) |  0.9745 |         0.885 |           0.8985 |            20 |              128 |         16384 |           1 |  0.043549707353273 |           3 |            4 | standard  |
      | (7cafab027cdd4fc9bf20a43e989df510, 16dff15d935f45e2a836b1f41b07b4e3) |   0.978 |        0.8905 |            0.891 |            10 |               16 |          8192 |           1 | 0.0627676336651573 |           5 |            4 | robust    |
      | (0e328920e86049928202db95e8cfb7be, bf9d2725eb16462d9a101f0a077ce2b5) |   0.976 |         0.875 |            0.888 |            14 |               16 |         16384 |           5 | 0.0192390310290551 |           9 |            2 | robust    |
      | (1c954fbc02b747bc813c587ac703c74a, ba49a80c2616407a8f1fe1fd12096fe0) |   0.962 |         0.856 |           0.8585 |            17 |               16 |         16384 |           5 | 0.0101590069352232 |           3 |            4 | l2        |
      | (3cbd945b62ec4634839372e403f6f377, 458b36a70db843719d202a8eda448f17) |   0.972 |         0.872 |           0.9135 |             9 |               64 |          4096 |           1 | 0.0100697459464075 |           5 |            4 | maxabs    |
      :END:

   3. notes on hparams:
      - I used three different input sizes in hparams training (4096, 8192,
        16384). As experimental test data I have got traces which are around
        8000 and traces which are around 32000 time steps. To balance between
        both, I will only use 16384 as an input size.
      - The UNET only excepts input sizes which are exactly the power of 2 and
        > 1024. To deal with that for experimental traces which have a different
        size, I append the median of the trace until it reaches the next biggest
        power of 2. That means in the script below my =input_size= will be
        =14000=, so each trace will be padded with =2384= median values (~15% of
        the input), and the corresponding labels will be =0=.
      - the epoch size used for training will be 100 epochs for each hparam
        configuration

*** Experiment: run training of 9 promising hparam combinations
   1. run training of =(9051e32b87d84f3485b980067addec30,
      61ff87bdb89b4e2ba64f8dacc774992d)= with hparams from above.

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=26 \
               -P first_filters=44 \
               -P input_size=14000 \
               -P lr_start=0.0136170138242663 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=7 \
               -P pool_size=2
      #+END_SRC

      #+RESULTS:
      #+begin_example
        INFO: 'exp-220227-unet' does not exist. Creating a new experiment
        2022/02/27 23:06:17 INFO mlflow.projects.utils: === Created directory /tmp/tmp5u38tprq for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/27 23:06:17 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 26 --input_size 14000 --lr_start 0.0136170138242663 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 7 --first_filters 44 --pool_size 2' in run with ID '484af471c61943fa90e5f78e78a229f0' ===
        2022-02-27 23:06:19.459522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:06:27,328 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-27 23:06:27,329 - train -  Tensorflow version: 2.5.0
        2022-02-27 23:06:27,329 - train -  tf.keras version: 2.5.0
        2022-02-27 23:06:27,329 - train -  Cudnn version: 8
        2022-02-27 23:06:27,329 - train -  Cuda version: 11.2
        2022-02-27 23:06:27.332616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-27 23:06:27.373032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-27 23:06:27.373166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:06:27.382894: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-27 23:06:27.382990: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-27 23:06:27.386881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-27 23:06:27.389946: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-27 23:06:27.399178: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-27 23:06:27.413770: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-27 23:06:27.415902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-27 23:06:27.419520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-27 23:06:27,419 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-27 23:06:27,420 - train -  Setting memory growth successful.
        2022-02-27 23:06:33,649 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-27 23:06:47,474 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-27 23:06:52,553 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-27 23:06:56,374 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-27 23:06:59,968 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-27 23:07:03,508 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-27 23:07:07,092 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-27 23:07:10,718 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-27 23:07:14,433 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-27 23:07:18,054 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-27 23:07:21,398 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-27 23:07:33,241 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-27 23:07:37,082 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-27 23:07:40,911 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-27 23:07:44,813 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-27 23:07:48,436 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-27 23:07:52,998 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-27 23:07:56,536 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-27 23:08:00,088 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-27 23:08:03,661 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-27 23:08:07,253 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-27 23:08:22,306 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-27 23:08:25,939 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-27 23:08:29,797 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-27 23:08:33,419 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-27 23:08:38,026 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-27 23:08:41,552 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-27 23:08:46,334 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-27 23:08:52,449 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-27 23:09:00,390 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-27 23:09:13,802 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-27 23:09:17,690 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-27 23:09:21,264 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-27 23:09:25,460 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-27 23:09:29,041 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-27 23:09:33,185 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-27 23:09:36,927 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-27 23:09:43,792 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-27 23:09:55,806 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-27 23:09:59,340 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-27 23:10:04,195 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-27 23:10:07,769 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-27 23:10:11,494 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-27 23:10:15,480 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-27 23:10:19,534 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-27 23:10:23,308 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-27 23:10:27,088 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-27 23:10:30,870 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-27 23:10:34,365 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-27 23:10:43,346 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-27 23:10:59,488 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-27 23:11:07,159 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-27 23:11:11,824 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-27 23:11:15,330 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-27 23:11:19,613 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-27 23:11:22,985 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-27 23:11:26,571 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-27 23:11:30,142 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-27 23:11:33,712 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-27 23:11:40,154 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-27 23:11:40,374 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-27 23:11:40,463 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-27 23:11:40.616724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-27 23:11:40.620393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-27 23:11:40.624428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-27 23:11:40.624579: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:11:41.105011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-27 23:11:41.105083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-27 23:11:41.105097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-27 23:11:41.107958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-27 23:11:43,160 - train -  number of examples: 4800
        2022-02-27 23:11:43,526 - train -  number of examples: 1200
        2022-02-27 23:11:46,063 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/27 23:11:46 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='26' for run ID='484
        af471c61943fa90e5f78e78a229f0'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-27 23:11:56.021789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-27 23:11:56.201257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-27 23:12:06.010819: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-27 23:12:06.325533: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-27 23:12:06.806608: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-27 23:12:07.089703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        184/184 [==============================] - 212s 1s/step - loss: 1.1422 - tp0.1: 8390499.0000 - fp0.1: 12828878.0000 - tn0.1: 55341968.0000 - fn0.1: 1819714.0000 - precision0.1: 0.3954 - recall0.1: 0.8218 - tp0.3: 7189476.0000 - fp0.3: 4
        881676.0000 - tn0.3: 63289180.0000 - fn0.3: 3020737.0000 - precision0.3: 0.5956 - recall0.3: 0.7041 - tp0.5: 6041120.0000 - fp0.5: 2184567.0000 - tn0.5: 65986268.0000 - fn0.5: 4169093.0000 - precision0.5: 0.7344 - recall0.5: 0.5917 - tp
        0.7: 4490541.0000 - fp0.7: 712795.0000 - tn0.7: 67458040.0000 - fn0.7: 5719672.0000 - precision0.7: 0.8630 - recall0.7: 0.4398 - tp0.9: 2966847.0000 - fp0.9: 153266.0000 - tn0.9: 68017552.0000 - fn0.9: 7243366.0000 - precision0.9: 0.950
        9 - recall0.9: 0.2906 - accuracy: 0.9189 - auc: 0.8890 - f1: 0.6554 - val_loss: 45.6530 - val_tp0.1: 2695397.0000 - val_fp0.1: 16186602.0000 - val_tn0.1: 695010.0000 - val_fn0.1: 18255.0000 - val_precision0.1: 0.1427 - val_recall0.1: 0.
        9933 - val_tp0.3: 2693432.0000 - val_fp0.3: 16009674.0000 - val_tn0.3: 871938.0000 - val_fn0.3: 20220.0000 - val_precision0.3: 0.1440 - val_recall0.3: 0.9925 - val_tp0.5: 2691511.0000 - val_fp0.5: 15860014.0000 - val_tn0.5: 1021598.0000
         - val_fn0.5: 22141.0000 - val_precision0.5: 0.1451 - val_recall0.5: 0.9918 - val_tp0.7: 2688428.0000 - val_fp0.7: 15650703.0000 - val_tn0.7: 1230909.0000 - val_fn0.7: 25224.0000 - val_precision0.7: 0.1466 - val_recall0.7: 0.9907 - val_
        tp0.9: 2681968.0000 - val_fp0.9: 15334839.0000 - val_tn0.9: 1546773.0000 - val_fn0.9: 31684.0000 - val_precision0.9: 0.1489 - val_recall0.9: 0.9883 - val_accuracy: 0.1895 - val_auc: 0.5616 - val_f1: 0.2531

        ...

        Epoch 100/100
        184/184 [==============================] - 184s 1s/step - loss: 0.0877 - tp0.1: 10015121.0000 - fp0.1: 1833216.0000 - tn0.1: 66390352.0000 - fn0.1: 142350.0000 - precision0.1: 0.8453 - recall0.1: 0.9860 - tp0.3: 9874038.0000 - fp0.3: 10
        86322.0000 - tn0.3: 67137280.0000 - fn0.3: 283433.0000 - precision0.3: 0.9009 - recall0.3: 0.9721 - tp0.5: 9674727.0000 - fp0.5: 664419.0000 - tn0.5: 67559176.0000 - fn0.5: 482744.0000 - precision0.5: 0.9357 - recall0.5: 0.9525 - tp0.7:
         9343030.0000 - fp0.7: 341635.0000 - tn0.7: 67881952.0000 - fn0.7: 814441.0000 - precision0.7: 0.9647 - recall0.7: 0.9198 - tp0.9: 8626370.0000 - fp0.9: 88068.0000 - tn0.9: 68135504.0000 - fn0.9: 1531101.0000 - precision0.9: 0.9899 - re
        call0.9: 0.8493 - accuracy: 0.9854 - auc: 0.9920 - f1: 0.9440 - val_loss: 0.1556 - val_tp0.1: 2623480.0000 - val_fp0.1: 609139.0000 - val_tn0.1: 16273852.0000 - val_fn0.1: 88793.0000 - val_precision0.1: 0.8116 - val_recall0.1: 0.9673 -
        val_tp0.3: 2573475.0000 - val_fp0.3: 375340.0000 - val_tn0.3: 16507651.0000 - val_fn0.3: 138798.0000 - val_precision0.3: 0.8727 - val_recall0.3: 0.9488 - val_tp0.5: 2518254.0000 - val_fp0.5: 251870.0000 - val_tn0.5: 16631121.0000 - val_
        fn0.5: 194019.0000 - val_precision0.5: 0.9091 - val_recall0.5: 0.9285 - val_tp0.7: 2439448.0000 - val_fp0.7: 153092.0000 - val_tn0.7: 16729899.0000 - val_fn0.7: 272825.0000 - val_precision0.7: 0.9409 - val_recall0.7: 0.8994 - val_tp0.9:
         2279822.0000 - val_fp0.9: 61468.0000 - val_tn0.9: 16821524.0000 - val_fn0.9: 432451.0000 - val_precision0.9: 0.9737 - val_recall0.9: 0.8406 - val_accuracy: 0.9772 - val_auc: 0.9814 - val_f1: 0.9187
        2022-02-28 04:24:39.818514: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 04:24:58 INFO mlflow.projects: === Run (ID '484af471c61943fa90e5f78e78a229f0') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =484af471c61943fa90e5f78e78a229f0=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9091 - val_recall0.5: 0.9285 - val_f10.5: 0.9187
        - val_auc: 0.9814

   2. run training of =(93b168c0ff7942c8a908a94129daf973,
      f243b3b742de4dbcb7ccfbd4244706f8)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=15 \
               -P first_filters=23 \
               -P input_size=14000 \
               -P lr_start=0.0305060808685107 \
               -P lr_power=7 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=quant_g \
               -P n_levels=6 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/02/28 14:14:59 INFO mlflow.projects.utils: === Created directory /tmp/tmpjco1jnk_ for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/28 14:15:00 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 15 --input_size 14000 --lr_start 0.0305060808685107 --lr_power 7 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler quant_g --n_levels 6 --first_filters 23 --pool_size 4' in run with ID '0cd2023eeaf745aca0d3e8ad5e1fc653' ===
        2022-02-28 14:15:13.580296: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:15:25,693 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-28 14:15:25,693 - train -  Tensorflow version: 2.5.0
        2022-02-28 14:15:25,693 - train -  tf.keras version: 2.5.0
        2022-02-28 14:15:25,693 - train -  Cudnn version: 8
        2022-02-28 14:15:25,693 - train -  Cuda version: 11.2
        2022-02-28 14:15:25.695839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-28 14:15:25.776740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 14:15:25.776884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:15:25.786987: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 14:15:25.787115: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-28 14:15:25.790205: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-28 14:15:25.791541: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-28 14:15:25.799938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-28 14:15:25.821517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-28 14:15:25.822676: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 14:15:25.826275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 14:15:25,826 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-28 14:15:25,827 - train -  Setting memory growth successful.
        2022-02-28 14:15:33,830 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-28 14:15:46,000 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-28 14:15:50,090 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-28 14:16:02,981 - train -  4/48: /beegfs/ye53nis/saves/first
        artifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-28 14:16:11,106 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-28 14:16:16,436 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-28 14:16:21,251 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-28 14:16:24,785 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-28 14:16:41,395 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-28 14:16:45,170 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-28 14:16:48,894 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-28 14:17:01,362 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-28 14:17:05,972 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-28 14:17:11,392 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-28 14:17:15,150 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-28 14:17:18,880 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-28 14:17:22,858 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-28 14:17:26,879 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-28 14:17:31,181 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-28 14:17:34,897 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-28 14:17:38,846 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-28 14:18:01,434 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-28 14:18:05,125 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-28 14:18:10,548 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-28 14:18:15,933 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-28 14:18:20,727 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-28 14:18:24,064 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-28 14:18:35,979 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-28 14:18:39,881 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-28 14:18:43,394 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-28 14:18:53,160 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-28 14:18:57,332 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-28 14:19:03,503 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-28 14:19:08,665 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-28 14:19:13,327 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-28 14:19:17,293 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-28 14:19:21,119 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-28 14:19:24,804 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-28 14:19:31,451 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-28 14:19:41,863 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-28 14:19:47,487 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-28 14:19:53,197 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-28 14:20:00,405 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-28 14:20:04,607 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-28 14:20:08,353 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-28 14:20:12,307 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-28 14:20:16,444 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-28 14:20:20,213 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-28 14:20:23,834 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-28 14:20:30,953 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-28 14:20:36,797 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-28 14:20:48,524 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-28 14:20:57,745 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-28 14:21:01,411 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-28 14:21:13,337 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-28 14:21:17,317 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-28 14:21:21,005 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-28 14:21:24,834 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-28 14:21:28,718 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-28 14:21:32,087 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-28 14:21:32,293 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-28 14:21:32,383 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-28 14:21:32.540303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-28 14:21:32.542865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 14:21:32.544861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 14:21:32.544960: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:21:32.969057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-28 14:21:32.969130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-28 14:21:32.969144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-28 14:21:32.972037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-28 14:21:35,138 - train -  number of examples: 4800
        2022-02-28 14:21:35,561 - train -  number of examples: 1200
        2022-02-28 14:21:37,968 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/28 14:21:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='15' for run ID='0cd
        2023eeaf745aca0d3e8ad5e1fc653'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-28 14:21:47.612006: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-28 14:21:47.786795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-28 14:22:00.556303: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 3118 of 4800
        2022-02-28 14:22:05.887971: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.
        2022-02-28 14:22:05.992991: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 14:22:06.329980: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-28 14:22:06.837590: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 14:22:07.115604: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        320/320 [==============================] - 80s 158ms/step - loss: 0.6557 - tp0.1: 8858269.0000 - fp0.1: 11367531.0000 - tn0.1: 57039588.0000 - fn0.1: 1377794.0000 - precision0.1: 0.4380 - recall0.1: 0.8654 - tp0.3: 8020446.0000 - fp0.3:
         6844078.0000 - tn0.3: 61563052.0000 - fn0.3: 2215617.0000 - precision0.3: 0.5396 - recall0.3: 0.7835 - tp0.5: 6484149.0000 - fp0.5: 3021931.0000 - tn0.5: 65385196.0000 - fn0.5: 3751914.0000 - precision0.5: 0.6821 - recall0.5: 0.6335 -
        tp0.7: 4743137.0000 - fp0.7: 1127848.0000 - tn0.7: 67279296.0000 - fn0.7: 5492926.0000 - precision0.7: 0.8079 - recall0.7: 0.4634 - tp0.9: 2178331.0000 - fp0.9: 182418.0000 - tn0.9: 68224688.0000 - fn0.9: 8057732.0000 - precision0.9: 0.
        9227 - recall0.9: 0.2128 - accuracy: 0.9139 - auc: 0.9007 - f1: 0.6569 - val_loss: 154.4101 - val_tp0.1: 2567299.0000 - val_fp0.1: 15932078.0000 - val_tn0.1: 1006227.0000 - val_fn0.1: 155196.0000 - val_precision0.1: 0.1388 - val_recall0
        .1: 0.9430 - val_tp0.3: 2564050.0000 - val_fp0.3: 15892674.0000 - val_tn0.3: 1045631.0000 - val_fn0.3: 158445.0000 - val_precision0.3: 0.1389 - val_recall0.3: 0.9418 - val_tp0.5: 2561216.0000 - val_fp0.5: 15863898.0000 - val_tn0.5: 1074
        407.0000 - val_fn0.5: 161279.0000 - val_precision0.5: 0.1390 - val_recall0.5: 0.9408 - val_tp0.7: 2556675.0000 - val_fp0.7: 15829841.0000 - val_tn0.7: 1108464.0000 - val_fn0.7: 165820.0000 - val_precision0.7: 0.1391 - val_recall0.7: 0.9
        391 - val_tp0.9: 2546087.0000 - val_fp0.9: 15767476.0000 - val_tn0.9: 1170829.0000 - val_fn0.9: 176408.0000 - val_precision0.9: 0.1390 - val_recall0.9: 0.9352 - val_accuracy: 0.1849 - val_auc: 0.4998 - val_f1: 0.2422

        ...

        Epoch 100/100
        320/320 [==============================] - 46s 145ms/step - loss: 0.1275 - tp0.1: 10018370.0000 - fp0.1: 2700999.0000 - tn0.1: 65706144.0000 - fn0.1: 217693.0000 - precision0.1: 0.7876 - recall0.1: 0.9787 - tp0.3: 9775954.0000 - fp0.3:
        1429847.0000 - tn0.3: 66977260.0000 - fn0.3: 460109.0000 - precision0.3: 0.8724 - recall0.3: 0.9551 - tp0.5: 9497895.0000 - fp0.5: 850165.0000 - tn0.5: 67556944.0000 - fn0.5: 738168.0000 - precision0.5: 0.9178 - recall0.5: 0.9279 - tp0.
        7: 9083449.0000 - fp0.7: 444475.0000 - tn0.7: 67962624.0000 - fn0.7: 1152614.0000 - precision0.7: 0.9534 - recall0.7: 0.8874 - tp0.9: 8160305.0000 - fp0.9: 123032.0000 - tn0.9: 68284080.0000 - fn0.9: 2075758.0000 - precision0.9: 0.9851
        - recall0.9: 0.7972 - accuracy: 0.9798 - auc: 0.9876 - f1: 0.9228 - val_loss: 0.1678 - val_tp0.1: 2639044.0000 - val_fp0.1: 807650.0000 - val_tn0.1: 16130655.0000 - val_fn0.1: 83451.0000 - val_precision0.1: 0.7657 - val_recall0.1: 0.969
        3 - val_tp0.3: 2571140.0000 - val_fp0.3: 452176.0000 - val_tn0.3: 16486129.0000 - val_fn0.3: 151355.0000 - val_precision0.3: 0.8504 - val_recall0.3: 0.9444 - val_tp0.5: 2500729.0000 - val_fp0.5: 291947.0000 - val_tn0.5: 16646358.0000 -
        val_fn0.5: 221766.0000 - val_precision0.5: 0.8955 - val_recall0.5: 0.9185 - val_tp0.7: 2397916.0000 - val_fp0.7: 172157.0000 - val_tn0.7: 16766148.0000 - val_fn0.7: 324579.0000 - val_precision0.7: 0.9330 - val_recall0.7: 0.8808 - val_tp
        0.9: 2174652.0000 - val_fp0.9: 58658.0000 - val_tn0.9: 16879648.0000 - val_fn0.9: 547843.0000 - val_precision0.9: 0.9737 - val_recall0.9: 0.7988 - val_accuracy: 0.9739 - val_auc: 0.9818 - val_f1: 0.9069
        2022-02-28 15:49:04.737117: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 15:49:22 INFO mlflow.projects: === Run (ID '0cd2023eeaf745aca0d3e8ad5e1fc653') succeeded ===
      #+end_example
      - name of run: =0cd2023eeaf745aca0d3e8ad5e1fc653=
      - metrics after 100th epoch:
        - loss: 0.1275 - val_loss: 0.1678
        - val_precision0.5: 0.8955 - val_recall0.5: 0.9185 - val_f10.5: 0.9069
        - val_auc: 0.9818

   3. run training of =(a5b8551144ff46e697a39cd1551e1475,
      98cf8cdef9c54b5286e277e75e2ab8c1)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=20 \
               -P first_filters=78 \
               -P input_size=14000 \
               -P lr_start=0.0584071108418767 \
               -P lr_power=4 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=4 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/02/28 17:34:45 INFO mlflow.projects.utils: === Created directory /tmp/tmpwue2ujb5 for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/28 17:34:45 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 20 --input_size 14000 --lr_start 0.0584071108418767 --lr_power 4 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 4 --first_filters 78 --pool_size 4' in run with ID 'fe81d71c52404ed790b3a32051258da9' ===
        2022-02-28 17:34:58.034002: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:35:10,330 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-28 17:35:10,331 - train -  Tensorflow version: 2.5.0
        2022-02-28 17:35:10,331 - train -  tf.keras version: 2.5.0
        2022-02-28 17:35:10,331 - train -  Cudnn version: 8
        2022-02-28 17:35:10,331 - train -  Cuda version: 11.2
        2022-02-28 17:35:10.333548: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-28 17:35:10.391240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 17:35:10.391388: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:35:10.401553: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 17:35:10.401669: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-28 17:35:10.405228: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-28 17:35:10.407042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-28 17:35:10.415485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-28 17:35:10.417900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-28 17:35:10.419606: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 17:35:10.422879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 17:35:10,423 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-28 17:35:10,423 - train -  Setting memory growth successful.
        2022-02-28 17:35:16,324 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-28 17:35:30,676 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-28 17:35:34,283 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-28 17:35:38,780 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-28 17:35:43,054 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-28 17:35:46,234 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-28 17:35:50,337 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-28 17:35:53,421 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-28 17:35:59,004 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-28 17:36:02,669 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-28 17:36:06,267 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-28 17:36:14,414 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-28 17:36:18,640 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-28 17:36:21,742 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-28 17:36:25,004 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-28 17:36:28,518 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-28 17:36:31,957 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-28 17:36:35,265 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-28 17:36:38,670 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-28 17:36:42,309 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-28 17:36:45,973 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-28 17:36:53,886 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-28 17:36:57,387 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-28 17:37:00,889 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-28 17:37:03,901 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-28 17:37:08,741 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-28 17:37:11,797 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-28 17:37:15,549 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-28 17:37:19,909 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-28 17:37:32,956 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-28 17:37:47,613 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-28 17:37:51,591 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-28 17:37:59,140 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-28 17:38:03,933 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-28 17:38:07,415 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-28 17:38:15,509 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-28 17:38:20,075 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-28 17:38:24,146 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-28 17:38:38,735 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-28 17:38:41,894 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-28 17:38:45,710 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-28 17:38:49,786 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-28 17:38:53,505 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-28 17:38:58,205 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-28 17:39:02,031 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-28 17:39:06,190 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-28 17:39:09,521 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-28 17:39:14,557 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-28 17:39:18,060 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-28 17:39:31,842 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-28 17:39:51,088 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-28 17:40:02,789 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-28 17:40:06,696 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-28 17:40:10,118 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-28 17:40:24,593 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-28 17:40:28,308 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-28 17:40:37,143 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-28 17:40:41,060 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-28 17:40:59,911 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-28 17:41:19,363 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-28 17:41:19,570 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-28 17:41:19,659 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-28 17:41:19.824149: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-28 17:41:19.827704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 17:41:19.831605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 17:41:19.831748: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:41:20.290008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-28 17:41:20.290081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-28 17:41:20.290096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-28 17:41:20.292984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-28 17:41:22,312 - train -  number of examples: 4800
        2022-02-28 17:41:22,698 - train -  number of examples: 1200
        2022-02-28 17:41:26,203 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/28 17:41:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='20' for run ID='fe8
        1d71c52404ed790b3a32051258da9'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-28 17:41:34.119597: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-28 17:41:34.266024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-28 17:41:42.993902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 17:41:43.305956: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-28 17:41:43.787015: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 17:41:44.068827: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        240/240 [==============================] - 146s 532ms/step - loss: 0.8392 - tp0.1: 8747285.0000 - fp0.1: 10445142.0000 - tn0.1: 57962008.0000 - fn0.1: 1488778.0000 - precision0.1: 0.4558 - recall0.1: 0.8546 - tp0.3: 7896000.0000 - fp0.3
        : 5233157.0000 - tn0.3: 63173976.0000 - fn0.3: 2340063.0000 - precision0.3: 0.6014 - recall0.3: 0.7714 - tp0.5: 6575708.0000 - fp0.5: 2263621.0000 - tn0.5: 66143520.0000 - fn0.5: 3660355.0000 - precision0.5: 0.7439 - recall0.5: 0.6424 -
         tp0.7: 5154156.0000 - fp0.7: 920133.0000 - tn0.7: 67487000.0000 - fn0.7: 5081907.0000 - precision0.7: 0.8485 - recall0.7: 0.5035 - tp0.9: 3283109.0000 - fp0.9: 213358.0000 - tn0.9: 68193792.0000 - fn0.9: 6952954.0000 - precision0.9: 0.
        9390 - recall0.9: 0.3207 - accuracy: 0.9247 - auc: 0.9073 - f1: 0.6894 - val_loss: 1.7768 - val_tp0.1: 2543119.0000 - val_fp0.1: 9378664.0000 - val_tn0.1: 7559641.0000 - val_fn0.1: 179376.0000 - val_precision0.1: 0.2133 - val_recall0.1:
         0.9341 - val_tp0.3: 2504900.0000 - val_fp0.3: 7161614.0000 - val_tn0.3: 9776691.0000 - val_fn0.3: 217595.0000 - val_precision0.3: 0.2591 - val_recall0.3: 0.9201 - val_tp0.5: 2470794.0000 - val_fp0.5: 5614724.0000 - val_tn0.5: 11323581.
        0000 - val_fn0.5: 251701.0000 - val_precision0.5: 0.3056 - val_recall0.5: 0.9075 - val_tp0.7: 2416278.0000 - val_fp0.7: 4187348.0000 - val_tn0.7: 12750957.0000 - val_fn0.7: 306217.0000 - val_precision0.7: 0.3659 - val_recall0.7: 0.8875
        - val_tp0.9: 2331726.0000 - val_fp0.9: 2968486.0000 - val_tn0.9: 13969819.0000 - val_fn0.9: 390769.0000 - val_precision0.9: 0.4399 - val_recall0.9: 0.8565 - val_accuracy: 0.7016 - val_auc: 0.8807 - val_f1: 0.4572

        ...

        Epoch 100/100
        240/240 [==============================] - 124s 515ms/step - loss: 0.0941 - tp0.1: 10073753.0000 - fp0.1: 1908290.0000 - tn0.1: 66498824.0000 - fn0.1: 162310.0000 - precision0.1: 0.8407 - recall0.1: 0.9841 - tp0.3: 9929412.0000 - fp0.3:
         1163791.0000 - tn0.3: 67243336.0000 - fn0.3: 306651.0000 - precision0.3: 0.8951 - recall0.3: 0.9700 - tp0.5: 9693885.0000 - fp0.5: 672284.0000 - tn0.5: 67734840.0000 - fn0.5: 542178.0000 - precision0.5: 0.9351 - recall0.5: 0.9470 - tp0
        .7: 9345709.0000 - fp0.7: 339542.0000 - tn0.7: 68067608.0000 - fn0.7: 890354.0000 - precision0.7: 0.9649 - recall0.7: 0.9130 - tp0.9: 8608433.0000 - fp0.9: 86583.0000 - tn0.9: 68320560.0000 - fn0.9: 1627630.0000 - precision0.9: 0.9900 -
         recall0.9: 0.8410 - accuracy: 0.9846 - auc: 0.9912 - f1: 0.9411 - val_loss: 0.1372 - val_tp0.1: 2648989.0000 - val_fp0.1: 600014.0000 - val_tn0.1: 16338291.0000 - val_fn0.1: 73506.0000 - val_precision0.1: 0.8153 - val_recall0.1: 0.9730
         - val_tp0.3: 2604739.0000 - val_fp0.3: 372047.0000 - val_tn0.3: 16566258.0000 - val_fn0.3: 117756.0000 - val_precision0.3: 0.8750 - val_recall0.3: 0.9567 - val_tp0.5: 2542400.0000 - val_fp0.5: 225996.0000 - val_tn0.5: 16712309.0000 - v
        al_fn0.5: 180095.0000 - val_precision0.5: 0.9184 - val_recall0.5: 0.9338 - val_tp0.7: 2459692.0000 - val_fp0.7: 126768.0000 - val_tn0.7: 16811536.0000 - val_fn0.7: 262803.0000 - val_precision0.7: 0.9510 - val_recall0.7: 0.9035 - val_tp0
        .9: 2288921.0000 - val_fp0.9: 43449.0000 - val_tn0.9: 16894856.0000 - val_fn0.9: 433574.0000 - val_precision0.9: 0.9814 - val_recall0.9: 0.8407 - val_accuracy: 0.9793 - val_auc: 0.9849 - val_f1: 0.9260
        2022-02-28 21:13:24.522272: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 21:13:37 INFO mlflow.projects: === Run (ID 'fe81d71c52404ed790b3a32051258da9') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =fe81d71c52404ed790b3a32051258da9=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9184 - val_recall0.5: 0.9338 - val_f10.5: 0.9260
        - val_auc: 0.9849

   4. run training of =(00f2635d9fa2463c9a066722163405be,
      d0a8e1748b194f3290d471b6b44f19f8)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=28 \
               -P first_filters=6 \
               -P input_size=14000 \
               -P lr_start=0.0553313915596308 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=minmax \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 01:02:32 INFO mlflow.projects.utils: === Created directory /tmp/tmpscsw8dai for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 01:02:32 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 28 --input_size 14000 --lr_start 0.0553313915596308 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler minmax --n_levels 5 --first_filters 6 --pool_size 4' in run with ID 'ff67be0b68e540a9a29a36a2d0c7a5be' ===
        2022-03-01 01:02:49.062309: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:03:02,012 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 01:03:02,013 - train -  Tensorflow version: 2.5.0
        2022-03-01 01:03:02,013 - train -  tf.keras version: 2.5.0
        2022-03-01 01:03:02,013 - train -  Cudnn version: 8
        2022-03-01 01:03:02,013 - train -  Cuda version: 11.2
        2022-03-01 01:03:02.017849: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 01:03:02.070568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 01:03:02.070675: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:03:02.081043: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 01:03:02.081139: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 01:03:02.085346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 01:03:02.088350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 01:03:02.097715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 01:03:02.100867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 01:03:02.103117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 01:03:02.106443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 01:03:02,106 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 01:03:02,107 - train -  Setting memory growth successful.
        2022-03-01 01:03:08,710 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 01:03:17,500 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 01:03:21,523 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 01:03:25,810 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 01:03:29,726 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 01:03:35,702 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 01:03:39,927 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 01:03:44,978 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 01:03:49,851 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 01:03:54,065 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 01:03:57,914 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 01:04:09,148 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 01:04:14,246 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 01:04:17,776 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 01:04:24,334 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 01:04:28,494 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 01:04:31,978 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 01:04:35,535 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 01:04:39,104 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 01:04:42,753 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 01:04:46,786 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 01:04:50,549 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 01:05:10,273 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 01:05:14,332 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 01:05:17,829 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 01:05:29,382 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 01:05:32,892 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 01:05:37,614 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 01:05:41,478 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 01:05:55,816 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 01:06:06,797 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 01:06:10,595 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 01:06:15,368 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 01:06:20,784 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 01:06:26,970 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 01:06:31,521 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 01:06:35,363 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 01:06:39,107 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 01:07:01,475 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 01:07:05,191 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 01:07:08,941 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 01:07:13,043 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 01:07:16,874 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 01:07:20,478 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 01:07:24,571 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 01:07:28,090 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 01:07:31,811 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 01:07:35,574 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 01:07:39,526 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 01:07:49,139 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 01:08:06,079 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 01:08:17,384 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 01:08:21,021 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 01:08:24,646 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 01:08:33,131 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 01:08:37,919 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 01:08:41,923 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 01:08:45,386 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 01:08:50,064 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 01:08:54,537 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 01:08:54,754 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 01:08:54,844 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 01:08:54.997694: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 01:08:55.000062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 01:08:55.002040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 01:08:55.002135: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:08:55.428415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 01:08:55.428487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 01:08:55.428501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 01:08:55.431349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 01:08:57,489 - train -  number of examples: 4800
        2022-03-01 01:08:57,859 - train -  number of examples: 1200
        2022-03-01 01:09:00,816 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 01:09:00 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='28' for run ID='ff6
        7be0b68e540a9a29a36a2d0c7a5be'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 01:09:09.470355: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 01:09:09.627221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 01:09:19.253073: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 01:09:19.568134: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 01:09:20.032500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 01:09:20.318967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        171/171 [==============================] - 38s 111ms/step - loss: 0.6328 - tp0.1: 9097064.0000 - fp0.1: 12967912.0000 - tn0.1: 55269208.0000 - fn0.1: 1112405.0000 - precision0.1: 0.4123 - recall0.1: 0.8910 - tp0.3: 8278749.0000 - fp0.3:
         7308225.0000 - tn0.3: 60928896.0000 - fn0.3: 1930720.0000 - precision0.3: 0.5311 - recall0.3: 0.8109 - tp0.5: 6546144.0000 - fp0.5: 2745102.0000 - tn0.5: 65492008.0000 - fn0.5: 3663325.0000 - precision0.5: 0.7045 - recall0.5: 0.6412 -
        tp0.7: 5069917.0000 - fp0.7: 1036309.0000 - tn0.7: 67200816.0000 - fn0.7: 5139552.0000 - precision0.7: 0.8303 - recall0.7: 0.4966 - tp0.9: 2806365.0000 - fp0.9: 200542.0000 - tn0.9: 68036592.0000 - fn0.9: 7403104.0000 - precision0.9: 0.
        9333 - recall0.9: 0.2749 - accuracy: 0.9183 - auc: 0.9138 - f1: 0.6714 - val_loss: 100.5511 - val_tp0.1: 2677947.0000 - val_fp0.1: 16589637.0000 - val_tn0.1: 0.0000e+00 - val_fn0.1: 0.0000e+00 - val_precision0.1: 0.1390 - val_recall0.1:
         1.0000 - val_tp0.3: 2677947.0000 - val_fp0.3: 16589563.0000 - val_tn0.3: 74.0000 - val_fn0.3: 0.0000e+00 - val_precision0.3: 0.1390 - val_recall0.3: 1.0000 - val_tp0.5: 2677947.0000 - val_fp0.5: 16589315.0000 - val_tn0.5: 322.0000 - va
        l_fn0.5: 0.0000e+00 - val_precision0.5: 0.1390 - val_recall0.5: 1.0000 - val_tp0.7: 2677947.0000 - val_fp0.7: 16589042.0000 - val_tn0.7: 595.0000 - val_fn0.7: 0.0000e+00 - val_precision0.7: 0.1390 - val_recall0.7: 1.0000 - val_tp0.9: 26
        77947.0000 - val_fp0.9: 16588561.0000 - val_tn0.9: 1076.0000 - val_fn0.9: 0.0000e+00 - val_precision0.9: 0.1390 - val_recall0.9: 1.0000 - val_accuracy: 0.1390 - val_auc: 0.5001 - val_f1: 0.2441

        ...

        Epoch 100/100
        171/171 [==============================] - 15s 89ms/step - loss: 0.0890 - tp0.1: 10079569.0000 - fp0.1: 1892418.0000 - tn0.1: 66332504.0000 - fn0.1: 142100.0000 - precision0.1: 0.8419 - recall0.1: 0.9861 - tp0.3: 9939857.0000 - fp0.3: 1
        140232.0000 - tn0.3: 67084692.0000 - fn0.3: 281812.0000 - precision0.3: 0.8971 - recall0.3: 0.9724 - tp0.5: 9703286.0000 - fp0.5: 647685.0000 - tn0.5: 67577248.0000 - fn0.5: 518383.0000 - precision0.5: 0.9374 - recall0.5: 0.9493 - tp0.7
        : 9385401.0000 - fp0.7: 340758.0000 - tn0.7: 67884160.0000 - fn0.7: 836268.0000 - precision0.7: 0.9650 - recall0.7: 0.9182 - tp0.9: 8688940.0000 - fp0.9: 89880.0000 - tn0.9: 68135024.0000 - fn0.9: 1532729.0000 - precision0.9: 0.9898 - r
        ecall0.9: 0.8501 - accuracy: 0.9851 - auc: 0.9922 - f1: 0.9433 - val_loss: 0.1286 - val_tp0.1: 2593533.0000 - val_fp0.1: 546329.0000 - val_tn0.1: 16060347.0000 - val_fn0.1: 67375.0000 - val_precision0.1: 0.8260 - val_recall0.1: 0.9747 -
         val_tp0.3: 2548361.0000 - val_fp0.3: 333669.0000 - val_tn0.3: 16273007.0000 - val_fn0.3: 112547.0000 - val_precision0.3: 0.8842 - val_recall0.3: 0.9577 - val_tp0.5: 2492439.0000 - val_fp0.5: 208035.0000 - val_tn0.5: 16398641.0000 - val
        _fn0.5: 168469.0000 - val_precision0.5: 0.9230 - val_recall0.5: 0.9367 - val_tp0.7: 2414912.0000 - val_fp0.7: 119511.0000 - val_tn0.7: 16487165.0000 - val_fn0.7: 245996.0000 - val_precision0.7: 0.9528 - val_recall0.7: 0.9076 - val_tp0.9
        : 2250009.0000 - val_fp0.9: 39723.0000 - val_tn0.9: 16566953.0000 - val_fn0.9: 410899.0000 - val_precision0.9: 0.9827 - val_recall0.9: 0.8456 - val_accuracy: 0.9805 - val_auc: 0.9859 - val_f1: 0.9298
        2022-03-01 01:40:07.449069: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 01:40:21 INFO mlflow.projects: === Run (ID 'ff67be0b68e540a9a29a36a2d0c7a5be') succeeded ===

      #+end_example

      - name of run: =ff67be0b68e540a9a29a36a2d0c7a5be=
      - metrics after 100th epoch:
        - loss: 0.0890 vs val_loss: 0.1286
        - val_precision0.5: 0.9230 - val_recall0.5: 0.9367 - val_f1: 0.9298
        - val_auc: 0.9859

   5. run training of =(5604d43c1ece461b8e6eaa0dfb65d6dc,
      3612536a77f34f22bc83d1d809140aa6)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=20 \
               -P first_filters=128 \
               -P input_size=14000 \
               -P lr_start=0.043549707353273 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=3 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 12:32:44 INFO mlflow.projects.utils: === Created directory /tmp/tmpuaqmbl4a for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 12:32:44 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 20 --input_size 14000 --lr_start 0.043549707353273 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_pa
        th_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 3 --first_filters 128 --pool_size 4' in run with ID '19e3e786e1bc4e2b93856f5dc9de8216' ===
        2022-03-01 12:32:58.514798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:33:09,490 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 12:33:09,490 - train -  Tensorflow version: 2.5.0
        2022-03-01 12:33:09,490 - train -  tf.keras version: 2.5.0
        2022-03-01 12:33:09,490 - train -  Cudnn version: 8
        2022-03-01 12:33:09,490 - train -  Cuda version: 11.2
        2022-03-01 12:33:09.493303: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 12:33:09.550241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 12:33:09.550350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:33:09.561190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 12:33:09.561299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 12:33:09.565126: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 12:33:09.567931: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 12:33:09.576981: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 12:33:09.597335: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 12:33:09.599375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 12:33:09.602568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 12:33:09,602 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 12:33:09,603 - train -  Setting memory growth successful.
        2022-03-01 12:33:15,918 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 12:33:19,510 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 12:33:23,436 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 12:33:27,059 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 12:33:31,773 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 12:33:35,876 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 12:33:39,462 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 12:33:42,942 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 12:33:46,757 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 12:33:51,064 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 12:33:56,528 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 12:34:00,572 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 12:34:04,069 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 12:34:07,965 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 12:34:18,633 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 12:34:21,910 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 12:34:25,641 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 12:34:30,386 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 12:34:34,226 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 12:34:37,740 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 12:34:43,348 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 12:34:46,797 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 12:34:50,435 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 12:34:54,778 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 12:34:58,764 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 12:35:02,693 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 12:35:15,387 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 12:35:19,459 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 12:35:23,164 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 12:35:27,345 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 12:35:30,844 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 12:35:34,995 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 12:35:38,565 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 12:35:43,358 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 12:35:48,209 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 12:35:52,885 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 12:35:57,900 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 12:36:01,708 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 12:36:05,386 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 12:36:09,008 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 12:36:13,039 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 12:36:16,946 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 12:36:20,517 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 12:36:24,115 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 12:36:27,768 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 12:36:32,136 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 12:36:36,005 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 12:36:39,799 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 12:36:43,465 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 12:36:47,166 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 12:36:50,897 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 12:36:56,421 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 12:36:59,926 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 12:37:03,654 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 12:37:07,675 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 12:37:11,784 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 12:37:18,953 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 12:37:22,467 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 12:37:26,203 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 12:37:31,518 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 12:37:31,732 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 12:37:31,822 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 12:37:32.029003: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 12:37:32.031379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 12:37:32.033418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 12:37:32.033500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:37:32.469006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 12:37:32.469079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 12:37:32.469093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 12:37:32.471972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 12:37:34,440 - train -  number of examples: 4800
        2022-03-01 12:37:34,767 - train -  number of examples: 1200
        2022-03-01 12:37:36,587 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 12:37:36 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='20' for run ID='19e
        3e786e1bc4e2b93856f5dc9de8216'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 12:37:44.731191: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 12:37:44.863807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 12:37:53.275302: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 12:37:53.580058: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 12:37:54.077952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 12:37:54.363640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        240/240 [==============================] - 220s 838ms/step - loss: 1.1221 - tp0.1: 8540565.0000 - fp0.1: 11192430.0000 - tn0.1: 57214708.0000 - fn0.1: 1695498.0000 - precision0.1: 0.4328 - recall0.1: 0.8344 - tp0.3: 7522117.0000 - fp0.3
        : 4392113.0000 - tn0.3: 64015032.0000 - fn0.3: 2713946.0000 - precision0.3: 0.6314 - recall0.3: 0.7349 - tp0.5: 6672931.0000 - fp0.5: 2324779.0000 - tn0.5: 66082352.0000 - fn0.5: 3563132.0000 - precision0.5: 0.7416 - recall0.5: 0.6519 -
         tp0.7: 5275458.0000 - fp0.7: 916716.0000 - tn0.7: 67490392.0000 - fn0.7: 4960605.0000 - precision0.7: 0.8520 - recall0.7: 0.5154 - tp0.9: 3246371.0000 - fp0.9: 199829.0000 - tn0.9: 68207312.0000 - fn0.9: 6989692.0000 - precision0.9: 0.
        9420 - recall0.9: 0.3172 - accuracy: 0.9251 - auc: 0.9067 - f1: 0.6939 - val_loss: 1.4857 - val_tp0.1: 978503.0000 - val_fp0.1: 435953.0000 - val_tn0.1: 16502352.0000 - val_fn0.1: 1743992.0000 - val_precision0.1: 0.6918 - val_recall0.1:
         0.3594 - val_tp0.3: 873592.0000 - val_fp0.3: 222905.0000 - val_tn0.3: 16715400.0000 - val_fn0.3: 1848903.0000 - val_precision0.3: 0.7967 - val_recall0.3: 0.3209 - val_tp0.5: 816820.0000 - val_fp0.5: 140072.0000 - val_tn0.5: 16798232.00
        00 - val_fn0.5: 1905675.0000 - val_precision0.5: 0.8536 - val_recall0.5: 0.3000 - val_tp0.7: 747818.0000 - val_fp0.7: 84156.0000 - val_tn0.7: 16854148.0000 - val_fn0.7: 1974677.0000 - val_precision0.7: 0.8988 - val_recall0.7: 0.2747 - v
        al_tp0.9: 619063.0000 - val_fp0.9: 32598.0000 - val_tn0.9: 16905708.0000 - val_fn0.9: 2103432.0000 - val_precision0.9: 0.9500 - val_recall0.9: 0.2274 - val_accuracy: 0.8959 - val_auc: 0.7267 - val_f1: 0.4440

        ...

        Epoch 100/100
        240/240 [==============================] - 197s 821ms/step - loss: 0.0929 - tp0.1: 10067403.0000 - fp0.1: 1713493.0000 - tn0.1: 66693648.0000 - fn0.1: 168660.0000 - precision0.1: 0.8546 - recall0.1: 0.9835 - tp0.3: 9949382.0000 - fp0.3:
         1087364.0000 - tn0.3: 67319792.0000 - fn0.3: 286681.0000 - precision0.3: 0.9015 - recall0.3: 0.9720 - tp0.5: 9760046.0000 - fp0.5: 690436.0000 - tn0.5: 67716696.0000 - fn0.5: 476017.0000 - precision0.5: 0.9339 - recall0.5: 0.9535 - tp0
        .7: 9431582.0000 - fp0.7: 374056.0000 - tn0.7: 68033088.0000 - fn0.7: 804481.0000 - precision0.7: 0.9619 - recall0.7: 0.9214 - tp0.9: 8660415.0000 - fp0.9: 112381.0000 - tn0.9: 68294768.0000 - fn0.9: 1575648.0000 - precision0.9: 0.9872
        - recall0.9: 0.8461 - accuracy: 0.9852 - auc: 0.9906 - f1: 0.9436 - val_loss: 0.2611 - val_tp0.1: 2521251.0000 - val_fp0.1: 602159.0000 - val_tn0.1: 16336146.0000 - val_fn0.1: 201244.0000 - val_precision0.1: 0.8072 - val_recall0.1: 0.92
        61 - val_tp0.3: 2463263.0000 - val_fp0.3: 387212.0000 - val_tn0.3: 16551093.0000 - val_fn0.3: 259232.0000 - val_precision0.3: 0.8642 - val_recall0.3: 0.9048 - val_tp0.5: 2406415.0000 - val_fp0.5: 272305.0000 - val_tn0.5: 16666000.0000 -
         val_fn0.5: 316080.0000 - val_precision0.5: 0.8983 - val_recall0.5: 0.8839 - val_tp0.7: 2314277.0000 - val_fp0.7: 168490.0000 - val_tn0.7: 16769815.0000 - val_fn0.7: 408218.0000 - val_precision0.7: 0.9321 - val_recall0.7: 0.8501 - val_t
        p0.9: 2130323.0000 - val_fp0.9: 72929.0000 - val_tn0.9: 16865376.0000 - val_fn0.9: 592172.0000 - val_precision0.9: 0.9669 - val_recall0.9: 0.7825 - val_accuracy: 0.9701 - val_auc: 0.9595 - val_f1: 0.8911
        2022-03-01 18:11:37.935237: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 18:11:48 INFO mlflow.projects: === Run (ID '19e3e786e1bc4e2b93856f5dc9de8216') succeeded ===

      #+end_example

      - name of run: =19e3e786e1bc4e2b93856f5dc9de8216=
      - metrics after 100th epoch:
        - val_precision0.5: 0.8983 - val_recall0.5: 0.8839 - val_f10.5: 0.8911
        - val_auc: 0.9595

   6. run training of =(7cafab027cdd4fc9bf20a43e989df510,
      16dff15d935f45e2a836b1f41b07b4e3)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=10 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0627676336651573 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=robust \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 19:36:22 INFO mlflow.projects.utils: === Created directory /tmp/tmpzbcp4g1j for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 19:36:22 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 10 --input_size 14000 --lr_start 0.0627676336651573 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler robust --n_levels 5 --first_filters 16 --pool_size 4' in run with ID '347669d050f344ad9fb9e480c814f727' ===
        2022-03-01 19:36:34.348943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:36:46,433 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 19:36:46,434 - train -  Tensorflow version: 2.5.0
        2022-03-01 19:36:46,434 - train -  tf.keras version: 2.5.0
        2022-03-01 19:36:46,434 - train -  Cudnn version: 8
        2022-03-01 19:36:46,434 - train -  Cuda version: 11.2
        2022-03-01 19:36:46.437417: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 19:36:46.506267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 19:36:46.506409: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:36:46.516098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 19:36:46.516211: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 19:36:46.519627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 19:36:46.522117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 19:36:46.531350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 19:36:46.534380: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 19:36:46.536313: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 19:36:46.539533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 19:36:46,539 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 19:36:46,540 - train -  Setting memory growth successful.
        2022-03-01 19:36:53,495 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 19:36:59,518 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 19:37:03,152 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 19:37:06,774 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 19:37:10,319 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 19:37:16,051 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 19:37:20,347 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 19:37:28,839 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 19:37:32,240 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 19:37:36,494 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 19:37:40,435 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 19:37:45,646 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 19:37:49,090 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 19:37:53,145 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 19:37:56,818 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 19:38:00,166 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 19:38:03,643 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 19:38:07,281 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 19:38:10,928 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 19:38:14,614 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 19:38:18,136 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 19:38:21,832 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 19:38:27,731 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 19:38:31,406 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 19:38:34,819 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 19:38:38,249 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 19:38:41,695 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 19:38:45,025 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 19:38:48,758 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 19:38:52,913 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 19:38:56,358 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 19:39:00,987 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 19:39:04,634 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 19:39:08,400 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 19:39:11,867 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 19:39:15,951 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 19:39:19,638 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 19:39:23,207 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 19:39:30,739 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 19:39:34,471 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 19:39:38,619 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 19:39:42,300 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 19:39:45,973 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 19:39:49,635 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 19:39:53,835 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 19:39:57,292 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 19:40:01,084 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 19:40:04,949 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 19:40:08,522 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 19:40:11,907 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 19:40:15,721 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 19:40:19,221 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 19:40:22,982 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 19:40:26,520 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 19:40:30,083 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 19:40:33,515 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 19:40:36,862 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 19:40:40,692 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 19:40:44,478 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 19:40:47,736 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 19:40:47,939 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 19:40:48,032 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 19:40:48.195482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 19:40:48.198562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 19:40:48.200594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 19:40:48.200695: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:40:48.635293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 19:40:48.635366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 19:40:48.635382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 19:40:48.638373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 19:40:51,863 - train -  number of examples: 4800
        2022-03-01 19:40:52,254 - train -  number of examples: 1200
        2022-03-01 19:40:54,716 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 19:40:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='10' for run ID='347
        669d050f344ad9fb9e480c814f727'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 19:41:04.464586: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 19:41:04.627492: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 19:41:14.720330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 19:41:15.055044: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 19:41:15.546433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 19:41:15.832893: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        480/480 [==============================] - 60s 82ms/step - loss: 0.5773 - tp0.1: 8880905.0000 - fp0.1: 10094803.0000 - tn0.1: 58312352.0000 - fn0.1: 1355158.0000 - precision0.1: 0.4680 - recall0.1: 0.8676 - tp0.3: 7871045.0000 - fp0.3:
        4514511.0000 - tn0.3: 63892572.0000 - fn0.3: 2365018.0000 - precision0.3: 0.6355 - recall0.3: 0.7690 - tp0.5: 6608273.0000 - fp0.5: 1693677.0000 - tn0.5: 66713460.0000 - fn0.5: 3627790.0000 - precision0.5: 0.7960 - recall0.5: 0.6456 - t
        p0.7: 5575527.0000 - fp0.7: 626556.0000 - tn0.7: 67780600.0000 - fn0.7: 4660536.0000 - precision0.7: 0.8990 - recall0.7: 0.5447 - tp0.9: 4341516.0000 - fp0.9: 163073.0000 - tn0.9: 68244088.0000 - fn0.9: 5894547.0000 - precision0.9: 0.96
        38 - recall0.9: 0.4241 - accuracy: 0.9323 - auc: 0.9124 - f1: 0.7129 - val_loss: 0.6884 - val_tp0.1: 2348236.0000 - val_fp0.1: 3299237.0000 - val_tn0.1: 13639068.0000 - val_fn0.1: 374259.0000 - val_precision0.1: 0.4158 - val_recall0.1:
        0.8625 - val_tp0.3: 2180062.0000 - val_fp0.3: 2146157.0000 - val_tn0.3: 14792148.0000 - val_fn0.3: 542433.0000 - val_precision0.3: 0.5039 - val_recall0.3: 0.8008 - val_tp0.5: 1966718.0000 - val_fp0.5: 1074503.0000 - val_tn0.5: 15863802.
        0000 - val_fn0.5: 755777.0000 - val_precision0.5: 0.6467 - val_recall0.5: 0.7224 - val_tp0.7: 1647155.0000 - val_fp0.7: 270297.0000 - val_tn0.7: 16668008.0000 - val_fn0.7: 1075340.0000 - val_precision0.7: 0.8590 - val_recall0.7: 0.6050
        - val_tp0.9: 1346781.0000 - val_fp0.9: 48532.0000 - val_tn0.9: 16889772.0000 - val_fn0.9: 1375714.0000 - val_precision0.9: 0.9652 - val_recall0.9: 0.4947 - val_accuracy: 0.9069 - val_auc: 0.8983 - val_f1: 0.6824

        ...

        Epoch 100/100
        480/480 [==============================] - 36s 75ms/step - loss: 0.0973 - tp0.1: 10083866.0000 - fp0.1: 2150370.0000 - tn0.1: 66256776.0000 - fn0.1: 152197.0000 - precision0.1: 0.8242 - recall0.1: 0.9851 - tp0.3: 9911194.0000 - fp0.3: 1
        217280.0000 - tn0.3: 67189872.0000 - fn0.3: 324869.0000 - precision0.3: 0.8906 - recall0.3: 0.9683 - tp0.5: 9675199.0000 - fp0.5: 716243.0000 - tn0.5: 67690904.0000 - fn0.5: 560864.0000 - precision0.5: 0.9311 - recall0.5: 0.9452 - tp0.7
        : 9261235.0000 - fp0.7: 330050.0000 - tn0.7: 68077096.0000 - fn0.7: 974828.0000 - precision0.7: 0.9656 - recall0.7: 0.9048 - tp0.9: 8585163.0000 - fp0.9: 94613.0000 - tn0.9: 68312512.0000 - fn0.9: 1650900.0000 - precision0.9: 0.9891 - r
        ecall0.9: 0.8387 - accuracy: 0.9838 - auc: 0.9915 - f1: 0.9381 - val_loss: 0.1400 - val_tp0.1: 2648521.0000 - val_fp0.1: 631749.0000 - val_tn0.1: 16306556.0000 - val_fn0.1: 73974.0000 - val_precision0.1: 0.8074 - val_recall0.1: 0.9728 -
         val_tp0.3: 2586061.0000 - val_fp0.3: 344848.0000 - val_tn0.3: 16593457.0000 - val_fn0.3: 136434.0000 - val_precision0.3: 0.8823 - val_recall0.3: 0.9499 - val_tp0.5: 2514973.0000 - val_fp0.5: 202882.0000 - val_tn0.5: 16735423.0000 - val
        _fn0.5: 207522.0000 - val_precision0.5: 0.9254 - val_recall0.5: 0.9238 - val_tp0.7: 2409626.0000 - val_fp0.7: 97831.0000 - val_tn0.7: 16840474.0000 - val_fn0.7: 312869.0000 - val_precision0.7: 0.9610 - val_recall0.7: 0.8851 - val_tp0.9:
         2228029.0000 - val_fp0.9: 30092.0000 - val_tn0.9: 16908212.0000 - val_fn0.9: 494466.0000 - val_precision0.9: 0.9867 - val_recall0.9: 0.8184 - val_accuracy: 0.9791 - val_auc: 0.9848 - val_f1: 0.9246
        2022-03-01 20:46:33.038541: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 20:46:47 INFO mlflow.projects: === Run (ID '347669d050f344ad9fb9e480c814f727') succeeded ===

      #+end_example

      - name of run: =347669d050f344ad9fb9e480c814f727=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9254 - val_recall0.5: 0.9238 - val_f10.5: 0.9246
        - val_auc: 0.9848

   7. run training of =(0e328920e86049928202db95e8cfb7be,
      bf9d2725eb16462d9a101f0a077ce2b5)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=14 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0192390310290551 \
               -P lr_power=5 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=robust \
               -P n_levels=9 \
               -P pool_size=2
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 22:12:06 INFO mlflow.projects.utils: === Created directory /tmp/tmpgcmidltj for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 22:12:06 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 14 --input_size 14000 --lr_start 0.0192390310290551 --lr_power 5 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler robust --n_levels 9 --first_filters 16 --pool_size 2' in run with ID 'c1204e3a8a1e4c40a35b5b7b1922d1ce' ===
        2022-03-01 22:12:20.335142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:12:33,450 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 22:12:33,451 - train -  Tensorflow version: 2.5.0
        2022-03-01 22:12:33,451 - train -  tf.keras version: 2.5.0
        2022-03-01 22:12:33,451 - train -  Cudnn version: 8
        2022-03-01 22:12:33,451 - train -  Cuda version: 11.2
        2022-03-01 22:12:33.453876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 22:12:33.508402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 22:12:33.508543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:12:33.518297: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 22:12:33.518392: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 22:12:33.521775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 22:12:33.523563: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 22:12:33.532074: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 22:12:33.534870: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 22:12:33.536502: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 22:12:33.539631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 22:12:33,539 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 22:12:33,540 - train -  Setting memory growth successful.
        2022-03-01 22:12:39,562 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 22:12:42,849 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 22:12:46,207 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 22:12:50,855 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 22:12:55,527 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 22:12:58,713 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 22:13:02,325 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 22:13:05,461 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 22:13:08,927 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 22:13:14,609 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 22:13:17,983 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 22:13:21,031 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 22:13:24,219 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 22:13:27,321 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 22:13:30,784 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 22:13:34,829 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 22:13:38,078 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 22:13:41,302 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 22:13:45,845 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 22:13:49,546 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 22:13:53,591 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 22:13:56,776 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 22:14:00,326 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 22:14:03,666 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 22:14:06,840 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 22:14:12,440 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 22:14:15,561 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 22:14:18,839 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 22:14:22,240 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 22:14:25,355 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 22:14:28,483 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 22:14:31,960 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 22:14:35,186 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 22:14:38,725 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 22:14:42,022 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 22:14:45,344 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 22:14:48,717 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 22:14:52,459 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 22:14:57,077 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 22:15:00,330 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 22:15:03,675 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 22:15:07,194 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 22:15:10,373 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 22:15:13,913 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 22:15:17,100 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 22:15:20,452 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 22:15:23,646 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 22:15:27,210 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 22:15:31,036 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 22:15:35,097 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 22:15:38,379 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 22:15:41,484 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 22:15:44,853 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 22:15:50,250 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 22:15:54,918 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 22:15:58,298 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 22:16:02,901 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 22:16:06,154 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 22:16:09,817 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 22:16:12,969 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 22:16:13,193 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 22:16:13,282 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 22:16:13.549849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 22:16:13.552236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 22:16:13.554196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 22:16:13.554316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:16:13.976589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 22:16:13.976661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 22:16:13.976674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 22:16:13.979482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 22:16:15,961 - train -  number of examples: 4800
        2022-03-01 22:16:16,380 - train -  number of examples: 1200
        2022-03-01 22:16:19,293 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 22:16:19 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='14' for run ID='c12
        04e3a8a1e4c40a35b5b7b1922d1ce'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 22:16:30.776559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 22:16:30.983303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 22:16:42.127026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 22:16:42.439526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 22:16:42.928881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 22:16:43.210835: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        342/342 [==============================] - 124s 292ms/step - loss: 0.7070 - tp0.1: 8568535.0000 - fp0.1: 13083853.0000 - tn0.1: 55158168.0000 - fn0.1: 1636041.0000 - precision0.1: 0.3957 - recall0.1: 0.8397 - tp0.3: 6954119.0000 - fp0.3
        : 4121236.0000 - tn0.3: 64120780.0000 - fn0.3: 3250457.0000 - precision0.3: 0.6279 - recall0.3: 0.6815 - tp0.5: 5914618.0000 - fp0.5: 1373295.0000 - tn0.5: 66868700.0000 - fn0.5: 4289958.0000 - precision0.5: 0.8116 - recall0.5: 0.5796 -
         tp0.7: 5157583.0000 - fp0.7: 495656.0000 - tn0.7: 67746344.0000 - fn0.7: 5046993.0000 - precision0.7: 0.9123 - recall0.7: 0.5054 - tp0.9: 4126657.0000 - fp0.9: 91030.0000 - tn0.9: 68151000.0000 - fn0.9: 6077919.0000 - precision0.9: 0.9
        784 - recall0.9: 0.4044 - accuracy: 0.9278 - auc: 0.8844 - f1: 0.6762 - val_loss: 0.6968 - val_tp0.1: 2338956.0000 - val_fp0.1: 2679424.0000 - val_tn0.1: 14116949.0000 - val_fn0.1: 361631.0000 - val_precision0.1: 0.4661 - val_recall0.1:
         0.8661 - val_tp0.3: 2156286.0000 - val_fp0.3: 1498035.0000 - val_tn0.3: 15298338.0000 - val_fn0.3: 544301.0000 - val_precision0.3: 0.5901 - val_recall0.3: 0.7985 - val_tp0.5: 1886303.0000 - val_fp0.5: 688918.0000 - val_tn0.5: 16107455.
        0000 - val_fn0.5: 814284.0000 - val_precision0.5: 0.7325 - val_recall0.5: 0.6985 - val_tp0.7: 1720047.0000 - val_fp0.7: 358918.0000 - val_tn0.7: 16437455.0000 - val_fn0.7: 980540.0000 - val_precision0.7: 0.8274 - val_recall0.7: 0.6369 -
         val_tp0.9: 1536712.0000 - val_fp0.9: 146022.0000 - val_tn0.9: 16650351.0000 - val_fn0.9: 1163875.0000 - val_precision0.9: 0.9132 - val_recall0.9: 0.5690 - val_accuracy: 0.9229 - val_auc: 0.9057 - val_f1: 0.7151

        ...

        Epoch 100/100
        342/342 [==============================] - 96s 282ms/step - loss: 0.1201 - tp0.1: 9816720.0000 - fp0.1: 2613299.0000 - tn0.1: 65809824.0000 - fn0.1: 206742.0000 - precision0.1: 0.7898 - recall0.1: 0.9794 - tp0.3: 9593189.0000 - fp0.3: 1
        365697.0000 - tn0.3: 67057408.0000 - fn0.3: 430273.0000 - precision0.3: 0.8754 - recall0.3: 0.9571 - tp0.5: 9310282.0000 - fp0.5: 760248.0000 - tn0.5: 67662912.0000 - fn0.5: 713180.0000 - precision0.5: 0.9245 - recall0.5: 0.9288 - tp0.7
        : 8896402.0000 - fp0.7: 359466.0000 - tn0.7: 68063680.0000 - fn0.7: 1127060.0000 - precision0.7: 0.9612 - recall0.7: 0.8876 - tp0.9: 8125429.0000 - fp0.9: 93565.0000 - tn0.9: 68329576.0000 - fn0.9: 1898033.0000 - precision0.9: 0.9886 -
        recall0.9: 0.8106 - accuracy: 0.9812 - auc: 0.9882 - f1: 0.9267 - val_loss: 0.1429 - val_tp0.1: 2631773.0000 - val_fp0.1: 731922.0000 - val_tn0.1: 16067311.0000 - val_fn0.1: 65954.0000 - val_precision0.1: 0.7824 - val_recall0.1: 0.9756
        - val_tp0.3: 2571221.0000 - val_fp0.3: 390541.0000 - val_tn0.3: 16408692.0000 - val_fn0.3: 126506.0000 - val_precision0.3: 0.8681 - val_recall0.3: 0.9531 - val_tp0.5: 2491171.0000 - val_fp0.5: 222824.0000 - val_tn0.5: 16576409.0000 - va
        l_fn0.5: 206556.0000 - val_precision0.5: 0.9179 - val_recall0.5: 0.9234 - val_tp0.7: 2379767.0000 - val_fp0.7: 112408.0000 - val_tn0.7: 16686825.0000 - val_fn0.7: 317960.0000 - val_precision0.7: 0.9549 - val_recall0.7: 0.8821 - val_tp0.
        9: 2166171.0000 - val_fp0.9: 33767.0000 - val_tn0.9: 16765466.0000 - val_fn0.9: 531556.0000 - val_precision0.9: 0.9847 - val_recall0.9: 0.8030 - val_accuracy: 0.9780 -
        2022-03-02 01:02:37.643121: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/02 01:03:00 INFO mlflow.projects: === Run (ID 'c1204e3a8a1e4c40a35b5b7b1922d1ce') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =c1204e3a8a1e4c40a35b5b7b1922d1ce=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9179 - val_recall0.5: 0.9234 - val_f1: 0.9207
        - val_auc: 0.9858

   8. run training of =(3cbd945b62ec4634839372e403f6f377,
      458b36a70db843719d202a8eda448f17)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=9 \
               -P first_filters=64 \
               -P input_size=14000 \
               -P lr_start=0.0100697459464075 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=maxabs \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/02 01:11:44 INFO mlflow.projects.utils: === Created directory /tmp/tmpx4epxfnm for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/02 01:11:44 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 9 --input_size 14000 --lr_start 0.0100697459464075 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_pa
        th_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler maxabs --n_levels 5 --first_filters 64 --pool_size 4' in run with ID '714af8cd12c1441eac4ca980e8c20070' ===
        2022-03-02 01:11:56.803319: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:12:07,546 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-02 01:12:07,546 - train -  Tensorflow version: 2.5.0
        2022-03-02 01:12:07,546 - train -  tf.keras version: 2.5.0
        2022-03-02 01:12:07,547 - train -  Cudnn version: 8
        2022-03-02 01:12:07,547 - train -  Cuda version: 11.2
        2022-03-02 01:12:07.550455: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-02 01:12:07.628356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-02 01:12:07.628511: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:12:07.638859: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-02 01:12:07.638985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-02 01:12:07.643056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-02 01:12:07.646183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-02 01:12:07.656023: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-02 01:12:07.659075: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-02 01:12:07.661143: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-02 01:12:07.664383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-02 01:12:07,664 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-02 01:12:07,665 - train -  Setting memory growth successful.
        2022-03-02 01:12:13,856 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-02 01:12:17,659 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-02 01:12:21,236 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-02 01:12:24,720 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-02 01:12:27,968 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-02 01:12:31,066 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-02 01:12:34,437 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-02 01:12:37,504 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-02 01:12:42,706 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-02 01:12:46,132 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-02 01:12:49,635 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-02 01:12:53,763 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-02 01:12:57,006 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-02 01:13:00,289 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-02 01:13:03,628 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-02 01:13:07,750 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-02 01:13:11,178 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-02 01:13:14,491 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-02 01:13:17,835 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-02 01:13:21,243 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-02 01:13:24,830 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-02 01:13:28,194 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-02 01:13:31,658 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-02 01:13:35,112 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-02 01:13:38,261 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-02 01:13:41,634 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-02 01:13:44,894 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-02 01:13:48,172 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-02 01:13:51,792 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-02 01:13:55,890 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-02 01:13:59,226 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-02 01:14:03,473 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-02 01:14:06,889 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-02 01:14:11,194 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-02 01:14:14,602 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-02 01:14:18,195 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-02 01:14:23,874 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-02 01:14:27,349 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-02 01:14:30,931 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-02 01:14:39,147 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-02 01:14:42,631 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-02 01:14:46,112 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-02 01:14:49,382 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-02 01:14:54,801 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-02 01:14:58,059 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-02 01:15:01,699 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-02 01:15:04,960 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-02 01:15:08,548 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-02 01:15:11,862 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-02 01:15:15,127 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-02 01:15:18,793 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-02 01:15:24,397 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-02 01:15:27,879 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-02 01:15:31,270 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-02 01:15:34,589 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-02 01:15:38,546 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-02 01:15:42,044 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-02 01:15:45,426 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-02 01:15:49,033 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-02 01:15:52,325 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-02 01:15:52,527 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-02 01:15:52,616 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-02 01:15:52.773335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-02 01:15:52.775655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-02 01:15:52.777670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-02 01:15:52.777752: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:15:53.202763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-02 01:15:53.202835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-02 01:15:53.202850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-02 01:15:53.205744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-02 01:15:55,214 - train -  number of examples: 4800
        2022-03-02 01:15:55,624 - train -  number of examples: 1200
        2022-03-02 01:15:57,731 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/02 01:15:57 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='9' for run ID='714a
        f8cd12c1441eac4ca980e8c20070'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-02 01:16:06.204044: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-02 01:16:06.363399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-02 01:16:14.227408: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-02 01:16:14.534785: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-02 01:16:15.007638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-02 01:16:15.294778: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        533/533 [==============================] - 129s 209ms/step - loss: 0.9630 - tp0.1: 8826943.0000 - fp0.1: 17028400.0000 - tn0.1: 51333204.0000 - fn0.1: 1405497.0000 - precision0.1: 0.3414 - recall0.1: 0.8626 - tp0.3: 7038448.0000 - fp0.3
        : 7003701.0000 - tn0.3: 61357888.0000 - fn0.3: 3193992.0000 - precision0.3: 0.5012 - recall0.3: 0.6879 - tp0.5: 4980151.0000 - fp0.5: 2201947.0000 - tn0.5: 66159680.0000 - fn0.5: 5252289.0000 - precision0.5: 0.6934 - recall0.5: 0.4867 -
         tp0.7: 3822069.0000 - fp0.7: 917042.0000 - tn0.7: 67444552.0000 - fn0.7: 6410371.0000 - precision0.7: 0.8065 - recall0.7: 0.3735 - tp0.9: 2341770.0000 - fp0.9: 282920.0000 - tn0.9: 68078696.0000 - fn0.9: 7890670.0000 - precision0.9: 0.
        8922 - recall0.9: 0.2289 - accuracy: 0.9052 - auc: 0.8844 - f1: 0.5720 - val_loss: 17.7890 - val_tp0.1: 2710616.0000 - val_fp0.1: 15396795.0000 - val_tn0.1: 1498695.0000 - val_fn0.1: 5542.0000 - val_precision0.1: 0.1497 - val_recall0.1:
         0.9980 - val_tp0.3: 2709922.0000 - val_fp0.3: 15341678.0000 - val_tn0.3: 1553812.0000 - val_fn0.3: 6236.0000 - val_precision0.3: 0.1501 - val_recall0.3: 0.9977 - val_tp0.5: 2709375.0000 - val_fp0.5: 15293665.0000 - val_tn0.5: 1601825.0
        000 - val_fn0.5: 6783.0000 - val_precision0.5: 0.1505 - val_recall0.5: 0.9975 - val_tp0.7: 2708822.0000 - val_fp0.7: 15242876.0000 - val_tn0.7: 1652614.0000 - val_fn0.7: 7336.0000 - val_precision0.7: 0.1509 - val_recall0.7: 0.9973 - val
        _tp0.9: 2707532.0000 - val_fp0.9: 15151973.0000 - val_tn0.9: 1743517.0000 - val_fn0.9: 8626.0000 - val_precision0.9: 0.1516 - val_recall0.9: 0.9968 - val_accuracy: 0.2198 - val_auc: 0.5561 - val_f1: 0.2615

        ...

        Epoch 100/100
        533/533 [==============================] - 108s 202ms/step - loss: 0.0724 - tp0.1: 10196374.0000 - fp0.1: 1589491.0000 - tn0.1: 66701600.0000 - fn0.1: 106580.0000 - precision0.1: 0.8651 - recall0.1: 0.9897 - tp0.3: 10080835.0000 - fp0.3
        : 986714.0000 - tn0.3: 67304368.0000 - fn0.3: 222119.0000 - precision0.3: 0.9108 - recall0.3: 0.9784 - tp0.5: 9895952.0000 - fp0.5: 600682.0000 - tn0.5: 67690432.0000 - fn0.5: 407002.0000 - precision0.5: 0.9428 - recall0.5: 0.9605 - tp0
        .7: 9574784.0000 - fp0.7: 291406.0000 - tn0.7: 67999680.0000 - fn0.7: 728170.0000 - precision0.7: 0.9705 - recall0.7: 0.9293 - tp0.9: 8942531.0000 - fp0.9: 72576.0000 - tn0.9: 68218544.0000 - fn0.9: 1360423.0000 - precision0.9: 0.9919 -
         recall0.9: 0.8680 - accuracy: 0.9872 - auc: 0.9942 - f1: 0.9516 - val_loss: 0.1303 - val_tp0.1: 2631957.0000 - val_fp0.1: 478568.0000 - val_tn0.1: 16426044.0000 - val_fn0.1: 75079.0000 - val_precision0.1: 0.8461 - val_recall0.1: 0.9723
         - val_tp0.3: 2587183.0000 - val_fp0.3: 308683.0000 - val_tn0.3: 16595929.0000 - val_fn0.3: 119853.0000 - val_precision0.3: 0.8934 - val_recall0.3: 0.9557 - val_tp0.5: 2531594.0000 - val_fp0.5: 203214.0000 - val_tn0.5: 16701398.0000 - v
        al_fn0.5: 175442.0000 - val_precision0.5: 0.9257 - val_recall0.5: 0.9352 - val_tp0.7: 2448316.0000 - val_fp0.7: 118418.0000 - val_tn0.7: 16786194.0000 - val_fn0.7: 258720.0000 - val_precision0.7: 0.9539 - val_recall0.7: 0.9044 - val_tp0
        .9: 2283631.0000 - val_fp0.9: 49167.0000 - val_tn0.9: 16855444.0000 - val_fn0.9: 423405.0000 - val_precision0.9: 0.9789 - val_recall0.9: 0.8436 - val_accuracy: 0.9807 - val_auc: 0.9843 - val_f1: 0.9304
        2022-03-02 04:20:37.604740: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/02 04:20:52 INFO mlflow.projects: === Run (ID '714af8cd12c1441eac4ca980e8c20070') succeeded ===

      #+end_example

      - name of run: =714af8cd12c1441eac4ca980e8c20070=
      - metrics after 100th epoch:
        - loss: 0.0724 - val_loss: 0.1303
        - val_precision0.5: 0.9257 - val_recall0.5: 0.9352 - val_f10.5: 0.9304
        - val_auc: 0.9843

   9. run training of =(3cbd945b62ec4634839372e403f6f377,
      458b36a70db843719d202a8eda448f17)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=17 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0101590069352232 \
               -P lr_power=5 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=l2 \
               -P n_levels=3 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/03 14:24:46 INFO mlflow.projects.utils: === Created directory /tmp/tmp7c_e9yu1 for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/03 14:24:46 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 17 --input_size 14000 --lr_start 0.0101590069352232 --lr_power 5 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler l2 --n_levels 3 --first_filters 16 --pool_size 4' in run with ID '34a6d207ac594035b1009c330fb67a65' ===
        2022-03-03 14:24:50.057413: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:24:54,004 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-03 14:24:54,004 - train -  Tensorflow version: 2.5.0
        2022-03-03 14:24:54,004 - train -  tf.keras version: 2.5.0
        2022-03-03 14:24:54,004 - train -  Cudnn version: 8
        2022-03-03 14:24:54,004 - train -  Cuda version: 11.2
        2022-03-03 14:24:54.006301: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-03 14:24:54.030317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-03 14:24:54.030405: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:24:54.038110: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-03 14:24:54.038189: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-03 14:24:54.041129: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-03 14:24:54.042988: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-03 14:24:54.050220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-03 14:24:54.052310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-03 14:24:54.053334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-03 14:24:54.056200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-03 14:24:54,056 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-03 14:24:54,056 - train -  Setting memory growth successful.
        2022-03-03 14:25:01,220 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-03 14:25:05,184 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-03 14:25:08,951 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-03 14:25:15,413 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-03 14:25:33,960 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-03 14:25:37,427 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-03 14:25:41,118 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-03 14:25:49,655 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-03 14:25:54,052 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-03 14:25:57,575 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-03 14:26:01,255 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-03 14:26:04,485 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-03 14:26:08,073 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-03 14:26:11,768 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-03 14:26:19,400 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-03 14:26:23,640 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-03 14:26:27,567 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-03 14:26:31,999 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-03 14:26:36,569 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-03 14:26:40,326 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-03 14:26:43,920 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-03 14:26:48,619 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-03 14:26:53,742 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-03 14:26:57,605 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-03 14:27:01,008 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-03 14:27:04,458 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-03 14:27:07,860 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-03 14:27:11,489 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-03 14:27:15,309 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-03 14:27:18,677 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-03 14:27:22,854 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-03 14:27:26,667 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-03 14:27:30,369 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-03 14:27:34,196 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-03 14:27:37,882 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-03 14:27:41,437 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-03 14:27:45,344 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-03 14:27:48,979 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-03 14:27:52,611 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-03 14:27:56,754 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-03 14:28:00,273 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-03 14:28:03,971 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-03 14:28:07,564 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-03 14:28:11,272 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-03 14:28:15,163 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-03 14:28:18,794 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-03 14:28:22,428 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-03 14:28:26,334 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-03 14:28:30,056 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-03 14:28:33,687 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-03 14:28:37,128 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-03 14:28:40,617 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-03 14:28:44,105 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-03 14:28:47,594 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-03 14:28:51,273 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-03 14:28:56,181 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-03 14:28:59,593 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-03 14:29:03,237 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-03 14:29:07,571 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-03 14:29:11,901 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-03 14:29:12,117 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-03 14:29:12,206 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-03 14:29:12.413198: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-03 14:29:12.417391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-03 14:29:12.419377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-03 14:29:12.419477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:29:12.833057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-03 14:29:12.833127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-03 14:29:12.833141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-03 14:29:12.835995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-03 14:29:14,768 - train -  number of examples: 4800
        2022-03-03 14:29:15,107 - train -  number of examples: 1200
        2022-03-03 14:29:16,570 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/03 14:29:16 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='17' for run ID='34a
        6d207ac594035b1009c330fb67a65'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-03 14:29:23.930177: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-03 14:29:24.066046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-03 14:29:33.256586: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-03 14:29:33.572296: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-03 14:29:34.075599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-03 14:29:34.363317: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        282/282 [==============================] - 45s 98ms/step - loss: 1.0922 - tp0.1: 8529810.0000 - fp0.1: 10393289.0000 - tn0.1: 57940184.0000 - fn0.1: 1681616.0000 - precision0.1: 0.4508 - recall0.1: 0.8353 - tp0.3: 7724105.0000 - fp0.3:
        3960382.0000 - tn0.3: 64373080.0000 - fn0.3: 2487321.0000 - precision0.3: 0.6611 - recall0.3: 0.7564 - tp0.5: 7024685.0000 - fp0.5: 1630985.0000 - tn0.5: 66702492.0000 - fn0.5: 3186741.0000 - precision0.5: 0.8116 - recall0.5: 0.6879 - t
        p0.7: 6159487.0000 - fp0.7: 585291.0000 - tn0.7: 67748208.0000 - fn0.7: 4051939.0000 - precision0.7: 0.9132 - recall0.7: 0.6032 - tp0.9: 4931800.0000 - fp0.9: 143363.0000 - tn0.9: 68190096.0000 - fn0.9: 5279626.0000 - precision0.9: 0.97
        18 - recall0.9: 0.4830 - accuracy: 0.9387 - auc: 0.9142 - f1: 0.7446 - val_loss: 3.2432 - val_tp0.1: 2699606.0000 - val_fp0.1: 16783988.0000 - val_tn0.1: 12739.0000 - val_fn0.1: 627.0000 - val_precision0.1: 0.1386 - val_recall0.1: 0.999
        8 - val_tp0.3: 2697002.0000 - val_fp0.3: 16748206.0000 - val_tn0.3: 48521.0000 - val_fn0.3: 3231.0000 - val_precision0.3: 0.1387 - val_recall0.3: 0.9988 - val_tp0.5: 2695536.0000 - val_fp0.5: 16737605.0000 - val_tn0.5: 59122.0000 - val_
        fn0.5: 4697.0000 - val_precision0.5: 0.1387 - val_recall0.5: 0.9983 - val_tp0.7: 2689329.0000 - val_fp0.7: 16678401.0000 - val_tn0.7: 118326.0000 - val_fn0.7: 10904.0000 - val_precision0.7: 0.1389 - val_recall0.7: 0.9960 - val_tp0.9: 22
        37862.0000 - val_fp0.9: 12480955.0000 - val_tn0.9: 4315772.0000 - val_fn0.9: 462371.0000 - val_precision0.9: 0.1520 - val_recall0.9: 0.8288 - val_accuracy: 0.1413 - val_auc: 0.5907 - val_f1: 0.2436

        ...

        Epoch 100/100
        282/282 [==============================] - 25s 88ms/step - loss: 0.2009 - tp0.1: 9736541.0000 - fp0.1: 3605117.0000 - tn0.1: 64740432.0000 - fn0.1: 462821.0000 - precision0.1: 0.7298 - recall0.1: 0.9546 - tp0.3: 9402084.0000 - fp0.3: 17
        39716.0000 - tn0.3: 66605812.0000 - fn0.3: 797278.0000 - precision0.3: 0.8439 - recall0.3: 0.9218 - tp0.5: 9016887.0000 - fp0.5: 920615.0000 - tn0.5: 67424920.0000 - fn0.5: 1182475.0000 - precision0.5: 0.9074 - recall0.5: 0.8841 - tp0.7
        : 8513773.0000 - fp0.7: 435436.0000 - tn0.7: 67910080.0000 - fn0.7: 1685589.0000 - precision0.7: 0.9513 - recall0.7: 0.8347 - tp0.9: 7585158.0000 - fp0.9: 106557.0000 - tn0.9: 68238992.0000 - fn0.9: 2614204.0000 - precision0.9: 0.9861 -
         recall0.9: 0.7437 - accuracy: 0.9732 - auc: 0.9746 - f1: 0.8956 - val_loss: 0.2670 - val_tp0.1: 2538570.0000 - val_fp0.1: 1039161.0000 - val_tn0.1: 15761772.0000 - val_fn0.1: 157457.0000 - val_precision0.1: 0.7095 - val_recall0.1: 0.94
        16 - val_tp0.3: 2435718.0000 - val_fp0.3: 590706.0000 - val_tn0.3: 16210227.0000 - val_fn0.3: 260309.0000 - val_precision0.3: 0.8048 - val_recall0.3: 0.9034 - val_tp0.5: 2326279.0000 - val_fp0.5: 379342.0000 - val_tn0.5: 16421591.0000 -
         val_fn0.5: 369748.0000 - val_precision0.5: 0.8598 - val_recall0.5: 0.8629 - val_tp0.7: 2189825.0000 - val_fp0.7: 228353.0000 - val_tn0.7: 16572580.0000 - val_fn0.7: 506202.0000 - val_precision0.7: 0.9056 - val_recall0.7: 0.8122 - val_t
        p0.9: 1947380.0000 - val_fp0.9: 92879.0000 - val_tn0.9: 16708054.0000 - val_fn0.9: 748647.0000 - val_precision0.9: 0.9545 - val_recall0.9: 0.7223 - val_accuracy: 0.9616 - val_auc: 0.9652 - val_f1: 0.8613
        2022-03-03 15:16:02.951715: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/03 15:16:13 INFO mlflow.projects: === Run (ID '34a6d207ac594035b1009c330fb67a65') succeeded ===

      #+end_example

      - name of run: =34a6d207ac594035b1009c330fb67a65=
      - metrics after 100th epoch:
        - val_precision0.5: 0.8598 - val_recall0.5: 0.8629 - val_f1: 0.8613
        - val_auc: 0.9652

   10. all metrics after 100th epoch with hparams
       | run                              |  val_auc | val_f1 0.5 | val_prec 0.5 | val_recall 0.5 | model size | hp_batch_size | hp_first_filters | hp_input_size       | hp_lr_power |        hp_lr_start | hp_n_levels | hp_pool_size | hp_scaler |
       |----------------------------------+----------+------------+--------------+----------------+------------+---------------+------------------+---------------------+-------------+--------------------+-------------+--------------+-----------|
       | 484af471c61943fa90e5f78e78a229f0 |   0.9814 |     0.9187 |       0.9091 |         0.9285 | 275 MB     |            26 |               44 | 16384 (here: 14000) |           1 | 0.0136170138242663 |           7 |            2 | standard  |
       | 0cd2023eeaf745aca0d3e8ad5e1fc653 |   0.9818 |     0.9069 |       0.8955 |         0.9185 | 200 MB     |            15 |               23 | 16384 (here: 14000) |           7 | 0.0305060808685107 |           6 |            4 | quant_g   |
       | fe81d71c52404ed790b3a32051258da9 |   0.9849 |     0.9260 |       0.9184 |         0.9338 | 186 MB     |            20 |               78 | 16384 (here: 14000) |           4 | 0.0584071108418767 |           4 |            4 | standard  |
       | ff67be0b68e540a9a29a36a2d0c7a5be | *0.9859* |     0.9298 |       0.9230 |       *0.9367* | 14 MB      |            28 |                6 | 16384 (here: 14000) |           1 | 0.0553313915596308 |           5 |            4 | minmax    |
       | 19e3e786e1bc4e2b93856f5dc9de8216 |   0.9595 |     0.8911 |       0.8983 |         0.8839 | 172 MB     |            20 |              128 | 16384 (here: 14000) |           1 |  0.043549707353273 |           3 |            4 | standard  |
       | 347669d050f344ad9fb9e480c814f727 |   0.9848 |     0.9246 |       0.9254 |         0.9238 | 73 MB      |            10 |               16 | 8192 (here: 14000)  |           1 | 0.0627676336651573 |           5 |            4 | robust    |
       | c1204e3a8a1e4c40a35b5b7b1922d1ce |   0.9858 |     0.9207 |       0.9179 |         0.9234 | 312 MB     |            14 |               16 | 16384 (here: 14000) |           5 | 0.0192390310290551 |           9 |            2 | robust    |
       | 714af8cd12c1441eac4ca980e8c20070 |   0.9843 |   *0.9304* |     *0.9257* |         0.9352 | 234 MB     |             9 |               64 | 4096 (here: 14000)  |           1 | 0.0100697459464075 |           5 |            4 | maxabs    |
       | 34a6d207ac594035b1009c330fb67a65 |   0.9652 |     0.8613 |       0.8598 |         0.8629 | 7 MB       |            17 |               16 | 16384 (here: 14000) |           5 | 0.0101590069352232 |           3 |            4 | l2        |
      :END:

*** Analysis XXX: show model architecture, loss plots, ...
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
    :END:
      #+BEGIN_SRC jupyter-python
        %cd ~/Programme/drmed-git
      #+END_SRC

      #+RESULTS:
      : /home/lex/Programme/drmed-git

      #+begin_src jupyter-python
        import datetime
        import logging
        import multipletau
        import os
        import sys

        import matplotlib.pyplot as plt
        import numpy as np
        import pandas as pd
        import seaborn as sns
        import tensorflow as tf

        from pathlib import Path
        from pprint import pprint
        from tensorflow.keras.optimizers import Adam
        from mlflow.keras import load_model

        FLUOTRACIFY_PATH = '/home/lex/Programme/drmed-git/src/'
        sys.path.append(FLUOTRACIFY_PATH)
        from fluotracify.training import (build_model as bm)

        model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                    '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                    '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                    'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                    'c1204e3a8a1e4c40a35b5b7b1922d1ce']

        model_name_ls = [f'{s:.5}' for s in model_ls]

        pred_thresh = 0.5

      #+end_src

      #+RESULTS:

      #+BEGIN_SRC jupyter-python
        for i in model_ls:
            print(f'model: {i}')
            try:
                logged_scaler = Path(f'/home/lex/Programme/drmed-git/data/mlruns/10/{i}/params/scaler')
                logged_scaler = !cat $logged_scaler
                logged_scaler = logged_scaler[0]

                # logged_model = Path(f'/home/lex/Programme/drmed-git/data/mlruns/10/{i}/artifacts/model')
                # logged_model = load_model(logged_model, compile=False)
                # logged_model.compile(loss=bm.binary_ce_dice_loss(),
                #                      optimizer=Adam(),
                #                      metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))
                # print(logged_model.summary())

            except AttributeError:
                pass
            print('----------------------------------------')
      #+END_SRC

      #+RESULTS:
      #+begin_example
        model: ff67be0b68e540a9a29a36a2d0c7a5be
        WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        2022-08-23 14:27:17,992 - build model -  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        Model: "unet_depth5"
        __________________________________________________________________________________________________
         Layer (type)                   Output Shape         Param #     Connected to
        ==================================================================================================
         input_1 (InputLayer)           [(None, None, 1)]    0           []

         encode0 (Sequential)           (None, None, 6)      186         ['input_1[0][0]']

         mp_encode0 (MaxPooling1D)      (None, None, 6)      0           ['encode0[0][0]']

         encode1 (Sequential)           (None, None, 12)     768         ['mp_encode0[0][0]']

         mp_encode1 (MaxPooling1D)      (None, None, 12)     0           ['encode1[0][0]']

         encode2 (Sequential)           (None, None, 24)     2832        ['mp_encode1[0][0]']

         mp_encode2 (MaxPooling1D)      (None, None, 24)     0           ['encode2[0][0]']

         encode3 (Sequential)           (None, None, 48)     10848       ['mp_encode2[0][0]']

         mp_encode3 (MaxPooling1D)      (None, None, 48)     0           ['encode3[0][0]']

         encode4 (Sequential)           (None, None, 96)     42432       ['mp_encode3[0][0]']

         mp_encode4 (MaxPooling1D)      (None, None, 96)     0           ['encode4[0][0]']

         two_conv_center (Sequential)   (None, None, 192)    167808      ['mp_encode4[0][0]']

         conv_transpose_decoder4 (Seque  (None, None, 192)   148416      ['two_conv_center[0][0]']
         ntial)

         decoder4 (Concatenate)         (None, None, 288)    0           ['encode4[0][0]',
                                                                          'conv_transpose_decoder4[0][0]']

         two_conv_decoder4 (Sequential)  (None, None, 192)   278400      ['decoder4[0][0]']

         conv_transpose_decoder3 (Seque  (None, None, 96)    74208       ['two_conv_decoder4[0][0]']
         ntial)

         decoder3 (Concatenate)         (None, None, 144)    0           ['encode3[0][0]',
                                                                          'conv_transpose_decoder3[0][0]']

         two_conv_decoder3 (Sequential)  (None, None, 96)    70080       ['decoder3[0][0]']

         conv_transpose_decoder2 (Seque  (None, None, 48)    18672       ['two_conv_decoder3[0][0]']
         ntial)

         decoder2 (Concatenate)         (None, None, 72)     0           ['encode2[0][0]',
                                                                          'conv_transpose_decoder2[0][0]']

         two_conv_decoder2 (Sequential)  (None, None, 48)    17760       ['decoder2[0][0]']

         conv_transpose_decoder1 (Seque  (None, None, 24)    4728        ['two_conv_decoder2[0][0]']
         ntial)

         decoder1 (Concatenate)         (None, None, 36)     0           ['encode1[0][0]',
                                                                          'conv_transpose_decoder1[0][0]']

         two_conv_decoder1 (Sequential)  (None, None, 24)    4560        ['decoder1[0][0]']

         conv_transpose_decoder0 (Seque  (None, None, 12)    1212        ['two_conv_decoder1[0][0]']
         ntial)

         decoder0 (Concatenate)         (None, None, 18)     0           ['encode0[0][0]',
                                                                          'conv_transpose_decoder0[0][0]']

         two_conv_decoder0 (Sequential)  (None, None, 12)    1200        ['decoder0[0][0]']

         conv1d_22 (Conv1D)             (None, None, 1)      13          ['two_conv_decoder0[0][0]']

        ==================================================================================================
        Total params: 844,123
        Trainable params: 840,379
        Non-trainable params: 3,744
        __________________________________________________________________________________________________
        None
        ----------------------------------------
        model: 347669d050f344ad9fb9e480c814f727WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        2022-08-23 14:27:26,761 - build model -  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        Model: "unet_depth5"
        __________________________________________________________________________________________________
         Layer (type)                   Output Shape         Param #     Connected to
        ==================================================================================================
         input_1 (InputLayer)           [(None, None, 1)]    0           []

         encode0 (Sequential)           (None, None, 16)     976         ['input_1[0][0]']

         mp_encode0 (MaxPooling1D)      (None, None, 16)     0           ['encode0[0][0]']

         encode1 (Sequential)           (None, None, 32)     4928        ['mp_encode0[0][0]']

         mp_encode1 (MaxPooling1D)      (None, None, 32)     0           ['encode1[0][0]']

         encode2 (Sequential)           (None, None, 64)     19072       ['mp_encode1[0][0]']

         mp_encode2 (MaxPooling1D)      (None, None, 64)     0           ['encode2[0][0]']

         encode3 (Sequential)           (None, None, 128)    75008       ['mp_encode2[0][0]']

         mp_encode3 (MaxPooling1D)      (None, None, 128)    0           ['encode3[0][0]']

         encode4 (Sequential)           (None, None, 256)    297472      ['mp_encode3[0][0]']

         mp_encode4 (MaxPooling1D)      (None, None, 256)    0           ['encode4[0][0]']

         two_conv_center (Sequential)   (None, None, 512)    1184768     ['mp_encode4[0][0]']

         conv_transpose_decoder4 (Seque  (None, None, 512)   1051136     ['two_conv_center[0][0]']
         ntial)

         decoder4 (Concatenate)         (None, None, 768)    0           ['encode4[0][0]',
                                                                          'conv_transpose_decoder4[0][0]']

         two_conv_decoder4 (Sequential)  (None, None, 512)   1971200     ['decoder4[0][0]']

         conv_transpose_decoder3 (Seque  (None, None, 256)   525568      ['two_conv_decoder4[0][0]']
         ntial)

         decoder3 (Concatenate)         (None, None, 384)    0           ['encode3[0][0]',
                                                                          'conv_transpose_decoder3[0][0]']

         two_conv_decoder3 (Sequential)  (None, None, 256)   494080      ['decoder3[0][0]']

         conv_transpose_decoder2 (Seque  (None, None, 128)   131712      ['two_conv_decoder3[0][0]']
         ntial)

         decoder2 (Concatenate)         (None, None, 192)    0           ['encode2[0][0]',
                                                                          'conv_transpose_decoder2[0][0]']

         two_conv_decoder2 (Sequential)  (None, None, 128)   124160      ['decoder2[0][0]']

         conv_transpose_decoder1 (Seque  (None, None, 64)    33088       ['two_conv_decoder2[0][0]']
         ntial)

         decoder1 (Concatenate)         (None, None, 96)     0           ['encode1[0][0]',
                                                                          'conv_transpose_decoder1[0][0]']

         two_conv_decoder1 (Sequential)  (None, None, 64)    31360       ['decoder1[0][0]']

         conv_transpose_decoder0 (Seque  (None, None, 32)    8352        ['two_conv_decoder1[0][0]']
         ntial)

         decoder0 (Concatenate)         (None, None, 48)     0           ['encode0[0][0]',
                                                                          'conv_transpose_decoder0[0][0]']

         two_conv_decoder0 (Sequential)  (None, None, 32)    8000        ['decoder0[0][0]']

         conv1d_22 (Conv1D)             (None, None, 1)      33          ['two_conv_decoder0[0][0]']

        ==================================================================================================
        Total params: 5,960,913
        Trainable params: 5,950,929
        Non-trainable params: 9,984
        __________________________________________________________________________________________________
        None
        ----------------------------------------
        model: 714af8cd12c1441eac4ca980e8c20070
        WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        2022-08-23 14:27:35,085 - build model -  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        Model: "unet_depth5"
        __________________________________________________________________________________________________
         Layer (type)                   Output Shape         Param #     Connected to
        ==================================================================================================
         input_1 (InputLayer)           [(None, None, 1)]    0           []

         encode0 (Sequential)           (None, None, 64)     13120       ['input_1[0][0]']

         mp_encode0 (MaxPooling1D)      (None, None, 64)     0           ['encode0[0][0]']

         encode1 (Sequential)           (None, None, 128)    75008       ['mp_encode0[0][0]']

         mp_encode1 (MaxPooling1D)      (None, None, 128)    0           ['encode1[0][0]']

         encode2 (Sequential)           (None, None, 256)    297472      ['mp_encode1[0][0]']

         mp_encode2 (MaxPooling1D)      (None, None, 256)    0           ['encode2[0][0]']

         encode3 (Sequential)           (None, None, 512)    1184768     ['mp_encode2[0][0]']

         mp_encode3 (MaxPooling1D)      (None, None, 512)    0           ['encode3[0][0]']

         encode4 (Sequential)           (None, None, 512)    1577984     ['mp_encode3[0][0]']

         mp_encode4 (MaxPooling1D)      (None, None, 512)    0           ['encode4[0][0]']

         two_conv_center (Sequential)   (None, None, 1024)   4728832     ['mp_encode4[0][0]']

         conv_transpose_decoder4 (Seque  (None, None, 512)   2099712     ['two_conv_center[0][0]']
         ntial)

         decoder4 (Concatenate)         (None, None, 1024)   0           ['encode4[0][0]',
                                                                          'conv_transpose_decoder4[0][0]']

         two_conv_decoder4 (Sequential)  (None, None, 512)   2364416     ['decoder4[0][0]']

         conv_transpose_decoder3 (Seque  (None, None, 512)   1051136     ['two_conv_decoder4[0][0]']
         ntial)

         decoder3 (Concatenate)         (None, None, 1024)   0           ['encode3[0][0]',
                                                                          'conv_transpose_decoder3[0][0]']

         two_conv_decoder3 (Sequential)  (None, None, 512)   2364416     ['decoder3[0][0]']

         conv_transpose_decoder2 (Seque  (None, None, 512)   1051136     ['two_conv_decoder3[0][0]']
         ntial)

         decoder2 (Concatenate)         (None, None, 768)    0           ['encode2[0][0]',
                                                                          'conv_transpose_decoder2[0][0]']

         two_conv_decoder2 (Sequential)  (None, None, 512)   1971200     ['decoder2[0][0]']

         conv_transpose_decoder1 (Seque  (None, None, 256)   525568      ['two_conv_decoder2[0][0]']
         ntial)

         decoder1 (Concatenate)         (None, None, 384)    0           ['encode1[0][0]',
                                                                          'conv_transpose_decoder1[0][0]']

         two_conv_decoder1 (Sequential)  (None, None, 256)   494080      ['decoder1[0][0]']

         conv_transpose_decoder0 (Seque  (None, None, 128)   131712      ['two_conv_decoder1[0][0]']
         ntial)

         decoder0 (Concatenate)         (None, None, 192)    0           ['encode0[0][0]',
                                                                          'conv_transpose_decoder0[0][0]']

         two_conv_decoder0 (Sequential)  (None, None, 128)   124160      ['decoder0[0][0]']

         conv1d_22 (Conv1D)             (None, None, 1)      129         ['two_conv_decoder0[0][0]']

        ==================================================================================================
        Total params: 20,054,849
        Trainable params: 20,033,345
        Non-trainable params: 21,504
        __________________________________________________________________________________________________
        None
        ----------------------------------------
        model: 34a6d207ac594035b1009c330fb67a65
        WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        2022-08-23 14:27:43,275 - build model -  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        Model: "unet_depth3"
        __________________________________________________________________________________________________
         Layer (type)                   Output Shape         Param #     Connected to
        ==================================================================================================
         input_1 (InputLayer)           [(None, None, 1)]    0           []

         encode0 (Sequential)           (None, None, 16)     976         ['input_1[0][0]']

         mp_encode0 (MaxPooling1D)      (None, None, 16)     0           ['encode0[0][0]']

         encode1 (Sequential)           (None, None, 32)     4928        ['mp_encode0[0][0]']

         mp_encode1 (MaxPooling1D)      (None, None, 32)     0           ['encode1[0][0]']

         encode2 (Sequential)           (None, None, 64)     19072       ['mp_encode1[0][0]']

         mp_encode2 (MaxPooling1D)      (None, None, 64)     0           ['encode2[0][0]']

         two_conv_center (Sequential)   (None, None, 128)    75008       ['mp_encode2[0][0]']

         conv_transpose_decoder2 (Seque  (None, None, 128)   66176       ['two_conv_center[0][0]']
         ntial)

         decoder2 (Concatenate)         (None, None, 192)    0           ['encode2[0][0]',
                                                                          'conv_transpose_decoder2[0][0]']

         two_conv_decoder2 (Sequential)  (None, None, 128)   124160      ['decoder2[0][0]']

         conv_transpose_decoder1 (Seque  (None, None, 64)    33088       ['two_conv_decoder2[0][0]']
         ntial)

         decoder1 (Concatenate)         (None, None, 96)     0           ['encode1[0][0]',
                                                                          'conv_transpose_decoder1[0][0]']

         two_conv_decoder1 (Sequential)  (None, None, 64)    31360       ['decoder1[0][0]']

         conv_transpose_decoder0 (Seque  (None, None, 32)    8352        ['two_conv_decoder1[0][0]']
         ntial)

         decoder0 (Concatenate)         (None, None, 48)     0           ['encode0[0][0]',
                                                                          'conv_transpose_decoder0[0][0]']

         two_conv_decoder0 (Sequential)  (None, None, 32)    8000        ['decoder0[0][0]']

         conv1d_14 (Conv1D)             (None, None, 1)      33          ['two_conv_decoder0[0][0]']

        ==================================================================================================
        Total params: 371,153
        Trainable params: 368,849
        Non-trainable params: 2,304
        __________________________________________________________________________________________________
        None
        ----------------------------------------
        model: 484af471c61943fa90e5f78e78a229f0
        ----------------------------------------
        model: 0cd2023eeaf745aca0d3e8ad5e1fc653
        WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        2022-08-23 14:27:49,590 - build model -  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
        Model: "unet_depth6"
        __________________________________________________________________________________________________
         Layer (type)                   Output Shape         Param #     Connected to
        ==================================================================================================
         input_1 (InputLayer)           [(None, None, 1)]    0           []

         encode0 (Sequential)           (None, None, 23)     1886        ['input_1[0][0]']

         mp_encode0 (MaxPooling1D)      (None, None, 23)     0           ['encode0[0][0]']

         encode1 (Sequential)           (None, None, 46)     9982        ['mp_encode0[0][0]']

         mp_encode1 (MaxPooling1D)      (None, None, 46)     0           ['encode1[0][0]']

         encode2 (Sequential)           (None, None, 92)     39008       ['mp_encode1[0][0]']

         mp_encode2 (MaxPooling1D)      (None, None, 92)     0           ['encode2[0][0]']

         encode3 (Sequential)           (None, None, 184)    154192      ['mp_encode2[0][0]']

         mp_encode3 (MaxPooling1D)      (None, None, 184)    0           ['encode3[0][0]']

         encode4 (Sequential)           (None, None, 368)    613088      ['mp_encode3[0][0]']

         mp_encode4 (MaxPooling1D)      (None, None, 368)    0           ['encode4[0][0]']

         encode5 (Sequential)           (None, None, 512)    1356800     ['mp_encode4[0][0]']

         mp_encode5 (MaxPooling1D)      (None, None, 512)    0           ['encode5[0][0]']

         two_conv_center (Sequential)   (None, None, 1024)   4728832     ['mp_encode5[0][0]']

         conv_transpose_decoder5 (Seque  (None, None, 512)   2099712     ['two_conv_center[0][0]']
         ntial)

         decoder5 (Concatenate)         (None, None, 1024)   0           ['encode5[0][0]',
                                                                          'conv_transpose_decoder5[0][0]']

         two_conv_decoder5 (Sequential)  (None, None, 512)   2364416     ['decoder5[0][0]']

         conv_transpose_decoder4 (Seque  (None, None, 512)   1051136     ['two_conv_decoder5[0][0]']
         ntial)

         decoder4 (Concatenate)         (None, None, 880)    0           ['encode4[0][0]',
                                                                          'conv_transpose_decoder4[0][0]']

         two_conv_decoder4 (Sequential)  (None, None, 512)   2143232     ['decoder4[0][0]']

         conv_transpose_decoder3 (Seque  (None, None, 368)   755504      ['two_conv_decoder4[0][0]']
         ntial)

         decoder3 (Concatenate)         (None, None, 552)    0           ['encode3[0][0]',
                                                                          'conv_transpose_decoder3[0][0]']

         two_conv_decoder3 (Sequential)  (None, None, 368)   1019360     ['decoder3[0][0]']

         conv_transpose_decoder2 (Seque  (None, None, 184)   271768      ['two_conv_decoder3[0][0]']
         ntial)

         decoder2 (Concatenate)         (None, None, 276)    0           ['encode2[0][0]',
                                                                          'conv_transpose_decoder2[0][0]']

         two_conv_decoder2 (Sequential)  (None, None, 184)   255760      ['decoder2[0][0]']

         conv_transpose_decoder1 (Seque  (None, None, 92)    68172       ['two_conv_decoder2[0][0]']
         ntial)

         decoder1 (Concatenate)         (None, None, 138)    0           ['encode1[0][0]',
                                                                          'conv_transpose_decoder1[0][0]']

         two_conv_decoder1 (Sequential)  (None, None, 92)    64400       ['decoder1[0][0]']

         conv_transpose_decoder0 (Seque  (None, None, 46)    17158       ['two_conv_decoder1[0][0]']
         ntial)

         decoder0 (Concatenate)         (None, None, 69)     0           ['encode0[0][0]',
                                                                          'conv_transpose_decoder0[0][0]']

         two_conv_decoder0 (Sequential)  (None, None, 46)    16330       ['decoder0[0][0]']

         conv1d_26 (Conv1D)             (None, None, 1)      47          ['two_conv_decoder0[0][0]']

        ==================================================================================================
        Total params: 17,030,783
        Trainable params: 17,011,503
        Non-trainable params: 19,280
        __________________________________________________________________________________________________
        None
        ----------------------------------------
        model: fe81d71c52404ed790b3a32051258da9
        ----------------------------------------
        model: 19e3e786e1bc4e2b93856f5dc9de8216
        ----------------------------------------
        model: c1204e3a8a1e4c40a35b5b7b1922d1ce
        ----------------------------------------
      #+end_example

      #+BEGIN_SRC jupyter-python
        echo "time val_f1 epoch"

      #+END_SRC
*** Analysis 1a: Run models on simulated test data
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:d37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
   :ID:       3d3f3924-b489-449e-abfd-318443f3fa94
   :END:
   1. go to correct folder, load modules
      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git

      #+begin_src jupyter-python
        import datetime
        import logging
        import multipletau
        import os
        import sys

        import matplotlib.pyplot as plt
        import numpy as np
        import pandas as pd
        import seaborn as sns
        import tensorflow as tf

        from pathlib import Path
        from pprint import pprint
        from tensorflow.keras.optimizers import Adam
        from mlflow.keras import load_model

        FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
        sys.path.append(FLUOTRACIFY_PATH)
        from fluotracify.applications import (corr_fit_object as cfo,
                                              correction,
                                              correlate)
        from fluotracify.imports import ptu_utils as ptu
        from fluotracify.training import (build_model as bm,
                                          preprocess_data as ppd)
        from fluotracify.simulations import (
           import_simulation_from_csv as isfc,
           analyze_simulations as ans,
        )

        logging.basicConfig(filename="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/jupyter.log",
                            format='%(asctime)s - %(message)s',
                            filemode='w',
                            force=True)
        log = logging.getLogger(__name__)
        log.setLevel(logging.DEBUG)

        sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                      context='paper')

        model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                    '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                    '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                    'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                    'c1204e3a8a1e4c40a35b5b7b1922d1ce']

        model_name_ls = [f'{s:.5}' for s in model_ls]

        pred_thresh = 0.5
      #+end_src

      #+RESULTS:
      : 2022-08-24 10:31:45.084478: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2022-08-24 10:31:45.084513: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+BEGIN_SRC jupyter-python
        import importlib
        importlib.reload(ppd)
        importlib.reload(cfo)
      #+END_SRC

      #+RESULTS:
      : <module 'fluotracify.applications.corr_fit_object' from '/beegfs/ye53nis/drmed-git/src/fluotracify/applications/corr_fit_object.py'>

   2. Load test data from simulation experiments
      #+BEGIN_SRC jupyter-python
        col_per_example = 3
        lab_thresh = 0.04
        artifact = 0
        model_type = 1
        fwhm = 250

        output_path = "/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-04-22_simulations/"
        sim_path = Path('/beegfs/ye53nis/saves/firstartifact_Nov2020_test')

        sim, _, nsamples, sim_params = isfc.import_from_csv(
            folder=sim_path,
            header=12,
            frac_train=1,
            col_per_example=col_per_example,
            dropindex=None,
            dropcolumns=None)

        diffrates = sim_params.loc['diffusion rate of molecules in micrometer^2 / s'].astype(np.float32)
        nmols = sim_params.loc['number of fast molecules'].astype(np.float32)
        clusters = sim_params.loc['diffusion rate of clusters in micrometer^2 / s'].astype(np.float32)
        sim_columns = [f'{d:.4}-{c:.4}' for d, c in zip(
            np.repeat(diffrates, nsamples[0]),
            np.repeat(clusters, nsamples[0]))]

        sim_sep = isfc.separate_data_and_labels(array=sim,
                                                nsamples=nsamples,
                                                col_per_example=col_per_example)
        sim_dirty = sim_sep['0']
        sim_dirty.columns = sim_columns

        sim_labels = sim_sep['1']
        sim_labels.columns = sim_columns
        sim_labbool = sim_labels > lab_thresh
        sim_labbool.columns = sim_columns
        sim_clean = sim_sep['2']
        sim_clean.columns = sim_columns

        sim_dirty
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      |       | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0  | 0.069-1.0   | 0.069-1.0  | ... | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    | 0.4-0.01    |
|-------+------------+------------+------------+------------+------------+------------+------------+------------+-------------+------------+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------|
| 0     | 395.062347 | 542.019287 | 259.171783 | 378.006470 | 672.683350 | 422.525299 | 435.934174 | 535.840027 | 341.197662  | 546.919556 | ... | 1194.309570 | 1331.900391 | 1614.625854 | 1096.244019 | 5350.819336 | 1109.356201 | 1231.328979 | 2721.381592 | 1671.956787 | 1572.913452 |
| 1     | 395.732605 | 676.451477 | 263.082733 | 365.738861 | 672.841858 | 436.986450 | 408.519165 | 578.790833 | 357.324097  | 518.666321 | ... | 1226.035278 | 1348.827026 | 1727.460327 | 1040.826294 | 5548.753418 | 1241.292969 | 1197.370972 | 2785.768066 | 1749.072510 | 1544.390259 |
| 2     | 385.598785 | 565.850403 | 258.483124 | 350.939362 | 680.929993 | 416.969391 | 408.744873 | 572.143921 | 350.399933  | 546.654846 | ... | 1236.471436 | 1323.095703 | 1817.804810 | 949.081665  | 5418.844727 | 1285.566650 | 1229.268799 | 2961.105225 | 1643.184204 | 1486.991211 |
| 3     | 375.055664 | 569.737793 | 252.117035 | 364.043427 | 651.953247 | 449.630371 | 390.186218 | 521.915283 | 366.314545  | 534.204285 | ... | 1192.580566 | 1219.429932 | 1844.903687 | 888.757324  | 5756.974121 | 1303.747803 | 1190.227539 | 3127.305664 | 1713.993042 | 1427.290771 |
| 4     | 400.554443 | 590.014893 | 241.840240 | 376.104645 | 681.107056 | 466.177185 | 380.395752 | 531.094727 | 370.980286  | 537.930359 | ... | 1168.627441 | 1194.065186 | 1756.768799 | 887.986389  | 5481.615234 | 1324.906250 | 1268.030762 | 2997.608887 | 1744.911865 | 1426.806763 |
| ...   | ...        | ...        | ...        | ...        | ...        | ...        | ...        | ...        | ...         | ...        | ... | ...         | ...         | ...         | ...         | ...         | ...         | ...         | ...         | ...         | ...         |
| 16379 | 433.562714 | 624.462646 | 643.004944 | 518.733643 | 563.566589 | 578.520813 | 348.858429 | 330.541473 | 9484.205078 | 376.017700 | ... | 1352.349854 | 1400.204102 | 2025.719604 | 934.456665  | 2333.292725 | 1499.182251 | 1344.230347 | 1172.255371 | 1347.495239 | 756.805908  |
| 16380 | 462.284454 | 616.137512 | 597.266296 | 487.652924 | 572.072327 | 612.569275 | 328.044495 | 331.003693 | 8237.546875 | 373.477081 | ... | 1305.663696 | 1453.817993 | 1847.917114 | 1012.087402 | 2349.776611 | 1498.571411 | 1446.490479 | 1191.984253 | 1482.415894 | 712.499878  |
| 16381 | 472.551483 | 612.926758 | 615.009460 | 516.941528 | 579.562378 | 624.847717 | 308.531097 | 308.009369 | 2722.457275 | 352.414612 | ... | 1384.178711 | 1428.226440 | 1641.537109 | 975.000366  | 2291.302734 | 1541.471436 | 1334.644897 | 1173.113770 | 1520.151367 | 587.645203  |
| 16382 | 486.679413 | 637.962769 | 616.344116 | 502.372345 | 593.559937 | 673.262634 | 307.834229 | 322.522400 | 2823.112305 | 336.442596 | ... | 1258.534058 | 1423.324341 | 1560.817139 | 1023.877014 | 2185.760742 | 1455.700928 | 1387.281250 | 1124.065552 | 1572.194336 | 618.202820  |
| 16383 | 489.893646 | 614.733704 | 614.638000 | 511.408234 | 595.268982 | 673.656921 | 318.466736 | 305.981110 | 1768.038330 | 361.107300 | ... | 1114.534912 | 1386.146484 | 1548.830078 | 1009.011658 | 2117.508789 | 1569.905518 | 1396.511353 | 1070.131104 | 1602.530029 | 654.377380  |

16384 rows × 3000 columns
      :END:

      #+BEGIN_SRC jupyter-python
        dataset_test, num_test_examples = ppd.tfds_from_pddf(
            features_df=sim_dirty, labels_df=sim_labbool, frac_val=False)
        dataset_test
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      : 2022-08-23 13:50:29.331909: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-08-23 13:50:29.331967: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-08-23 13:50:29.331995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node100): /proc/driver/nvidia/version does not exist
      : 2022-08-23 13:50:29.332353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : <MapDataset element_spec=(TensorSpec(shape=(16384, 1), dtype=tf.float32, name=None), TensorSpec(shape=(16384, 1), dtype=tf.float32, name=None))>
      :END:


      #+begin_src jupyter-python :pandoc t
        eva = pd.DataFrame()
        for i in model_ls:
            logged_scaler = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{i}/params/scaler')
            logged_scaler = !cat $logged_scaler
            logged_scaler = logged_scaler[0]

            logged_model = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{i}/artifacts/model')
            logged_model = load_model(logged_model, compile=False)
            logged_model.compile(loss=bm.binary_ce_dice_loss(),
                                 optimizer=Adam(),
                                 metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))

            dataset = dataset_test.map(
                lambda trace, label: ppd.tfds_scale_trace_and_label(trace, label, logged_scaler),
                num_parallel_calls=tf.data.AUTOTUNE)
            dataset = dataset.map(
                ppd.tfds_pad_trace_and_label,
                num_parallel_calls=tf.data.AUTOTUNE)
            dataset = dataset.batch(1)
            print(f'model: {i}')
            eva_new = logged_model.evaluate(dataset, verbose=2, return_dict=True)
            eva_new = pd.DataFrame(eva_new.values(), index=eva_new.keys(), columns=[f'{i}'])
            eva = pd.concat([eva, eva_new], axis='columns')
            print('----------------------------------------')


      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
      : model: ff67be0b68e540a9a29a36a2d0c7a5be
      : 3000/3000 - 47s - loss: 0.1929 - tp0.1: 7216054.0000 - fp0.1: 1445349.0000 - tn0.1: 40150456.0000 - fn0.1: 340179.0000 - precision0.1: 0.8331 - recall0.1: 0.9550 - tp0.3: 7068737.0000 - fp0.3: 874006.0000 - tn0.3: 40721760.0000 - fn0.3: 487496.0000 - precision0.3: 0.8900 - recall0.3: 0.9355 - tp0.5: 6879515.0000 - fp0.5: 517256.0000 - tn0.5: 41078488.0000 - fn0.5: 676718.0000 - precision0.5: 0.9301 - recall0.5: 0.9104 - tp0.7: 6640601.0000 - fp0.7: 285835.0000 - tn0.7: 41309920.0000 - fn0.7: 915632.0000 - precision0.7: 0.9587 - recall0.7: 0.8788 - tp0.9: 6140071.0000 - fp0.9: 88637.0000 - tn0.9: 41507120.0000 - fn0.9: 1416162.0000 - precision0.9: 0.9858 - recall0.9: 0.8126 - accuracy: 0.9757 - auc: 0.9756 - f1: 0.9202 - 47s/epoch - 16ms/step
      : ----------------------------------------
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
      : model: 347669d050f344ad9fb9e480c814f727


    - we get =run1_2_my= with a summary of the best hyperparameter training runs
      from the code block ~#+CALL: get-hparam-comparison()~
      #+CALL: get-hparam-comparison()

      #+RESULTS:
      :RESULTS:
      | Run ID:                                                              | val_auc | val_recall0.5 | val_precision0.5 | hp_batch_size | hp_first_filters | hp_input_size | hp_lr_power | hp_lr_start        | hp_n_levels | hp_pool_size | hp_scaler |
|----------------------------------------------------------------------+---------+---------------+------------------+---------------+------------------+---------------+-------------+--------------------+-------------+--------------+-----------|
| (9051e32b87d84f3485b980067addec30, 61ff87bdb89b4e2ba64f8dacc774992d) | 0.981   | 0.8975        | 0.918            | 26            | 44               | 16384         | 1           | 0.0136170138242663 | 7           | 2            | standard  |
| (93b168c0ff7942c8a908a94129daf973, f243b3b742de4dbcb7ccfbd4244706f8) | 0.976   | 0.893         | 0.852            | 15            | 23               | 16384         | 7           | 0.0305060808685107 | 6           | 4            | quant_g   |
| (a5b8551144ff46e697a39cd1551e1475, 98cf8cdef9c54b5286e277e75e2ab8c1) | 0.984   | 0.916         | 0.909            | 20            | 78               | 16384         | 4           | 0.0584071108418767 | 4           | 4            | standard  |
| (00f2635d9fa2463c9a066722163405be, d0a8e1748b194f3290d471b6b44f19f8) | 0.987   | 0.929         | 0.9065           | 28            | 6                | 16384         | 1           | 0.0553313915596308 | 5           | 4            | minmax    |
| (5604d43c1ece461b8e6eaa0dfb65d6dc, 3612536a77f34f22bc83d1d809140aa6) | 0.9745  | 0.885         | 0.8985           | 20            | 128              | 16384         | 1           | 0.043549707353273  | 3           | 4            | standard  |
| (7cafab027cdd4fc9bf20a43e989df510, 16dff15d935f45e2a836b1f41b07b4e3) | 0.978   | 0.8905        | 0.891            | 10            | 16               | 8192          | 1           | 0.0627676336651573 | 5           | 4            | robust    |
| (0e328920e86049928202db95e8cfb7be, bf9d2725eb16462d9a101f0a077ce2b5) | 0.976   | 0.875         | 0.888            | 14            | 16               | 16384         | 5           | 0.0192390310290551 | 9           | 2            | robust    |
| (1c954fbc02b747bc813c587ac703c74a, ba49a80c2616407a8f1fe1fd12096fe0) | 0.962   | 0.856         | 0.8585           | 17            | 16               | 16384         | 5           | 0.0101590069352232 | 3           | 4            | l2        |
| (3cbd945b62ec4634839372e403f6f377, 458b36a70db843719d202a8eda448f17) | 0.972   | 0.872         | 0.9135           | 9             | 64               | 4096          | 1           | 0.0100697459464075 | 5           | 4            | maxabs    |
      :END:

      #+BEGIN_SRC jupyter-python
        model_dict = {
            ('9051e32b87d84f3485b980067addec30', '61ff87bdb89b4e2ba64f8dacc774992d') :  '484af471c61943fa90e5f78e78a229f0',
            ('93b168c0ff7942c8a908a94129daf973', 'f243b3b742de4dbcb7ccfbd4244706f8') :  '0cd2023eeaf745aca0d3e8ad5e1fc653',
            ('a5b8551144ff46e697a39cd1551e1475', '98cf8cdef9c54b5286e277e75e2ab8c1') :  'fe81d71c52404ed790b3a32051258da9',
            ('00f2635d9fa2463c9a066722163405be', 'd0a8e1748b194f3290d471b6b44f19f8') :  'ff67be0b68e540a9a29a36a2d0c7a5be',
            ('5604d43c1ece461b8e6eaa0dfb65d6dc', '3612536a77f34f22bc83d1d809140aa6') :  '19e3e786e1bc4e2b93856f5dc9de8216',
            ('7cafab027cdd4fc9bf20a43e989df510', '16dff15d935f45e2a836b1f41b07b4e3') :  '347669d050f344ad9fb9e480c814f727',
            ('0e328920e86049928202db95e8cfb7be', 'bf9d2725eb16462d9a101f0a077ce2b5') :  'c1204e3a8a1e4c40a35b5b7b1922d1ce',
            ('1c954fbc02b747bc813c587ac703c74a', 'ba49a80c2616407a8f1fe1fd12096fe0') :  '714af8cd12c1441eac4ca980e8c20070',
            ('3cbd945b62ec4634839372e403f6f377', '458b36a70db843719d202a8eda448f17') :  '34a6d207ac594035b1009c330fb67a65'}


        inference = pd.DataFrame([['42s', '14ms', '275 MB'],
                                  ['65s', '22ms', '200 MB'],
                                  ['201s', '67ms', '186 MB'],
                                  ['45s', '15ms', '14 MB'],
                                  ['370s', '123ms', '172 MB'],
                                  ['95s', '32ms', '73 MB'],
                                  ['230s', '77ms', '312 MB'],
                                  ['361s', '120ms', '234 MB'],
                                  ['230s', '77ms', '7 MB']],
                                  columns=['HPC inference time (whole test dataset)', 'HPC inference time (one trace)', 'Model size'],
                                 index=['484af471c61943fa90e5f78e78a229f0',
                                        '0cd2023eeaf745aca0d3e8ad5e1fc653',
                                        'fe81d71c52404ed790b3a32051258da9',
                                        'ff67be0b68e540a9a29a36a2d0c7a5be',
                                        '19e3e786e1bc4e2b93856f5dc9de8216',
                                        '347669d050f344ad9fb9e480c814f727',
                                        'c1204e3a8a1e4c40a35b5b7b1922d1ce',
                                        '714af8cd12c1441eac4ca980e8c20070',
                                        '34a6d207ac594035b1009c330fb67a65']).T

        evaluation = pd.concat([eva, inference], axis='index')

        index = [f'test {e}' for e in evaluation.index]
        evaluation.index = index
        training = run1_2_my.loc[cond2 & cond3]

        training = training.rename(index=model_dict).T
        final = pd.concat([training, evaluation])
        final.to_csv('data/exp-220227-unet/mlflow/2022-08-23_all-models.csv')
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      |                                              | 484af471c61943fa90e5f78e78a229f0 | 0cd2023eeaf745aca0d3e8ad5e1fc653 | fe81d71c52404ed790b3a32051258da9 | ff67be0b68e540a9a29a36a2d0c7a5be | 19e3e786e1bc4e2b93856f5dc9de8216 | 347669d050f344ad9fb9e480c814f727 | c1204e3a8a1e4c40a35b5b7b1922d1ce | 714af8cd12c1441eac4ca980e8c20070 | 34a6d207ac594035b1009c330fb67a65 |
      |----------------------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------|
      | val_auc                                      |                            0.981 |                            0.976 |                            0.984 |                            0.987 |                           0.9745 |                            0.978 |                            0.976 |                            0.962 |                            0.972 |
      | val_recall0.5                                |                           0.8975 |                            0.893 |                            0.916 |                            0.929 |                            0.885 |                           0.8905 |                            0.875 |                            0.856 |                            0.872 |
      | val_precision0.5                             |                            0.918 |                            0.852 |                            0.909 |                           0.9065 |                           0.8985 |                            0.891 |                            0.888 |                           0.8585 |                           0.9135 |
      | hp_batch_size                                |                               26 |                               15 |                               20 |                               28 |                               20 |                               10 |                               14 |                               17 |                                9 |
      | hp_first_filters                             |                               44 |                               23 |                               78 |                                6 |                              128 |                               16 |                               16 |                               16 |                               64 |
      | hp_input_size                                |                            16384 |                            16384 |                            16384 |                            16384 |                            16384 |                             8192 |                            16384 |                            16384 |                             4096 |
      | hp_lr_power                                  |                                1 |                                7 |                                4 |                                1 |                                1 |                                1 |                                5 |                                5 |                                1 |
      | hp_lr_start                                  |               0.0136170138242663 |               0.0305060808685107 |               0.0584071108418767 |               0.0553313915596308 |                0.043549707353273 |               0.0627676336651573 |               0.0192390310290551 |               0.0101590069352232 |               0.0100697459464075 |
      | hp_n_levels                                  |                                7 |                                6 |                                4 |                                5 |                                3 |                                5 |                                9 |                                3 |                                5 |
      | hp_pool_size                                 |                                2 |                                4 |                                4 |                                4 |                                4 |                                4 |                                2 |                                4 |                                4 |
      | hp_scaler                                    |                         standard |                          quant_g |                         standard |                           minmax |                         standard |                           robust |                           robust |                               l2 |                           maxabs |
      | test loss                                    |                         0.228701 |                         0.291168 |                         0.207543 |                         0.192903 |                          0.39377 |                         0.289283 |                         0.264141 |                          0.18674 |                         0.318487 |
      | test tp0.1                                   |                        7120162.0 |                        7030956.0 |                        7195616.0 |                        7216054.0 |                        6702946.0 |                        6968717.0 |                        7094671.0 |                        7191122.0 |                        6898118.0 |
      | test fp0.1                                   |                        1418863.0 |                        1944947.0 |                        1635920.0 |                        1445349.0 |                        1573303.0 |                        1346502.0 |                        1783490.0 |                        1089514.0 |                        1865476.0 |
      | test tn0.1                                   |                       40176900.0 |                       39650840.0 |                       39959820.0 |                       40150456.0 |                       40022456.0 |                       40249248.0 |                       39812172.0 |                       40506272.0 |                       39730280.0 |
      | test fn0.1                                   |                         436071.0 |                         525277.0 |                         360617.0 |                         340179.0 |                         853287.0 |                         587516.0 |                         461562.0 |                         365111.0 |                         658115.0 |
      | test precision0.1                            |                         0.833838 |                         0.783315 |                         0.814764 |                         0.833128 |                         0.809901 |                         0.838068 |                         0.799115 |                         0.868426 |                         0.787133 |
      | test recall0.1                               |                          0.94229 |                         0.930484 |                         0.952276 |                          0.95498 |                         0.887075 |                         0.922248 |                         0.938916 |                         0.951681 |                         0.912904 |
      | test tp0.3                                   |                        6967838.0 |                        6780626.0 |                        7057588.0 |                        7068737.0 |                        6536047.0 |                        6749402.0 |                        6893942.0 |                        7062843.0 |                        6565790.0 |
      | test fp0.3                                   |                         864351.0 |                        1063352.0 |                        1032334.0 |                         874006.0 |                        1023316.0 |                         704964.0 |                         923800.0 |                         687977.0 |                         850301.0 |
      | test tn0.3                                   |                       40731400.0 |                       40532408.0 |                       40563420.0 |                       40721760.0 |                       40572400.0 |                       40890776.0 |                       40671944.0 |                       40907784.0 |                       40745504.0 |
      | test fn0.3                                   |                         588395.0 |                         775607.0 |                         498645.0 |                         487496.0 |                        1020186.0 |                         806831.0 |                         662291.0 |                         493390.0 |                         990443.0 |
      | test precision0.3                            |                         0.889641 |                         0.864437 |                         0.872393 |                         0.889962 |                         0.864629 |                         0.905429 |                         0.881833 |                         0.911238 |                         0.885344 |
      | test recall0.3                               |                         0.922131 |                         0.897355 |                         0.934009 |                         0.935484 |                         0.864987 |                         0.893223 |                         0.912352 |                         0.934704 |                         0.868924 |
      | test tp0.5                                   |                        6806719.0 |                        6547596.0 |                        6873409.0 |                        6879515.0 |                        6381884.0 |                        6514890.0 |                        6657803.0 |                        6907934.0 |                        6236955.0 |
      | test fp0.5                                   |                         561522.0 |                         671113.0 |                         627857.0 |                         517256.0 |                         718562.0 |                         394738.0 |                         506659.0 |                         432424.0 |                         431128.0 |
      | test tn0.5                                   |                       41034252.0 |                       40924664.0 |                       40967908.0 |                       41078488.0 |                       40877184.0 |                       41201060.0 |                       41089052.0 |                       41163320.0 |                       41164680.0 |
      | test fn0.5                                   |                         749514.0 |                        1008637.0 |                         682824.0 |                         676718.0 |                        1174349.0 |                        1041343.0 |                         898430.0 |                         648299.0 |                        1319278.0 |
      | test precision0.5                            |                         0.923792 |                         0.907031 |                           0.9163 |                          0.93007 |                           0.8988 |                         0.942871 |                         0.929282 |                          0.94109 |                         0.935345 |
      | test recall0.5                               |                         0.900809 |                         0.866516 |                         0.909634 |                         0.910442 |                         0.844585 |                         0.862188 |                         0.881101 |                         0.914203 |                         0.825405 |
      | test tp0.7                                   |                        6576475.0 |                        6228335.0 |                        6630207.0 |                        6640601.0 |                        6136998.0 |                        6185431.0 |                        6321268.0 |                        6663553.0 |                        5823676.0 |
      | test fp0.7                                   |                         327204.0 |                         381447.0 |                         350175.0 |                         285835.0 |                         446064.0 |                         178898.0 |                         240152.0 |                         227729.0 |                         194655.0 |
      | test tn0.7                                   |                       41268520.0 |                       41214264.0 |                       41245624.0 |                       41309920.0 |                       41149748.0 |                       41416908.0 |                       41355624.0 |                       41368048.0 |                       41401160.0 |
      | test fn0.7                                   |                         979758.0 |                        1327898.0 |                         926026.0 |                         915632.0 |                        1419235.0 |                        1370802.0 |                        1234965.0 |                         892680.0 |                        1732557.0 |
      | test precision0.7                            |                         0.952604 |                         0.942291 |                         0.949834 |                         0.958733 |                         0.932241 |                         0.971891 |                         0.963399 |                         0.966954 |                         0.967656 |
      | test recall0.7                               |                         0.870338 |                         0.824265 |                         0.877449 |                         0.878824 |                         0.812177 |                         0.818587 |                         0.836563 |                         0.881862 |                         0.770712 |
      | test tp0.9                                   |                        6102547.0 |                        5564160.0 |                        6120144.0 |                        6140071.0 |                        5641558.0 |                        5650455.0 |                        5713166.0 |                        6190425.0 |                        5096155.0 |
      | test fp0.9                                   |                         119229.0 |                         132517.0 |                         115037.0 |                          88637.0 |                         190273.0 |                          48800.0 |                          64046.0 |                          69867.0 |                          44052.0 |
      | test tn0.9                                   |                       41476596.0 |                       41463236.0 |                       41480668.0 |                       41507120.0 |                       41405512.0 |                       41546992.0 |                       41531720.0 |                       41525924.0 |                       41551772.0 |
      | test fn0.9                                   |                        1453686.0 |                        1992073.0 |                        1436089.0 |                        1416162.0 |                        1914675.0 |                        1905778.0 |                        1843067.0 |                        1365808.0 |                        2460078.0 |
      | test precision0.9                            |                         0.980837 |                         0.976738 |                          0.98155 |                          0.98577 |                         0.967373 |                         0.991437 |                         0.988914 |                          0.98884 |                          0.99143 |
      | test recall0.9                               |                         0.807618 |                         0.736367 |                         0.809946 |                         0.812584 |                          0.74661 |                         0.747787 |                         0.756087 |                         0.819247 |                         0.674431 |
      | test accuracy                                |                         0.973328 |                         0.965825 |                         0.973334 |                         0.975708 |                         0.961488 |                         0.970784 |                         0.971414 |                         0.978012 |                         0.964389 |
      | test auc                                     |                         0.968705 |                         0.961385 |                         0.973758 |                         0.975623 |                         0.939052 |                          0.95903 |                         0.966802 |                         0.974297 |                         0.953582 |
      | test f1                                      |                         0.912155 |                         0.886311 |                         0.912955 |                         0.920152 |                          0.87085 |                         0.900726 |                          0.90455 |                         0.927452 |                         0.876943 |
      | test HPC inference time (whole test dataset) |                              42s |                              65s |                             201s |                              45s |                             370s |                              95s |                             230s |                             361s |                             230s |
      | test HPC inference time (one trace)          |                             14ms |                             22ms |                             67ms |                             15ms |                            123ms |                             32ms |                             77ms |                            120ms |                             77ms |
      | test Model size                              |                           275 MB |                           200 MB |                           186 MB |                            14 MB |                           172 MB |                            73 MB |                           312 MB |                           234 MB |                             7 MB |
      :END:

      #+BEGIN_SRC jupyter-python
        final.loc[['val_auc', 'test auc', 'val_recall0.5', 'test recall0.5', 'val_precision0.5',
                   'test precision0.5', 'test f1', 'hp_batch_size', 'hp_input_size', 'hp_lr_power',
                   'hp_lr_start', 'hp_n_levels', 'hp_pool_size', 'hp_scaler',
                   'test HPC inference time (whole test dataset)', 'test HPC inference time (one trace)',
                   'test Model size']]


      #+END_SRC

      #+RESULTS:
      :RESULTS:
      |                                              | 0cd2023eeaf745aca0d3e8ad5e1fc653 | ff67be0b68e540a9a29a36a2d0c7a5be | 484af471c61943fa90e5f78e78a229f0 | fe81d71c52404ed790b3a32051258da9 | 19e3e786e1bc4e2b93856f5dc9de8216 | 347669d050f344ad9fb9e480c814f727 | c1204e3a8a1e4c40a35b5b7b1922d1ce | 714af8cd12c1441eac4ca980e8c20070 | 34a6d207ac594035b1009c330fb67a65 |
      |----------------------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------+----------------------------------|
      | val_auc                                      |                            0.976 |                            0.987 |                            0.981 |                            0.984 |                           0.9745 |                            0.978 |                            0.976 |                            0.962 |                            0.972 |
      | test auc                                     |                         0.961385 |                         0.975623 |                         0.968705 |                         0.973758 |                         0.939052 |                          0.95903 |                         0.966802 |                         0.974297 |                         0.953582 |
      | val_recall0.5                                |                            0.893 |                            0.929 |                           0.8975 |                            0.916 |                            0.885 |                           0.8905 |                            0.875 |                            0.856 |                            0.872 |
      | test recall0.5                               |                         0.866516 |                         0.910442 |                         0.900809 |                         0.909634 |                         0.844585 |                         0.862188 |                         0.881101 |                         0.914203 |                         0.825405 |
      | val_precision0.5                             |                            0.852 |                           0.9065 |                            0.918 |                            0.909 |                           0.8985 |                            0.891 |                            0.888 |                           0.8585 |                           0.9135 |
      | test precision0.5                            |                         0.907031 |                          0.93007 |                         0.923792 |                           0.9163 |                           0.8988 |                         0.942871 |                         0.929282 |                          0.94109 |                         0.935345 |
      | test f1                                      |                         0.886311 |                         0.920152 |                         0.912155 |                         0.912955 |                          0.87085 |                         0.900726 |                          0.90455 |                         0.927452 |                         0.876943 |
      | hp_batch_size                                |                               15 |                               28 |                               26 |                               20 |                               20 |                               10 |                               14 |                               17 |                                9 |
      | hp_input_size                                |                            16384 |                            16384 |                            16384 |                            16384 |                            16384 |                             8192 |                            16384 |                            16384 |                             4096 |
      | hp_lr_power                                  |                                7 |                                1 |                                1 |                                4 |                                1 |                                1 |                                5 |                                5 |                                1 |
      | hp_lr_start                                  |               0.0305060808685107 |               0.0553313915596308 |               0.0136170138242663 |               0.0584071108418767 |                0.043549707353273 |               0.0627676336651573 |               0.0192390310290551 |               0.0101590069352232 |               0.0100697459464075 |
      | hp_n_levels                                  |                                6 |                                5 |                                7 |                                4 |                                3 |                                5 |                                9 |                                3 |                                5 |
      | hp_pool_size                                 |                                4 |                                4 |                                2 |                                4 |                                4 |                                4 |                                2 |                                4 |                                4 |
      | hp_scaler                                    |                          quant_g |                           minmax |                         standard |                         standard |                         standard |                           robust |                           robust |                               l2 |                           maxabs |
      | test HPC inference time (whole test dataset) |                              65s |                              45s |                              42s |                             201s |                             370s |                              95s |                             230s |                             361s |                             230s |
      | test HPC inference time (one trace)          |                             22ms |                             15ms |                             14ms |                             67ms |                            123ms |                             32ms |                             77ms |                            120ms |                             77ms |
      | test Model size                              |                           200 MB |                            14 MB |                           275 MB |                           186 MB |                           172 MB |                            73 MB |                           312 MB |                           234 MB |                             7 MB |
      :END:

    - plot loss vs validation loss for models in hyperparameter training
      #+BEGIN_SRC jupyter-python
        model_dict = {
            ('9051e32b87d84f3485b980067addec30', '61ff87bdb89b4e2ba64f8dacc774992d') :  '484af471c61943fa90e5f78e78a229f0',
            ('93b168c0ff7942c8a908a94129daf973', 'f243b3b742de4dbcb7ccfbd4244706f8') :  '0cd2023eeaf745aca0d3e8ad5e1fc653',
            ('a5b8551144ff46e697a39cd1551e1475', '98cf8cdef9c54b5286e277e75e2ab8c1') :  'fe81d71c52404ed790b3a32051258da9',
            ('00f2635d9fa2463c9a066722163405be', 'd0a8e1748b194f3290d471b6b44f19f8') :  'ff67be0b68e540a9a29a36a2d0c7a5be',
            ('5604d43c1ece461b8e6eaa0dfb65d6dc', '3612536a77f34f22bc83d1d809140aa6') :  '19e3e786e1bc4e2b93856f5dc9de8216',
            ('7cafab027cdd4fc9bf20a43e989df510', '16dff15d935f45e2a836b1f41b07b4e3') :  '347669d050f344ad9fb9e480c814f727',
            ('0e328920e86049928202db95e8cfb7be', 'bf9d2725eb16462d9a101f0a077ce2b5') :  'c1204e3a8a1e4c40a35b5b7b1922d1ce',
            ('1c954fbc02b747bc813c587ac703c74a', 'ba49a80c2616407a8f1fe1fd12096fe0') :  '714af8cd12c1441eac4ca980e8c20070',
            ('3cbd945b62ec4634839372e403f6f377', '458b36a70db843719d202a8eda448f17') :  '34a6d207ac594035b1009c330fb67a65'}

        hparam = run1_2_my.loc[cond2 & cond3]
        hparam.rename(index=model_dict)

        fig, axs = plt.subplots(len(hparam), 2, facecolor='white', figsize=(9, len(hparam)*3),
                                sharex=True, tight_layout=True)
        for i, idx in enumerate(hparam.index):
            for j in range(2):
                print(i, idx[j], model_dict[idx])
                try:
                    logged_val_loss = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/8/{idx[j]}/metrics/val_loss')
                    logged_val_loss = !cat $logged_val_loss
                    logged_val_loss = [i.split(' ') for i in logged_val_loss]
                    logged_val_loss = pd.DataFrame(logged_val_loss, columns=['time', 'val_loss', 'epoch']).astype(float)

                    logged_train_loss = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/8/{idx[j]}/metrics/loss')
                    logged_train_loss = !cat $logged_train_loss
                    logged_train_loss = [i.split(' ') for i in logged_train_loss]
                    logged_train_loss = pd.DataFrame(logged_train_loss, columns=['time', 'train_loss', 'epoch']).astype(float)

                    losses = pd.DataFrame([logged_train_loss.iloc[-1, 1], logged_val_loss.iloc[-1, 1]], index=['train loss', 'val loss'],
                                          columns=[f'{model_dict[idx]}_{j}'])
                    display(losses)
                    last_losses = pd.concat([last_losses, ])
                    sns.lineplot('epoch', 'train_loss', data=logged_train_loss, ax=axs[i, j], label='train loss')
                    sns.lineplot('epoch', 'val_loss', data=logged_val_loss, ax=axs[i, j], label='val loss')
                    if j == 0:
                        axs[i, j].set_title(model_dict[idx])
                except ValueError:
                    pass
        plt.setp(axs, yscale='log', ylabel='')
        fig.align_ylabels(axs)
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      : 0 9051e32b87d84f3485b980067addec30 484af471c61943fa90e5f78e78a229f0
      |            | 484af471c61943fa90e5f78e78a229f0_0 |
      |------------+------------------------------------|
      | train loss |                           0.196100 |
      | val loss   |                           0.199457 |
      : 0 61ff87bdb89b4e2ba64f8dacc774992d 484af471c61943fa90e5f78e78a229f0
      |            | 484af471c61943fa90e5f78e78a229f0_1 |
      |------------+------------------------------------|
      | train loss |                           0.194301 |
      | val loss   |                           0.197833 |
      : 1 93b168c0ff7942c8a908a94129daf973 0cd2023eeaf745aca0d3e8ad5e1fc653
      |            | 0cd2023eeaf745aca0d3e8ad5e1fc653_0 |
      |------------+------------------------------------|
      | train loss |                           0.245977 |
      | val loss   |                           0.250499 |
      |            |                                    |
      : 1 f243b3b742de4dbcb7ccfbd4244706f8 0cd2023eeaf745aca0d3e8ad5e1fc653
      |            | 0cd2023eeaf745aca0d3e8ad5e1fc653_1 |
      |------------+------------------------------------|
      | train loss |                           0.278278 |
      | val loss   |                           0.283107 |
      : 2 a5b8551144ff46e697a39cd1551e1475 fe81d71c52404ed790b3a32051258da9
      |            | fe81d71c52404ed790b3a32051258da9_0 |
      |------------+------------------------------------|
      | train loss |                           0.185773 |
      | val loss   |                           0.186789 |
      : 2 98cf8cdef9c54b5286e277e75e2ab8c1 fe81d71c52404ed790b3a32051258da9
      |            | fe81d71c52404ed790b3a32051258da9_1 |
      |------------+------------------------------------|
      | train loss |                           0.183874 |
      | val loss   |                           0.184316 |
      : 3 00f2635d9fa2463c9a066722163405be ff67be0b68e540a9a29a36a2d0c7a5be
      |            | ff67be0b68e540a9a29a36a2d0c7a5be_0 |
      |------------+------------------------------------|
      | train loss |                           0.172448 |
      | val loss   |                           0.178439 |
      |            |                                    |
      : 3 d0a8e1748b194f3290d471b6b44f19f8 ff67be0b68e540a9a29a36a2d0c7a5be
      : 4 5604d43c1ece461b8e6eaa0dfb65d6dc 19e3e786e1bc4e2b93856f5dc9de8216
      |            | 19e3e786e1bc4e2b93856f5dc9de8216_0 |
      |------------+------------------------------------|
      | train loss |                           0.250983 |
      | val loss   |                           0.260167 |
      : 4 3612536a77f34f22bc83d1d809140aa6 19e3e786e1bc4e2b93856f5dc9de8216
      |            | 19e3e786e1bc4e2b93856f5dc9de8216_1 |
      |------------+------------------------------------|
      | train loss |                           0.246347 |
      | val loss   |                           0.242849 |
      : 5 7cafab027cdd4fc9bf20a43e989df510 347669d050f344ad9fb9e480c814f727
      |            | 347669d050f344ad9fb9e480c814f727_0 |
      |------------+------------------------------------|
      | train loss |                           0.194196 |
      | val loss   |                           0.221606 |
      : 5 16dff15d935f45e2a836b1f41b07b4e3 347669d050f344ad9fb9e480c814f727
      |            | 347669d050f344ad9fb9e480c814f727_1 |
      |------------+------------------------------------|
      | train loss |                           0.196745 |
      | val loss   |                           0.250257 |
      : 6 0e328920e86049928202db95e8cfb7be c1204e3a8a1e4c40a35b5b7b1922d1ce
      |            | c1204e3a8a1e4c40a35b5b7b1922d1ce_0 |
      |------------+------------------------------------|
      | train loss |                           0.266620 |
      | val loss   |                           0.279587 |
      |            |                                    |
      : 6 bf9d2725eb16462d9a101f0a077ce2b5 c1204e3a8a1e4c40a35b5b7b1922d1ce
      |            | c1204e3a8a1e4c40a35b5b7b1922d1ce_1 |
      |------------+------------------------------------|
      | train loss |                           0.262320 |
      | val loss   |                           0.265113 |
      |            |                                    |
      : 7 1c954fbc02b747bc813c587ac703c74a 714af8cd12c1441eac4ca980e8c20070
      |            | 714af8cd12c1441eac4ca980e8c20070_0 |
      |------------+------------------------------------|
      | train loss |                           0.310728 |
      | val loss   |                           0.317540 |
      |            |                                    |
      : 7 ba49a80c2616407a8f1fe1fd12096fe0 714af8cd12c1441eac4ca980e8c20070
      |            | 714af8cd12c1441eac4ca980e8c20070_1 |
      |------------+------------------------------------|
      | train loss |                           0.303487 |
      | val loss   |                           0.340323 |
      |            |                                    |
      : 8 3cbd945b62ec4634839372e403f6f377 34a6d207ac594035b1009c330fb67a65
      |            | 34a6d207ac594035b1009c330fb67a65_0 |
      |------------+------------------------------------|
      | train loss |                           0.189994 |
      | val loss   |                           0.249494 |
      : 8 458b36a70db843719d202a8eda448f17 34a6d207ac594035b1009c330fb67a65
      |            | 34a6d207ac594035b1009c330fb67a65_1 |
      |------------+------------------------------------|
      | train loss |                           0.211194 |
      | val loss   |                           0.239334 |
      |            |                                    |
      :END:
      [[file:./data/exp-220227-unet/jupyter/supplementary_train-loss-vs-val-loss.png]]

*** Analysis 1b: correct simulated test data
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
    :END:

    #+BEGIN_SRC jupyter-python
      %cd ~/Programme/drmed-git
    #+END_SRC

    #+RESULTS:
    : /home/lex/Programme/drmed-git

    #+BEGIN_SRC jupyter-python
      import os
      import numpy as np
      import matplotlib.pyplot as plt
      import pandas as pd
      import seaborn as sns
      from pathlib import Path
      from pprint import pprint
      # use seaborn style as default even if I just use matplotlib

      sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                    context='paper')
      # logging.basicConfig(filename="/home/lex/Programme/drmed-git/data/exp-220316-publication1/jupyter.log",
      #               filemode='w', format='%(asctime)s - %(message)s',
      #               force=True,
      #               level=logging.DEBUG)
    #+END_SRC

    #+RESULTS:

    #+BEGIN_SRC jupyter-python
      path = Path('data/exp-220227-unet/220425_simexps/0cd20')

      odot069_0dot01_path = path / '0.069_results/0cd20_0dot069-0dot01_outputParam.csv'
      odot069_0dot1_path = path / '0.069_results/0cd20_0dot069-0dot1_outputParam.csv'
      odot069_1dot0_path = path / '0.069_results/0cd20_0dot069-1dot0_outputParam.csv'

      odot08_0dot01_path = path / '0.08_results/0cd20_0dot08-0dot01_outputParam.csv'
      odot08_0dot1_path = path / '0.08_results/0cd20_0dot08-0dot1_outputParam.csv'
      odot08_1dot0_path = path / '0.08_results/0cd20_0dot08-1dot0_outputParam.csv'

      odot1_0dot01_path = path / '0.1_results/0cd20_0dot1-0dot01_outputParam.csv'
      odot1_0dot1_path = path / '0.1_results/0cd20_0dot1-0dot1_outputParam.csv'
      odot1_1dot0_path = path / '0.1_results/0cd20_0dot1-1dot0_outputParam.csv'

      odot2_0dot01_path = path / '0.2_results/0cd20_0dot2-0dot01_outputParam.csv'
      odot2_0dot1_path = path / '0.2_results/0cd20_0dot2-0dot1_outputParam.csv'
      odot2_1dot0_path = path / '0.2_results/0cd20_0dot2-1dot0_outputParam.csv'

      odot4_0dot01_path = path / '0.4_results/0cd20_0dot4-0dot01_outputParam.csv'
      odot4_0dot1_path = path / '0.4_results/0cd20_0dot4-0dot1_outputParam.csv'
      odot4_1dot0_path = path / '0.4_results/0cd20_0dot4-1dot0_outputParam.csv'

      odot6_0dot01_path = path / '0.6_results/0cd20_0dot6-0dot01_outputParam.csv'
      odot6_0dot1_path = path / '0.6_results/0cd20_0dot6-0dot1_outputParam.csv'
      odot6_1dot0_path = path / '0.6_results/0cd20_0dot6-1dot0_outputParam.csv'

      one_0dot01_path = path / '1.0_results/0cd20_1dot0-0dot01_outputParam.csv'
      one_0dot1_path = path / '1.0_results/0cd20_1dot0-0dot1_outputParam.csv'
      one_1dot0_path = path / '1.0_results/0cd20_1dot0-1dot0_outputParam.csv'

      three_0dot01_path = path / '3.0_results/0cd20_3dot0-0dot01_outputParam.csv'
      three_0dot1_path = path / '3.0_results/0cd20_3dot0-0dot1_outputParam.csv'
      three_1dot0_path = path / '3.0_results/0cd20_3dot0-1dot0_outputParam.csv'

      ten_0dot01_path = path / '10.0_results/0cd20_10dot0-0dot01_outputParam.csv'
      ten_0dot1_path = path / '10.0_results/0cd20_10dot0-0dot1_outputParam.csv'
      ten_1dot0_path = path / '10.0_results/0cd20_10dot0-1dot0_outputParam.csv'

      fifty_0dot01_path = path / '50.0_results/0cd20_50dot0-0dot01_outputParam.csv'
      fifty_0dot1_path = path / '50.0_results/0cd20_50dot0-0dot1_outputParam.csv'
      fifty_1dot0_path = path / '50.0_results/0cd20_50dot0-1dot0_outputParam.csv'

    #+END_SRC

    #+RESULTS:

    - we load the data and combine it. We convert the simulated D [um2/s] in
      t[ms]. Based on an exploratory plot of A1 and A2 we swap A1-A2 and
      txy1-txy2, so that A1 and txy1 always represent the bigger fitted fraction
      size.
    #+BEGIN_SRC jupyter-python
      odot069_0dot01 = pd.read_csv(odot069_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[163,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot069_0dot1 = pd.read_csv(odot069_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[163,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot069_1dot0 = pd.read_csv(odot069_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[163,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      odot08_0dot01 = pd.read_csv(odot08_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[141,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot08_0dot01[['txy1', 'txy2']] = odot08_0dot01[['txy2', 'txy1']]
      odot08_0dot01[['A1', 'A2']] = odot08_0dot01[['A2', 'A1']]
      odot08_0dot1 = pd.read_csv(odot08_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[141,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot08_1dot0 = pd.read_csv(odot08_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[141,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      odot1_0dot01 = pd.read_csv(odot1_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[113,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot1_0dot1 = pd.read_csv(odot1_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[113,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot1_1dot0 = pd.read_csv(odot1_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[113,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      odot2_0dot01 = pd.read_csv(odot2_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[56.4,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot2_0dot1 = pd.read_csv(odot2_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[56.4,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot2_0dot1[['txy1', 'txy2']] = odot2_0dot1[['txy2', 'txy1']]
      odot2_0dot1[['A1', 'A2']] = odot2_0dot1[['A2', 'A1']]
      odot2_1dot0 = pd.read_csv(odot2_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[56.4,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      odot4_0dot01 = pd.read_csv(odot4_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[28.2,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot4_0dot1 = pd.read_csv(odot4_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[28.2,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot4_0dot1[['txy1', 'txy2']] = odot4_0dot1[['txy2', 'txy1']]
      odot4_0dot1[['A1', 'A2']] = odot4_0dot1[['A2', 'A1']]
      odot4_1dot0 = pd.read_csv(odot4_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[28.2,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      odot6_0dot01 = pd.read_csv(odot6_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[18.8,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot6_0dot1 = pd.read_csv(odot6_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[18.8,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      odot6_1dot0 = pd.read_csv(odot6_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[18.8,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      one_0dot01 = pd.read_csv(one_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[11.3,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      one_0dot1 = pd.read_csv(one_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[11.3,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      one_1dot0 = pd.read_csv(one_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[11.3,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      three_0dot01 = pd.read_csv(three_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[3.76,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      three_0dot1 = pd.read_csv(three_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[3.76,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      three_0dot1[['txy1', 'txy2']] = three_0dot1[['txy2', 'txy1']]
      three_0dot1[['A1', 'A2']] = three_0dot1[['A2', 'A1']]
      three_1dot0 = pd.read_csv(three_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[3.76,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      ten_0dot01 = pd.read_csv(ten_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[1.13,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      ten_0dot1 = pd.read_csv(ten_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[1.13,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      ten_1dot0 = pd.read_csv(ten_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[1.13,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      fifty_0dot01 = pd.read_csv(fifty_0dot01_path, sep=',').assign(
          artifact_speed=100*[1127,], stationary_speed=100*[0.23,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      fifty_0dot1 = pd.read_csv(fifty_0dot1_path, sep=',').assign(
          artifact_speed=100*[113,], stationary_speed=100*[0.23,],
          model=100*['0cd20',], correction=100*['cut and shift',])
      fifty_0dot1[['txy1', 'txy2']] = fifty_0dot1[['txy2', 'txy1']]
      fifty_0dot1[['A1', 'A2']] = fifty_0dot1[['A2', 'A1']]
      fifty_1dot0 = pd.read_csv(fifty_1dot0_path, sep=',').assign(
          artifact_speed=100*[11.3,], stationary_speed=100*[0.23,],
          model=100*['0cd20',], correction=100*['cut and shift',])

      all_param = pd.concat([odot069_0dot01, odot069_0dot1, odot069_1dot0,
                             odot08_0dot01, odot08_0dot1, odot08_1dot0,
                             odot1_0dot01, odot1_0dot1, odot1_1dot0,
                             odot2_0dot01, odot2_0dot1, odot2_1dot0,
                             odot4_0dot01, odot4_0dot1, odot4_1dot0,
                             odot6_0dot01, odot6_0dot1, odot6_1dot0,
                             one_0dot01, one_0dot1, one_1dot0,
                             three_0dot01, three_0dot1, three_1dot0,
                             ten_0dot01, ten_0dot1, ten_1dot0,
                             fifty_0dot01, fifty_0dot1, fifty_1dot0],
                            ignore_index=True)

      all_param = pd.wide_to_long(all_param, stubnames='txy',
                                  i=['name_of_plot'],
                                  j='fitted species (txy)')
      all_param = all_param.reset_index()
      all_param = pd.wide_to_long(all_param, stubnames='A',
                                  i=['name_of_plot', 'fitted species (txy)'],
                                  j='fitted species (A)')
      all_param = all_param.reset_index()
      all_param
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    |       | name_of_plot                                      | fitted species (txy) | fitted species (A) |   N (FCS) | parent_name          | master_file | stdev(A1) | stdev(A2) | parent_uqid | Dimen | ... | cpm (kHz) | alpha1 |   xmax | artifact_speed | stdev(offset) | stdev(txy1) |    offset | bri (kHz) | Diff_species |        A |
    |-------+---------------------------------------------------+----------------------+--------------------+-----------+----------------------+-------------+-----------+-----------+-------------+-------+-----+-----------+--------+--------+----------------+---------------+-------------+-----------+-----------+--------------+----------|
    |     0 | 2022-04-25_multipletau_0cd20_0dot069-0dot01_26... |                    1 |                  2 | 37.523452 | 0cd20_0dot069-0dot01 | Not known   | None      | None      |           0 |    2D | ... |  0.026650 |    1.0 | 8192.0 |         1127.0 | None          | None        | -0.001696 |       1.0 |            2 | 0.001292 |
    |     1 | 2022-04-25_multipletau_0cd20_0dot069-0dot01_26... |                    1 |                  1 | 37.523452 | 0cd20_0dot069-0dot01 | Not known   | None      | None      |           0 |    2D | ... |  0.026650 |    1.0 | 8192.0 |         1127.0 | None          | None        | -0.001696 |       1.0 |            2 | 0.998708 |
    |     2 | 2022-04-25_multipletau_0cd20_0dot069-0dot01_26... |                    1 |                  2 | 35.394544 | 0cd20_0dot069-0dot01 | Not known   | None      | None      |           0 |    2D | ... |  0.028253 |    1.0 | 8192.0 |         1127.0 | None          | None        | -0.001883 |       1.0 |            2 | 0.002290 |
    |     3 | 2022-04-25_multipletau_0cd20_0dot069-0dot01_26... |                    1 |                  1 | 35.394544 | 0cd20_0dot069-0dot01 | Not known   | None      | None      |           0 |    2D | ... |  0.028253 |    1.0 | 8192.0 |         1127.0 | None          | None        | -0.001883 |       1.0 |            2 | 0.997710 |
    |     4 | 2022-04-25_multipletau_0cd20_0dot069-0dot01_26... |                    1 |                  2 | 27.754107 | 0cd20_0dot069-0dot01 | Not known   | None      | None      |           0 |    2D | ... |  0.036031 |    1.0 | 8192.0 |         1127.0 | None          | None        | -0.008520 |       1.0 |            2 | 0.526621 |
    |   ... | ...                                               |                  ... |                ... |       ... | ...                  | ...         | ...       | ...       |         ... |   ... | ... |       ... |    ... |    ... |            ... | ...           | ...         |       ... |       ... |          ... |      ... |
    | 11995 | 2022-04-25_multipletau_0cd20_50dot0-1dot0_1797... |                    2 |                  1 |  1.000001 | 0cd20_50dot0-1dot0   | Not known   | None      | None      |           0 |    2D | ... |  0.999999 |    1.0 | 1024.0 |           11.3 | None          | None        | -0.000090 |       1.0 |            2 | 1.000000 |
    | 11996 | 2022-04-25_multipletau_0cd20_50dot0-1dot0_1798... |                    2 |                  2 |  1.000001 | 0cd20_50dot0-1dot0   | Not known   | None      | None      |           0 |    2D | ... |  0.999999 |    1.0 | 1024.0 |           11.3 | None          | None        | -0.000090 |       1.0 |            2 | 0.000000 |
    | 11997 | 2022-04-25_multipletau_0cd20_50dot0-1dot0_1798... |                    2 |                  1 |  1.000001 | 0cd20_50dot0-1dot0   | Not known   | None      | None      |           0 |    2D | ... |  0.999999 |    1.0 | 1024.0 |           11.3 | None          | None        | -0.000090 |       1.0 |            2 | 1.000000 |
    | 11998 | 2022-04-25_multipletau_0cd20_50dot0-1dot0_1799... |                    2 |                  2 |  1.000001 | 0cd20_50dot0-1dot0   | Not known   | None      | None      |           0 |    2D | ... |  0.999999 |    1.0 | 1024.0 |           11.3 | None          | None        | -0.000090 |       1.0 |            2 | 0.000000 |
    | 11999 | 2022-04-25_multipletau_0cd20_50dot0-1dot0_1799... |                    2 |                  1 |  1.000001 | 0cd20_50dot0-1dot0   | Not known   | None      | None      |           0 |    2D | ... |  0.999999 |    1.0 | 1024.0 |           11.3 | None          | None        | -0.000090 |       1.0 |            2 | 1.000000 |

12000 rows × 37 columns
    :END:

    #+BEGIN_SRC jupyter-python
      # data = all_param.loc[all_param['correction'].isin(['no correction', 'delete and shift'])]

      g = sns.catplot(data=all_param,
                      y='txy',
                      x='model',
                      hue='fitted species (txy)',
                      col='artifact_speed',
                      row='stationary_speed',
                      sharey=True,
                      height=5,
                      aspect=1,
                      legend_out=True,
                      kind='boxen',
                      showfliers=False,
                      margin_titles=True)
      g.map_dataframe(sns.stripplot,
            y='txy',
            x='model',
            hue="fitted species (txy)",
            dodge=True,
            palette=sns.color_palette(['0.3']),
            size=4,
            jitter=0.2)
      # add hlines
      artifact_speed = np.tile(sorted(set(all_param['artifact_speed'])), 10)
      stationary_speed = np.repeat(sorted(set(all_param['stationary_speed'])), 3)
      g.tight_layout()
      g.fig.suptitle('Prediction and "cut and shift" correction applied on simulated test data', y=1.03, size=20)
      for i, axes in enumerate(g.axes.flat):
      #      _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=45)
          axes.axhline(artifact_speed[i], ls='--', lw=4, c=sns.color_palette()[1])
          axes.axhline(stationary_speed[i], ls='--', lw=4, c=sns.color_palette()[0])
      plt.setp(g.axes, yscale='log', # xlabel='model',
               ylabel=r'transit time $\tau_{D}$ (log)')
      # plt.setp(g.legend, title='Correlator and\nfit parameter')
      plot1_file = 'analysis1_0cd20_simulation_transit-times'
      plt.show()
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    : 0
    [[file:./data/exp-220227-unet/jupyter/ca7e75f176820ccd6a0135473cc2d59ad6c30316.png]]
    :END:
    [[file:./data/exp-220227-unet/jupyter/analysis1_0cd20_simulation_transit-times.svg]]

    #+BEGIN_SRC jupyter-python
            # data = all_param.loc[all_param['correction'].isin(['no correction', 'delete and shift'])]

      g = sns.catplot(data=all_param,
                      y='A',
                      x='model',
                      hue='fitted species (A)',
                      col='artifact_speed',
                      row='stationary_speed',
                      sharey=True,
                      height=5,
                      aspect=1,
                      legend_out=True,
                      kind='boxen',
                      showfliers=False,
                      margin_titles=True)
      g.map_dataframe(sns.stripplot,
            y='A',
            x='model',
            hue="fitted species (A)",
            dodge=True,
            palette=sns.color_palette(['0.3']),
            size=4,
            jitter=0.2)
      # add hlines
      g.tight_layout()
      g.fig.suptitle('Prediction and "cut and shift" correction applied on simulated test data', y=1.03, size=20)
      #for i, axes in enumerate(g.axes.flat):
      #      _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=45)
      plt.setp(g.axes, # xlabel='model',
               ylabel=r'relative fitted fraction size')
      # plt.setp(g.legend, title='Correlator and\nfit parameter')

      plot1_file = 'analysis1_0cd20_simulation_fraction-size'
      plt.savefig(f'{plot1_file}.pdf', bbox_inches='tight', dpi=300)
      os.system(f'pdf2svg {plot1_file}.pdf {plot1_file}.svg')
      os.system(f'rm {plot1_file}.pdf')
    #+END_SRC

    #+RESULTS:


    [[file:./data/exp-220227-unet/jupyter/analysis1_0cd20_simulation_fraction-size.png]]

    #+BEGIN_SRC jupyter-python
      all_param.keys()
    #+END_SRC

    #+RESULTS:
    : Index(['name_of_plot', 'fitted species (txy)', 'fitted species (A)',
    :        'stdev(alpha2)', 'GN0', 'alpha2', 'xmax', 'stdev(A2)',
    :        'Triplet_species', 'Dimen', 'time of fit', 'above zero', 'cpm (kHz)',
    :        'N (mom)', 'stdev(txy2)', 'parent_uqid', 'stdev(offset)', 'N (FCS)',
    :        'stdev(A1)', 'correction', 'txy', 'Triplet_eq', 'stationary_speed',
    :        'master_file', 'stdev(txy1)', 'parent_name', 'artifact_speed',
    :        'stdev(GN0)', 'Diff_species', 'xmin', 'model', 'alpha1',
    :        'stdev(alpha1)', 'bri (kHz)', 'offset', 'Diff_eq', 'A'],
    :       dtype='object')

    #+BEGIN_SRC jupyter-python
      %cd ~/Programme/drmed-git
    #+END_SRC

*** Analysis 2a: Run models on experimental data
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bde3 :pandoc t
    :END:

    #+NAME: prepare-jupyter
    #+BEGIN_SRC jupyter-python :var data_path="/beegfs/ye53nis/data/1911DD_atto+LUVs" :var output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-05-22_experimental/"
      %cd /beegfs/ye53nis/drmed-git
      import logging
      import os
      import sys

      import matplotlib.pyplot as plt
      import numpy as np
      import pandas as pd
      import seaborn as sns

      from pathlib import Path
      from pprint import pprint
      from tensorflow.keras.optimizers import Adam
      from mlflow.keras import load_model

      FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
      sys.path.append(FLUOTRACIFY_PATH)
      from fluotracify.applications import corr_fit_object as cfo
      from fluotracify.training import build_model as bm

      data_path = Path(data_path)
      output_path = Path(output_path)
      log_path = output_path.parent / f'{output_path.name}.log'

      logging.basicConfig(filename=log_path,
                          filemode='w', format='%(asctime)s - %(message)s',
                          force=True)

      log = logging.getLogger(__name__)
      log.setLevel(logging.DEBUG)

      sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                    context='paper')
      class ParameterClass():
          """Stores parameters for correlation """
          def __init__(self):
              # Where the data is stored.
              self.data = []
              self.objectRef = []
              self.subObjectRef = []
              self.colors = ['blue', 'green', 'red', 'cyan', 'magenta',
                             'yellow', 'black']
              self.numOfLoaded = 0
              # very fast from Ncasc ~ 14 onwards
              self.NcascStart = 0
              self.NcascEnd = 30  # 25
              self.Nsub = 6  # 6
              self.photonLifetimeBin = 10  # used for photon decay
              self.photonCountBin = 1  # used for time series

      par_obj = ParameterClass()

      model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                  '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                  '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                  'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                  'c1204e3a8a1e4c40a35b5b7b1922d1ce']

      model_name_ls = [f'{s:.5}' for s in model_ls]

      # scaler_ls = ['minmax', 'robust', 'maxabs', 'l2', 'standard', 'quant_g', 'standard',
      #              'standard', 'robust']

      pred_thresh = 0.5

      if data_path.name == "1911DD_atto+LUVs":
          path_clean1 = data_path / 'clean_ptu_part1/'
          path_clean2 = data_path / 'clean_ptu_part2/'
          path_dirty1 = data_path / 'dirty_ptu_part1/'
          path_dirty2 = data_path / 'dirty_ptu_part2/'
          files_clean1 = [path_clean1 / f for f in os.listdir(path_clean1) if f.endswith('.ptu')]
          files_clean2 = [path_clean2 / f for f in os.listdir(path_clean2) if f.endswith('.ptu')]
          files_dirty1 = [path_dirty1 / f for f in os.listdir(path_dirty1) if f.endswith('.ptu')]
          files_dirty2 = [path_dirty2 / f for f in os.listdir(path_dirty2) if f.endswith('.ptu')]

      if data_path.name == "191113_Pex5_2_structured":
          path_clean = data_path / 'HsPEX5EGFP 1-100001'
          path_dirty = data_path / 'TbPEX5EGFP 1-10002'
          files_clean = [path_clean / f for f in os.listdir(path_clean) if f.endswith('.ptu')]
          files_dirty = [path_dirty / f for f in os.listdir(path_dirty) if f.endswith('.ptu')]

      def predict_correct_correlate_ptu(files, model_id, method, out_path):

          logged_scaler = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{model_ls[model_id]}/params/scaler')
          logged_scaler = !cat $logged_scaler
          logged_scaler = logged_scaler[0]

          logged_model = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{model_ls[model_id]}/artifacts/model')
          logged_model = load_model(logged_model, compile=False)
          logged_model.compile(loss=bm.binary_ce_dice_loss(),
                               optimizer=Adam(),
                               metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))
          if method == 'delete_and_shift':
              method_str = 'DELSHIFT'
          elif method == 'delete':
              method_str = 'DEL'
          for idx, myfile in enumerate(files):
              ptufile = cfo.PicoObject(myfile, par_obj)
              ptufile.predictTimeSeries(model=logged_model,
                                        scaler=logged_scaler)
              ptufile.correctTCSPC(method=method)
              for key in list(ptufile.trueTimeArr.keys()):
                  if method_str in key:
                      ptufile.get_autocorrelation(method='tttr2xfcs', name=key)


              for m in ['multipletau', 'tttr2xfcs', 'tttr2xfcs_with_weights']:
                  if m in list(ptufile.autoNorm.keys()):
                      for key, item in list(ptufile.autoNorm[m].items()):
                          if method_str in key:
                              ptufile.save_autocorrelation(name=key, method=m,
                                                           output_path=out_path)


      def correlate_ptu(files, out_path):
          for idx, myfile in enumerate(files):
              ptufile = cfo.PicoObject(myfile, par_obj)
              for key in list(ptufile.trueTimeArr.keys()):
                  ptufile.get_autocorrelation(method='tttr2xfcs', name=key)


              for m in ['multipletau', 'tttr2xfcs', 'tttr2xfcs_with_weights']:
                  if m in list(ptufile.autoNorm.keys()):
                      for key, item in list(ptufile.autoNorm[m].items()):
                          ptufile.save_autocorrelation(name=key, method=m,
                                                       output_path=out_path)


    #+END_SRC

    #+RESULTS: prepare-jupyter
    : /beegfs/ye53nis/drmed-git
    : 2023-01-10 17:38:18.004165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2023-01-10 17:38:18.004236: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

    #+NAME: kill-jupyter
    #+BEGIN_SRC jupyter-python
      os._exit(00)
    #+END_SRC

    #+RESULTS:
    : 7a752b61-60c1-4322-8105-e8dbd705caa0

    #+CALL: prepare-jupyter()

      #+begin_src jupyter-python
        model_id = 0

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty1,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-05-23 14:47:32.428742: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-23 14:47:32.428785: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-23 14:47:32.428823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-23 14:47:32.429138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    : 2df4455b-0130-4b59-af50-3a85f1419fd2

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-23 19:52:48.412017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-23 19:52:48.412054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


      #+begin_src jupyter-python
        model_id = 0

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-05-23 19:53:11.911961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-23 19:53:11.912000: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-23 19:53:11.912024: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-23 19:53:11.912392: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()

   - on node 2:
      #+begin_src jupyter-python
        model_id = 1

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty1 and files_dirty2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()

   - on node 3:
      #+begin_src jupyter-python
        model_id = 2

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty1 and files_dirty2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()
   - on node 2:
      #+begin_src jupyter-python
        model_id = 3  # 34a6d

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=0,
            out_path=out_dir)
      #+end_src

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()
   - on node 3:
      #+BEGIN_SRC jupyter-python
        model_id = 4  # 484af

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=0,
            out_path=out_dir)
      #+END_SRC

    #+CALL: kill-jupyter()

    #+RESULTS:
    : ea569473-6848-41cb-bae6-4f5ac1590e71

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-23 21:51:34.834624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-23 21:51:34.834663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

   - on node 1:
      #+BEGIN_SRC jupyter-python
        model_id = 5 # 0cd20

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_dirty1,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-23 21:52:02.797179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-23 21:52:02.797239: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-23 21:52:02.797260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-23 21:52:02.797625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-24 10:12:54.289832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-24 10:12:54.289868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+BEGIN_SRC jupyter-python
        model_id = 5 # 0cd20

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_dirty2,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-24 10:13:01.303436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-24 10:13:01.303503: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-24 10:13:01.303541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-24 10:13:01.303975: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter()

   - on node 2:
      #+BEGIN_SRC jupyter-python
        model_id = 6 # fe81d

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_dirty1,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

    #+CALL: kill-jupyter()

    #+RESULTS:
    : bf3b2ade-cc27-404c-b7bc-9db7a0583d4e

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-24 13:29:48.438857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-24 13:29:48.438908: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

   - on node 1:
      #+BEGIN_SRC jupyter-python
        model_id = 7 # 19e3e

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_dirty1,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-24 13:30:26.419948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-24 13:30:26.420019: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-24 13:30:26.420055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-24 13:30:26.420612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()

    #+RESULTS:
    : c55ec613-2fe9-4dd8-bbb0-03251a8173c2

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-24 17:07:04.399895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-24 17:07:04.399949: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

   - on node 1:
      #+BEGIN_SRC jupyter-python
        model_id = 7 # 19e3e

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_dirty2,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-24 17:07:10.270368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-24 17:07:10.270428: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-24 17:07:10.270454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-24 17:07:10.270792: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

   - on node 3:
      #+BEGIN_SRC jupyter-python
        model_id = 8  # c1204

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=0,
            out_path=out_dir)
      #+END_SRC

   - on node 1:
      #+BEGIN_SRC jupyter-python
        model_id = 5 # 0cd20

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_clean1,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-25 14:48:29.187895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-25 14:48:29.187952: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-25 14:48:29.187985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-25 14:48:29.188422: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    : 7e9aa800-f60f-4d9a-b565-722c72070338

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-25 16:48:58.124680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-25 16:48:58.124720: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+BEGIN_SRC jupyter-python
        model_id = 5 # 0cd20

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_clean2,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-25 16:49:18.365951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-25 16:49:18.366011: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-25 16:49:18.366045: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-25 16:49:18.366534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

   - on node 3:
      #+begin_src jupyter-python
        model_id = 2 # 714af

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

   - on node 2:
      #+begin_src jupyter-python
        model_id = 0 # ff67b

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean1,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

   - on node 1:
      #+BEGIN_SRC jupyter-python
        model_id = 1 # 34766

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_clean1,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-26 00:11:02.988574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-26 00:11:02.988629: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-26 00:11:02.988653: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-26 00:11:02.988969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    :RESULTS:
    # [goto error]
    : ---------------------------------------------------------------------------
    : NameError                                 Traceback (most recent call last)
    : Input In [1], in <cell line: 1>()
    : ----> 1 os._exit(00)
    :
    : NameError: name 'os' is not defined
    :END:

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-26 11:49:10.130005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-26 11:49:10.130041: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+BEGIN_SRC jupyter-python
        model_id = 1

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
        files=files_clean2,
        model_id=model_id, method='delete_and_shift',
        out_path=out_dir)
      #+END_SRC

      #+RESULTS:
      : 2022-05-26 11:49:16.690889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-05-26 11:49:16.690951: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-05-26 11:49:16.690989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node105): /proc/driver/nvidia/version does not exist
      : 2022-05-26 11:49:16.691462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
   - on node 2:
      #+begin_src jupyter-python
        model_id = 3 # 34a6d

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src
   - on node 3:
      #+begin_src jupyter-python
        out_dir = output_path / f'clean/'

        os.makedirs(out_dir, exist_ok=True)

        correlate_ptu(
            files=files_clean_1 and files_clean2,
            out_path=out_dir)
      #+end_src

   - on node 1:
    #+CALL: kill-jupyter()

    #+RESULTS:
    : a26d0ea2-4340-4437-afb6-5e931c8efe68

    #+CALL: prepare-jupyter()

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-05-27 13:21:04.304353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-05-27 13:21:04.304423: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        out_dir = output_path / f'dirty/'

        os.makedirs(out_dir, exist_ok=True)

        correlate_ptu(
            files=files_dirty2,
            out_path=out_dir)
      #+end_src

      #+RESULTS:

   - on node 2:
      #+begin_src jupyter-python
        model_id = 7 # 19e3e

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src
   - on node 3:
      #+begin_src jupyter-python
        model_id = 4 # 484af

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

   - on node 2:
      #+begin_src jupyter-python
        model_id = 8 # c1204

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

   - on node 3:
      #+begin_src jupyter-python
        model_id = 6 # fe81d

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean_1 and files_clean2,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src


    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git

   - on node 1:
    #+BEGIN_SRC jupyter-python
      out_dir = output_path / f'clean/'

      os.makedirs(out_dir, exist_ok=True)

      correlate_ptu(
          files=files_clean,
          out_path=out_dir)
    #+END_SRC

    #+RESULTS:
    : 274c16ef-1bb8-47fd-9ac9-d83e193d2c7c

    #+CALL: kill-jupyter()
    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-03 00:20:04.405561: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-03 00:20:04.405614: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

    #+BEGIN_SRC jupyter-python
      out_dir = output_path / f'dirty/'

      os.makedirs(out_dir, exist_ok=True)

      correlate_ptu(
          files=files_dirty,
          out_path=out_dir)
    #+END_SRC

    #+RESULTS:

      #+RESULTS:
      : 2022-06-02 16:25:02.408577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-02 16:25:02.408633: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-02 16:25:02.408668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-02 16:25:02.409190: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
      # [goto error]

      on node 2:
      #+begin_src jupyter-python
        model_id = 0 # ff67b

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      on node 3:
      #+begin_src jupyter-python
        model_id = 1  # 34766

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    : e17bafa1-336e-4ae4-9eac-2e4e754b163b

    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-03 00:35:48.794905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-03 00:35:48.794949: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      on node 1:
      #+begin_src jupyter-python
        model_id = 2  # 714af

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 00:36:59.208902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 00:36:59.208990: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 00:36:59.209034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 00:36:59.209615: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    : cb8ca215-2cec-4c8a-b57f-9e7a3fa0850a

    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-03 01:03:42.934510: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-03 01:03:42.934560: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 2  # 714af

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 01:03:53.314614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 01:03:53.314706: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 01:03:53.314759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 01:03:53.315343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      on node 2:
      #+begin_src jupyter-python
        model_id = 3 # 34a6d

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      on node 1:
      #+begin_src jupyter-python
        model_id = 4  # 484af

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 16:05:25.702609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 16:05:25.702662: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 16:05:25.702697: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 16:05:25.703121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()

    #+RESULTS:
    : ---------------------------------------------------------------------------
    : NameError                                 Traceback (most recent call last)
    : Input In [1], in <cell line: 1>()
    : ----> 1 os._exit(00)
    :
    : NameError: name 'os' is not defined
    :RESULTS:
    # [goto error]
    :END:



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-03 17:13:28.754363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-03 17:13:28.754407: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 4  # 484af

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 17:13:35.380945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 17:13:35.380992: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 17:13:35.381021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 17:13:35.381294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      on node 3:
      #+begin_src jupyter-python
        model_id = 5  # 0cd20

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      on node 2:
      #+begin_src jupyter-python
        model_id = 6 # fe81d

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      on node 1:
      #+begin_src jupyter-python
        model_id = 7  # 19e3e

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 17:59:22.958003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 17:59:22.958066: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 17:59:22.958106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 17:59:22.958596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-03 18:12:09.643502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-03 18:12:09.643564: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 7  # 19e3e

        out_dir = output_path / f'clean_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 18:12:16.305111: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 18:12:16.305153: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 18:12:16.305181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 18:12:16.305464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      on node 3:
      #+begin_src jupyter-python
        model_id = 8  # c1204

        out_dir = output_path / f'dirty_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete_and_shift',
            out_path=out_dir)
      #+end_src
    - on node 2
      #+begin_src jupyter-python
        model_id = 0 # ff67b

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete',
            out_path=out_dir)
      #+end_src

      on node 1:
      #+begin_src jupyter-python
        model_id = 1  # 34766

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-03 18:34:51.572833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-03 18:34:51.572883: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-03 18:34:51.572912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-03 18:34:51.573277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()

    #+RESULTS:
    : 947e95f9-7f45-4e35-a5f6-857c1a00df32



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-05 19:58:02.542852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-05 19:58:02.542898: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 1  # 34766

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-05 19:58:25.596269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-05 19:58:25.596330: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-05 19:58:25.596366: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-05 19:58:25.596907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    - on node 3
      #+begin_src jupyter-python
        model_id = 2  # 714af

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete',
            out_path=out_dir)
      #+end_src
      on node 1:
      #+begin_src jupyter-python
        model_id = 3  # 34a6d

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-05 20:29:47.728848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-05 20:29:47.728912: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-05 20:29:47.728949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-05 20:29:47.729437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()

    #+RESULTS:
    : 2623f23f-2abb-44a9-8a8a-37fe279cda97



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-06 11:30:37.942306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-06 11:30:37.942353: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 3  # 34a6d

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 11:30:52.913876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 11:30:52.913938: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 11:30:52.913990: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-06 11:30:52.914431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    - on node 2
      #+begin_src jupyter-python
        model_id = 4  # 484af

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete',
            out_path=out_dir)
      #+end_src

    - on node 3
      #+begin_src jupyter-python
        model_id = 5  # 0cd20

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete',
            out_path=out_dir)
      #+end_src

      on node 1:
      #+begin_src jupyter-python
        model_id = 6   # fe81d

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 16:01:59.893483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 16:01:59.893526: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 16:01:59.893551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node034): /proc/driver/nvidia/version does not exist
      : 2022-06-06 16:01:59.893887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.


    #+CALL: kill-jupyter()

    #+RESULTS:
    :RESULTS:
    # [goto error]
    : ---------------------------------------------------------------------------
    : NameError                                 Traceback (most recent call last)
    : Input In [1], in <cell line: 1>()
    : ----> 1 os._exit(00)
    :
    : NameError: name 'os' is not defined
    :END:



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-06 16:01:50.356512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-06 16:01:50.356556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 6  # fe81d

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src
    - on node 2
      #+begin_src jupyter-python
        model_id = 7  # 19e3e

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty and files_clean,
            model_id=model_id, method='delete',
            out_path=out_dir)
      #+end_src

**** node 2
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8890:c37e524a-8134-4d8f-b24a-367acaf1bdd5
    :END:
    1. Set up tmux (if we haven't done that before) (=#+CALL:
       setup-tmux[:session local]=)
       #+CALL: setup-tmux[:session local]

       #+RESULTS:
       |         |                                        |           |
       | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
       | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    2. Request compute node
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux2
         cd /
         srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
       #+END_SRC

    3. Start Jupyter Lab (~#+CALL: jpt-tmux[:session jpmux]~)
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux2
       conda activate tf
       export PORT=8890
       export XDG_RUNTIME_DIR=''
       export XDG_RUNTIME_DIR=""
       jupyter lab --no-browser --port=$PORT
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node152 /]$ jupyter lab --no-browser --port=$PORT
         [I 2022-06-03 00:24:43.720 ServerApp] jupyterlab | extension was successfully linked.
         [I 2022-06-03 00:24:44.304 ServerApp] nbclassic | extension was successfully linked.
         [I 2022-06-03 00:24:44.363 ServerApp] nbclassic | extension was successfully loaded.
         [I 2022-06-03 00:24:44.364 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/jupyterlab
         [I 2022-06-03 00:24:44.364 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf/share/jupyter/lab
         [I 2022-06-03 00:24:44.368 ServerApp] jupyterlab | extension was successfully loaded.
         [I 2022-06-03 00:24:44.369 ServerApp] Serving notebooks from local directory: /
         [I 2022-06-03 00:24:44.369 ServerApp] Jupyter Server 1.13.5 is running at:
         [I 2022-06-03 00:24:44.369 ServerApp] http://localhost:8890/lab?token=b2f94d18a55263d5a94b5c7e52c96c60bfdfc076bfb6f00a
         [I 2022-06-03 00:24:44.369 ServerApp]  or http://127.0.0.1:8890/lab?token=b2f94d18a55263d5a94b5c7e52c96c60bfdfc076bfb6f00a
         [I 2022-06-03 00:24:44.370 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
         [C 2022-06-03 00:24:44.376 ServerApp]

             To access the server, open this file in a browser:
                 file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-207633-open.html
             Or copy and paste one of these URLs:
                 http://localhost:8890/lab?token=b2f94d18a55263d5a94b5c7e52c96c60bfdfc076bfb6f00a
              or http://127.0.0.1:8890/lab?token=b2f94d18a55263d5a94b5c7e52c96c60bfdfc076bfb6f00a
       #+end_example

    4. Create SSH Tunnel for jupyter lab to the local computer (e.g. ~#+CALL:
       ssh-tunnel(port="8889", node="node160")~)
       #+CALL: ssh-tunnel[:session jpmux2](port="8890", node="node152")

       #+RESULTS:
       |                   |           |                                        |           |   |          |      |      |             |
       | sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |   |          |      |      |             |
       | ye53nis@node152's | password: |                                        |           |   |          |      |      |             |
       | Last              | login:    | Mon                                    | Jun       | 6 | 11:31:14 | 2022 | from | login01.ara |


    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-06 16:03:48.742170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-06 16:03:48.742202: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 7  # 19e3e

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 16:03:54.537136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 16:03:54.537186: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 16:03:54.537212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node152): /proc/driver/nvidia/version does not exist
      : 2022-06-06 16:03:54.537595: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    : 744ddb63-44d8-4041-b531-2ce90bcb0e5c


    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-06 11:31:31.271711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-06 11:31:31.271745: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 4  # 484af

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 11:31:39.219733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 11:31:39.219776: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 11:31:39.219797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node152): /proc/driver/nvidia/version does not exist
      : 2022-06-06 11:31:39.220117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `

**** node 3
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8891:b37e524a-8134-4d8f-b24a-367acaf1bdd5
    :END:
    1. Set up tmux (if we haven't done that before) (=#+CALL:
       setup-tmux[:session local]=)
       #+CALL: setup-tmux[:session local]

       #+RESULTS:
       |         |                                        |           |
       | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
       | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    2. Request compute node
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux3
         cd /
         srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
       #+END_SRC

    3. Start Jupyter Lab (~#+CALL: jpt-tmux[:session jpmux]~)
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux3
       conda activate tf
       export PORT=8891
       export XDG_RUNTIME_DIR=''
       export XDG_RUNTIME_DIR=""
       jupyter lab --no-browser --port=$PORT
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node155 /]$ jupyter lab --no-browser --port=$PORT
         [I 2022-06-03 00:28:12.112 ServerApp] jupyterlab | extension was successfully linked.
         [I 2022-06-03 00:28:12.735 ServerApp] nbclassic | extension was successfully linked.
         [I 2022-06-03 00:28:12.778 ServerApp] nbclassic | extension was successfully loaded.
         [I 2022-06-03 00:28:12.780 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/jupyterlab
         [I 2022-06-03 00:28:12.780 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf/share/jupyter/lab
         [I 2022-06-03 00:28:12.783 ServerApp] jupyterlab | extension was successfully loaded.
         [I 2022-06-03 00:28:12.784 ServerApp] Serving notebooks from local directory: /
         [I 2022-06-03 00:28:12.784 ServerApp] Jupyter Server 1.13.5 is running at:
         [I 2022-06-03 00:28:12.784 ServerApp] http://localhost:8891/lab?token=fe7d23f6a124fa20ea2b5d7f0dfadc3b20f0db64f8feadfd
         [I 2022-06-03 00:28:12.784 ServerApp]  or http://127.0.0.1:8891/lab?token=fe7d23f6a124fa20ea2b5d7f0dfadc3b20f0db64f8feadfd
         [I 2022-06-03 00:28:12.784 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
         [C 2022-06-03 00:28:12.790 ServerApp]

             To access the server, open this file in a browser:
                 file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-12523-open.html
             Or copy and paste one of these URLs:
                 http://localhost:8891/lab?token=fe7d23f6a124fa20ea2b5d7f0dfadc3b20f0db64f8feadfd
              or http://127.0.0.1:8891/lab?token=fe7d23f6a124fa20ea2b5d7f0dfadc3b20f0db64f8feadfd
       #+end_example

    4. Create SSH Tunnel for jupyter lab to the local computer (e.g. ~#+CALL:
       ssh-tunnel(port="8889", node="node160")~)
       #+CALL: ssh-tunnel[:session jpmux3](port="8891", node="node155")

       #+RESULTS:
       |                   |           |                                        |           |   |          |      |      |             |
       | sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |   |          |      |      |             |
       | ye53nis@node155's | password: |                                        |           |   |          |      |      |             |
       | Last              | login:    | Mon                                    | Jun       | 6 | 11:32:59 | 2022 | from | login01.ara |



    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git
    : 2022-06-06 16:04:50.862041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-06-06 16:04:50.862080: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5  # 0cd20

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 11:33:30.480931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 11:33:30.480975: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 11:33:30.481005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node155): /proc/driver/nvidia/version does not exist
      : 2022-06-06 11:33:30.481315: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    #+CALL: kill-jupyter()

    #+RESULTS:
    :RESULTS:
    # [goto error]
    : ---------------------------------------------------------------------------
    : NameError                                 Traceback (most recent call last)
    : Input In [1], in <cell line: 1>()
    : ----> 1 os._exit(00)
    :
    : NameError: name 'os' is not defined
    :END:


    #+CALL: prepare-jupyter("/beegfs/ye53nis/data/191113_Pex5_2_structured", output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-06-02_experimental-pex5/")

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git

      #+begin_src jupyter-python
        model_id = 5  # 0cd20

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2022-06-06 16:04:56.835044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2022-06-06 16:04:56.835085: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2022-06-06 16:04:56.835105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node155): /proc/driver/nvidia/version does not exist
      : 2022-06-06 16:04:56.835386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

**** <2023-01-10 Di> Apply =averaging= and =settozero= correction with =0cd20=
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bde3 :pandoc t
    :END:

    - let's first prepare the function which loads modules, the files list, and
      provides a wrapper for the =fluotracify= correlation and correction
      functions:
      ~prepare-jupyter-averaging(data_path="/beegfs/ye53nis/data/1911DD_atto+LUVs",
      output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2023-01-10_experimental-averaging-delete/")~

      #+NAME: prepare-jupyter-averaging
      #+BEGIN_SRC jupyter-python :var data_path="/beegfs/ye53nis/data/1911DD_atto+LUVs" :var output_path="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2023-01-10_experimental-averaging-delete/"
        %cd /beegfs/ye53nis/drmed-git
        import logging
        import os
        import sys

        import matplotlib.pyplot as plt
        import numpy as np
        import pandas as pd
        import seaborn as sns

        from pathlib import Path
        from pprint import pprint
        from tensorflow.keras.optimizers import Adam
        from mlflow.keras import load_model

        FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
        sys.path.append(FLUOTRACIFY_PATH)
        from fluotracify.applications import corr_fit_object as cfo
        from fluotracify.training import build_model as bm

        data_path = Path(data_path)
        output_path = Path(output_path)
        log_path = output_path.parent / f'{output_path.name}.log'

        logging.basicConfig(filename=log_path,
                            filemode='w', format='%(asctime)s - %(message)s',
                            force=True)

        log = logging.getLogger(__name__)
        log.setLevel(logging.DEBUG)

        sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                      context='paper')

        class ParameterClass():
            """Stores parameters for correlation """
            def __init__(self):
                # Where the data is stored.
                self.data = []
                self.objectRef = []
                self.subObjectRef = []
                self.colors = ['blue', 'green', 'red', 'cyan', 'magenta',
                               'yellow', 'black']
                self.numOfLoaded = 0
                # very fast from Ncasc ~ 14 onwards
                self.NcascStart = 0
                self.NcascEnd = 30  # 25
                self.Nsub = 6  # 6
                self.photonLifetimeBin = 10  # used for photon decay
                self.photonCountBin = 1  # used for time series

        par_obj = ParameterClass()

        model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                    '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                    '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                    'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                    'c1204e3a8a1e4c40a35b5b7b1922d1ce']

        model_name_ls = [f'{s:.5}' for s in model_ls]

        # scaler_ls = ['minmax', 'robust', 'maxabs', 'l2', 'standard', 'quant_g', 'standard',
        #              'standard', 'robust']

        pred_thresh = 0.5

        if data_path.name == "1911DD_atto+LUVs":
            path_clean1 = data_path / 'clean_ptu_part1/'
            path_clean2 = data_path / 'clean_ptu_part2/'
            path_dirty1 = data_path / 'dirty_ptu_part1/'
            path_dirty2 = data_path / 'dirty_ptu_part2/'
            files_clean1 = [path_clean1 / f for f in os.listdir(path_clean1) if f.endswith('.ptu')]
            files_clean2 = [path_clean2 / f for f in os.listdir(path_clean2) if f.endswith('.ptu')]
            files_dirty1 = [path_dirty1 / f for f in os.listdir(path_dirty1) if f.endswith('.ptu')]
            files_dirty2 = [path_dirty2 / f for f in os.listdir(path_dirty2) if f.endswith('.ptu')]

        if data_path.name == "191113_Pex5_2_structured":
            path_clean = data_path / 'HsPEX5EGFP 1-100001'
            path_dirty = data_path / 'TbPEX5EGFP 1-10002'
            files_clean = [path_clean / f for f in os.listdir(path_clean) if f.endswith('.ptu')]
            files_dirty = [path_dirty / f for f in os.listdir(path_dirty) if f.endswith('.ptu')]

        def predict_correct_correlate_ptu(files, model_id, method, out_path):

            logged_scaler = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{model_ls[model_id]}/params/scaler')
            logged_scaler = !cat $logged_scaler
            logged_scaler = logged_scaler[0]

            logged_model = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{model_ls[model_id]}/artifacts/model')
            logged_model = load_model(logged_model, compile=False)
            logged_model.compile(loss=bm.binary_ce_dice_loss(),
                                 optimizer=Adam(),
                                 metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))
            if method == 'delete_and_shift':
                method_corr = 'tttr2xfcs'
                method_str = 'DELSHIFT'
            elif method == 'delete':
                method_corr = 'tttr2xfcs'
                method_str = 'DEL'
            elif method == 'weights':
                method_corr = 'tttr2xfcs_with_weights'
                method_str = 'tttr2xfcs_with_weights'
            elif method == 'averaging':
                method_corr = 'tttr2xfcs_with_averaging'
                method_str = 'tttr2xfcs_with_averaging'
            for idx, myfile in enumerate(files):
                ptufile = cfo.PicoObject(myfile, par_obj)
                ptufile.predictTimeSeries(method='unet',
                                          model=logged_model,
                                          scaler=logged_scaler)
                ptufile.correctTCSPC(method=method)
                if method in ['delete', 'delete_and_shift', 'weights']:
                    for key in ptufile.trueTimeArr.keys():
                        ptufile.get_autocorrelation(method=method_corr, name=key)
                elif method == 'averaging':
                    for key in ptufile.trueTimeParts.keys():
                        ptufile.get_autocorrelation(method=method_corr, name=key)

                if method_corr in list(ptufile.autoNorm.keys()):
                    for key in list(ptufile.autoNorm[method_corr].keys()):
                        if ((method_str in key) or
                            (method_str in ['tttr2xfcs_with_weights',
                                            'tttr2xfcs_with_averaging'])):
                            ptufile.save_autocorrelation(name=key, method=method_corr,
                                                         output_path=out_path)
      #+END_SRC

      #+RESULTS: prepare-jupyter-averaging
      : /beegfs/ye53nis/drmed-git

      #+BEGIN_SRC jupyter-python
        import importlib
        importlib.reload(cfo)
      #+END_SRC

      #+RESULTS:
      : <module 'fluotracify.applications.corr_fit_object' from '/beegfs/ye53nis/drmed-git/src/fluotracify/applications/corr_fit_object.py'>

    - let's also define a function to kill the jupyter environment. This is due
      to the =fluotracify= correlation algorithm memory allocation problem I
      haven't figured out yet. It will fill the memory after processing ~300
      files of the =af488= experiments (higher count rates). Because I haven't
      figured out how to solve this problem, I split the folders in parts and
      restart the environment.
      #+NAME: kill-jupyter
      #+BEGIN_SRC jupyter-python
        os._exit(00)
      #+END_SRC

      #+RESULTS:
      : 7a752b61-60c1-4322-8105-e8dbd705caa0

    - first: =af488luvs= and =af488= averaging  correction. We only use mode
      =0cd20= for prediction, because this has proved to be the most robust.
    - =#+CALL: prepare-jupyter-averaging()=
      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-12 13:29:49.334418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-12 13:29:49.334472: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'dirty_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty1,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:

    - =#+CALL: kill-jupyter()=
      #+CALL: kill-jupyter()

      #+RESULTS:
      : 1603e9bd-2d3a-4295-ace3-d86b1cdf4f4f

    - =#+CALL: prepare-jupyter-averaging()= etc...
      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-12 17:28:27.364198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-12 17:28:27.364273: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'dirty_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty2,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-12 17:28:58.975546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-12 17:28:58.975606: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-12 17:28:58.975643: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-12 17:28:58.976216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()
      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-13 12:01:00.676480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-13 12:01:00.676539: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'clean_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean1,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-13 12:07:29.082697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-13 12:07:29.082756: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-13 12:07:29.082791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-13 12:07:29.083227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+RESULTS:
      : 5b633a1b-0c54-453f-a4bf-a9d30182fdd3

      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-13 14:38:58.893878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-13 14:38:58.893919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'clean_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean2,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-13 14:39:25.593798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-13 14:39:25.593871: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-13 14:39:25.593915: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-13 14:39:25.594445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+RESULTS:
      : a965cd3e-f452-4c79-9428-b5152c3ba8aa

    - second: =af488luvs= and =af488= delete correction.
    - =#+CALL: prepare-jupyter-averaging()= etc...
      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-16 16:37:55.758832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-16 16:37:55.758867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty1,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+RESULTS:
      : b91bd6bb-e7b8-44c1-b014-02275b3516b6

      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-16 23:53:43.486077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-16 23:53:43.486120: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'dirty_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty2,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-16 23:53:57.181417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-16 23:53:57.181479: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-16 23:53:57.181516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-16 23:53:57.181940: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-17 13:11:45.290135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-17 13:11:45.290197: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean1,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-17 13:12:04.995182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-17 13:12:04.995223: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-17 13:12:04.995253: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-17 13:12:04.995535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+RESULTS:
      : 63efbb75-e4b2-4b2c-ba46-ecf44a9d66fc

      #+CALL: prepare-jupyter-averaging()

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-17 17:20:22.162939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-17 17:20:22.162993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'clean_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean2,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : 2023-01-17 17:20:51.771891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
      : 2023-01-17 17:20:51.771954: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
      : 2023-01-17 17:20:51.771992: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node117): /proc/driver/nvidia/version does not exist
      : 2023-01-17 17:20:51.772457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
      : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+CALL: kill-jupyter()

      #+RESULTS:
      : 63efbb75-e4b2-4b2c-ba46-ecf44a9d66fc

    - third: =tb-pex5= and =hs-pex5= with  averaging correction and set to zero
      correction. Because these files are small and memory allocation is less of
      a problem, we don't need to kill our jupyter session in between
    - =#+CALL: prepare-jupyter-averaging("/beegfs/ye53nis/data/191113_Pex5_2_structured")=
      #+CALL: prepare-jupyter-averaging("/beegfs/ye53nis/data/191113_Pex5_2_structured")

      #+RESULTS:
      :RESULTS:
      : /beegfs/ye53nis/drmed-git
      : 2023-01-18 11:53:14.696643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
      : 2023-01-18 11:53:14.696707: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
      :END:

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'tbpex5_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'tbpex5_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_dirty,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'hspex5_averaging_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='averaging',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

      #+begin_src jupyter-python
        model_id = 5

        out_dir = output_path / f'hspex5_delete_{model_name_ls[model_id]}/'

        os.makedirs(out_dir, exist_ok=True)

        ptufile = predict_correct_correlate_ptu(
            files=files_clean,
            model_id=model_id,
            method='delete',
            out_path=out_dir)
      #+end_src

      #+RESULTS:
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

   #+begin_src jupyter-python


     out_path = '/home/lex/Programme/drmed-git/data/exp-220316-publication1/230102_modulation-filtering'
     # correlate.correlate_timetrace_and_save(df=sim_nan, out_path=out_path, out_txt='nan')

     for idx, col in enumerate(sim_labbool.columns):
         mod_trace = sim_labbool.iloc[:, idx+2].astype(np.float64)
         dirty_trace = sim_dirty.iloc[:, idx+2].astype(np.float64)
         mod_corr = autocorrelate(
             a=mod_trace,
             m=16,
             deltat=1,
             normalize=True)
         dirty_corr = autocorrelate(
             a=dirty_trace,
             m=16,
             deltat=1,
             normalize=True)
         filt_corr = dirty_corr[1:, 1] / mod_corr[1:, 1]
         fig, ax = plt.subplots(1, 3, figsize=(16, 9))
         sns.lineplot(mod_corr[1:60, 0], filt_corr[:59], ax=ax[0])
         sns.lineplot(mod_corr[1:, 0], mod_corr[1:, 1], ax=ax[1])
         sns.lineplot(dirty_corr[1:, 0], dirty_corr[1:, 1], ax=ax[2])
         plt.setp(ax, xscale='log')
         plt.show()

         break
   #+end_src

*** Analysis 2b: plot experimental af488 data
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
    :END:
     #+BEGIN_SRC jupyter-python
       %cd ~/Programme/drmed-git
     #+END_SRC

     #+RESULTS:
     : /home/lex/Programme/drmed-git

     #+BEGIN_SRC jupyter-python
       import os
       import numpy as np
       import matplotlib.pyplot as plt
       import matplotlib.ticker as ticker
       import pandas as pd
       import seaborn as sns
       from pathlib import Path
       from pprint import pprint

       sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                     context='paper')

       model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                   '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                   '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                   'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                   'c1204e3a8a1e4c40a35b5b7b1922d1ce']

       model_name_ls = [f'{s:.5}' for s in model_ls]
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       path = Path('data/exp-220227-unet/2022-05-22_experimental-af488/')

       # averaged values
       dirty_avg_1comp_path = path / 'dirty-all-results/dirty_all_1comp_outputParam.csv'
       dirty_avg_2comp_path = path / 'dirty-all-results/dirty_all_2comp_outputParam.csv'
       clean_avg_1comp_path = path / 'clean-all-results/clean_all_1comp_outputParam.csv'
       clean_avg_2comp_path = path / 'clean-all-results/clean_all_2comp_outputParam.csv'

       # dirty params
       dirty_noc_1comp_path = path / 'dirty-all-results/dirty_no-correction_1comp_outputParam.csv'
       dirty_noc_2comp_path = path / 'dirty-all-results/dirty_no-correction_2comp_outputParam.csv'

       dirty_0cd20_1comp_path = path / 'dirty-all-results/dirty_0cd20_1comp_outputParam.csv'
       dirty_0cd20_2comp_path = path / 'dirty-all-results/dirty_0cd20_2comp_outputParam.csv'
       dirty_19e3e_1comp_path = path / 'dirty-all-results/dirty_19e3e_1comp_outputParam.csv'
       dirty_19e3e_2comp_path = path / 'dirty-all-results/dirty_19e3e_2comp_outputParam.csv'
       dirty_34766_1comp_path = path / 'dirty-all-results/dirty_34766_1comp_outputParam.csv'
       dirty_34766_2comp_path = path / 'dirty-all-results/dirty_34766_2comp_outputParam.csv'
       dirty_34a6d_1comp_path = path / 'dirty-all-results/dirty_34a6d_1comp_outputParam.csv'
       dirty_34a6d_2comp_path = path / 'dirty-all-results/dirty_34a6d_2comp_outputParam.csv'
       dirty_484af_1comp_path = path / 'dirty-all-results/dirty_484af_1comp_outputParam.csv'
       dirty_484af_2comp_path = path / 'dirty-all-results/dirty_484af_2comp_outputParam.csv'
       dirty_714af_1comp_path = path / 'dirty-all-results/dirty_714af_1comp_outputParam.csv'
       dirty_714af_2comp_path = path / 'dirty-all-results/dirty_714af_2comp_outputParam.csv'
       dirty_c1204_1comp_path = path / 'dirty-all-results/dirty_c1204_1comp_outputParam.csv'
       dirty_c1204_2comp_path = path / 'dirty-all-results/dirty_c1204_2comp_outputParam.csv'
       dirty_fe81d_1comp_path = path / 'dirty-all-results/dirty_fe81d_1comp_outputParam.csv'
       dirty_fe81d_2comp_path = path / 'dirty-all-results/dirty_fe81d_2comp_outputParam.csv'
       dirty_ff67b_1comp_path = path / 'dirty-all-results/dirty_ff67b_1comp_outputParam.csv'
       dirty_ff67b_2comp_path = path / 'dirty-all-results/dirty_ff67b_2comp_outputParam.csv'


       # clean params
       clean_noc_1comp_path = path / 'clean-all-results/clean_no-correction_1comp_outputParam.csv'
       clean_noc_2comp_path = path / 'clean-all-results/clean_no-correction_2comp_outputParam.csv'

       clean_0cd20_1comp_path = path / 'clean-all-results/clean_0cd20_1comp_outputParam.csv'
       clean_0cd20_2comp_path = path / 'clean-all-results/clean_0cd20_2comp_outputParam.csv'
       clean_19e3e_1comp_path = path / 'clean-all-results/clean_19e3e_1comp_outputParam.csv'
       clean_19e3e_2comp_path = path / 'clean-all-results/clean_19e3e_2comp_outputParam.csv'
       clean_34766_1comp_path = path / 'clean-all-results/clean_34766_1comp_outputParam.csv'
       clean_34766_2comp_path = path / 'clean-all-results/clean_34766_2comp_outputParam.csv'
       clean_34a6d_1comp_path = path / 'clean-all-results/clean_34a6d_1comp_outputParam.csv'
       clean_34a6d_2comp_path = path / 'clean-all-results/clean_34a6d_2comp_outputParam.csv'
       clean_484af_1comp_path = path / 'clean-all-results/clean_484af_1comp_outputParam.csv'
       clean_484af_2comp_path = path / 'clean-all-results/clean_484af_2comp_outputParam.csv'
       clean_714af_1comp_path = path / 'clean-all-results/clean_714af_1comp_outputParam.csv'
       clean_714af_2comp_path = path / 'clean-all-results/clean_714af_2comp_outputParam.csv'
       clean_c1204_1comp_path = path / 'clean-all-results/clean_c1204_1comp_outputParam.csv'
       clean_c1204_2comp_path = path / 'clean-all-results/clean_c1204_2comp_outputParam.csv'
       clean_fe81d_1comp_path = path / 'clean-all-results/clean_fe81d_1comp_outputParam.csv'
       clean_fe81d_2comp_path = path / 'clean-all-results/clean_fe81d_2comp_outputParam.csv'
       clean_ff67b_1comp_path = path / 'clean-all-results/clean_ff67b_1comp_outputParam.csv'
       clean_ff67b_2comp_path = path / 'clean-all-results/clean_ff67b_2comp_outputParam.csv'


       # average parameters
       dirty_avg_1comp =  pd.read_csv(dirty_avg_1comp_path, sep=',').assign(
           artifact=10*['dirty',])
       dirty_avg_2comp =  pd.read_csv(dirty_avg_2comp_path, sep=',').assign(
           artifact=10*['dirty',])
       clean_avg_1comp =  pd.read_csv(clean_avg_1comp_path, sep=',').assign(
           artifact=10*['clean',])
       clean_avg_2comp =  pd.read_csv(clean_avg_2comp_path, sep=',').assign(
           artifact=10*['clean',])

       # dirty params
       dirty_noc_1comp = pd.read_csv(dirty_noc_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['No correction'])
       dirty_noc_2comp = pd.read_csv(dirty_noc_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['No correction'])

       dirty_0cd20_1comp =  pd.read_csv(dirty_0cd20_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['0cd20'])
       dirty_0cd20_2comp =  pd.read_csv(dirty_0cd20_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['0cd20'])
       dirty_19e3e_1comp =  pd.read_csv(dirty_19e3e_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['19e3e'])
       dirty_19e3e_2comp =  pd.read_csv(dirty_19e3e_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['19e3e'])
       dirty_34766_1comp =  pd.read_csv(dirty_34766_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34766'])
       dirty_34766_2comp =  pd.read_csv(dirty_34766_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34766'])
       dirty_34a6d_1comp =  pd.read_csv(dirty_34a6d_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34a6d'])
       dirty_34a6d_2comp =  pd.read_csv(dirty_34a6d_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34a6d'])
       dirty_484af_1comp =  pd.read_csv(dirty_484af_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['484af'])
       dirty_484af_2comp =  pd.read_csv(dirty_484af_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['484af'])
       dirty_714af_1comp =  pd.read_csv(dirty_714af_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['714af'])
       dirty_714af_2comp =  pd.read_csv(dirty_714af_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['714af'])
       dirty_c1204_1comp =  pd.read_csv(dirty_c1204_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['c1204'])
       dirty_c1204_2comp =  pd.read_csv(dirty_c1204_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['c1204'])
       dirty_fe81d_1comp =  pd.read_csv(dirty_fe81d_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['fe81d'])
       dirty_fe81d_2comp =  pd.read_csv(dirty_fe81d_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['fe81d'])
       dirty_ff67b_1comp =  pd.read_csv(dirty_ff67b_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['ff67b'])
       dirty_ff67b_2comp =  pd.read_csv(dirty_ff67b_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['ff67b'])

       # clean params
       clean_noc_1comp = pd.read_csv(clean_noc_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['No correction'])
       clean_noc_2comp = pd.read_csv(clean_noc_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['No correction'])

       clean_0cd20_1comp =  pd.read_csv(clean_0cd20_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['0cd20'])
       clean_0cd20_2comp =  pd.read_csv(clean_0cd20_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['0cd20'])
       clean_19e3e_1comp =  pd.read_csv(clean_19e3e_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['19e3e'])
       clean_19e3e_2comp =  pd.read_csv(clean_19e3e_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['19e3e'])
       clean_34766_1comp =  pd.read_csv(clean_34766_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34766'])
       clean_34766_2comp =  pd.read_csv(clean_34766_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34766'])
       clean_34a6d_1comp =  pd.read_csv(clean_34a6d_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34a6d'])
       clean_34a6d_2comp =  pd.read_csv(clean_34a6d_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34a6d'])
       clean_484af_1comp =  pd.read_csv(clean_484af_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['484af'])
       clean_484af_2comp =  pd.read_csv(clean_484af_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['484af'])
       clean_714af_1comp =  pd.read_csv(clean_714af_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['714af'])
       clean_714af_2comp =  pd.read_csv(clean_714af_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['714af'])
       clean_c1204_1comp =  pd.read_csv(clean_c1204_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['c1204'])
       clean_c1204_2comp =  pd.read_csv(clean_c1204_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['c1204'])
       clean_fe81d_1comp =  pd.read_csv(clean_fe81d_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['fe81d'])
       clean_fe81d_2comp =  pd.read_csv(clean_fe81d_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['fe81d'])
       clean_ff67b_1comp =  pd.read_csv(clean_ff67b_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['ff67b'])
       clean_ff67b_2comp =  pd.read_csv(clean_ff67b_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['ff67b'])

       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       avg_param.head()
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     |   | name_of_plot | master_file | parent_name  | parent_uqid  | time of fit              | Diff_eq     | Diff_species | Triplet_eq | Triplet_species | Dimen | ... | stdev(AR1) | artifact | A2  | stdev(A2) | txy2 | stdev(txy2) | alpha2 | stdev(alpha2) | AR2 | stdev(AR2) |
|---+--------------+-------------+--------------+--------------+--------------------------+-------------+--------------+------------+-----------------+-------+-----+------------+----------+-----+-----------+------+-------------+--------+---------------+-----+------------|
| 0 | clean        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 1 | 0cd20        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 2 | 19e3e        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 3 | 34a6d        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 4 | 484af        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |

5 rows × 34 columns
     :END:

     #+BEGIN_SRC jupyter-python
       def sort_fit(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0]) * 1000
           t_slow = float(array[0, 1]) * 1000
           if np.isnan(t_slow):
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}$'
               out = f'$\\tau_D={t_fast:.1f}, N={nfcs:.1f}$'
           elif f'{A_fast:.0%}' == '100%':
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}(100\\%)$'
               out = f'$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$'
           elif f'{A_slow:.0%}' == '100%':
               # if tt_low_high[0] <= t_slow <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_slow:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_slow:.2f}(100\\%)$'
               out = f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$'
           else:
               # if (tt_low_high[0] <= t_fast <= tt_low_high[1]) or (
               #     tt_low_high[0] <= t_slow <= tt_low_high[1]):
               #     out = f'\\cellcolor[HTML]{{009e73}}\\colorbox[HTML]{{009e73}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}\\colorbox[HTML]{{d55e00}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               out = f'\\makecell{{$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$\\\\'\
                     f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$}}'
               out = out.replace('%', '\\%')
           return out
       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       avg_param['fit results'] = avg_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(lambda x: sort_fit(x), axis=1)
       avg_param = avg_param[['name_of_plot', 'Diff_species', 'artifact', 'fit results']]
       avg_param = avg_param.pivot_table(values='fit results',
                                         columns='artifact',
                                         index=['name_of_plot', 'Diff_species'],
                                         aggfunc=lambda x: '-'.join(x))
       avg_param.loc[('clean', 1), 'dirty'] = avg_param.loc[('dirty', 1), 'dirty']
       avg_param.loc[('clean', 2), 'dirty'] = avg_param.loc[('dirty', 2), 'dirty']

       avg_param = avg_param.rename(index={'clean' : 'no correction'})
       # to get all models
       # first = ['no correction',] + model_name_ls.copy()
       # just two examples
       first = ['no correction', '0cd20', '34a6d']
       second = [1, 2]
       index_order = pd.MultiIndex.from_product([first, second],
                                                names=[r'\makecell{type of\\processing}', 'fit'])
       avg_param = avg_param.reindex(index=index_order)

       with pd.option_context("max_colwidth", 1000):
           print(avg_param.to_latex(escape=False,
                                    column_format='cccc',
                                    caption=('Experimental results')))
       avg_param
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     #+begin_example
       \begin{table}
       \centering
       \caption{Experimental results}
       \begin{tabular}{cccc}
       \toprule
             & artifact &                                                                             clean &                                                                                  dirty \\
       \makecell{type of\\processing} & fit &                                                                                   &                                                                                        \\
       \midrule
       no correction & 1 &                                                             $\tau_D=39.7, N=14.3$ &                                                                 $\tau_D=7355.0, N=4.7$ \\
             & 2 &  \makecell{$\tau_D^{fast}=9.5, N\cdot A=4.9$\\$\tau_D^{slow}=69.8, N\cdot A=8.6$} &   \makecell{$\tau_D^{fast}=78.3, N\cdot A=0.7$\\$\tau_D^{slow}=11944.6, N\cdot A=3.5$} \\
       0cd20 & 1 &                                                             $\tau_D=39.6, N=14.3$ &                                                                  $\tau_D=71.3, N=21.7$ \\
             & 2 &  \makecell{$\tau_D^{fast}=8.9, N\cdot A=4.6$\\$\tau_D^{slow}=67.5, N\cdot A=8.8$} &   \makecell{$\tau_D^{fast}=38.8, N\cdot A=15.5$\\$\tau_D^{slow}=5823.0, N\cdot A=3.9$} \\
       34a6d & 1 &                                                             $\tau_D=39.7, N=14.3$ &                                                                  $\tau_D=78.9, N=22.5$ \\
             & 2 &  \makecell{$\tau_D^{fast}=9.4, N\cdot A=4.8$\\$\tau_D^{slow}=69.6, N\cdot A=8.6$} &  \makecell{$\tau_D^{fast}=41.9, N\cdot A=14.2$\\$\tau_D^{slow}=22526.1, N\cdot A=4.6$} \\
       \bottomrule
       \end{tabular}
       \end{table}
     #+end_example
     |                                | artifact | clean                                             | dirty                                             |
|--------------------------------+----------+---------------------------------------------------+---------------------------------------------------|
| \makecell{type of\\processing} | fit      |                                                   |                                                   |
| no correction                  | 1        | $\tau_D=39.7, N=14.3$                             | $\tau_D=7355.0, N=4.7$                            |
|                                | 2        | \makecell{$\tau_D^{fast}=9.5, N\cdot A=4.9$\\$... | \makecell{$\tau_D^{fast}=78.3, N\cdot A=0.7$\\... |
| 0cd20                          | 1        | $\tau_D=39.6, N=14.3$                             | $\tau_D=71.3, N=21.7$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=8.9, N\cdot A=4.6$\\$... | \makecell{$\tau_D^{fast}=38.8, N\cdot A=15.5$\... |
| 34a6d                          | 1        | $\tau_D=39.7, N=14.3$                             | $\tau_D=78.9, N=22.5$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=9.4, N\cdot A=4.8$\\$... | \makecell{$\tau_D^{fast}=41.9, N\cdot A=14.2$\... |
     :END:

     #+BEGIN_SRC jupyter-python

       def sort_fit_simple(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0])
           t_slow = float(array[0, 1])
           if np.isnan(t_slow):
               # 1-component fit
               out = t_fast, N_fast, pd.NA, pd.NA
           # 2-component fits
           elif f'{A_fast:.0%}' == '100%':
               out = t_fast, N_fast, pd.NA, pd.NA
           elif f'{A_slow:.0%}' == '100%':
               out = t_slow, N_slow, pd.NA, pd.NA
           else:
               out = t_fast, N_fast, t_slow, N_slow
           return out

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       all_param = all_param.reset_index()
       (all_param['t_fast'], all_param['N_fast'], all_param['t_slow'],
        all_param['N_slow']) = zip(*all_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(
            lambda x: sort_fit_simple(x), axis=1))
       all_param = all_param[['index', 'Diff_species', 'processing', 'artifact',
                              't_fast', 'N_fast', 't_slow', 'N_slow']]
       all_param = all_param.loc[((all_param['Diff_species'] == 1) & (all_param['artifact'] == 'clean')) | ((all_param['Diff_species'] == 2) & (all_param['artifact'] == 'dirty'))]
       pub_param = all_param.loc[(all_param['processing'] == 'No correction') | (all_param['processing'] == '0cd20') | (all_param['processing'] == '34a6d')]
       pub_param = pub_param.replace(['clean'], '424 traces of\nAlexaFluor488\n(no artifacts)\nN (FCS) from\n1 species fit')
       pub_param = pub_param.replace(['dirty'], '440 traces of\nAF488 + DiO LUVs\n(peak artifacts)\nN (FCS) $\\cdot$ A from\nfast sp. of 2 sp. fit')
       pub_param = pub_param.replace(['0cd20'], 'large model (200 MB),\n6 levels,\npool size=4,\nscaler=quantile\ntransform (Gaussian pdf)')
       pub_param = pub_param.replace(['34a6d'], 'small model (7 MB),\n3 levels,\npool size=4,\nscaler=l2')
       g = sns.catplot(data=pub_param,
                       y='t_fast',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='t_fast',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores transit times',
                      size=25)

       g._legend.set_title('')
       new_labels = ['424 traces of\nAlexaFluor488\n(no artifacts)\n$\\tau_D$ from\n1 species fit',
                     '440 traces of\nAF488 + DiO LUVs\n(peak artifacts)\n$\\tau_D$ from\nfast sp. of 2 sp. fit']
       for t, l in zip(g._legend.texts, new_labels):
           t.set_text(l)
       plt.setp(g.axes, yscale='log', xlabel='',
                ylabel=r'log transit time $\tau_{D}$ $[ms]$')

       g.tight_layout()
       plot2_file = 'analysis2_biological_0cd20+34a6d_transit-times'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')

       g = sns.catplot(data=pub_param,
                       y='N_fast',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='N_fast',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores particle number',
                      size=25)
       g._legend.set_title('')
       plt.setp(g.axes, xlabel='',
                ylabel=r'particle number $N$ $[fl^{-1}]$')

       g.tight_layout()
       plot2_file = 'analysis2_biological_0cd20+34a6d_particle-number'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')

     #+END_SRC

     #+RESULTS:

     #+begin_src jupyter-python
       N_param = all_param.pivot_table(values='N_fast',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])

       t_param = all_param.pivot_table(values='t_fast',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])
       t_param = t_param * 1000
       display(N_param.describe().T)
       display(t_param.describe().T)
       display(t_param.median(axis=0))
       display(N_param.median(axis=0))
     #+end_src

     #+RESULTS:
     :RESULTS:
     |               |          |              | count |       mean |        std |       min |       25% |       50% |        75% |         max |
     |---------------+----------+--------------+-------+------------+------------+-----------+-----------+-----------+------------+-------------|
     | processing    | artifact | Diff_species |       |            |            |           |           |           |            |             |
     | 0cd20         | clean    |            1 | 424.0 |  14.335000 |   0.263291 | 13.412392 | 14.205747 | 14.341568 |  14.505898 |   14.988332 |
     |               | dirty    |            2 | 440.0 |  15.106186 |   1.484036 |  6.267150 | 14.334271 | 15.248202 |  16.039287 |   18.110889 |
     | 19e3e         | clean    |            1 | 424.0 |  14.329986 |   0.263853 | 13.367317 | 14.201544 | 14.336272 |  14.511038 |   14.931337 |
     |               | dirty    |            2 | 440.0 |  13.270444 |   3.181698 |  0.562121 | 11.573624 | 13.826313 |  15.704750 |   18.581205 |
     | 34766         | clean    |            1 | 424.0 |  14.684973 |   0.276662 | 13.720920 | 14.551659 | 14.702547 |  14.869845 |   15.347210 |
     |               | dirty    |            2 | 440.0 |  15.267823 |   2.476381 |  6.346636 | 13.704650 | 15.732460 |  17.068360 |   19.961155 |
     | 34a6d         | clean    |            1 | 424.0 |  14.325905 |   0.264438 | 13.365160 | 14.194973 | 14.335075 |  14.510599 |   14.933380 |
     |               | dirty    |            2 | 440.0 |  13.641062 |   2.740812 |  1.417894 | 12.297284 | 14.302934 |  15.593493 |   17.885668 |
     | 484af         | clean    |            1 | 424.0 |  14.317763 |   0.263824 | 13.365161 | 14.188180 | 14.325842 |  14.499389 |   14.919546 |
     |               | dirty    |            2 | 440.0 |  12.784654 |   3.023495 |  1.591405 | 10.908164 | 13.373178 |  15.029049 |   18.453017 |
     | 714af         | clean    |            1 | 424.0 |  14.318594 |   0.263337 | 13.365161 | 14.189044 | 14.325842 |  14.497586 |   14.919546 |
     |               | dirty    |            2 | 440.0 |  12.233933 |   2.490236 |  5.295190 | 10.570730 | 12.420635 |  14.066820 |   17.968677 |
     | No correction | clean    |            1 | 424.0 |  14.324938 |   0.264089 | 13.369703 | 14.194097 | 14.331944 |  14.503913 |   14.925030 |
     |               | dirty    |            2 | 440.0 |   1.151438 |   0.843793 |  0.112582 |  0.518223 |  0.978458 |   1.540923 |    5.476162 |
     | c1204         | clean    |            1 | 424.0 |  15.254311 |   0.321478 | 13.987100 | 15.077046 | 15.262632 |  15.475146 |   16.260415 |
     |               | dirty    |            2 | 440.0 |  15.532688 |   3.448340 |  1.815959 | 13.639535 | 15.912205 |  18.127480 |   21.748767 |
     | fe81d         | clean    |            1 | 424.0 |  14.319104 |   0.263526 | 13.365161 | 14.189106 | 14.326219 |  14.499389 |   14.919546 |
     |               | dirty    |            2 | 440.0 |  13.077269 |   3.152211 |  0.536799 | 11.056025 | 13.689452 |  15.387298 |   19.102249 |
     | ff67b         | clean    |            1 | 424.0 |  14.319636 |   0.263558 | 13.365161 | 14.189298 | 14.326219 |  14.499389 |   14.919546 |
     |               | dirty    |            2 | 440.0 |  12.894021 |   2.446790 |  4.838165 | 11.518550 | 13.089802 |  14.484227 |   18.392188 |
     |               |          |              | count |       mean |        std |       min |       25% |       50% |        75% |         max |
     |---------------+----------+--------------+-------+------------+------------+-----------+-----------+-----------+------------+-------------|
     | processing    | artifact | Diff_species |       |            |            |           |           |           |            |             |
     | 0cd20         | clean    |            1 | 424.0 |  39.574374 |   1.040061 | 37.190978 | 38.879728 | 39.575746 |  40.279227 |   42.984704 |
     |               | dirty    |            2 | 440.0 |  38.933931 |   5.459816 | 21.356080 | 35.228893 | 38.762520 |  42.262441 |   62.131261 |
     | 19e3e         | clean    |            1 | 424.0 |  39.656947 |   1.047036 | 37.102746 | 38.934719 | 39.568778 |  40.416838 |   42.501109 |
     |               | dirty    |            2 | 440.0 |  41.351740 |   4.525924 | 19.027233 | 38.362287 | 41.177209 |  43.854646 |   60.151240 |
     | 34766         | clean    |            1 | 424.0 |  35.077446 |   1.109175 | 32.086412 | 34.355154 | 35.067658 |  35.736697 |   38.864156 |
     |               | dirty    |            2 | 440.0 |  38.910032 |   3.349258 | 27.709990 | 36.625985 | 38.713203 |  41.009242 |   49.822679 |
     | 34a6d         | clean    |            1 | 424.0 |  39.707795 |   1.038806 | 36.985999 | 39.012984 | 39.667568 |  40.457557 |   42.803298 |
     |               | dirty    |            2 | 440.0 |  41.654939 |   4.707523 | 30.986888 | 38.312301 | 41.267814 |  44.652582 |   57.155144 |
     | 484af         | clean    |            1 | 424.0 |  39.854861 |   1.040952 | 37.153441 | 39.141726 | 39.854056 |  40.582409 |   42.744448 |
     |               | dirty    |            2 | 440.0 |  41.036124 |   4.307502 | 31.922451 | 38.063892 | 40.605601 |  43.505466 |   63.739400 |
     | 714af         | clean    |            1 | 424.0 |  39.838266 |   1.041757 | 37.153441 | 39.107415 | 39.835832 |  40.571805 |   42.696864 |
     |               | dirty    |            2 | 440.0 |  41.791645 |   4.068318 | 31.775699 | 38.784115 | 41.430208 |  44.084046 |   55.334179 |
     | No correction | clean    |            1 | 424.0 |  39.726486 |   1.037956 | 37.049340 | 39.010144 | 39.678008 |  40.444667 |   42.680513 |
     |               | dirty    |            2 | 440.0 | 373.284240 | 938.964455 |  9.128891 | 44.671731 | 69.978078 | 149.833895 | 9657.429422 |
     | c1204         | clean    |            1 | 424.0 |  29.247641 |   1.225078 | 25.901046 | 28.399698 | 29.177928 |  30.113028 |   32.740869 |
     |               | dirty    |            2 | 440.0 |  35.503411 |   2.690742 | 29.246945 | 33.580404 | 35.278166 |  36.865166 |   44.796158 |
     | fe81d         | clean    |            1 | 424.0 |  39.828821 |   1.044278 | 37.153441 | 39.089567 | 39.830813 |  40.555985 |   42.744448 |
     |               | dirty    |            2 | 440.0 |  40.766428 |   6.403163 | 12.890876 | 37.417914 | 40.439757 |  43.275102 |   84.641627 |
     | ff67b         | clean    |            1 | 424.0 |  39.830343 |   1.042279 | 37.153441 | 39.087859 | 39.803435 |  40.555985 |   42.744448 |
     |               | dirty    |            2 | 440.0 |  41.757214 |   4.040506 | 32.434107 | 38.893139 | 41.451285 |  44.293295 |   57.788748 |
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1               39.575746
                      dirty     2               38.762520
       19e3e          clean     1               39.568778
                      dirty     2               41.177209
       34766          clean     1               35.067658
                      dirty     2               38.713203
       34a6d          clean     1               39.667568
                      dirty     2               41.267814
       484af          clean     1               39.854056
                      dirty     2               40.605601
       714af          clean     1               39.835832
                      dirty     2               41.430208
       No correction  clean     1               39.678008
                      dirty     2               69.978078
       c1204          clean     1               29.177928
                      dirty     2               35.278166
       fe81d          clean     1               39.830813
                      dirty     2               40.439757
       ff67b          clean     1               39.803435
                      dirty     2               41.451285
       dtype: float64
     #+end_example
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1               14.341568
                      dirty     2               15.248202
       19e3e          clean     1               14.336272
                      dirty     2               13.826313
       34766          clean     1               14.702547
                      dirty     2               15.732460
       34a6d          clean     1               14.335075
                      dirty     2               14.302934
       484af          clean     1               14.325842
                      dirty     2               13.373178
       714af          clean     1               14.325842
                      dirty     2               12.420635
       No correction  clean     1               14.331944
                      dirty     2                0.978458
       c1204          clean     1               15.262632
                      dirty     2               15.912205
       fe81d          clean     1               14.326219
                      dirty     2               13.689452
       ff67b          clean     1               14.326219
                      dirty     2               13.089802
       dtype: float64
     #+end_example
     :END:

     #+BEGIN_SRC jupyter-python
g = sns.catplot(data=all_param,
                y='A',
                x='artifact-correction',
                hue='fitted species (A)',
                sharey=True,
                height=5,
                aspect=2,
                legend_out=True,
                kind='boxen',
                showfliers=False)
g.map_dataframe(sns.stripplot,
      y='A',
      x='artifact-correction',
      hue='fitted species (A)',
      dodge=True,
      palette=sns.color_palette(['0.3']),
      size=4,
      jitter=0.2)
g.tight_layout()
g.fig.suptitle('Fraction sizes of AlexaFluor488 (clean) vs\nAlexaFluor488 + Dio LUVs (dirty) with different correction methods',
               y=1.08, size=20)
for axes in g.axes.flat:
     _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=45)
plt.setp(g.axes, xlabel='biological sample - correction method',
         ylabel='relative fraction size')
plt.show()
     #+END_SRC

*** Analysis 2b: plot experimental pex5 data
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:a37e524a-8134-4d8f-b24a-367acaf1bdd3 :pandoc t
    :END:
     #+BEGIN_SRC jupyter-python
       %cd ~/Programme/drmed-git
     #+END_SRC

     #+RESULTS:
     : /home/lex/Programme/drmed-git

     #+BEGIN_SRC jupyter-python
       import os
       import numpy as np
       import matplotlib.pyplot as plt
       import matplotlib.ticker as ticker
       import pandas as pd
       import seaborn as sns
       from pathlib import Path
       from pprint import pprint

       sns.set_theme(style="whitegrid", font_scale=2, palette='colorblind',
                     context='paper')

       model_ls = ['ff67be0b68e540a9a29a36a2d0c7a5be', '347669d050f344ad9fb9e480c814f727',
                   '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65',
                   '484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653',
                   'fe81d71c52404ed790b3a32051258da9', '19e3e786e1bc4e2b93856f5dc9de8216',
                   'c1204e3a8a1e4c40a35b5b7b1922d1ce']

       model_name_ls = [f'{s:.5}' for s in model_ls]
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       pprint(sns.plotting_context("paper"))
     #+END_SRC

     #+RESULTS:
     #+begin_example
       {'axes.labelsize': 9.600000000000001,
        'axes.linewidth': 1.0,
        'axes.titlesize': 9.600000000000001,
        'font.size': 9.600000000000001,
        'grid.linewidth': 0.8,
        'legend.fontsize': 8.8,
        'legend.title_fontsize': 9.600000000000001,
        'lines.linewidth': 1.2000000000000002,
        'lines.markersize': 4.800000000000001,
        'patch.linewidth': 0.8,
        'xtick.labelsize': 8.8,
        'xtick.major.size': 4.800000000000001,
        'xtick.major.width': 1.0,
        'xtick.minor.size': 3.2,
        'xtick.minor.width': 0.8,
        'ytick.labelsize': 8.8,
        'ytick.major.size': 4.800000000000001,
        'ytick.major.width': 1.0,
        'ytick.minor.size': 3.2,
        'ytick.minor.width': 0.8}
     #+end_example

     #+BEGIN_SRC jupyter-python
       path = Path('data/exp-220227-unet/2022-06-02_experimental-pex5/')

       # averaged values
       dirty_avg_1comp_path = path / 'dirty-all-results/dirty_avg_cas_1comp_outputParam.csv'
       dirty_avg_2comp_path = path / 'dirty-all-results/dirty_avg_cas_2comp_outputParam.csv'
       clean_avg_1comp_path = path / 'clean-all-results/clean_avg_cas_1comp_outputParam.csv'
       clean_avg_2comp_path = path / 'clean-all-results/clean_avg_cas_2comp_outputParam.csv'

       # dirty params
       dirty_noc_1comp_path = path / 'dirty-all-results/dirty_no-correction_1comp_outputParam.csv'
       dirty_noc_2comp_path = path / 'dirty-all-results/dirty_no-correction_2comp_outputParam.csv'

       dirty_0cd20_1comp_path = path / 'dirty-all-results/dirty_0cd20_1comp_outputParam.csv'
       dirty_0cd20_2comp_path = path / 'dirty-all-results/dirty_0cd20_2comp_outputParam.csv'
       dirty_19e3e_1comp_path = path / 'dirty-all-results/dirty_19e3e_1comp_outputParam.csv'
       dirty_19e3e_2comp_path = path / 'dirty-all-results/dirty_19e3e_2comp_outputParam.csv'
       dirty_34766_1comp_path = path / 'dirty-all-results/dirty_34766_1comp_outputParam.csv'
       dirty_34766_2comp_path = path / 'dirty-all-results/dirty_34766_2comp_outputParam.csv'
       dirty_34a6d_1comp_path = path / 'dirty-all-results/dirty_34a6d_1comp_outputParam.csv'
       dirty_34a6d_2comp_path = path / 'dirty-all-results/dirty_34a6d_2comp_outputParam.csv'
       dirty_484af_1comp_path = path / 'dirty-all-results/dirty_484af_1comp_outputParam.csv'
       dirty_484af_2comp_path = path / 'dirty-all-results/dirty_484af_2comp_outputParam.csv'
       dirty_714af_1comp_path = path / 'dirty-all-results/dirty_714af_1comp_outputParam.csv'
       dirty_714af_2comp_path = path / 'dirty-all-results/dirty_714af_2comp_outputParam.csv'
       dirty_c1204_1comp_path = path / 'dirty-all-results/dirty_c1204_1comp_outputParam.csv'
       dirty_c1204_2comp_path = path / 'dirty-all-results/dirty_c1204_2comp_outputParam.csv'
       dirty_fe81d_1comp_path = path / 'dirty-all-results/dirty_fe81d_1comp_outputParam.csv'
       dirty_fe81d_2comp_path = path / 'dirty-all-results/dirty_fe81d_2comp_outputParam.csv'
       dirty_ff67b_1comp_path = path / 'dirty-all-results/dirty_ff67b_1comp_outputParam.csv'
       dirty_ff67b_2comp_path = path / 'dirty-all-results/dirty_ff67b_2comp_outputParam.csv'


       # clean params
       clean_noc_1comp_path = path / 'clean-all-results/clean_no-correction_1comp_outputParam.csv'
       clean_noc_2comp_path = path / 'clean-all-results/clean_no-correction_2comp_outputParam.csv'

       clean_0cd20_1comp_path = path / 'clean-all-results/clean_0cd20_1comp_outputParam.csv'
       clean_0cd20_2comp_path = path / 'clean-all-results/clean_0cd20_2comp_outputParam.csv'
       clean_19e3e_1comp_path = path / 'clean-all-results/clean_19e3e_1comp_outputParam.csv'
       clean_19e3e_2comp_path = path / 'clean-all-results/clean_19e3e_2comp_outputParam.csv'
       clean_34766_1comp_path = path / 'clean-all-results/clean_34766_1comp_outputParam.csv'
       clean_34766_2comp_path = path / 'clean-all-results/clean_34766_2comp_outputParam.csv'
       clean_34a6d_1comp_path = path / 'clean-all-results/clean_34a6d_1comp_outputParam.csv'
       clean_34a6d_2comp_path = path / 'clean-all-results/clean_34a6d_2comp_outputParam.csv'
       clean_484af_1comp_path = path / 'clean-all-results/clean_484af_1comp_outputParam.csv'
       clean_484af_2comp_path = path / 'clean-all-results/clean_484af_2comp_outputParam.csv'
       clean_714af_1comp_path = path / 'clean-all-results/clean_714af_1comp_outputParam.csv'
       clean_714af_2comp_path = path / 'clean-all-results/clean_714af_2comp_outputParam.csv'
       clean_c1204_1comp_path = path / 'clean-all-results/clean_c1204_1comp_outputParam.csv'
       clean_c1204_2comp_path = path / 'clean-all-results/clean_c1204_2comp_outputParam.csv'
       clean_fe81d_1comp_path = path / 'clean-all-results/clean_fe81d_1comp_outputParam.csv'
       clean_fe81d_2comp_path = path / 'clean-all-results/clean_fe81d_2comp_outputParam.csv'
       clean_ff67b_1comp_path = path / 'clean-all-results/clean_ff67b_1comp_outputParam.csv'
       clean_ff67b_2comp_path = path / 'clean-all-results/clean_ff67b_2comp_outputParam.csv'


       # average parameters
       dirty_avg_1comp =  pd.read_csv(dirty_avg_1comp_path, sep=',').assign(
           artifact=10*['dirty',])
       dirty_avg_2comp =  pd.read_csv(dirty_avg_2comp_path, sep=',').assign(
           artifact=10*['dirty',])
       clean_avg_1comp =  pd.read_csv(clean_avg_1comp_path, sep=',').assign(
           artifact=10*['clean',])
       clean_avg_2comp =  pd.read_csv(clean_avg_2comp_path, sep=',').assign(
           artifact=10*['clean',])

       # dirty params
       dirty_noc_1comp = pd.read_csv(dirty_noc_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['No correction'])
       dirty_noc_2comp = pd.read_csv(dirty_noc_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['No correction'])

       dirty_0cd20_1comp =  pd.read_csv(dirty_0cd20_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['0cd20'])
       dirty_0cd20_2comp =  pd.read_csv(dirty_0cd20_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['0cd20'])
       dirty_19e3e_1comp =  pd.read_csv(dirty_19e3e_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['19e3e'])
       dirty_19e3e_2comp =  pd.read_csv(dirty_19e3e_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['19e3e'])
       dirty_34766_1comp =  pd.read_csv(dirty_34766_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['34766'])
       dirty_34766_2comp =  pd.read_csv(dirty_34766_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['34766'])
       dirty_34a6d_1comp =  pd.read_csv(dirty_34a6d_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['34a6d'])
       dirty_34a6d_2comp =  pd.read_csv(dirty_34a6d_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['34a6d'])
       dirty_484af_1comp =  pd.read_csv(dirty_484af_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['484af'])
       dirty_484af_2comp =  pd.read_csv(dirty_484af_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['484af'])
       dirty_714af_1comp =  pd.read_csv(dirty_714af_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['714af'])
       dirty_714af_2comp =  pd.read_csv(dirty_714af_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['714af'])
       dirty_c1204_1comp =  pd.read_csv(dirty_c1204_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['c1204'])
       dirty_c1204_2comp =  pd.read_csv(dirty_c1204_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['c1204'])
       dirty_fe81d_1comp =  pd.read_csv(dirty_fe81d_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['fe81d'])
       dirty_fe81d_2comp =  pd.read_csv(dirty_fe81d_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['fe81d'])
       dirty_ff67b_1comp =  pd.read_csv(dirty_ff67b_1comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['ff67b'])
       dirty_ff67b_2comp =  pd.read_csv(dirty_ff67b_2comp_path, sep=',').assign(
           artifact=250*['dirty',], processing=250*['ff67b'])

       # clean params
       clean_noc_1comp = pd.read_csv(clean_noc_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['No correction'])
       clean_noc_2comp = pd.read_csv(clean_noc_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['No correction'])

       clean_0cd20_1comp =  pd.read_csv(clean_0cd20_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['0cd20'])
       clean_0cd20_2comp =  pd.read_csv(clean_0cd20_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['0cd20'])
       clean_19e3e_1comp =  pd.read_csv(clean_19e3e_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['19e3e'])
       clean_19e3e_2comp =  pd.read_csv(clean_19e3e_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['19e3e'])
       clean_34766_1comp =  pd.read_csv(clean_34766_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['34766'])
       clean_34766_2comp =  pd.read_csv(clean_34766_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['34766'])
       clean_34a6d_1comp =  pd.read_csv(clean_34a6d_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['34a6d'])
       clean_34a6d_2comp =  pd.read_csv(clean_34a6d_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['34a6d'])
       clean_484af_1comp =  pd.read_csv(clean_484af_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['484af'])
       clean_484af_2comp =  pd.read_csv(clean_484af_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['484af'])
       clean_714af_1comp =  pd.read_csv(clean_714af_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['714af'])
       clean_714af_2comp =  pd.read_csv(clean_714af_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['714af'])
       clean_c1204_1comp =  pd.read_csv(clean_c1204_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['c1204'])
       clean_c1204_2comp =  pd.read_csv(clean_c1204_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['c1204'])
       clean_fe81d_1comp =  pd.read_csv(clean_fe81d_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['fe81d'])
       clean_fe81d_2comp =  pd.read_csv(clean_fe81d_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['fe81d'])
       clean_ff67b_1comp =  pd.read_csv(clean_ff67b_1comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['ff67b'])
       clean_ff67b_2comp =  pd.read_csv(clean_ff67b_2comp_path, sep=',').assign(
           artifact=250*['clean',], processing=250*['ff67b'])

       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       avg_param.head()
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     |   | name_of_plot | master_file | parent_name  | parent_uqid  | time of fit             | Diff_eq     | Diff_species | Triplet_eq | Triplet_species | Dimen | ... | stdev(AR1) | artifact | A2  | stdev(A2) | txy2 | stdev(txy2) | alpha2 | stdev(alpha2) | AR2 | stdev(AR2) |
|---+--------------+-------------+--------------+--------------+-------------------------+-------------+--------------+------------+-----------------+-------+-----+------------+----------+-----+-----------+------+-------------+--------+---------------+-----+------------|
| 0 | clean        | Not known   | average_data | average_data | Mon Jun 6 16:14:44 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 1 | 0cd20        | Not known   | average_data | average_data | Mon Jun 6 16:13:31 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 2 | 19e3e        | Not known   | average_data | average_data | Mon Jun 6 16:13:31 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 3 | 34a6d        | Not known   | average_data | average_data | Mon Jun 6 16:13:31 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 4 | 484af        | Not known   | average_data | average_data | Mon Jun 6 16:13:31 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |

5 rows × 34 columns
     :END:

     #+BEGIN_SRC jupyter-python
       def sort_fit(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0]) * 1000
           t_slow = float(array[0, 1]) * 1000
           if np.isnan(t_slow):
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}$'
               out = f'$\\tau_D={t_fast:.1f}, N={nfcs:.1f}$'
           elif f'{A_fast:.0%}' == '100%':
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}(100\\%)$'
               out = f'$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$'
           elif f'{A_slow:.0%}' == '100%':
               # if tt_low_high[0] <= t_slow <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_slow:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_slow:.2f}(100\\%)$'
               out = f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$'
           else:
               # if (tt_low_high[0] <= t_fast <= tt_low_high[1]) or (
               #     tt_low_high[0] <= t_slow <= tt_low_high[1]):
               #     out = f'\\cellcolor[HTML]{{009e73}}\\colorbox[HTML]{{009e73}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}\\colorbox[HTML]{{d55e00}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               out = f'\\makecell{{$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$\\\\'\
                     f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$}}'
               out = out.replace('%', '\\%')
           return out
       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       avg_param['fit results'] = avg_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(lambda x: sort_fit(x), axis=1)
       avg_param = avg_param[['name_of_plot', 'Diff_species', 'artifact', 'fit results']]
       avg_param = avg_param.pivot_table(values='fit results',
                                         columns='artifact',
                                         index=['name_of_plot', 'Diff_species'],
                                         aggfunc=lambda x: '-'.join(x))
       avg_param.loc[('clean', 1), 'dirty'] = avg_param.loc[('dirty', 1), 'dirty']
       avg_param.loc[('clean', 2), 'dirty'] = avg_param.loc[('dirty', 2), 'dirty']

       avg_param = avg_param.rename(index={'clean' : 'no correction'})
       # to get all models
       first = ['no correction',] + model_name_ls.copy()
       # just two examples
       # first = ['no correction', '0cd20', '34a6d']
       second = [1, 2]
       index_order = pd.MultiIndex.from_product([first, second],
                                                names=[r'\makecell{type of\\processing}', 'fit'])
       avg_param = avg_param.reindex(index=index_order)

       with pd.option_context("max_colwidth", 1000):
           print(avg_param.to_latex(escape=False,
                                    column_format='ccll',
                                    caption=('Experimental results')))
       avg_param
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     #+begin_example
       \begin{table}
       \centering
       \caption{Experimental results}
       \begin{tabular}{ccll}
       \toprule
             & artifact &                                                                                 clean &                                                                                 dirty \\
       \makecell{type of\\processing} & fit &                                                                                       &                                                                                       \\
       \midrule
       no correction & 1 &                                                                 $\tau_D=213.8, N=1.1$ &                                                                 $\tau_D=302.7, N=0.9$ \\
             & 2 &    \makecell{$\tau_D^{fast}=11.9, N\cdot A=0.2$\\$\tau_D^{slow}=326.1, N\cdot A=0.8$} &    \makecell{$\tau_D^{fast}=31.2, N\cdot A=0.2$\\$\tau_D^{slow}=586.3, N\cdot A=0.6$} \\
       ff67b & 1 &                                                                 $\tau_D=122.0, N=2.1$ &                                                                 $\tau_D=145.4, N=1.6$ \\
             & 2 &     \makecell{$\tau_D^{fast}=4.8, N\cdot A=0.4$\\$\tau_D^{slow}=178.9, N\cdot A=1.5$} &    \makecell{$\tau_D^{fast}=15.7, N\cdot A=0.4$\\$\tau_D^{slow}=256.8, N\cdot A=1.1$} \\
       34766 & 1 &                                                                  $\tau_D=83.5, N=3.8$ &                                                                  $\tau_D=72.4, N=4.4$ \\
             & 2 &   \makecell{$\tau_D^{fast}=54.9, N\cdot A=3.0$\\$\tau_D^{slow}=6174.1, N\cdot A=0.5$} &   \makecell{$\tau_D^{fast}=43.1, N\cdot A=3.2$\\$\tau_D^{slow}=7643.3, N\cdot A=0.7$} \\
       714af & 1 &                                                                  $\tau_D=99.4, N=2.9$ &                                                                 $\tau_D=120.4, N=2.3$ \\
             & 2 &     \makecell{$\tau_D^{fast}=6.3, N\cdot A=0.7$\\$\tau_D^{slow}=166.5, N\cdot A=1.9$} &   \makecell{$\tau_D^{fast}=61.5, N\cdot A=1.7$\\$\tau_D^{slow}=1759.0, N\cdot A=0.5$} \\
       34a6d & 1 &                                                                  $\tau_D=70.6, N=4.0$ &                                                                  $\tau_D=59.7, N=4.5$ \\
             & 2 &   \makecell{$\tau_D^{fast}=52.2, N\cdot A=3.1$\\$\tau_D^{slow}=7165.8, N\cdot A=0.5$} &   \makecell{$\tau_D^{fast}=37.4, N\cdot A=3.4$\\$\tau_D^{slow}=8435.8, N\cdot A=0.7$} \\
       484af & 1 &                                                                 $\tau_D=138.9, N=2.0$ &                                                                 $\tau_D=124.0, N=2.1$ \\
             & 2 &     \makecell{$\tau_D^{fast}=6.8, N\cdot A=0.4$\\$\tau_D^{slow}=211.8, N\cdot A=1.4$} &     \makecell{$\tau_D^{fast}=7.8, N\cdot A=0.5$\\$\tau_D^{slow}=190.2, N\cdot A=1.5$} \\
       0cd20 & 1 &                                                                 $\tau_D=195.1, N=1.2$ &                                                                 $\tau_D=206.0, N=1.1$ \\
             & 2 &     \makecell{$\tau_D^{fast}=7.1, N\cdot A=0.2$\\$\tau_D^{slow}=277.5, N\cdot A=0.9$} &     \makecell{$\tau_D^{fast}=7.7, N\cdot A=0.2$\\$\tau_D^{slow}=288.6, N\cdot A=0.8$} \\
       fe81d & 1 &                                                                 $\tau_D=153.8, N=1.7$ &                                                                 $\tau_D=138.5, N=1.8$ \\
             & 2 &     \makecell{$\tau_D^{fast}=6.5, N\cdot A=0.3$\\$\tau_D^{slow}=223.7, N\cdot A=1.2$} &     \makecell{$\tau_D^{fast}=6.2, N\cdot A=0.3$\\$\tau_D^{slow}=196.3, N\cdot A=1.3$} \\
       19e3e & 1 &                                                                 $\tau_D=133.1, N=2.0$ &                                                                 $\tau_D=117.5, N=2.3$ \\
             & 2 &     \makecell{$\tau_D^{fast}=5.8, N\cdot A=0.4$\\$\tau_D^{slow}=197.1, N\cdot A=1.4$} &     \makecell{$\tau_D^{fast}=7.0, N\cdot A=0.5$\\$\tau_D^{slow}=179.6, N\cdot A=1.6$} \\
       c1204 & 1 &                                                                  $\tau_D=43.0, N=5.9$ &                                                                  $\tau_D=35.2, N=6.4$ \\
             & 2 &  \makecell{$\tau_D^{fast}=33.4, N\cdot A=4.7$\\$\tau_D^{slow}=10150.3, N\cdot A=0.7$} &  \makecell{$\tau_D^{fast}=24.7, N\cdot A=4.9$\\$\tau_D^{slow}=13801.3, N\cdot A=0.8$} \\
       \bottomrule
       \end{tabular}
       \end{table}
     #+end_example
     |                                | artifact | clean                                             | dirty                                             |
|--------------------------------+----------+---------------------------------------------------+---------------------------------------------------|
| \makecell{type of\\processing} | fit      |                                                   |                                                   |
| no correction                  | 1        | $\tau_D=213.8, N=1.1$                             | $\tau_D=302.7, N=0.9$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=11.9, N\cdot A=0.2$\\... | \makecell{$\tau_D^{fast}=31.2, N\cdot A=0.2$\\... |
| ff67b                          | 1        | $\tau_D=122.0, N=2.1$                             | $\tau_D=145.4, N=1.6$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=4.8, N\cdot A=0.4$\\$... | \makecell{$\tau_D^{fast}=15.7, N\cdot A=0.4$\\... |
| 34766                          | 1        | $\tau_D=83.5, N=3.8$                              | $\tau_D=72.4, N=4.4$                              |
|                                | 2        | \makecell{$\tau_D^{fast}=54.9, N\cdot A=3.0$\\... | \makecell{$\tau_D^{fast}=43.1, N\cdot A=3.2$\\... |
| 714af                          | 1        | $\tau_D=99.4, N=2.9$                              | $\tau_D=120.4, N=2.3$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=6.3, N\cdot A=0.7$\\$... | \makecell{$\tau_D^{fast}=61.5, N\cdot A=1.7$\\... |
| 34a6d                          | 1        | $\tau_D=70.6, N=4.0$                              | $\tau_D=59.7, N=4.5$                              |
|                                | 2        | \makecell{$\tau_D^{fast}=52.2, N\cdot A=3.1$\\... | \makecell{$\tau_D^{fast}=37.4, N\cdot A=3.4$\\... |
| 484af                          | 1        | $\tau_D=138.9, N=2.0$                             | $\tau_D=124.0, N=2.1$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=6.8, N\cdot A=0.4$\\$... | \makecell{$\tau_D^{fast}=7.8, N\cdot A=0.5$\\$... |
| 0cd20                          | 1        | $\tau_D=195.1, N=1.2$                             | $\tau_D=206.0, N=1.1$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=7.1, N\cdot A=0.2$\\$... | \makecell{$\tau_D^{fast}=7.7, N\cdot A=0.2$\\$... |
| fe81d                          | 1        | $\tau_D=153.8, N=1.7$                             | $\tau_D=138.5, N=1.8$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=6.5, N\cdot A=0.3$\\$... | \makecell{$\tau_D^{fast}=6.2, N\cdot A=0.3$\\$... |
| 19e3e                          | 1        | $\tau_D=133.1, N=2.0$                             | $\tau_D=117.5, N=2.3$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=5.8, N\cdot A=0.4$\\$... | \makecell{$\tau_D^{fast}=7.0, N\cdot A=0.5$\\$... |
| c1204                          | 1        | $\tau_D=43.0, N=5.9$                              | $\tau_D=35.2, N=6.4$                              |
|                                | 2        | \makecell{$\tau_D^{fast}=33.4, N\cdot A=4.7$\\... | \makecell{$\tau_D^{fast}=24.7, N\cdot A=4.9$\\... |
     :END:

     #+begin_src jupyter-python

       def sort_fit_simple(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0])
           t_slow = float(array[0, 1])
           # for pex5: want to plot t_slow
           if np.isnan(t_slow):
               # 1-component fit
               # out = t_fast, N_fast, pd.NA, pd.NA
               out = pd.NA, pd.NA, t_fast, N_fast
           # 2-component fits
           elif f'{A_fast:.0%}' == '100%':
               # out = t_fast, N_fast, pd.NA, pd.NA
               out = pd.NA, pd.NA, t_fast, N_fast
           elif f'{A_slow:.0%}' == '100%':
               # out = t_slow, N_slow, pd.NA, pd.NA
               out = pd.NA, pd.NA, t_slow, N_slow
           else:
               out = t_fast, N_fast, t_slow, N_slow
           return out

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       all_param = all_param.reset_index()
       (all_param['t_fast'], all_param['N_fast'], all_param['t_slow'],
        all_param['N_slow']) = zip(*all_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(
            lambda x: sort_fit_simple(x), axis=1))
       all_param = all_param[['index', 'Diff_species', 'processing', 'artifact',
                              't_fast', 'N_fast', 't_slow', 'N_slow']]
       # for plotting 1 species AND 2 species fits
       # pub_param = all_param.loc[((all_param['Diff_species'] == 1) & (all_param['artifact'] == 'clean')) | (all_param['artifact'] == 'dirty')]
       # for only plotting 1 species fits
       pub_param = all_param.loc[(all_param['Diff_species'] == 1)]
       pub_param = pub_param.replace(
           ['clean'], '250 traces of\nHs-PEX5-EGFP\n(no artifacts)\nN (FCS) from\n1 species fit')
       pub_param.loc[(pub_param['Diff_species'] == 1) & (pub_param['artifact'] == 'dirty')] = pub_param.loc[
           (pub_param['Diff_species'] == 1) & (pub_param['artifact'] == 'dirty')].replace(
           ['dirty'], '250 traces of\nTb-PEX5-EGFP\n(peak artifacts)\nN (FCS) from\n1 species fit')
       pub_param.loc[(pub_param['Diff_species'] == 2) & (pub_param['artifact'] == 'dirty')] = pub_param.loc[
           (pub_param['Diff_species'] == 2) & (pub_param['artifact'] == 'dirty')].replace(
           ['dirty'], '250 traces of\nTb-PEX5-EGFP\n(peak artifacts)\nN (FCS) $\\cdot$ A from\nslow sp. of 2 sp. fit')
       # comparing no correction, 0cd20, fe81d, and ff67b
       # pub_param = pub_param.loc[(all_param['processing'] == 'No correction') | (all_param['processing'] == '0cd20')| (all_param['processing'] == 'fe81d')| (all_param['processing'] == 'ff67b')]
       # only no correction and 0cd20
       pub_param = pub_param.loc[(all_param['processing'] == 'No correction') | (all_param['processing'] == '0cd20')]
       # pub_param = pub_param.replace(['0cd20'], 'large model (200 MB),\n6 levels,\npool size=4,\nscaler=quantile\ntransform (Gaussian pdf)')
       # pub_param = pub_param.replace(['34a6d'], 'small model (7 MB),\n3 levels,\npool size=4,\nscaler=l2')
       g = sns.catplot(data=pub_param,
                       y='t_slow',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='t_slow',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores transit times',
                      size=25)

       g._legend.set_title('')
       # new_labels = ['250 traces of\nHs-PEX5-EGFP\n(no artifacts)\nN (FCS) from\n1 species fit',
       #               '250 traces of\nTb-PEX5-EGFP\n(peak artifacts)\nN (FCS) $\\cdot$ A from\n1 species fit',
       #               '250 traces of\nTb-PEX5-EGFP\n(peak artifacts)\nN (FCS) $\\cdot$ A from\nslow sp. of 2 sp. fit']
       # for t, l in zip(g._legend.texts, new_labels):
       #     t.set_text(l)
       plt.setp(g.axes, yscale='log', xlabel='',
                ylabel=r'log transit time $\tau_{D}$ $[ms]$')
       for ax in g.axes.flatten():
           ax.grid(visible=True, which='both', axis='y')
       g.tight_layout()
       plot2_file = 'analysis3_biological_noc+0cd20_1sp_transit-times'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')

       g = sns.catplot(data=pub_param,
                       y='N_slow',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='N_slow',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores particle number',
                      size=25)
       g._legend.set_title('')
       plt.setp(g.axes, xlabel='',
                ylabel=r'particle number $N$ $[fl^{-1}]$')

       g.tight_layout()
       plot2_file = 'analysis3_biological_noc+0cd20_1sp_particle-number'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')
     #+end_src

     #+RESULTS:

     #+begin_src jupyter-python
       N_param = all_param.pivot_table(values='N_slow',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])

       t_param = all_param.pivot_table(values='t_slow',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])
       t_param = t_param * 1000
       display(N_param.describe().T)
       display(t_param.describe().T)
       display(t_param.median(axis=0))
       display(N_param.median(axis=0))
     #+end_src

     #+RESULTS:
     :RESULTS:
     |               |          |              | count | mean      | std       | min      | 25%      | 50%      | 75%      | max        |
|---------------+----------+--------------+-------+-----------+-----------+----------+----------+----------+----------+------------|
| processing    | artifact | Diff_species |       |           |           |          |          |          |          |            |
| 0cd20         | clean    | 1            | 250.0 | 1.283681  | 0.331273  | 0.711906 | 0.993304 | 1.349288 | 1.545703 | 2.466550   |
|               |          | 2            | 250.0 | 0.859777  | 0.308950  | 0.149177 | 0.609196 | 0.926528 | 1.102579 | 1.808718   |
|               | dirty    | 1            | 250.0 | 1.076527  | 0.092880  | 0.871258 | 1.020479 | 1.058181 | 1.117519 | 1.300814   |
|               |          | 2            | 250.0 | 0.699150  | 0.195871  | 0.043323 | 0.675802 | 0.751587 | 0.807867 | 0.964632   |
| 19e3e         | clean    | 1            | 250.0 | 2.099823  | 0.396407  | 1.675333 | 1.847394 | 1.921758 | 2.140211 | 3.446744   |
|               |          | 2            | 250.0 | 1.022104  | 0.616786  | 0.065982 | 0.365168 | 1.244541 | 1.408030 | 3.446782   |
|               | dirty    | 1            | 250.0 | 2.307817  | 0.232564  | 1.659399 | 2.150454 | 2.285697 | 2.456244 | 3.021975   |
|               |          | 2            | 250.0 | 0.686930  | 0.568277  | 0.023491 | 0.161794 | 0.482306 | 1.229205 | 2.659892   |
| 34766         | clean    | 1            | 250.0 | 11.938585 | 88.548751 | 0.500000 | 3.253603 | 3.624025 | 4.285079 | 999.984621 |
|               |          | 2            | 250.0 | 8.692555  | 89.175045 | 0.028206 | 0.351072 | 0.499177 | 0.809769 | 999.999983 |
|               | dirty    | 1            | 250.0 | 4.508193  | 1.097667  | 1.874917 | 3.749425 | 4.153814 | 5.092429 | 8.361214   |
|               |          | 2            | 250.0 | 0.718706  | 0.368755  | 0.005509 | 0.517003 | 0.641224 | 0.903212 | 2.209470   |
| 34a6d         | clean    | 1            | 250.0 | 4.117083  | 1.448084  | 1.369858 | 3.344342 | 3.578869 | 4.259735 | 13.338871  |
|               |          | 2            | 250.0 | 0.580332  | 0.462812  | 0.013905 | 0.370369 | 0.445908 | 0.604474 | 4.100952   |
|               | dirty    | 1            | 250.0 | 4.589240  | 0.677313  | 2.440459 | 4.129991 | 4.508246 | 4.945682 | 6.826721   |
|               |          | 2            | 250.0 | 0.660055  | 0.197948  | 0.008958 | 0.594125 | 0.663819 | 0.768504 | 1.128638   |
| 484af         | clean    | 1            | 250.0 | 2.001893  | 0.350020  | 1.591885 | 1.770829 | 1.846756 | 2.083310 | 3.031847   |
|               |          | 2            | 250.0 | 1.009255  | 0.548804  | 0.072668 | 0.516660 | 1.194404 | 1.331486 | 2.692780   |
|               | dirty    | 1            | 250.0 | 2.169071  | 0.243734  | 1.139235 | 2.014037 | 2.168339 | 2.306431 | 3.165567   |
|               |          | 2            | 250.0 | 0.578596  | 0.511649  | 0.023654 | 0.145429 | 0.249873 | 1.121982 | 1.818200   |
| 714af         | clean    | 1            | 250.0 | 3.031178  | 0.711727  | 2.278981 | 2.534664 | 2.702620 | 3.389998 | 6.530143   |
|               |          | 2            | 250.0 | 1.036692  | 0.870417  | 0.034122 | 0.259274 | 0.818381 | 1.765778 | 5.681282   |
|               | dirty    | 1            | 250.0 | 2.482608  | 0.624358  | 1.173982 | 1.915721 | 2.553865 | 2.896530 | 3.960503   |
|               |          | 2            | 250.0 | 0.507754  | 0.248540  | 0.027141 | 0.385177 | 0.474798 | 0.593258 | 1.326390   |
| No correction | clean    | 1            | 250.0 | 1.237887  | 0.345995  | 0.659560 | 0.943297 | 1.310739 | 1.517006 | 2.431642   |
|               |          | 2            | 250.0 | 0.852315  | 0.281484  | 0.180091 | 0.619734 | 0.907235 | 1.070789 | 1.792435   |
|               | dirty    | 1            | 250.0 | 0.911898  | 0.151483  | 0.252451 | 0.848349 | 0.915594 | 0.992811 | 1.247015   |
|               |          | 2            | 250.0 | 0.589915  | 0.149190  | 0.047123 | 0.536370 | 0.609846 | 0.685742 | 0.896543   |
| c1204         | clean    | 1            | 250.0 | 13.999780 | 88.747128 | 0.500000 | 4.964437 | 5.549268 | 6.355662 | 999.999951 |
|               |          | 2            | 250.0 | 5.156233  | 62.777280 | 0.007749 | 0.582338 | 0.710018 | 0.876728 | 991.775374 |
|               | dirty    | 1            | 250.0 | 6.524568  | 2.835437  | 0.272083 | 4.923490 | 5.842289 | 7.124991 | 19.207418  |
|               |          | 2            | 250.0 | 0.832655  | 0.618884  | 0.002353 | 0.588914 | 0.769519 | 0.918340 | 4.639226   |
| fe81d         | clean    | 1            | 250.0 | 1.728585  | 0.299107  | 1.324613 | 1.547029 | 1.625520 | 1.734985 | 2.626756   |
|               |          | 2            | 250.0 | 0.243494  | 0.247336  | 0.086145 | 0.184821 | 0.184821 | 0.184822 | 1.710978   |
|               | dirty    | 1            | 250.0 | 1.807793  | 0.222325  | 0.782951 | 1.678265 | 1.794022 | 1.927468 | 2.611554   |
|               |          | 2            | 250.0 | 0.759890  | 0.475136  | 0.026716 | 0.185844 | 0.933750 | 1.173312 | 1.627117   |
| ff67b         | clean    | 1            | 250.0 | 1.648666  | 0.245511  | 1.172057 | 1.443347 | 1.615278 | 1.807949 | 2.400101   |
|               |          | 2            | 250.0 | 0.739951  | 0.370918  | 0.104779 | 0.374833 | 0.862629 | 1.025650 | 1.591238   |
|               | dirty    | 1            | 250.0 | 1.634511  | 0.243402  | 1.161910 | 1.430746 | 1.600269 | 1.793080 | 2.378696   |
|               |          | 2            | 250.0 | 0.696151  | 0.359131  | 0.040757 | 0.375000 | 0.781483 | 0.976849 | 1.569625   |
     |               |          |              | count | mean         | std           | min        | 25%         | 50%          | 75%          | max          |
|---------------+----------+--------------+-------+--------------+---------------+------------+-------------+--------------+--------------+--------------|
| processing    | artifact | Diff_species |       |              |               |            |             |              |              |              |
| 0cd20         | clean    | 1            | 250.0 | 197.570985   | 11.101835     | 160.695535 | 192.968388  | 198.556645   | 205.036205   | 2.220655e+02 |
|               |          | 2            | 250.0 | 280.897057   | 28.923894     | 206.374945 | 262.867890  | 280.139615   | 298.796244   | 3.918368e+02 |
|               | dirty    | 1            | 250.0 | 206.551871   | 15.053643     | 168.164778 | 196.704872  | 204.380621   | 215.109384   | 2.709864e+02 |
|               |          | 2            | 250.0 | 292.091408   | 36.117303     | 222.714584 | 266.425671  | 289.283075   | 313.342227   | 4.286999e+02 |
| 19e3e         | clean    | 1            | 250.0 | 132.288021   | 30.888578     | 31.672874  | 112.333834  | 141.425264   | 156.280586   | 1.926578e+02 |
|               |          | 2            | 250.0 | 478.755567   | 3084.914359   | 87.408804  | 168.913027  | 194.549764   | 219.723347   | 4.794009e+04 |
|               | dirty    | 1            | 250.0 | 117.538069   | 19.185842     | 70.540207  | 103.631883  | 118.080619   | 128.510121   | 2.025103e+02 |
|               |          | 2            | 250.0 | 3818.725709  | 12052.219158  | 123.536742 | 166.214234  | 216.058934   | 1712.162065  | 1.228968e+05 |
| 34766         | clean    | 1            | 250.0 | 79.203956    | 38.094671     | 0.100001   | 63.252963   | 85.977906    | 97.012400    | 5.111561e+02 |
|               |          | 2            | 250.0 | 18121.137320 | 116460.962001 | 0.100000   | 1895.631493 | 5921.302088  | 10408.616412 | 1.431861e+06 |
|               | dirty    | 1            | 250.0 | 74.093788    | 29.472329     | 1.941936   | 52.517698   | 76.406010    | 90.828987    | 1.881877e+02 |
|               |          | 2            | 250.0 | 8262.560339  | 5391.700427   | 108.664281 | 4810.829127 | 7419.255886  | 11373.612749 | 2.987600e+04 |
| 34a6d         | clean    | 1            | 250.0 | 71.857265    | 30.109081     | 0.470029   | 54.986690   | 82.155275    | 93.856629    | 1.296096e+02 |
|               |          | 2            | 250.0 | 12787.675912 | 25520.168959  | 8.134197   | 4032.761045 | 6360.452280  | 10731.926359 | 2.112239e+05 |
|               | dirty    | 1            | 250.0 | 61.203539    | 20.821339     | 10.719464  | 45.270303   | 60.767515    | 77.052043    | 1.275615e+02 |
|               |          | 2            | 250.0 | 9083.861267  | 5311.133740   | 73.473466  | 5639.763121 | 8696.141542  | 11938.989864 | 3.011757e+04 |
| 484af         | clean    | 1            | 250.0 | 138.513257   | 31.425414     | 57.149791  | 112.159983  | 147.354910   | 163.701603   | 2.014395e+02 |
|               |          | 2            | 250.0 | 431.372332   | 1740.229207   | 87.106177  | 171.082606  | 206.820377   | 237.975641   | 2.376139e+04 |
|               | dirty    | 1            | 250.0 | 123.449861   | 24.884642     | 74.870080  | 108.477502  | 120.852269   | 134.613662   | 3.220168e+02 |
|               |          | 2            | 250.0 | 21267.333987 | 178344.911712 | 126.294887 | 179.399868  | 264.879728   | 6592.294313  | 1.999977e+06 |
| 714af         | clean    | 1            | 250.0 | 97.730979    | 28.567263     | 13.672387  | 79.625034   | 106.051397   | 116.483956   | 1.602460e+02 |
|               |          | 2            | 250.0 | 1267.698996  | 6044.773242   | 57.763965  | 131.234026  | 151.718876   | 180.793446   | 8.953522e+04 |
|               | dirty    | 1            | 250.0 | 116.574433   | 27.782409     | 47.153987  | 100.185728  | 116.619789   | 134.272941   | 2.277835e+02 |
|               |          | 2            | 250.0 | 2395.477742  | 2266.242512   | 112.015555 | 650.723991  | 1801.884611  | 3269.742806  | 1.720913e+04 |
| No correction | clean    | 1            | 250.0 | 214.855630   | 8.822180      | 185.807688 | 210.189569  | 214.746329   | 219.805545   | 2.403676e+02 |
|               |          | 2            | 250.0 | 321.551484   | 43.688060     | 246.432630 | 295.687219  | 314.881710   | 341.093333   | 5.870439e+02 |
|               | dirty    | 1            | 250.0 | 302.247780   | 149.046252    | 196.602847 | 238.924744  | 257.972620   | 295.907485   | 1.541290e+03 |
|               |          | 2            | 250.0 | 1142.796085  | 5941.456080   | 282.560029 | 385.873863  | 446.398681   | 572.919199   | 9.036049e+04 |
| c1204         | clean    | 1            | 250.0 | 48.505891    | 24.383016     | 0.100000   | 31.755113   | 50.736213    | 67.725039    | 1.002715e+02 |
|               |          | 2            | 250.0 | 53894.663962 | 242087.754187 | 0.100006   | 6150.287450 | 9870.186308  | 17083.366372 | 1.997993e+06 |
|               | dirty    | 1            | 250.0 | 40.025113    | 24.589357     | 0.100000   | 20.073745   | 42.172284    | 56.167103    | 1.075048e+02 |
|               |          | 2            | 250.0 | 27334.872660 | 39775.953327  | 27.651454  | 6997.120244 | 11507.858061 | 29091.046730 | 2.741183e+05 |
| fe81d         | clean    | 1            | 250.0 | 154.346231   | 34.135789     | 50.294612  | 131.738794  | 166.773715   | 180.351216   | 2.075641e+02 |
|               |          | 2            | 250.0 | 359.140767   | 1986.706440   | 99.457663  | 223.036000  | 223.036000   | 223.036000   | 3.158828e+04 |
|               | dirty    | 1            | 250.0 | 136.898092   | 31.063928     | 84.315054  | 120.800932  | 132.385430   | 147.859495   | 4.574161e+02 |
|               |          | 2            | 250.0 | 1600.701942  | 5501.971865   | 131.831459 | 176.036186  | 208.895751   | 256.397019   | 4.171204e+04 |
| ff67b         | clean    | 1            | 250.0 | 138.380852   | 20.881043     | 91.342176  | 125.062844  | 137.088984   | 150.851639   | 2.185942e+02 |
|               |          | 2            | 250.0 | 405.415378   | 663.893359    | 129.189984 | 191.203319  | 233.471726   | 317.105507   | 6.537676e+03 |
|               | dirty    | 1            | 250.0 | 144.545469   | 21.425438     | 95.693924  | 130.799124  | 143.170302   | 157.675393   | 2.277492e+02 |
|               |          | 2            | 250.0 | 573.491150   | 1065.235255   | 138.442970 | 204.447256  | 262.463979   | 447.224488   | 9.867625e+03 |
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1                 198.556645
                                2                 280.139615
                      dirty     1                 204.380621
                                2                 289.283075
       19e3e          clean     1                 141.425264
                                2                 194.549764
                      dirty     1                 118.080619
                                2                 216.058934
       34766          clean     1                  85.977906
                                2                5921.302088
                      dirty     1                  76.406010
                                2                7419.255886
       34a6d          clean     1                  82.155275
                                2                6360.452280
                      dirty     1                  60.767515
                                2                8696.141542
       484af          clean     1                 147.354910
                                2                 206.820377
                      dirty     1                 120.852269
                                2                 264.879728
       714af          clean     1                 106.051397
                                2                 151.718876
                      dirty     1                 116.619789
                                2                1801.884611
       No correction  clean     1                 214.746329
                                2                 314.881710
                      dirty     1                 257.972620
                                2                 446.398681
       c1204          clean     1                  50.736213
                                2                9870.186308
                      dirty     1                  42.172284
                                2               11507.858061
       fe81d          clean     1                 166.773715
                                2                 223.036000
                      dirty     1                 132.385430
                                2                 208.895751
       ff67b          clean     1                 137.088984
                                2                 233.471726
                      dirty     1                 143.170302
                                2                 262.463979
       dtype: float64
     #+end_example
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1               1.349288
                                2               0.926528
                      dirty     1               1.058181
                                2               0.751587
       19e3e          clean     1               1.921758
                                2               1.244541
                      dirty     1               2.285697
                                2               0.482306
       34766          clean     1               3.624025
                                2               0.499177
                      dirty     1               4.153814
                                2               0.641224
       34a6d          clean     1               3.578869
                                2               0.445908
                      dirty     1               4.508246
                                2               0.663819
       484af          clean     1               1.846756
                                2               1.194404
                      dirty     1               2.168339
                                2               0.249873
       714af          clean     1               2.702620
                                2               0.818381
                      dirty     1               2.553865
                                2               0.474798
       No correction  clean     1               1.310739
                                2               0.907235
                      dirty     1               0.915594
                                2               0.609846
       c1204          clean     1               5.549268
                                2               0.710018
                      dirty     1               5.842289
                                2               0.769519
       fe81d          clean     1               1.625520
                                2               0.184821
                      dirty     1               1.794022
                                2               0.933750
       ff67b          clean     1               1.615278
                                2               0.862629
                      dirty     1               1.600269
                                2               0.781483
       dtype: float64
     #+end_example
     :END:

     #+BEGIN_SRC jupyter-python
g = sns.catplot(data=all_param,
                y='A',
                x='artifact-correction',
                hue='fitted species (A)',
                sharey=True,
                height=5,
                aspect=2,
                legend_out=True,
                kind='boxen',
                showfliers=False)
g.map_dataframe(sns.stripplot,
      y='A',
      x='artifact-correction',
      hue='fitted species (A)',
      dodge=True,
      palette=sns.color_palette(['0.3']),
      size=4,
      jitter=0.2)
g.tight_layout()
g.fig.suptitle('Fraction sizes of AlexaFluor488 (clean) vs\nAlexaFluor488 + Dio LUVs (dirty) with different correction methods',
               y=1.08, size=20)
for axes in g.axes.flat:
     _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=45)
plt.setp(g.axes, xlabel='biological sample - correction method',
         ylabel='relative fraction size')
plt.show()
     #+END_SRC
       # dirty params
       dirty_noc_1comp_path = path / 'dirty-all-results/dirty_no-correction_1comp_outputParam.csv'
       dirty_noc_2comp_path = path / 'dirty-all-results/dirty_no-correction_2comp_outputParam.csv'

       dirty_0cd20_1comp_path = path / 'dirty-all-results/dirty_0cd20_1comp_outputParam.csv'
       dirty_0cd20_2comp_path = path / 'dirty-all-results/dirty_0cd20_2comp_outputParam.csv'
       dirty_19e3e_1comp_path = path / 'dirty-all-results/dirty_19e3e_1comp_outputParam.csv'
       dirty_19e3e_2comp_path = path / 'dirty-all-results/dirty_19e3e_2comp_outputParam.csv'
       dirty_34766_1comp_path = path / 'dirty-all-results/dirty_34766_1comp_outputParam.csv'
       dirty_34766_2comp_path = path / 'dirty-all-results/dirty_34766_2comp_outputParam.csv'
       dirty_34a6d_1comp_path = path / 'dirty-all-results/dirty_34a6d_1comp_outputParam.csv'
       dirty_34a6d_2comp_path = path / 'dirty-all-results/dirty_34a6d_2comp_outputParam.csv'
       dirty_484af_1comp_path = path / 'dirty-all-results/dirty_484af_1comp_outputParam.csv'
       dirty_484af_2comp_path = path / 'dirty-all-results/dirty_484af_2comp_outputParam.csv'
       dirty_714af_1comp_path = path / 'dirty-all-results/dirty_714af_1comp_outputParam.csv'
       dirty_714af_2comp_path = path / 'dirty-all-results/dirty_714af_2comp_outputParam.csv'
       dirty_c1204_1comp_path = path / 'dirty-all-results/dirty_c1204_1comp_outputParam.csv'
       dirty_c1204_2comp_path = path / 'dirty-all-results/dirty_c1204_2comp_outputParam.csv'
       dirty_fe81d_1comp_path = path / 'dirty-all-results/dirty_fe81d_1comp_outputParam.csv'
       dirty_fe81d_2comp_path = path / 'dirty-all-results/dirty_fe81d_2comp_outputParam.csv'
       dirty_ff67b_1comp_path = path / 'dirty-all-results/dirty_ff67b_1comp_outputParam.csv'
       dirty_ff67b_2comp_path = path / 'dirty-all-results/dirty_ff67b_2comp_outputParam.csv'


       # clean params
       clean_noc_1comp_path = path / 'clean-all-results/clean_no-correction_1comp_outputParam.csv'
       clean_noc_2comp_path = path / 'clean-all-results/clean_no-correction_2comp_outputParam.csv'

       clean_0cd20_1comp_path = path / 'clean-all-results/clean_0cd20_1comp_outputParam.csv'
       clean_0cd20_2comp_path = path / 'clean-all-results/clean_0cd20_2comp_outputParam.csv'
       clean_19e3e_1comp_path = path / 'clean-all-results/clean_19e3e_1comp_outputParam.csv'
       clean_19e3e_2comp_path = path / 'clean-all-results/clean_19e3e_2comp_outputParam.csv'
       clean_34766_1comp_path = path / 'clean-all-results/clean_34766_1comp_outputParam.csv'
       clean_34766_2comp_path = path / 'clean-all-results/clean_34766_2comp_outputParam.csv'
       clean_34a6d_1comp_path = path / 'clean-all-results/clean_34a6d_1comp_outputParam.csv'
       clean_34a6d_2comp_path = path / 'clean-all-results/clean_34a6d_2comp_outputParam.csv'
       clean_484af_1comp_path = path / 'clean-all-results/clean_484af_1comp_outputParam.csv'
       clean_484af_2comp_path = path / 'clean-all-results/clean_484af_2comp_outputParam.csv'
       clean_714af_1comp_path = path / 'clean-all-results/clean_714af_1comp_outputParam.csv'
       clean_714af_2comp_path = path / 'clean-all-results/clean_714af_2comp_outputParam.csv'
       clean_c1204_1comp_path = path / 'clean-all-results/clean_c1204_1comp_outputParam.csv'
       clean_c1204_2comp_path = path / 'clean-all-results/clean_c1204_2comp_outputParam.csv'
       clean_fe81d_1comp_path = path / 'clean-all-results/clean_fe81d_1comp_outputParam.csv'
       clean_fe81d_2comp_path = path / 'clean-all-results/clean_fe81d_2comp_outputParam.csv'
       clean_ff67b_1comp_path = path / 'clean-all-results/clean_ff67b_1comp_outputParam.csv'
       clean_ff67b_2comp_path = path / 'clean-all-results/clean_ff67b_2comp_outputParam.csv'


       # average parameters
       dirty_avg_1comp =  pd.read_csv(dirty_avg_1comp_path, sep=',').assign(
           artifact=10*['dirty',])
       dirty_avg_2comp =  pd.read_csv(dirty_avg_2comp_path, sep=',').assign(
           artifact=10*['dirty',])
       clean_avg_1comp =  pd.read_csv(clean_avg_1comp_path, sep=',').assign(
           artifact=10*['clean',])
       clean_avg_2comp =  pd.read_csv(clean_avg_2comp_path, sep=',').assign(
           artifact=10*['clean',])

       # dirty params
       dirty_noc_1comp = pd.read_csv(dirty_noc_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['No correction'])
       dirty_noc_2comp = pd.read_csv(dirty_noc_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['No correction'])

       dirty_0cd20_1comp =  pd.read_csv(dirty_0cd20_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['0cd20'])
       dirty_0cd20_2comp =  pd.read_csv(dirty_0cd20_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['0cd20'])
       dirty_19e3e_1comp =  pd.read_csv(dirty_19e3e_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['19e3e'])
       dirty_19e3e_2comp =  pd.read_csv(dirty_19e3e_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['19e3e'])
       dirty_34766_1comp =  pd.read_csv(dirty_34766_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34766'])
       dirty_34766_2comp =  pd.read_csv(dirty_34766_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34766'])
       dirty_34a6d_1comp =  pd.read_csv(dirty_34a6d_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34a6d'])
       dirty_34a6d_2comp =  pd.read_csv(dirty_34a6d_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['34a6d'])
       dirty_484af_1comp =  pd.read_csv(dirty_484af_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['484af'])
       dirty_484af_2comp =  pd.read_csv(dirty_484af_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['484af'])
       dirty_714af_1comp =  pd.read_csv(dirty_714af_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['714af'])
       dirty_714af_2comp =  pd.read_csv(dirty_714af_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['714af'])
       dirty_c1204_1comp =  pd.read_csv(dirty_c1204_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['c1204'])
       dirty_c1204_2comp =  pd.read_csv(dirty_c1204_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['c1204'])
       dirty_fe81d_1comp =  pd.read_csv(dirty_fe81d_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['fe81d'])
       dirty_fe81d_2comp =  pd.read_csv(dirty_fe81d_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['fe81d'])
       dirty_ff67b_1comp =  pd.read_csv(dirty_ff67b_1comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['ff67b'])
       dirty_ff67b_2comp =  pd.read_csv(dirty_ff67b_2comp_path, sep=',').assign(
           artifact=440*['dirty',], processing=440*['ff67b'])

       # clean params
       clean_noc_1comp = pd.read_csv(clean_noc_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['No correction'])
       clean_noc_2comp = pd.read_csv(clean_noc_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['No correction'])

       clean_0cd20_1comp =  pd.read_csv(clean_0cd20_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['0cd20'])
       clean_0cd20_2comp =  pd.read_csv(clean_0cd20_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['0cd20'])
       clean_19e3e_1comp =  pd.read_csv(clean_19e3e_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['19e3e'])
       clean_19e3e_2comp =  pd.read_csv(clean_19e3e_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['19e3e'])
       clean_34766_1comp =  pd.read_csv(clean_34766_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34766'])
       clean_34766_2comp =  pd.read_csv(clean_34766_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34766'])
       clean_34a6d_1comp =  pd.read_csv(clean_34a6d_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34a6d'])
       clean_34a6d_2comp =  pd.read_csv(clean_34a6d_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['34a6d'])
       clean_484af_1comp =  pd.read_csv(clean_484af_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['484af'])
       clean_484af_2comp =  pd.read_csv(clean_484af_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['484af'])
       clean_714af_1comp =  pd.read_csv(clean_714af_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['714af'])
       clean_714af_2comp =  pd.read_csv(clean_714af_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['714af'])
       clean_c1204_1comp =  pd.read_csv(clean_c1204_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['c1204'])
       clean_c1204_2comp =  pd.read_csv(clean_c1204_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['c1204'])
       clean_fe81d_1comp =  pd.read_csv(clean_fe81d_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['fe81d'])
       clean_fe81d_2comp =  pd.read_csv(clean_fe81d_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['fe81d'])
       clean_ff67b_1comp =  pd.read_csv(clean_ff67b_1comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['ff67b'])
       clean_ff67b_2comp =  pd.read_csv(clean_ff67b_2comp_path, sep=',').assign(
           artifact=424*['clean',], processing=424*['ff67b'])

       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       avg_param.head()
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     |   | name_of_plot | master_file | parent_name  | parent_uqid  | time of fit              | Diff_eq     | Diff_species | Triplet_eq | Triplet_species | Dimen | ... | stdev(AR1) | artifact | A2  | stdev(A2) | txy2 | stdev(txy2) | alpha2 | stdev(alpha2) | AR2 | stdev(AR2) |
|---+--------------+-------------+--------------+--------------+--------------------------+-------------+--------------+------------+-----------------+-------+-----+------------+----------+-----+-----------+------+-------------+--------+---------------+-----+------------|
| 0 | clean        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 1 | 0cd20        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 2 | 19e3e        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 3 | 34a6d        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |
| 4 | 484af        | Not known   | average_data | average_data | Mon May 30 11:34:02 2022 | Equation 1B | 1            | no triplet | 1               | 3D    | ... | 0          | clean    | NaN | NaN       | NaN  | NaN         | NaN    | NaN           | NaN | NaN        |

5 rows × 34 columns
     :END:

     #+BEGIN_SRC jupyter-python
       def sort_fit(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0]) * 1000
           t_slow = float(array[0, 1]) * 1000
           if np.isnan(t_slow):
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}$'
               out = f'$\\tau_D={t_fast:.1f}, N={nfcs:.1f}$'
           elif f'{A_fast:.0%}' == '100%':
               # if tt_low_high[0] <= t_fast <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_fast:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_fast:.2f}(100\\%)$'
               out = f'$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$'
           elif f'{A_slow:.0%}' == '100%':
               # if tt_low_high[0] <= t_slow <= tt_low_high[1]:
               #     out = f'\\cellcolor[HTML]{{009e73}}${t_slow:.2f}(100\\%)$'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}${t_slow:.2f}(100\\%)$'
               out = f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$'
           else:
               # if (tt_low_high[0] <= t_fast <= tt_low_high[1]) or (
               #     tt_low_high[0] <= t_slow <= tt_low_high[1]):
               #     out = f'\\cellcolor[HTML]{{009e73}}\\colorbox[HTML]{{009e73}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               # else:
               #     out = f'\\cellcolor[HTML]{{d55e00}}\\colorbox[HTML]{{d55e00}}{{\\makecell{{${t_fast:.2f}^f({A_fast:.0%})$\\\\'\
               #           f'${t_slow:.2f}^s({A_slow:.0%})$}}}}'
               out = f'\\makecell{{$\\tau_D^{{fast}}={t_fast:.1f}, N\\cdot A={N_fast:.1f}$\\\\'\
                     f'$\\tau_D^{{slow}}={t_slow:.1f}, N\\cdot A={N_slow:.1f}$}}'
               out = out.replace('%', '\\%')
           return out
       avg_param = pd.concat([clean_avg_1comp, clean_avg_2comp,
                              dirty_avg_1comp, dirty_avg_2comp])

       avg_param['fit results'] = avg_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(lambda x: sort_fit(x), axis=1)
       avg_param = avg_param[['name_of_plot', 'Diff_species', 'artifact', 'fit results']]
       avg_param = avg_param.pivot_table(values='fit results',
                                         columns='artifact',
                                         index=['name_of_plot', 'Diff_species'],
                                         aggfunc=lambda x: '-'.join(x))
       avg_param.loc[('clean', 1), 'dirty'] = avg_param.loc[('dirty', 1), 'dirty']
       avg_param.loc[('clean', 2), 'dirty'] = avg_param.loc[('dirty', 2), 'dirty']

       avg_param = avg_param.rename(index={'clean' : 'no correction'})
       # to get all models
       # first = ['no correction',] + model_name_ls.copy()
       # just two examples
       first = ['no correction', '0cd20', '34a6d']
       second = [1, 2]
       index_order = pd.MultiIndex.from_product([first, second],
                                                names=[r'\makecell{type of\\processing}', 'fit'])
       avg_param = avg_param.reindex(index=index_order)

       with pd.option_context("max_colwidth", 1000):
           print(avg_param.to_latex(escape=False,
                                    column_format='cccc',
                                    caption=('Experimental results')))
       avg_param
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     #+begin_example
       \begin{table}
       \centering
       \caption{Experimental results}
       \begin{tabular}{cccc}
       \toprule
             & artifact &                                                                             clean &                                                                                  dirty \\
       \makecell{type of\\processing} & fit &                                                                                   &                                                                                        \\
       \midrule
       no correction & 1 &                                                             $\tau_D=39.7, N=14.3$ &                                                                 $\tau_D=7355.0, N=4.7$ \\
             & 2 &  \makecell{$\tau_D^{fast}=9.5, N\cdot A=4.9$\\$\tau_D^{slow}=69.8, N\cdot A=8.6$} &   \makecell{$\tau_D^{fast}=78.3, N\cdot A=0.7$\\$\tau_D^{slow}=11944.6, N\cdot A=3.5$} \\
       0cd20 & 1 &                                                             $\tau_D=39.6, N=14.3$ &                                                                  $\tau_D=71.3, N=21.7$ \\
             & 2 &  \makecell{$\tau_D^{fast}=8.9, N\cdot A=4.6$\\$\tau_D^{slow}=67.5, N\cdot A=8.8$} &   \makecell{$\tau_D^{fast}=38.8, N\cdot A=15.5$\\$\tau_D^{slow}=5823.0, N\cdot A=3.9$} \\
       34a6d & 1 &                                                             $\tau_D=39.7, N=14.3$ &                                                                  $\tau_D=78.9, N=22.5$ \\
             & 2 &  \makecell{$\tau_D^{fast}=9.4, N\cdot A=4.8$\\$\tau_D^{slow}=69.6, N\cdot A=8.6$} &  \makecell{$\tau_D^{fast}=41.9, N\cdot A=14.2$\\$\tau_D^{slow}=22526.1, N\cdot A=4.6$} \\
       \bottomrule
       \end{tabular}
       \end{table}
     #+end_example
     |                                | artifact | clean                                             | dirty                                             |
|--------------------------------+----------+---------------------------------------------------+---------------------------------------------------|
| \makecell{type of\\processing} | fit      |                                                   |                                                   |
| no correction                  | 1        | $\tau_D=39.7, N=14.3$                             | $\tau_D=7355.0, N=4.7$                            |
|                                | 2        | \makecell{$\tau_D^{fast}=9.5, N\cdot A=4.9$\\$... | \makecell{$\tau_D^{fast}=78.3, N\cdot A=0.7$\\... |
| 0cd20                          | 1        | $\tau_D=39.6, N=14.3$                             | $\tau_D=71.3, N=21.7$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=8.9, N\cdot A=4.6$\\$... | \makecell{$\tau_D^{fast}=38.8, N\cdot A=15.5$\... |
| 34a6d                          | 1        | $\tau_D=39.7, N=14.3$                             | $\tau_D=78.9, N=22.5$                             |
|                                | 2        | \makecell{$\tau_D^{fast}=9.4, N\cdot A=4.8$\\$... | \makecell{$\tau_D^{fast}=41.9, N\cdot A=14.2$\... |
     :END:

     #+BEGIN_SRC jupyter-python

       def sort_fit_simple(param_ls):
           nfcs = list(param_ls)[-1]
           array = np.array(list(param_ls)[:-1]).reshape((2, 2))
           # sort by transit times
           array = array[:, array[0, :].argsort()]
           A_fast = float(array[1, 0])
           A_slow = float(array[1, 1])
           N_fast = A_fast * float(nfcs)
           N_slow = A_slow * float(nfcs)
           t_fast = float(array[0, 0])
           t_slow = float(array[0, 1])
           if np.isnan(t_slow):
               # 1-component fit
               out = t_fast, N_fast, pd.NA, pd.NA
           # 2-component fits
           elif f'{A_fast:.0%}' == '100%':
               out = t_fast, N_fast, pd.NA, pd.NA
           elif f'{A_slow:.0%}' == '100%':
               out = t_slow, N_slow, pd.NA, pd.NA
           else:
               out = t_fast, N_fast, t_slow, N_slow
           return out

       all_param = pd.concat([clean_noc_1comp, clean_noc_2comp,
                              dirty_noc_1comp, dirty_noc_2comp,
                              dirty_0cd20_1comp, dirty_0cd20_2comp,
                              dirty_19e3e_1comp, dirty_19e3e_2comp,
                              dirty_34766_1comp, dirty_34766_2comp,
                              dirty_34a6d_1comp, dirty_34a6d_2comp,
                              dirty_484af_1comp, dirty_484af_2comp,
                              dirty_714af_1comp, dirty_714af_2comp,
                              dirty_c1204_1comp, dirty_c1204_2comp,
                              dirty_fe81d_1comp, dirty_fe81d_2comp,
                              dirty_ff67b_1comp, dirty_ff67b_2comp,
                              clean_0cd20_1comp, clean_0cd20_2comp,
                              clean_19e3e_1comp, clean_19e3e_2comp,
                              clean_34766_1comp, clean_34766_2comp,
                              clean_34a6d_1comp, clean_34a6d_2comp,
                              clean_484af_1comp, clean_484af_2comp,
                              clean_714af_1comp, clean_714af_2comp,
                              clean_c1204_1comp, clean_c1204_2comp,
                              clean_fe81d_1comp, clean_fe81d_2comp,
                              clean_ff67b_1comp, clean_ff67b_2comp])
       all_param = all_param.reset_index()
       (all_param['t_fast'], all_param['N_fast'], all_param['t_slow'],
        all_param['N_slow']) = zip(*all_param[['txy1', 'txy2', 'A1', 'A2', 'N (FCS)']].apply(
            lambda x: sort_fit_simple(x), axis=1))
       all_param = all_param[['index', 'Diff_species', 'processing', 'artifact',
                              't_fast', 'N_fast', 't_slow', 'N_slow']]
       all_param = all_param.loc[((all_param['Diff_species'] == 1) & (all_param['artifact'] == 'clean')) | ((all_param['Diff_species'] == 2) & (all_param['artifact'] == 'dirty'))]
       pub_param = all_param.loc[(all_param['processing'] == 'No correction') | (all_param['processing'] == '0cd20') | (all_param['processing'] == '34a6d')]
       pub_param = pub_param.replace(['clean'], '424 traces of\nAlexaFluor488\n(no artifacts)\nN (FCS) from\n1 species fit')
       pub_param = pub_param.replace(['dirty'], '440 traces of\nAF488 + DiO LUVs\n(peak artifacts)\nN (FCS) $\\cdot$ A from\nfast sp. of 2 sp. fit')
       pub_param = pub_param.replace(['0cd20'], 'large model (200 MB),\n6 levels,\npool size=4,\nscaler=quantile\ntransform (Gaussian pdf)')
       pub_param = pub_param.replace(['34a6d'], 'small model (7 MB),\n3 levels,\npool size=4,\nscaler=l2')
       g = sns.catplot(data=pub_param,
                       y='t_fast',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='t_fast',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores transit times',
                      size=25)

       g._legend.set_title('')
       new_labels = ['424 traces of\nAlexaFluor488\n(no artifacts)\n$\\tau_D$ from\n1 species fit',
                     '440 traces of\nAF488 + DiO LUVs\n(peak artifacts)\n$\\tau_D$ from\nfast sp. of 2 sp. fit']
       for t, l in zip(g._legend.texts, new_labels):
           t.set_text(l)
       plt.setp(g.axes, yscale='log', xlabel='',
                ylabel=r'log transit time $\tau_{D}$ $[ms]$')

       g.tight_layout()
       plot2_file = 'analysis2_biological_0cd20+34a6d_transit-times'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')

       g = sns.catplot(data=pub_param,
                       y='N_fast',
                       x='processing',
                       hue='artifact',
                       sharey=True,
                       height=10,
                       aspect=1,
                       legend_out=True,
                       kind='boxen',
                       showfliers=False)
       g.map_dataframe(sns.stripplot,
             y='N_fast',
             x='processing',
             hue='artifact',
             dodge=True,
             palette=sns.color_palette(['0.3']),
             size=4,
             jitter=0.2)
       g.fig.suptitle('Simulation → prediction → correction pipeline\nsuccessfully restores particle number',
                      size=25)
       g._legend.set_title('')
       plt.setp(g.axes, xlabel='',
                ylabel=r'particle number $N$ $[fl^{-1}]$')

       g.tight_layout()
       plot2_file = 'analysis2_biological_0cd20+34a6d_particle-number'
       plt.savefig(f'{plot2_file}.pdf', bbox_inches='tight', dpi=300)
       os.system(f'pdf2svg {plot2_file}.pdf {plot2_file}.svg')
       plt.close('all')

     #+END_SRC

     #+RESULTS:

     #+begin_src jupyter-python
       N_param = all_param.pivot_table(values='N_fast',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])

       t_param = all_param.pivot_table(values='t_fast',
                                       index='index',
                                       columns=['processing', 'artifact', 'Diff_species'])
       t_param = t_param * 1000
       display(N_param.describe().T)
       display(t_param.describe().T)
       display(t_param.median(axis=0))
       display(N_param.median(axis=0))
     #+end_src

     #+RESULTS:
     :RESULTS:
     |               |          |              | count | mean      | std      | min       | 25%       | 50%       | 75%       | max       |
|---------------+----------+--------------+-------+-----------+----------+-----------+-----------+-----------+-----------+-----------|
| processing    | artifact | Diff_species |       |           |          |           |           |           |           |           |
| 0cd20         | clean    | 1            | 424.0 | 14.335000 | 0.263291 | 13.412392 | 14.205747 | 14.341568 | 14.505898 | 14.988332 |
|               | dirty    | 2            | 440.0 | 15.106186 | 1.484036 | 6.267150  | 14.334271 | 15.248202 | 16.039287 | 18.110889 |
| 19e3e         | clean    | 1            | 424.0 | 14.329986 | 0.263853 | 13.367317 | 14.201544 | 14.336272 | 14.511038 | 14.931337 |
|               | dirty    | 2            | 440.0 | 13.270444 | 3.181698 | 0.562121  | 11.573624 | 13.826313 | 15.704750 | 18.581205 |
| 34766         | clean    | 1            | 424.0 | 14.684973 | 0.276662 | 13.720920 | 14.551659 | 14.702547 | 14.869845 | 15.347210 |
|               | dirty    | 2            | 440.0 | 15.267823 | 2.476381 | 6.346636  | 13.704650 | 15.732460 | 17.068360 | 19.961155 |
| 34a6d         | clean    | 1            | 424.0 | 14.325905 | 0.264438 | 13.365160 | 14.194973 | 14.335075 | 14.510599 | 14.933380 |
|               | dirty    | 2            | 440.0 | 13.641062 | 2.740812 | 1.417894  | 12.297284 | 14.302934 | 15.593493 | 17.885668 |
| 484af         | clean    | 1            | 424.0 | 14.317763 | 0.263824 | 13.365161 | 14.188180 | 14.325842 | 14.499389 | 14.919546 |
|               | dirty    | 2            | 440.0 | 12.784654 | 3.023495 | 1.591405  | 10.908164 | 13.373178 | 15.029049 | 18.453017 |
| 714af         | clean    | 1            | 424.0 | 14.318594 | 0.263337 | 13.365161 | 14.189044 | 14.325842 | 14.497586 | 14.919546 |
|               | dirty    | 2            | 440.0 | 12.233933 | 2.490236 | 5.295190  | 10.570730 | 12.420635 | 14.066820 | 17.968677 |
| No correction | clean    | 1            | 424.0 | 14.324938 | 0.264089 | 13.369703 | 14.194097 | 14.331944 | 14.503913 | 14.925030 |
|               | dirty    | 2            | 440.0 | 1.151438  | 0.843793 | 0.112582  | 0.518223  | 0.978458  | 1.540923  | 5.476162  |
| c1204         | clean    | 1            | 424.0 | 15.254311 | 0.321478 | 13.987100 | 15.077046 | 15.262632 | 15.475146 | 16.260415 |
|               | dirty    | 2            | 440.0 | 15.532688 | 3.448340 | 1.815959  | 13.639535 | 15.912205 | 18.127480 | 21.748767 |
| fe81d         | clean    | 1            | 424.0 | 14.319104 | 0.263526 | 13.365161 | 14.189106 | 14.326219 | 14.499389 | 14.919546 |
|               | dirty    | 2            | 440.0 | 13.077269 | 3.152211 | 0.536799  | 11.056025 | 13.689452 | 15.387298 | 19.102249 |
| ff67b         | clean    | 1            | 424.0 | 14.319636 | 0.263558 | 13.365161 | 14.189298 | 14.326219 | 14.499389 | 14.919546 |
|               | dirty    | 2            | 440.0 | 12.894021 | 2.446790 | 4.838165  | 11.518550 | 13.089802 | 14.484227 | 18.392188 |
     |               |          |              | count | mean       | std        | min       | 25%       | 50%       | 75%        | max         |
|---------------+----------+--------------+-------+------------+------------+-----------+-----------+-----------+------------+-------------|
| processing    | artifact | Diff_species |       |            |            |           |           |           |            |             |
| 0cd20         | clean    | 1            | 424.0 | 39.574374  | 1.040061   | 37.190978 | 38.879728 | 39.575746 | 40.279227  | 42.984704   |
|               | dirty    | 2            | 440.0 | 38.933931  | 5.459816   | 21.356080 | 35.228893 | 38.762520 | 42.262441  | 62.131261   |
| 19e3e         | clean    | 1            | 424.0 | 39.656947  | 1.047036   | 37.102746 | 38.934719 | 39.568778 | 40.416838  | 42.501109   |
|               | dirty    | 2            | 440.0 | 41.351740  | 4.525924   | 19.027233 | 38.362287 | 41.177209 | 43.854646  | 60.151240   |
| 34766         | clean    | 1            | 424.0 | 35.077446  | 1.109175   | 32.086412 | 34.355154 | 35.067658 | 35.736697  | 38.864156   |
|               | dirty    | 2            | 440.0 | 38.910032  | 3.349258   | 27.709990 | 36.625985 | 38.713203 | 41.009242  | 49.822679   |
| 34a6d         | clean    | 1            | 424.0 | 39.707795  | 1.038806   | 36.985999 | 39.012984 | 39.667568 | 40.457557  | 42.803298   |
|               | dirty    | 2            | 440.0 | 41.654939  | 4.707523   | 30.986888 | 38.312301 | 41.267814 | 44.652582  | 57.155144   |
| 484af         | clean    | 1            | 424.0 | 39.854861  | 1.040952   | 37.153441 | 39.141726 | 39.854056 | 40.582409  | 42.744448   |
|               | dirty    | 2            | 440.0 | 41.036124  | 4.307502   | 31.922451 | 38.063892 | 40.605601 | 43.505466  | 63.739400   |
| 714af         | clean    | 1            | 424.0 | 39.838266  | 1.041757   | 37.153441 | 39.107415 | 39.835832 | 40.571805  | 42.696864   |
|               | dirty    | 2            | 440.0 | 41.791645  | 4.068318   | 31.775699 | 38.784115 | 41.430208 | 44.084046  | 55.334179   |
| No correction | clean    | 1            | 424.0 | 39.726486  | 1.037956   | 37.049340 | 39.010144 | 39.678008 | 40.444667  | 42.680513   |
|               | dirty    | 2            | 440.0 | 373.284240 | 938.964455 | 9.128891  | 44.671731 | 69.978078 | 149.833895 | 9657.429422 |
| c1204         | clean    | 1            | 424.0 | 29.247641  | 1.225078   | 25.901046 | 28.399698 | 29.177928 | 30.113028  | 32.740869   |
|               | dirty    | 2            | 440.0 | 35.503411  | 2.690742   | 29.246945 | 33.580404 | 35.278166 | 36.865166  | 44.796158   |
| fe81d         | clean    | 1            | 424.0 | 39.828821  | 1.044278   | 37.153441 | 39.089567 | 39.830813 | 40.555985  | 42.744448   |
|               | dirty    | 2            | 440.0 | 40.766428  | 6.403163   | 12.890876 | 37.417914 | 40.439757 | 43.275102  | 84.641627   |
| ff67b         | clean    | 1            | 424.0 | 39.830343  | 1.042279   | 37.153441 | 39.087859 | 39.803435 | 40.555985  | 42.744448   |
|               | dirty    | 2            | 440.0 | 41.757214  | 4.040506   | 32.434107 | 38.893139 | 41.451285 | 44.293295  | 57.788748   |
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1               39.575746
                      dirty     2               38.762520
       19e3e          clean     1               39.568778
                      dirty     2               41.177209
       34766          clean     1               35.067658
                      dirty     2               38.713203
       34a6d          clean     1               39.667568
                      dirty     2               41.267814
       484af          clean     1               39.854056
                      dirty     2               40.605601
       714af          clean     1               39.835832
                      dirty     2               41.430208
       No correction  clean     1               39.678008
                      dirty     2               69.978078
       c1204          clean     1               29.177928
                      dirty     2               35.278166
       fe81d          clean     1               39.830813
                      dirty     2               40.439757
       ff67b          clean     1               39.803435
                      dirty     2               41.451285
       dtype: float64
     #+end_example
     #+begin_example
       processing     artifact  Diff_species
       0cd20          clean     1               14.341568
                      dirty     2               15.248202
       19e3e          clean     1               14.336272
                      dirty     2               13.826313
       34766          clean     1               14.702547
                      dirty     2               15.732460
       34a6d          clean     1               14.335075
                      dirty     2               14.302934
       484af          clean     1               14.325842
                      dirty     2               13.373178
       714af          clean     1               14.325842
                      dirty     2               12.420635
       No correction  clean     1               14.331944
                      dirty     2                0.978458
       c1204          clean     1               15.262632
                      dirty     2               15.912205
       fe81d          clean     1               14.326219
                      dirty     2               13.689452
       ff67b          clean     1               14.326219
                      dirty     2               13.089802
       dtype: float64
     #+end_example
     :END:

     #+BEGIN_SRC jupyter-python
g = sns.catplot(data=all_param,
                y='A',
                x='artifact-correction',
                hue='fitted species (A)',
                sharey=True,
                height=5,
                aspect=2,
                legend_out=True,
                kind='boxen',
                showfliers=False)
g.map_dataframe(sns.stripplot,
      y='A',
      x='artifact-correction',
      hue='fitted species (A)',
      dodge=True,
      palette=sns.color_palette(['0.3']),
      size=4,
      jitter=0.2)
g.tight_layout()
g.fig.suptitle('Fraction sizes of AlexaFluor488 (clean) vs\nAlexaFluor488 + Dio LUVs (dirty) with different correction methods',
               y=1.08, size=20)
for axes in g.axes.flat:
     _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=45)
plt.setp(g.axes, xlabel='biological sample - correction method',
         ylabel='relative fraction size')
plt.show()
     #+END_SRC

*** the trained models

   10. all metrics after 100th epoch with hparams
       | run                                | val_auc | val_f1 0.5 | val_prec 0.5 | val_recall 0.5 | model size | hp_batch_size | hp_first_filters | hp_input_size       | hp_lr_power |        hp_lr_start | hp_n_levels | hp_pool_size | hp_scaler |
       |------------------------------------+---------+------------+--------------+----------------+------------+---------------+------------------+---------------------+-------------+--------------------+-------------+--------------+-----------|
       | 484af471c61943fa90e5f78e78a229f0   |  0.9814 |     0.9187 |       0.9091 |         0.9285 | 275 MB     |            26 |               44 | 16384 (here: 14000) |           1 | 0.0136170138242663 |           7 |            2 | standard  |
       | 0cd2023eeaf745aca0d3e8ad5e1fc653   |  0.9818 |     0.9069 |       0.8955 |         0.9185 | 200 MB     |            15 |               23 | 16384 (here: 14000) |           7 | 0.0305060808685107 |           6 |            4 | quant_g   |
       | fe81d71c52404ed790b3a32051258da9   |  0.9849 |     0.9260 |       0.9184 |         0.9338 | 186 MB     |            20 |               78 | 16384 (here: 14000) |           4 | 0.0584071108418767 |           4 |            4 | standard  |
       | ff67be0b68e540a9a29a36a2d0c7a5be + |  0.9859 |     0.9298 |       0.9230 |         0.9367 | 14 MB      |            28 |                6 | 16384 (here: 14000) |           1 | 0.0553313915596308 |           5 |            4 | minmax    |
       | 19e3e786e1bc4e2b93856f5dc9de8216   |  0.9595 |     0.8911 |       0.8983 |         0.8839 | 172 MB     |            20 |              128 | 16384 (here: 14000) |           1 |  0.043549707353273 |           3 |            4 | standard  |
       | 347669d050f344ad9fb9e480c814f727 + |  0.9848 |     0.9246 |       0.9254 |         0.9238 | 73 MB      |            10 |               16 | 8192 (here: 14000)  |           1 | 0.0627676336651573 |           5 |            4 | robust    |
       | c1204e3a8a1e4c40a35b5b7b1922d1ce   |  0.9858 |     0.9207 |       0.9179 |         0.9234 | 312 MB     |            14 |               16 | 16384 (here: 14000) |           5 | 0.0192390310290551 |           9 |            2 | robust    |
       | 714af8cd12c1441eac4ca980e8c20070 + |  0.9843 |     0.9304 |       0.9257 |         0.9352 | 234 MB     |             9 |               64 | 4096 (here: 14000)  |           1 | 0.0100697459464075 |           5 |            4 | maxabs    |
       | 34a6d207ac594035b1009c330fb67a65 + |  0.9652 |     0.8613 |       0.8598 |         0.8629 | 7 MB       |            17 |               16 | 16384 (here: 14000) |           5 | 0.0101590069352232 |           3 |            4 | l2        |
