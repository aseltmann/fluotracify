#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:3
#+HTML_HEAD_EXTRA: <style type="text/css">.example {background-color: #FBFBBF;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-emacs-lisp {background-color: #F7ECFB;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-sh {background-color: #F0FBE9;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-tmux {background-color: #E1EED8;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-python {background-color: #E6EDF4;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-jupyter-python {background-color: #FAEAE1;}</style>

* README
** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks. It also contains notes taken
     during the process of setting up this workflow for reproducible research.
   - This file contains explanations of how things are organized, of the
     workflow for doing experiments, changes made to the code, and the observed
     behavior in the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Therefore: if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch of the repository. The /master/ branch is clean from any results, it
     contains only source code and the analysis.
   - This project is my take on [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]]. The idea was postulated in
     a blog post in 2006:
     #+BEGIN_QUOTE
     ... there is a URL to a laboratory notebook that is freely available and
     indexed on common search engines. It does not necessarily have to look like
     a paper notebook but it is essential that all of the information available
     to the researchers to make their conclusions is equally available to the
     rest of the world ---Jean-Claude Bradley
     #+END_QUOTE
   - Proposal on how to deal with truly private data (e.g. notes from a
     confidential meeting with a colleague), which might otherwise be noted in a
     normal Lab notebook: do not include them here. Only notes relevant to the
     current project should be taken
** Code block languages used in this document

   #+BEGIN_SRC sh
     # This is a sh block for shell / bash scripting. In the context of this file,
     # these blocks are mainly used for operations on my local computer.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light green colour (#F0FBE9)
   #+END_SRC

   #+BEGIN_SRC tmux
     # This block can open and access tmux sessions, used for shell scripting on
     # remote computing clusters.
     # In the LabBook.html rendering of this document, these blocks will have a
     # distinct light green colour (#E1EED8)
   #+END_SRC

   #+BEGIN_SRC python
     # This is a python block. In the context of this file, it is seldomly used
     # (only for examplary scripts.)
     # In the LabBook.html rendering of this document, these blocks will have a
     # light blue colour (#E6EDF4)
   #+END_SRC

   #+BEGIN_SRC jupyter-python :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
     # This is a jupyter-python block. The code is sent to a jupyter kernel running
     # on a remote high performance computing cluster. Most of my jupyter code is
     # executed this way.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light orange colour (#FAEAE1)
   #+END_SRC

   #+BEGIN_SRC emacs-lisp
     ;; This is a emacs-lisp block, the language used to customize Emacs, which is
     ;; sometimes necessary, since the reproducible workflow of this LabBook is
     ;; tightly integrated with Emacs and org-mode.
     ;; In the LabBook.html rendering of this document, these blocks will have a
     ;; light violet colour (#F7ECFB)
   #+END_SRC

   #+begin_example
     This is a literal example block. It can be used very flexibly - in the context
     of this document the output of most code blocks is displayed this way.
     In the LabBook.html rendering of this document, these blocks will have a light
     yellow colour (#FBFBBF)
   #+end_example

** Experiments workflow:
   1) Create a new branch from =master=
   2) Print out the git log from the latest commit and the metadata
   3) Call the analysis scripts, follow the principles outlined in
      [[* Organization of code]]
   4) All machine learning runs are saved in =data/mlruns=, all other data in
      =data/#experiment-name=
   5) Add a "** #experiment-name" section to this file under [[* Data]]
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote =data= branch
** Example for experimental setup procedure

*** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

** tools used (notes)
*** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
*** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
*** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
*** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

* Template for data entry and setup notes:
** exp-#date-#title
*** git:

    #+begin_src sh
    git log -1
    #+end_src

*** System Metadata:

    #+NAME: jp-metadata
    #+BEGIN_SRC jupyter-python :var _long="true"
      import os
      import pprint

      ramlist = os.popen('free -th').readlines()[-1].split()[1:]

      print('No of CPUs in system:', os.cpu_count())
      print('No of CPUs the current process can use:',
            len(os.sched_getaffinity(0)))
      print('load average:', os.getloadavg())
      print('os.uname(): ', os.uname())
      print('PID of process:', os.getpid())
      print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
          ramlist[0], ramlist[1], ramlist[2]))

      !echo the current directory: $PWD
      !echo My disk usage:
      !df -h
      if _long:
          %conda list
          pprint.pprint(dict(os.environ), sort_dicts=False)

    #+END_SRC

*** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:

    #+NAME: setup-tmux
    #+BEGIN_SRC sh :session local
    rm ~/.tmux-local-socket-remote-machine
    REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
    echo $REMOTE_SOCKET
    ssh ara -tfN \
        -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
    #+END_SRC

    #+RESULTS: setup-tmux
    | rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
    | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
    | /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
    | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

*** SSH tunneling
    :PROPERTIES:
    :CUSTOM_ID: ssh-tunneling
    :END:

    Different applications can be run on the remote compute node. If I want to
    access them at the local machine, and open them with the browser, I use this
    tunneling script.

    #+NAME: ssh-tunnel
    #+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
    ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
    #+END_SRC

    #+RESULTS: ssh-tunnel
    | sh-5.0$           | sh-5.0$   | ye53nis@ara-login01.rz.uni-jena.de's | password:        |     |      |    |        |      |    |      |      |
    | ye53nis@node001's | password: |                                      |                  |     |      |    |        |      |    |      |      |
    | Access            | denied    | by                                   | pam_slurm_adopt: | you | have | no | active | jobs | on | this | node |
    | Authentication    | failed.   |                                      |                  |     |      |    |        |      |    |      |      |
    | Connection        | to        | ara-login01.rz.uni-jena.de           | closed.          |     |      |    |        |      |    |      |      |

    Apps I use that way:
    - Jupyter lab for running Python 3-Kernels
    - TensorBoard
    - Mlflow ui

*** jupyter scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-jp
    :END:

    Starting a jupyter instance on a server where the necessary libraries are
    installed is easy using this script:

    #+NAME: jpt-tmux
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
    conda activate tf-nightly
    export PORT=9999
    export XDG_RUNTIME_DIR=''
    export XDG_RUNTIME_DIR=""
    jupyter lab --no-browser --port=$PORT
    #+END_SRC

    On the compute node of the HPC, the users' environment is managed through
    module files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements
    are needed because of a jupyter bug which did not let it start. Right now,
    =ob-tmux= does not support a =:var= header like normal =org-babel= does. So
    the =$port= variable has to be set here in the template.

    Now this port has to be tunnelled on our local computer (See
    [[#ssh-tunneling]]). While the tmux session above keeps running, no matter if
    Emacs is running or not, this following ssh tunnel needs to be active
    locally to connect to the notebook. If you close Emacs, it would need to be
    reestablished

** Setup notes
*** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

*** =emacs-jupyter= Setup

    =Emacs-jupyter= aims to be an API for a lot of functionalities of the
    =jupyter= project. The documentation can be found on [[https://github.com/dzop/emacs-jupyter][GitHub]].

    1. For the *whole document*: connect ot a running jupyter instance
       1. =M-x jupyter-server-list-kernels=
          1. set server URL, e.g. =http://localhost:8889=
          2. set websocket URL, e.g. =http://localhost:8889=
       2. two possibilities
          1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
          2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
             *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    2. In the *subtree* where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. customize the output folder using the following org-mode variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/plots
    3. For each *individual block*, the following customizations might be useful
       1. jupyter kernels can return multiple kinds of rich output (images,
          html, ...) or scalar data (plain text, numbers, lists, ...). To force
          a plain output, use =:results scalar=. To show the output in the
          minibuffer only, use =:results silent=
       2. to change the priority of different rich outputs, use =:display=
          header argument, e.g. =:display text/plain text/html= prioritizes
          plain text over html. All supported mimetypes in default order:
          1. text/org
          2. image/svg+xml, image/jpeg, image/png
          3. text/html
          4. text/markdown
          5. text/latex
          6. text/plain
       3. We can set jupyter to output pandas DataFrames as org tables
          automatically using the source block header argument =:pandoc t=
       4. useful keybindings
          - =M-i= to open the documentation for wherever your pointer is (like
            pressing =Shift-TAB= in Jupyter notebooks)
          - =C-c C-i= to interrupt the kernel, =C-c C-r= to restart the kernel

* Organization of git
** remote/origin/master branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *master* in an *#experiment-name* branch, ### meaning some meaningful
    descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/#experiment-name**, except
    machine learning-specific data and metadata from `mlflow` runs, which are
    saved under **data/mlruns** (this allows easily comparing machine learning
    runs with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *#experiment-name* branches are merged here. Afterwards the original
    branch is deleted and on the data branch there is a *Git tag* which shows
    the merge commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

** Git TAGs
*** Stable versions:
*** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
* Organization of code
** scripts:
** src/
*** fluotracify/
**** imports/
**** simulations/
**** training/
**** applications/
**** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

*** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

* Changes in this repository (without "* Data" in this file)
** Changes in LabBook.org (without "* Data")
*** 2020-11-04
    - update "jupyter scripts" in  [[* Template for data entry and setup notes:]]
      for new conda environment on server (now =conda activate tf-nightly=)
*** 2020-05-31
    - extend general documentation in README
    - Add code block examples
    - extend documentation on experiment workflow
    - move setup notes from README to "Template for data entry and setup notes"
    - remove emacs-lisp code for custom tmux block functions (not relevant
      enough)
    - change named "jpt-tmux" from starting a jupyter notebook to starting
      jupyter lab. Load a conda environment instead of using Lmod's =module
      load=
*** 2020-05-07
    - extend documentation on git model
    - extend documentation on jupyter setup
*** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
*** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
** Changes in src/fluotracify

* DEVELOPMENT TESTING (don't merge in master)
  :LOGBOOK:
  CLOCK: [2020-04-23 Do 13:35]--[2020-04-23 Do 14:57] =>  1:22
  :END:
** configured custom yasnippets,
   - check =yas-describe-tables= for current snippets
   - use =C-c & C-n= to create new snippet (its put in =.emacs.d/snippets/=)

#+BEGIN_SRC sh :session local
  ls -Rl ~/.emacs.d/snippets/
#+END_SRC

#+RESULTS:
| /home/lex/.emacs.d/snippets/:         |     |    |       |                       |
| total                                 |     |    |       |                       |
| drwxr-xr-x                            | Apr | 23 | 15:23 | org-mode              |
| /home/lex/.emacs.d/snippets/org-mode: |     |    |       |                       |
| total                                 |     |    |       |                       |
| -rw-r--r--                            | Apr | 23 | 14:32 | jupyter-python-block  |
| -rw-r--r--                            | Apr | 23 | 14:35 | jupyter-python-header |
| -rw-r--r--                            | Apr | 23 | 15:23 | lmod-srun             |
| -rw-r--r--                            | Apr | 23 | 14:53 | src2                  |
| -rw-r--r--                            | Apr | 23 | 15:00 | tmux                  |

** fix hardlinks of org-files outside =Dokumente/org=
#+BEGIN_SRC sh :session local :results verbatim
  cd Dokumente/org/linkedfiles
  ls -li
  find / -samefile LabBook.org
#+END_SRC

#+RESULTS:
#+begin_example
total 84
4992947 -rw-r--r-- 2 lex lex 11786 Apr 23 14:14 LabBook.org
 404446 -rw-r--r-- 1 lex lex 21544 Apr  4 22:53 LabBook.org~
 404411 -rw-r--r-- 2 lex lex 23355 Apr 20 01:44 lexbn-source.org
4328628 -rw-r--r-- 1 lex lex 20829 Apr 19 14:37 lexbn-source.org~

/home/lex/Dokumente/org/linkedfiles/LabBook.org
/home/lex/Programme/drmed-git/LabBook.org
#+end_example

** connect LabBook to HPC with jupyter etc
   :LOGBOOK:
   CLOCK: [2020-04-23 Do 17:30]--[2020-04-23 Do 17:46] =>  0:16
   CLOCK: [2020-04-23 Do 16:05]--[2020-04-23 Do 16:38] =>  0:33
   CLOCK: [2020-04-23 Do 15:20]--[2020-04-23 Do 15:50] =>  0:30
   CLOCK: [2020-04-23 Do 14:57]--[2020-04-23 Do 15:07] =>  0:10
   :END:
*** connect to compute node
#+BEGIN_SRC sh :session org-ssh :results verbatim
  ssh ara
#+END_SRC

#+RESULTS:
: ssh: Could not resolve hostname ara: Name or service not known

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    48 | mix   | node[003,007-008,023-026,029,031,033-038,040,053,063-064,066-072,075-078,083-085,090-094,117-119,121-125,131,133]                                                                                 |
| b_standard* | up    | 8-08:00:00 |    82 | alloc | node[002,004-006,009-022,027-028,030,032,039,041-045,047-052,054-062,065,073-074,079-082,086-089,095-116,120,126,132,134-136]                                                                     |
| b_standard* | up    | 8-08:00:00 |     1 | idle  | node046                                                                                                                                                                                           |
| gpu_test    | up    |    1:00:00 |     1 | idle  | node127                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | idle  | node130                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     4 | mix   | node[137-140]                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | idle  | node141                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    68 | mix   | node[144,151,162-163,167,169,171-172,177-181,186,191,196-198,200,203-209,212-214,216,218,221-222,224-231,233,235-237,241-249,255,257,259-260,265-268,297,303-304,309-310,315]                     |
| s_standard  | up    | 8-08:00:00 |    83 | alloc | node[142-143,145-150,152-161,164-166,168,170,173-176,182-185,187-190,192-195,199,201-202,210-211,215,217,219-220,223,232,234,238-240,250-254,256,258,261-264,293-296,298-302,305-308,311-314,316] |
| s_fat       | up    | 8-08:00:00 |     3 | mix   | node[269-270,272]                                                                                                                                                                                 |
| s_fat       | up    | 8-08:00:00 |     1 | alloc | node271                                                                                                                                                                                           |

#+BEGIN_SRC sh :session org-ssh
  tmux ls
#+END_SRC

#+RESULTS:
|       0: | 1 | windows | (created | Mon | Apr | 13 | 19:54:44 | 2020 |
| ob-tmux: | 1 | windows | (created | Mon | Apr | 13 | 19:55:21 | 2020 |


#+CALL:setup-tmux[:session local]

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  echo test
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ echo test
  test
  [ye53nis@login01 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 -
  -pty bash
  [ye53nis@node018 ~]$
#+end_example

*** start and connect to jupyter
:PROPERTIES:
:header-args:jupyter-python: :session /jpy:localhost#8889:2912b27f-1dbe-4a8e-9c59-6cc02f5434cf
:END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export PORT=8889
#+END_SRC


#+CALL: jpt-tmux[:session tmux]

#+RESULTS:
#+begin_example
[ye53nis@node007 drmed-git]$ export PORT=8889
[ye53nis@node007 drmed-git]$ module load tools/python/3.7
[ye53nis@node007 drmed-git]$ export XDG_RUNTIME_DIR=''
[ye53nis@node007 drmed-git]$ export XDG_RUNTIME_DIR=""
[ye53nis@node007 drmed-git]$ jupyter notebook --no-browser --port=$PORT
[I 16:44:59.413 NotebookApp] Serving notebooks from local directory: /beegfs/ye53nis/drmed-git
[I 16:44:59.413 NotebookApp] The Jupyter Notebook is running at:
[I 16:44:59.413 NotebookApp] http://localhost:8889/?token=552a9cff48203d5a263cb083b80b939dbbc856758df651dd
[I 16:44:59.413 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 16:44:59.425 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-84165-open.html
    Or copy and paste one of these URLs:
        http://localhost:8889/?token=552a9cff48203d5a263cb083b80b939dbbc856758df651dd
#+end_example

#+CALL: jpt-tunnel(port="8889", node="node007")

#+RESULTS:
| Connection        | closed                               | by        |          10.138.225.252 | port    | 22 |     |      |    |       |        |
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |                         |         |    |     |      |    |       |        |
| Warning:          | Permanently                          | added     | 'node007,192.168.193.7' | (ECDSA) | to | the | list | of | known | hosts. |
| ye53nis@node007's | password:                            |           |                         |         |    |     |      |    |       |        |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           2912b27f-1dbe-4a8e-9c59-6cc02f5434cf   2 minutes ago        starting   0
#+end_example

Passing a boolean value to a variable in =org-babel= was not trivial: you have to
use the infamous *single quote '* from emacs-lisp programming to show that the
expression should be returned as written, not evaluated.

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 48
  No of CPUs the current process can use: 48
  load average: (0.08, 0.03, 0.05)
  posix.uname_result(sysname='Linux', nodename='node007', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 92855
  RAM total: 137G, RAM used: 1.3G, RAM free: 120G
  the current directory: /beegfs/ye53nis/drmed-git
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  4.3G   46G   9% /
  devtmpfs              63G     0   63G   0% /dev
  tmpfs                 63G  199M   63G   1% /dev/shm
  tmpfs                 63G   59M   63G   1% /run
  tmpfs                 63G     0   63G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs01-ib:/home        80T   59T   22T  73% /home
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  /dev/sda3            6.0G  441M  5.6G   8% /var
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  5.5G  163G   4% /local
  beegfs_nodev         524T  427T   98T  82% /beegfs
  tmpfs                 13G     0   13G   0% /run/user/67339
#+end_example

** set up mlflow
   :LOGBOOK:
   CLOCK: [2020-04-24 Fr 13:09]--[2020-04-24 Fr 13:52] =>  0:43
   CLOCK: [2020-04-24 Fr 11:07]--[2020-04-24 Fr 11:30] =>  0:23
   CLOCK: [2020-04-23 Do 19:05]--[2020-04-23 Do 19:50] =>  0:45
   CLOCK: [2020-04-23 Do 17:59]--[2020-04-23 Do 18:49] =>  0:50
   CLOCK: [2020-04-23 Do 17:46]--[2020-04-23 Do 17:51] =>  0:05
   :END:
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
   :END:

*** how do I submit mlflow jobs?
- I will need two sessions
  - one *tmux session* for running the jupyter kernel, having a REPL, fast and
    interactive coding. I need tmux bc the connection to the node would break if
    I log out of ssh.
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
      echo tüdelü
    #+END_SRC
  - one *sh ssh session* for sending command line commands. SLURM handles the
    job and outputs files - so it should continue, even if I log out
- alternative solution: tmux windows (*note: after using tmux windows, the
  normal =:session tmux= without window specification doesn't work anymore*)
  - this is window =mlflow= for sending mlflow commands. we have to request some
    computation power by SLURM again
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
      echo pwd
    #+END_SRC
  - this is window =ob1= (name automatically created when you don't specify a
    window name) where our jupyter kernel runs:
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:ob1
      echo testö
    #+END_SRC
**** Failed approaches:
- then jobs are submitted e.g. as bash scripts (this is just an example from the
  wiki):
  #+BEGIN_SRC sh
    #!/bin/bash
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_standard
    #SBATCH --nodes=4
    #SBATCH --ntasks-per-node=36
    #SBATCH --time=1:00
    module purge
    module load tools/python/3.7 mpi/intel/2019-Update5
    srun python intro.py
  #+END_SRC
- test:
  #+NAME: sh-test-script
  #+BEGIN_SRC sh :shebang "#!/bin/bash"
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_test
    #SBATCH --nodes=1
    hostname
  #+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow :noweb yes
  sbatch <<sh-test-script>>
#+END_SRC

  #+BEGIN_SRC sh :session org-ssh :noweb yes :tangle yes
    sbatch <<sh-test-script>>
  #+END_SRC

  #+RESULTS:
  |                                                   |
  | sbatch: error: Unable to open file sh-test-script |

Note: t

**** Note: do it like for jupyter: srun a bash script, then execute mlflow
*** Reading the docs: mlflow
- searched for papers, found [[http://sites.computer.org/debull/A18dec/A18DEC-CD.pdf#page=41][two]] [[https://mlsys.org/Conferences/2019/doc/2019/demo_33.pdf][papers]], but they don't seem very exhaustive.
- took notes [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*<2020-04-16 Do 12:57> =mlflow=][here]]
- shall I keep MLflow files in a folder inside the =data/exp#= folder for each
  experiment or do a central =data/mlflow= folder? → I tend towards the second
  option. MLflow has an environment variable =MLFLOW_EXPERIMENT_NAME= which
  would be the same as =exp#=.
- Inside the folder, should I use "normal" files or a database for saving stuff?
  → I tend towards normal files, since I have no experiments with databases..
- MLflow Tracking Service API might be useful for accessing the results from
  inside org documents.

*** Reading Barredo Arrieta et al: Explainable Artificial Intelligence (XIA)
*** Set up git on HPC
    :LOGBOOK:
    CLOCK: [2020-04-24 Fr 14:35]--[2020-04-24 Fr 17:53] =>  3:18
    CLOCK: [2020-04-24 Fr 13:53]--[2020-04-24 Fr 14:15] =>  0:22
    :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
  git clone https://github.com/aseltmann/fluotracify
#+END_SRC

Wanted to git pull my repository on HPC, noticed that it already exists - and
has uncommited changes. Have to sort that out.

Git runs now on HPC, but had to resolve merge conflicts in code → used *Magit*
and especially Ediff. Watched these resources:
- https://www.youtube.com/watch?v=9S2pMZ6U5Tc&t=715s - short resource on smerge
  and ediff
- https://www.youtube.com/watch?v=j-k-lkilbEs - nice intro to magit in general

*** run mlflow test
**** Use a local tmux session:

#+BEGIN_SRC tmux :session local
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ pwd
  /home/lex
#+end_example

#+BEGIN_SRC tmux :session local
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_EXPERIMENT_ID=0.1
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow run .
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run .
  Specify only one of 'experiment-name' or 'experiment-id' options.
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local2
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  mlflow run /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run /home/lex/Programme/drmed-git/
  2020/04/28 01:17:01 INFO mlflow.projects: === Created directory /tmp/tmp_goyesz7
   for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/28 01:17:01 INFO mlflow.projects: === Running command 'source /home/lex/
  Programme/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114
  b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/tra
  in.py 5 0.2 16384 1e-5 10' in run with ID 'c0f7e64fdda64801860e9805948db29d' ===

  /home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709
  c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_interna
  l.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib
  ; see the module's documentation for alternative uses
    import imp
  2.1.0
  train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set003.csv
  train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set002.csv
  test 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tra
  ces_brightclust_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted time
  steps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-28 01:17:15.293658: I tensorflow/core/platform/cpu_feature_guard.cc:142]
   Your CPU supports instructions that this TensorFlow binary was not compiled to
  use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-28 01:17:15.340845: I tensorflow/core/platform/profile_utils/cpu_utils.c
  c:94] CPU Frequency: 2400500000 Hz
  2020-04-28 01:17:15.342222: I tensorflow/compiler/xla/service/service.cc:168] XL
  A service 0x5654fb291850 initialized for platform Host (this does not guarantee
  that XLA will be used). Devices:
  2020-04-28 01:17:15.342284: I tensorflow/compiler/xla/service/service.cc:176]
  StreamExecutor device (0): Host, Default Version
  2020-04-28 01:17:15.344811: I tensorflow/core/common_runtime/process_util.cc:147
  ] Creating new thread pool with default inter op setting: 2. Tune using inter_op
  _parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 65, in <module>
      with mlflow.start_run():
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 122, in
   start_run
      active_run_obj = MlflowClient().get_run(existing_run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 96, in
  get_run
      return self._tracking_client.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client
  .py", line 49, in get_run
      return self.store.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 423, in get_run
      run_info = self._get_run_info(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 442, in _get_run_info
      databricks_pb2.RESOURCE_DOES_NOT_EXIST)
  mlflow.exceptions.MlflowException: Run 'c0f7e64fdda64801860e9805948db29d' not fo
  und
  Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7fb42c4
  f4440>
  Traceback (most recent call last):
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_
  ops.py", line 3462, in __del__
  AttributeError: 'NoneType' object has no attribute 'device'
  2020/04/28 01:17:16 ERROR mlflow.cli: === Run (ID 'c0f7e64fdda64801860e9805948db
  29d') failed ===
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

**** use remote tmux
#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+RESULTS:
| Permission                           | denied,   | please | try    | again. |          |          |      |                |            |                |    |           |
| ye53nis@ara-login01.rz.uni-jena.de's | password: |        |        |        |          |          |      |                |            |                |    |           |
| Last                                 | failed    | login: | Tue    | Apr    |       28 | 11:05:11 | CEST |           2020 | from       | 10.231.181.150 | on | ssh:notty |
| There                                | was       | 1      | failed | login  |  attempt |    since | the  |           last | successful |         login. |    |           |
| Last                                 | login:    | Tue    | Apr    | 28     | 10:57:34 |     2020 | from | 10.231.181.150 |            |                |    |           |

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    26 | mix   | node[005-006,008,014,018,025-026,029,031,039,043,046,063-064,070-071,085-086,108,110,120,126,132,134-136]                                                                                                         |
| b_standard* | up    | 8-08:00:00 |    96 | alloc | node[002-004,009-013,015-017,019-024,027-028,030,032-037,040-042,045,047-062,065,067-068,072-082,084,087-107,109,111-116,119,121-125,131]                                                                         |
| b_standard* | up    | 8-08:00:00 |     9 | idle  | node[007,038,044,066,069,083,117-118,133]                                                                                                                                                                         |
| gpu_test    | up    |    1:00:00 |     1 | mix   | node127                                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | mix   | node130                                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     2 | mix   | node[139-140]                                                                                                                                                                                                     |
| b_fat       | up    | 8-08:00:00 |     2 | alloc | node[137-138]                                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | alloc | node141                                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    50 | mix   | node[146,151,155,157,162-163,167,169,177,183,186,191,196-200,203,219,224-231,233,235,239,241-246,249,255,257,259-260,265-268,297,303,309-310,315]                                                                 |
| s_standard  | up    | 8-08:00:00 |    97 | alloc | node[142-145,147-150,154,156,158-161,164-166,168,170-176,178-182,184-185,187-190,192-195,201-202,204-218,220-223,232,234,236-238,240,247-248,250-254,256,258,261-264,293-296,298-301,304-305,307-308,311-314,316] |
| s_standard  | up    | 8-08:00:00 |     4 | idle  | node[152-153,302,306]                                                                                                                                                                                             |
| s_fat       | up    | 8-08:00:00 |     4 | alloc | node[269-272]                                                                                                                                                                                                     |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    srun -p b_standard --time=7-08:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
: server version is too old for client

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC emacs-lisp
  (setq org-babel-tmux-location "/usr/local/bin/tmux")
#+END_SRC

#+RESULTS:
: /usr/local/bin/tmux


#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load tools/python/3.7
  module load module-git
  mlflow --version
  git --version
  cd drmed-git
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow --version
  git --version
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  mlflow, version 1.7.0
  [ye53nis@node007 ~]$ git --version
  git version 1.8.3.1
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . --no-conda
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow run . --no-conda
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  2020/04/29 13:31:21 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/04/30 17:56:53 INFO mlflow.projects: === Creating conda environment mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 ===
  Collecting package metadata (repodata.json): done
  Solving environment: done

  Downloading and Extracting Packages
  gorilla-0.3.0        | 11 KB     | ################################################################################################################################################################### | 100%
  pyasn1-0.4.8         | 58 KB     | ################################################################################################################################################################### | 100%
  mako-1.1.2           | 63 KB     | ################################################################################################################################################################### | 100%
  flask-1.1.2          | 74 KB     | ################################################################################################################################################################### | 100%
  tensorboard-2.1.0    | 3.3 MB    | ################################################################################################################################################################### | 100%
  google-auth-1.13.1   | 57 KB     | ################################################################################################################################################################### | 100%
  tensorflow-estimator | 251 KB    | ################################################################################################################################################################### | 100%
  ncurses-6.2          | 817 KB    | ################################################################################################################################################################### | 100%
  intel-openmp-2020.0  | 756 KB    | ################################################################################################################################################################### | 100%
  cloudpickle-1.4.0    | 29 KB     | ################################################################################################################################################################### | 100%
  mlflow-1.8.0         | 3.2 MB    | ################################################################################################################################################################### | 100%
  databricks-cli-0.9.1 | 48 KB     | ################################################################################################################################################################### | 100%
  mkl-service-2.3.0    | 218 KB    | ################################################################################################################################################################### | 100%
  markupsafe-1.1.1     | 29 KB     | ################################################################################################################################################################### | 100%
  libstdcxx-ng-9.1.0   | 3.1 MB    | ################################################################################################################################################################### | 100%
  prometheus_client-0. | 42 KB     | ################################################################################################################################################################### | 100%
  appdirs-1.4.3        | 15 KB     | ################################################################################################################################################################### | 100%
  libprotobuf-3.11.4   | 2.9 MB    | ################################################################################################################################################################### | 100%
  protobuf-3.11.4      | 636 KB    | ################################################################################################################################################################### | 100%
  tensorflow-2.1.0     | 4 KB      | ################################################################################################################################################################### | 100%
  configparser-3.7.4   | 43 KB     | ################################################################################################################################################################### | 100%
  opt_einsum-3.1.0     | 54 KB     | ################################################################################################################################################################### | 100%
  oauthlib-3.1.0       | 88 KB     | ################################################################################################################################################################### | 100%
  python-dateutil-2.8. | 224 KB    | ################################################################################################################################################################### | 100%
  werkzeug-1.0.1       | 240 KB    | ################################################################################################################################################################### | 100%
  tabulate-0.8.3       | 39 KB     | ################################################################################################################################################################### | 100%
  jinja2-2.11.2        | 103 KB    | ################################################################################################################################################################### | 100%
  c-ares-1.15.0        | 89 KB     | ################################################################################################################################################################### | 100%
  requests-oauthlib-1. | 22 KB     | ################################################################################################################################################################### | 100%
  docker-pycreds-0.4.0 | 14 KB     | ################################################################################################################################################################### | 100%
  packaging-20.3       | 36 KB     | ################################################################################################################################################################### | 100%
  keras-preprocessing- | 36 KB     | ################################################################################################################################################################### | 100%
  itsdangerous-1.1.0   | 28 KB     | ################################################################################################################################################################### | 100%
  mkl-2020.0           | 128.9 MB  | ################################################################################################################################################################### | 100%
  keras-applications-1 | 33 KB     | ################################################################################################################################################################### | 100%
  scipy-1.4.1          | 14.5 MB   | ################################################################################################################################################################### | 100%
  blinker-1.4          | 22 KB     | ################################################################################################################################################################### | 100%
  google-auth-oauthlib | 20 KB     | ################################################################################################################################################################### | 100%
  wrapt-1.12.1         | 49 KB     | ################################################################################################################################################################### | 100%
  click-7.1.1          | 71 KB     | ################################################################################################################################################################### | 100%
  h5py-2.10.0          | 1.0 MB    | ################################################################################################################################################################### | 100%
  rsa-4.0              | 29 KB     | ################################################################################################################################################################### | 100%
  pyjwt-1.7.1          | 33 KB     | ################################################################################################################################################################### | 100%
  pyasn1-modules-0.2.7 | 63 KB     | ################################################################################################################################################################### | 100%
  google-pasta-0.2.0   | 44 KB     | ################################################################################################################################################################### | 100%
  mkl_fft-1.0.15       | 154 KB    | ################################################################################################################################################################### | 100%
  alembic-1.4.2        | 117 KB    | ################################################################################################################################################################### | 100%
  backports-1.0        | 139 KB    | ################################################################################################################################################################### | 100%
  entrypoints-0.3      | 12 KB     | ################################################################################################################################################################### | 100%
  pyyaml-5.3.1         | 181 KB    | ################################################################################################################################################################### | 100%
  querystring_parser-1 | 10 KB     | ################################################################################################################################################################### | 100%
  prometheus_flask_exp | 15 KB     | ################################################################################################################################################################### | 100%
  cachetools-3.1.1     | 14 KB     | ################################################################################################################################################################### | 100%
  smmap-3.0.2          | 26 KB     | ################################################################################################################################################################### | 100%
  simplejson-3.17.0    | 101 KB    | ################################################################################################################################################################### | 100%
  pyparsing-2.4.6      | 64 KB     | ################################################################################################################################################################### | 100%
  pytz-2019.3          | 231 KB    | ################################################################################################################################################################### | 100%
  sqlalchemy-1.3.13    | 1.4 MB    | ################################################################################################################################################################### | 100%
  absl-py-0.9.0        | 167 KB    | ################################################################################################################################################################### | 100%
  numpy-base-1.18.1    | 4.2 MB    | ################################################################################################################################################################### | 100%
  mkl_random-1.1.0     | 321 KB    | ################################################################################################################################################################### | 100%
  python-editor-1.0.4  | 11 KB     | ################################################################################################################################################################### | 100%
  gunicorn-20.0.4      | 123 KB    | ################################################################################################################################################################### | 100%
  tensorflow-base-2.1. | 95.2 MB   | ################################################################################################################################################################### | 100%
  markdown-3.1.1       | 118 KB    | ################################################################################################################################################################### | 100%
  astor-0.8.0          | 46 KB     | ################################################################################################################################################################### | 100%
  grpcio-1.27.2        | 1.3 MB    | ################################################################################################################################################################### | 100%
  sqlparse-0.3.1       | 34 KB     | ################################################################################################################################################################### | 100%
  gitdb-4.0.2          | 49 KB     | ################################################################################################################################################################### | 100%
  pandas-1.0.3         | 8.6 MB    | ################################################################################################################################################################### | 100%
  docker-py-4.2.0      | 188 KB    | ################################################################################################################################################################### | 100%
  websocket-client-0.5 | 62 KB     | ################################################################################################################################################################### | 100%
  numpy-1.18.1         | 5 KB      | ################################################################################################################################################################### | 100%
  gitpython-3.1.1      | 328 KB    | ################################################################################################################################################################### | 100%
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/04/30 18:00:02 INFO mlflow.projects: === Created directory /tmp/tmpbcxyzo3m for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/30 18:00:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /home/ye53nis/drmed-git/src 5
  0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '09b669bd51ba4317a6ba4db833a3abb1' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  /home/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-30 18:00:19.551555: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-30 18:00:19.563688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-04-30 18:00:19.566795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b0cba23c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-04-30 18:00:19.566832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-04-30 18:00:19.567000: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='09b669bd51ba4317a6ba4db833a3abb1'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-04-30 18:00:46.639927: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6587 - mean_io_u: 0.4028 - precision: 0.2306 - recall: 0.7511 - val_loss: 1.5574 - val_mean_io_u: 0.3914 - val_precision: 0.1894 - val_recall:
   0.6051
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.6133 - mean_io_u: 0.4082 - precision: 0.2488 - recall: 0.7948/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.6116152, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588262662579). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 107s 3s/step - loss: 1.6042 - mean_io_u: 0.4055 - precision: 0.2566 - recall: 0.7927 - val_loss: 1.6116 - val_mean_io_u: 0.4122 - val_precision: 0.1641 - val_recall:
   0.8504
  Epoch 3/10
  32/32 [==============================] - 107s 3s/step - loss: 1.5036 - mean_io_u: 0.3934 - precision: 0.3298 - recall: 0.8165 - val_loss: 1.6282 - val_mean_io_u: 0.4021 - val_precision: 0.1870 - val_recall:
   0.9343
  Epoch 4/10
  32/32 [==============================] - 105s 3s/step - loss: 1.4783 - mean_io_u: 0.4014 - precision: 0.3343 - recall: 0.8179 - val_loss: 1.6338 - val_mean_io_u: 0.3861 - val_precision: 0.2262 - val_recall:
   0.9908
  Epoch 5/10
  32/32 [==============================] - 106s 3s/step - loss: 1.4398 - mean_io_u: 0.4006 - precision: 0.3735 - recall: 0.8220 - val_loss: 1.7444 - val_mean_io_u: 0.4101 - val_precision: 0.1798 - val_recall:
   0.9999
  Epoch 6/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3941 - mean_io_u: 0.3988 - precision: 0.4144 - recall: 0.8005 - val_loss: 1.8832 - val_mean_io_u: 0.4179 - val_precision: 0.1642 - val_recall:
   0.9999
  Epoch 7/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3660 - mean_io_u: 0.4000 - precision: 0.4544 - recall: 0.8108 - val_loss: 2.0017 - val_mean_io_u: 0.3885 - val_precision: 0.2230 - val_recall:
   0.9999
  Epoch 8/10
  32/32 [==============================] - 106s 3s/step - loss: 1.3169 - mean_io_u: 0.3993 - precision: 0.5203 - recall: 0.8057 - val_loss: 2.5556 - val_mean_io_u: 0.4147 - val_precision: 0.1706 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3050 - mean_io_u: 0.4047 - precision: 0.5429 - recall: 0.8009 - val_loss: 3.0439 - val_mean_io_u: 0.3991 - val_precision: 0.2017 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2911 - mean_io_u: 0.4098 - precision: 0.5691 - recall: 0.7966 - val_loss: 3.6402 - val_mean_io_u: 0.3934 - val_precision: 0.2132 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 843ms/step - loss: 3.5632 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-04-30 18:19:28.557139: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/04/30 18:19:46 INFO mlflow.projects: === Run (ID '09b669bd51ba4317a6ba4db833a3abb1') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Success!!!
** Find solution for large file problem
   :LOGBOOK:
   CLOCK: [2020-05-02 Sa 13:17]--[2020-05-02 Sa 13:43] =>  0:26
   :END:
*** using =git-lfs=
    :LOGBOOK:
    CLOCK: [2020-05-05 Di 13:37]--[2020-05-05 Di 13:38] =>  0:01
    CLOCK: [2020-05-02 Sa 14:41]--[2020-05-02 Sa 16:13] =>  1:32
    :END:
Problem: the deep network =unet.tf= is too big (>300MB) and github only allows a
maximum file size of 100MB. Two possible solutions:
- *Git Large File Storage*: https://git-lfs.github.com/ replace large files with text pointers inside
  Git. Configured with a =.gitattributes= file per project. Git commands stay
  the same
- *Git-annex*: https://git-annex.branchable.com/ own git annex command line
  tool. "stupid filename and metadata tracker".
- See [[file:~/Dokumente/org/04_Digital-und-Technik/software-setup.org::*=git-annex= vs =git-lfs=][here]] for notes

NOTE: *git commands should not be done on compute node, it's easier on login
node via normal ssh*

#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+BEGIN_SRC sh :session org-ssh :results output
  pwd
  git status
#+END_SRC

#+RESULTS:
#+begin_example
/home/ye53nis/drmed-git
# On branch develop
Your branch is ahead of 'origin/develop' by 1 commit.
(use "git push" to publish your local commits)

Untracked files:
(use "git add <file>..." to include in what will be committed)

data/exp-devtest/
nothing added to commit but untracked files present (use "git add" to track)
#+end_example

Encountered problem: git-lfs only syncs files *inside* the repo. The advised way
to save large files on the HPC is to use the dedicated =/beegfs= file system,
which is optimised for that stuff. My current repo is in =/home=
- version 1: migrate git repo to beegfs - effectively abandoning =/home=
- version 2: stay at =/home= and keep track of =/beegfs= using tools like
  =git-annex=

I am trying version 1 now

Works!!

My =-gitattributes= file has the following line to track all contents of a
folder which contains ".tf" somewhere in =data/=
#+begin_example
  data/**/*.tf/** filter=lfs diff=lfs merge=lfs -text
#+end_example

** run mlflow model as above, but save everything on =/beegfs=

   :LOGBOOK:
   CLOCK: [2020-05-02 Sa 16:13]--[2020-05-02 Sa 16:15] =>  0:02
   :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
: server exited unexpectedly

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ git status
  # On branch develop
  nothing to commit, working directory clean
  [ye53nis@node007 drmed-git]$ git log -1
  commit 9e6182fbeae831a151342827efa59581e4310ae6
  Author: Alex Seltmann <seltmann@posteo.de>
  Date:   Sat May 2 13:23:42 2020 +0200

      first successful mlflow run without trained net
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  2020/05/02 14:47:02 INFO mlflow.projects: === Created directory /tmp/tmp7uyf926z for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/02 14:47:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src
  5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'cda4eec66a6947c38ec2ee2006563ae5' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  ^[[B^[[B^[[B^[[B^[[B^[[B2.1.0
  /beegfs/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a41791e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-02 14:48:28.731100: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6869 - mean_io_u: 0.4035 - precision: 0.1949 - recall: 0.6740 - val_loss: 1.5778 - val_mean_io_u: 0.4210 - val_precision: 0.1500 - val_recall:
   5.7965e-05
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.5936 - mean_io_u: 0.4047 - precision: 0.2461 - recall: 0.7594/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588423924159). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 106s 3s/step - loss: 1.5935 - mean_io_u: 0.4051 - precision: 0.2456 - recall: 0.7601 - val_loss: 1.5412 - val_mean_io_u: 0.3977 - val_precision: 0.3000 - val_recall:
   8.9508e-05
  Epoch 3/10
  32/32 [==============================] - 108s 3s/step - loss: 1.5357 - mean_io_u: 0.4039 - precision: 0.2901 - recall: 0.8025 - val_loss: 1.5201 - val_mean_io_u: 0.3834 - val_precision: 0.2500 - val_recall:
   6.5409e-05
  Epoch 4/10
  32/32 [==============================] - 109s 3s/step - loss: 1.4929 - mean_io_u: 0.4041 - precision: 0.3227 - recall: 0.8099 - val_loss: 1.5400 - val_mean_io_u: 0.3990 - val_precision: 0.2011 - val_recall:
   0.0535
  Epoch 5/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4589 - mean_io_u: 0.4054 - precision: 0.3445 - recall: 0.7970 - val_loss: 1.5471 - val_mean_io_u: 0.3927 - val_precision: 0.2178 - val_recall:
   0.3854
  Epoch 6/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4293 - mean_io_u: 0.4059 - precision: 0.3692 - recall: 0.7784 - val_loss: 1.6078 - val_mean_io_u: 0.4057 - val_precision: 0.1891 - val_recall:
   0.9730
  Epoch 7/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3821 - mean_io_u: 0.4005 - precision: 0.4276 - recall: 0.7645 - val_loss: 1.7784 - val_mean_io_u: 0.4182 - val_precision: 0.1636 - val_recall:
   0.9998
  Epoch 8/10
  32/32 [==============================] - 109s 3s/step - loss: 1.3219 - mean_io_u: 0.3993 - precision: 0.5042 - recall: 0.8182 - val_loss: 1.9800 - val_mean_io_u: 0.3925 - val_precision: 0.2150 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2852 - mean_io_u: 0.3930 - precision: 0.5602 - recall: 0.7957 - val_loss: 2.5127 - val_mean_io_u: 0.4206 - val_precision: 0.1587 - val_recall:
   1.0000
  Epoch 10/10
  32/32 [==============================] - 108s 3s/step - loss: 1.2926 - mean_io_u: 0.4057 - precision: 0.5469 - recall: 0.8147 - val_loss: 2.9090 - val_mean_io_u: 0.3916 - val_precision: 0.2169 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 865ms/step - loss: 2.9045 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/05/02 15:07:38 INFO mlflow.projects: === Run (ID 'cda4eec66a6947c38ec2ee2006563ae5') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Comparison to run at =/home=:
- some "misformed experiment" warning. Probably bc I tried to rebase the repo on
  the remote, because I committed the big =unet.tf= folder and wanted to redo
  that (it seemed that failed and my first test run got lost)
- same conda env got loaded, and the run seems to have conducted without
  problems, jippieh!

*** checking out mlflow error messages [3/5]
    :LOGBOOK:
    CLOCK: [2020-05-05 Di 14:30]--[2020-05-05 Di 15:38] =>  1:08
    CLOCK: [2020-05-05 Di 13:43]--[2020-05-05 Di 14:09] =>  0:26
    CLOCK: [2020-05-02 Sa 16:15]--[2020-05-02 Sa 18:06] =>  1:51
    :END:

**** TODO 1. tensorflow: your CPU supports instructions that this TF binary was not compiled to use

#+begin_example
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142]
    Your CPU supports instructions that this TensorFlow binary was not
    compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94]
    CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168]
    XLA service 0x563a41791e20 initialized for platform Host (this does not
    guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]
    StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147]
    Creating new thread pool with default inter op setting: 2.
    Tune using inter_op_parallelism_threads for best performance.

  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319]
    Sets are not currently considered sequences, but this may change in the future,
    so consider avoiding using them.
#+end_example

See [[https://github.com/tensorflow/tensorflow/issues/34369][this Github issue]]: the second part of the error is related to the first one,
and thus can be ignored (or solved following one of the paths below)

See [[https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u][here]]: It's only an issue if you run the code on a CPU!

The mentioned SSE, AVX, FMA etc are extensions from Intel and AMD to
speed up linear algebra computation, e.g. dot-product, matrix multiply,
convolution, etc. AVX and FMA speed them up on a CPU up to 300%. The warning
states that the CPU does support them, but =tensorflow= does not with the
default installation.

If you have a GPU:
- don't care about AVX etc support, because running on a GPU is way better
- you can ignore this warning by:
  #+BEGIN_SRC python
    # Just disables the warning, doesn't enable AVX/FMA
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
  #+END_SRC
  or
  #+BEGIN_SRC sh
    export TF_CPP_MIN_LOG_LEVEL=2
  #+END_SRC

If you don't have a GPU / don't want to use it:
- default tensorflow is intended to be compatible with as many CPUs as possible,
  that's why these libraries are note preinstalled
- *build tensorflow from the source optimized for /your/ CPU* - that's quite
  some additional work... if I should do this, here is TF [[https://www.tensorflow.org/install/source][guide]]
***** TODO Run this code on a GPU node, then decide. Maybe use docker to easily use TF on the nodes
**** TODO 2. mlflow: ABCs from 'collections'

  #+begin_example
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389:
      DeprecationWarning: Using or importing the ABCs from 'collections' instead of from
      'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
      if isinstance(sample_weight_mode, collections.Mapping):
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60:
      DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0,
      use inspect.signature() or inspect.getfullargspec()
  #+end_example

I suspect these will be solved with an =mlflow= update.

**** DONE 3. calling BaseResourceVariable.__init__
     CLOSED: [2020-05-18 Mo 10:44]

     - State "DONE"       from "PENDING"    [2020-05-18 Mo 10:44] \\
       Use tf.nightly
     - State "PENDING"    from "TODO"       [2020-05-05 Di 15:01] \\
       Wait till this commit
       https://github.com/tensorflow/tensorflow/commit/1e2c8c6873770a70ace0613a65c11826666c4623#diff-aa6c341a4b212afc57b49be73e689dc2
       which introduces Conv1DTranspose officially is released. If it takes too long:
       install tf-nightly, but this might be unstable.
#+begin_example
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786:
      calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops)
      with constraint is deprecated and will be removed in a future version.
      Instructions for updating:
      If using Keras pass *_constraint arguments to layers.
    WARNING:tensorflow:Model failed to serialize as JSON.
      Ignoring... Layers with arguments in `__init__` must override `get_config`.

    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552:
      UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` must override `get_config`.
      try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
#+end_example

The =BaseResourceVariable= one seems to be connected to keras' SavedModel
 format and happens in the [[https://www.tensorflow.org/tutorials/keras/save_and_load][official TF keras tutorial]] when using
=model.save('saved_model/my_model')=.

I am still not settled on how to save models anyway. I think I will use
[[https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html#mlflow.tensorflow.save_model][mlflow.tensorflow.save_model()]] or =mlflow.tensorflow.log_model= (not sure what
the difference is). BUT this needs a /serialized/ collection of TF graphs and
variables. Maybe I have to do some more work, see below...

from [[https://www.tensorflow.org/guide/keras/save_and_serialize][TF keras guide]]:
- Saving the architecture (= layers and how these layers are connected) → model
  can be created with freshly initialized state for weights and no compilation
  info
  - Sequential model / functional API model: are explicit graphs of layers,
    config always available in a structured form.
    - =layer.get_config()= or =model.get_config()= will return Python dict
      containing the config of the model
    - Model can be reconstructed
      - Sequential model: =Sequential.from_config(config)=
      - Functional API model: =Model.from_config(config)=
  - Custom objects
    - Models and layers: In order to save/load a model with custom-defined
      layers, or a subclassed model, you should overwrite the =get_config= and
      optionally =from_config= methods. Additionally, you should use register
      the custom object so that Keras is aware of it.
    - Custom functions (e.g. activation loss...) do not need =get_config=,
      function name is sufficient for loading as long as it is registered as a
      custom object
    - defining =Get_config=: should return a JSON-serializable dict in order to
      be compatible with Keras architecture- and model-saving APIs
    - defining =from_config(config)=: should return a new layer or model object
      that is created from the config. Default implementation returns
      =cls(**config)=

See [[https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf][this SO question]]:
- an example for a class which makes =model.save= fail:
  #+BEGIN_SRC python
    class encoder(tf.keras.layers.Layer):

        def __init__(
            self,
            vocab_size, num_layers, units, d_model, num_heads, dropout,
            ,**kwargs,
        ):
            super().__init__(**kwargs)
            self.vocab_size = vocab_size
            self.num_layers = num_layers
            self.units = units
            self.d_model = d_model
            self.num_heads = num_heads
            self.dropout = dropout

        # Other methods etc.
  #+END_SRC
- and now you need to override this method:
  #+BEGIN_SRC python
        def get_config(self):

            config = super().get_config().copy()
            config.update({
                'vocab_size': self.vocab_size,
                'num_layers': self.num_layers,
                'units': self.units,
                'd_model': self.d_model,
                'num_heads': self.num_heads,
                'dropout': self.dropout,
            })
            return config
  #+END_SRC
- and for =layer.from_config=:
  #+BEGIN_SRC python
        @classmethod
        def from_config(cls, config):
            return cls(**config)
  #+END_SRC
**** DONE 4. Logging to MLflow failed: Changing param values is not allowed
     CLOSED: [2020-05-28 Do 00:38]

     - State "DONE"       from "PENDING"    [2020-05-28 Do 00:38]
     - State "PENDING"    from "TODO"       [2020-05-05 Di 13:46] \\
       Renamed batch_size to _batch_size to emphasize the local character. let's see if
       the error still occurs

#+BEGIN_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70:
    UserWarning: Logging to MLflow failed:
    Changing param values is not allowed.
    Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'.
    Attempted logging new value 'None'.
  try_mlflow_log(mlflow.log_params, defaults)
#+END_example

Couldn't find anything googling that. Probably has something to do with naming
the variable =batch_size=, which may be a variable the autologging feature
already uses?

**** DONE 5. invalid value tf.Tensor(..., dtype=float32). Please specify value as a valid double
     CLOSED: [2020-05-18 Mo 10:46]

     - State "DONE"       from "PENDING"    [2020-05-18 Mo 10:46] \\
       Use mlflow.tensorflow.autolog(every_n_iter=1), now metric logging on end
       of epoch works (this every_n_iter value is working different for TF 2.0)
     - State "TODO"       from "PENDING"    [2020-05-05 Di 15:26]
     - State "PENDING"    from "TODO"       [2020-05-05 Di 13:53] \\
       I added tf.keras.backend.set_floatx('float64')
#+begin_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:549:
    UserWarning: Logging to MLflow failed:
    Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss'
    (timestamp=1588423924159). Please specify value as a valid double (64-bit floating point)
  try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
#+end_example

Check out if val_loss got logged in the end. → doesn't seem so. It can be found
under =artifacts/tensorboard_logs= and these are not text files, but some binary
files.

In theory, validation loss and training loss should be logged by mlflow as well
(and custom metrics as well) → check that they are a valid 64-bit integer value.

**** Test run 1: fixing 4. and 5.

     :LOGBOOK:
     CLOCK: [2020-05-06 Mi 16:10]--[2020-05-06 Mi 17:17] =>  1:07
     :END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
  [ye53nis@node007 drmed-git]$ git log -1
  commit e9983783a946d57f95b3a28405c5a2d74108f6b9
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Tue May 5 15:07:02 2020 +0200

      Set tf.keras standard to float64; rename var
  [ye53nis@node007 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 79, in <module>
      tf.keras.metrics.Recall()
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
      result = method(self, *args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 439, in compile
      masks=self._prepare_output_masks())
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 2004, in _handle_metrics
      target, output, output_mask))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 1955, in _handle_per_output_metrics
      metric_fn, y_true, y_pred, weights=weights, mask=mask)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1155, in call_metric_function
      return metric_fn(y_true, y_pred, sample_weight=weights)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 196, in __call__
      replica_local_fn, *args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py", line 1135, in call_repli
  ca_local_fn
      return fn(*args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 179, in replica_local_fn
      update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 76, in decorated
      update_op = update_state_fn(*args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 1216, in update_state
      sample_weight=sample_weight)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 440, in update_confusion_matrix_varia
  bles
      variables_to_update[matrix_cond]))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 416, in weighted_assign_add
      return var.assign_add(math_ops.reduce_sum(label_and_pred, 1))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 785, in assign_add
      self.handle, ops.convert_to_tensor(delta, dtype=self.dtype),
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py", line 1290, in convert_to_tensor
      (dtype.name, value.dtype.name, value))
  ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics/precision/Sum:0' shape=(1,) dtype=float32>
  2020/05/05 15:16:13 ERROR mlflow.cli: === Run (ID '0fcf9dc61b3148d6b535b5e66a8a3db0') failed ===
  [ye53nis@node007 drmed-git]$
#+end_example

there is an issue with tf.metrics see [[https://github.com/tensorflow/tensorflow/issues/36790][here]]. For now,
tf.keras.backend.set_floatx('float64') doesn't work.

Next try: log the metrics manually and see if that works.
Or: Check first if the tensorboard metrics stored in =mlruns/artifacts= is maybe enough

I found a [[https://medium.com/@ij_82957/how-to-reduce-mlflow-logging-overhead-by-using-log-batch-b61301cc540f][nice article]] dealing with how to log metrics from a history object.
For now I implement a approach based on =mlflow.log_metrics()=. There is a
faster approch using =mlflow.entities.Metric=, =mlflow.tracking.MlflowClient=
and =mlflow_client.log_batch()=. But I want to try the naive approach first.

**** Test run 2: do dynamic testing using jupyter
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
   :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p gpu_test --time=1:00:00 --gres=gpu:2 --mem-per-cpu=1000 --ntasks-per-node=48 --pty bash
#+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load nvidia/cuda/10.1.168
  module load nvidia/cudnn/7.5.1.10
  conda activate tensorflow_nightly
  export PORT=8889
  export XDG_RUNTIME_DIR=''
  export XDG_RUNTIME_DIR=""
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/cluster/nvidia/cuda/10.1.168/extras/CUPTI/lib64
  jupyter notebook --no-browser --port=$PORT
#+END_SRC

#+CALL: jpt-tunnel(port="8889", node="node127")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |   |          |      |      |             |
| ye53nis@node127's | password:                            |           |     |   |          |      |      |             |
| Last              | login:                               | Wed       | May | 6 | 23:16:52 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3          9e7e4701-35b1-4031-8f44-ed2586b82d49   2 minutes ago        starting   0
#+end_example

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 72
  No of CPUs the current process can use: 24
  load average: (0.09, 1.05, 11.15)
  posix.uname_result(sysname='Linux', nodename='node243', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 448659
  RAM total: 199G, RAM used: 2.3G, RAM free: 154G
  the current directory: /home/ye53nis
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  3.2G   47G   7% /
  devtmpfs              94G     0   94G   0% /dev
  tmpfs                 94G 1018M   93G   2% /dev/shm
  tmpfs                 94G   59M   94G   1% /run
  tmpfs                 94G     0   94G   0% /sys/fs/cgroup
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  nfs01-ib:/home        80T   59T   22T  73% /home
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs02-ib:/data01      88T   59T   29T  68% /data01
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  4.3G  165G   3% /local
  /dev/sda3            6.0G  404M  5.6G   7% /var
  beegfs_nodev         524T  425T  100T  82% /beegfs
  tmpfs                 19G     0   19G   0% /run/user/67339
#+end_example

#+BEGIN_SRC jupyter-python
  %cd /beegfs/ye53nis/drmed-git
#+END_SRC

#+RESULTS:
: /beegfs/ye53nis/drmed-git

#+BEGIN_SRC jupyter-python
  import sys
  import matplotlib.pyplot as plt
  import tensorflow as tf
  sys.path.append('/beegfs/ye53nis/drmed-git/src/')
  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
  tf.config.list_physical_devices('GPU')
#+END_SRC

#+RESULTS:
: []

#+BEGIN_SRC jupyter-python
  _batch_size = 5
  frac_val = 0.2
  length_delimiter = 16384
  learning_rate = 1e-5
  epochs = 2
  csv_path = '/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/'
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  train, test, nsamples, experiment_params = isfc.import_from_csv(
      path=csv_path,
      header=12,
      frac_train=0.8,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')

  train_data, train_labels = isfc.separate_data_and_labels(array=train,
                                                           nsamples=nsamples)
  test_data, test_labels = isfc.separate_data_and_labels(array=test,
                                                         nsamples=nsamples)

  # get bool as ground truth
  train_labels_bool = train_labels > 0.04

  test_labels_bool = test_labels > 0.04
  print(
      '\nfor each 20,000 timestap trace there are the following numbers '
      'of corrupted timesteps:\n',
      test_labels_bool.sum(axis=0).head())

  # Cleanup
  del train, test
#+END_SRC

#+RESULTS:
#+begin_example
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
#+end_example

#+BEGIN_SRC jupyter-python
  dataset_train, dataset_val, num_train_examples, num_val_examples = ppd.tfds_from_pddf_for_unet(
      features_df=train_data,
      labels_df=train_labels_bool,
      is_training=True,
      batch_size=_batch_size,
      length_delimiter=length_delimiter,
      frac_val=frac_val)

  dataset_test, num_test_examples = ppd.tfds_from_pddf_for_unet(
      features_df=test_data,
      labels_df=test_labels_bool,
      is_training=False,
      batch_size=_batch_size,
      length_delimiter=length_delimiter)
#+END_SRC

#+RESULTS:
: number of training examples: 160, number of validation examples: 40
:
: ------------------------
: number of test examples: 100
:

#+BEGIN_SRC jupyter-python
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
#+END_SRC

#+RESULTS:
: WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
: INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
: Number of devices: 1

#+BEGIN_SRC jupyter-python
  model = bm.unet_1d_alt(input_size=length_delimiter)
  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
  loss = bm.binary_ce_dice_loss

  model.compile(loss=loss,
                optimizer=optimizer,
                metrics=[
                    tf.keras.metrics.MeanIoU(num_classes=2),
                    tf.keras.metrics.Precision(),
                    tf.keras.metrics.Recall()
                ])

  history = model.fit(
      x=dataset_train,
      epochs=epochs,
      steps_per_epoch=tf.math.ceil(num_train_examples / _batch_size),
      validation_data=dataset_val,
      validation_steps=tf.math.ceil(num_val_examples / _batch_size))
#+END_SRC

#+RESULTS:
: input - shape:	 (None, 16384, 1)
: output - shape:	 (None, 16384, 1)
: Epoch 1/2
: 32/32 [==============================] - 50s 2s/step - loss: 1.6011 - mean_io_u: 0.4080 - precision: 0.2163 - recall: 0.6183 - val_loss: 1.5998 - val_mean_io_u: 0.4234 - val_precision: 0.1501 - val_recall: 0.8740
: Epoch 2/2
: 32/32 [==============================] - 49s 2s/step - loss: 1.5107 - mean_io_u: 0.3981 - precision: 0.3011 - recall: 0.6895 - val_loss: 1.6026 - val_mean_io_u: 0.4151 - val_precision: 0.1624 - val_recall: 0.8894

These GPU modules were missing:
libcublas.so.10 - I wrote to Sabine Irmer about that
libcudnn.so.7 - There was an extra =module load nvidia/cudnn/7.5.1.10= available

#+BEGIN_SRC jupyter-python :results scalar
  history.history
#+END_SRC

#+RESULTS:
#+begin_example
  {'loss': [1.5873368978500366,
    1.5292785167694092,
    1.4659773111343384,
    1.416449785232544,
    1.345642328262329,
    1.3310154676437378,
    1.2963486909866333,
    1.2417198419570923,
    1.2305928468704224,
    1.2321150302886963],
   'mean_io_u': [0.0,
    3985559344291687.4037455916404724,
    0.4071432948112488,
    0.40351858735084534,
    0.39908209443092346,
    0.41106948256492615,
    0.4076460599899292,
    0.40254250168800354,
    0.4079275131225586,
    0.41036319732666016],
   'precision': [0.2488986849784851,
    0.30270472168922424,
    0.34654930233955383,
    0.4073646366596222,
    0.49564093351364136,
    0.5083103179931641,
    0.5742575526237488,
    0.6650815606117249,
    0.6706622838973999,
    0.671720564365387],
   'recall': [0.537831723690033,
    0.6538828611373901,
    0.7087317705154419,
    0.7070884108543396,
    0.7108414173126221,
    0.7444652915000916,
    0.7134528160095215,
    0.7382367849349976,
    0.7559362649917603,
    0.741098940372467],
   'val_loss': [1.49961519241333,
    1.48013174533844,
    1.473410964012146,
    1.4653061628341675,
    1.4866881370544434,
    1.5756771564483643,
    1.785191297531128,
    2.664144515991211,
    3.5446887016296387,
    4.201501369476318],
   'val_mean_io_u': [0.3783065676689148,
    0.37820738554000854,
    0.3933570981025696,
    0.3894149661064148,
    0.42156678438186646,
    0.3901313841342926,
    0.3508506715297699,
    0.3951469361782074,
    0.4056693911552429,
    0.38204270601272583],
   'val_precision': [0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.24144163727760315,
    0.2983255386352539,
    0.2097124308347702,
    0.18867774307727814,
    0.23592336475849152],
   'val_recall': [0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.9312672019004822,
    0.9996521472930908,
    0.9997889995574951,
    0.9999595880508423,
    0.9999547004699707]}
#+end_example

#+BEGIN_SRC jupyter-python :results scalar
  model.evaluate(dataset_test,
                 steps=tf.math.ceil(num_test_examples / _batch_size))
#+END_SRC

#+RESULTS:
:RESULTS:
: 20/20 [==============================] - 10s 519ms/step - loss: 4.2488 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
: [4.248773097991943,
:  0.38494813442230225,
:  0.23011629283428192,
:  0.9999707937240601]
:END:

#+BEGIN_SRC jupyter-python :display image
  it = iter(dataset_test)

  fig, ax = plt.subplots(5, figsize=(16, 12))
  count = 0
  while count < 5:
      example = next(it)
      ax[count].plot(example[0][0])
      prediction = model.predict(example[0])
      prediction = prediction[0] > 0.5
      ax[count].plot(prediction*2)
      ax[count].plot(example[1][0])
      count += 1
#+END_SRC

#+RESULTS:
: 0c67d91d-f101-4868-b9a4-ed8cee57bee9

**** Test run 3: fixing 4. and 5. part 2
     :LOGBOOK:
     CLOCK: [2020-05-08 Fr 21:41]--[2020-05-08 Fr 21:41] =>  0:00
     CLOCK: [2020-05-08 Fr 20:07]--[2020-05-08 Fr 20:54] =>  0:47
     CLOCK: [2020-05-08 Fr 17:56]--[2020-05-08 Fr 18:08] =>  0:12
     CLOCK: [2020-05-08 Fr 15:41]--[2020-05-08 Fr 16:23] =>  0:42
     CLOCK: [2020-05-08 Fr 14:55]--[2020-05-08 Fr 15:25] =>  0:30
     :END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p s_standard --time=7-10:00:00 --ntasks-per-node=36 --mem-per-cpu=2000 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 ~]$ srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
  (base) [ye53nis@node262 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  cd /beegfs/ye53nis/drmed-git
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  commit 00cf780bf75e57ef38c5fcf06cbbbb18abc38a13
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Thu May 7 19:00:51 2020 +0200

      Mention LabBook.html; fix links
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node262 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/05/08 15:04:40 INFO mlflow.projects: === Created directory /tmp/tmps8r9h7ee for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/08 15:04:40 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'f360fcfaeb7f4750bdc5ef8326d2240a' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  fluotracify path:  /beegfs/ye53nis/drmed-git/src
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-08 15:05:42.782717: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
  2020-05-08 15:05:42.797518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
  2020-05-08 15:05:42.800274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564142ebde50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-08 15:05:42.800378: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-08 15:05:42.800727: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='f360fcfaeb7f4750bdc5ef8326d2240a'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-08 15:06:09.400241: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 157s 5s/step - loss: 1.4794 - mean_io_u: 0.4027 - precision: 0.1746 - recall: 0.0652 - val_loss: 1.5356 - val_mean_io_u: 0.4155 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 2/10
  31/32 [============================>.] - ETA: 4s - loss: 1.4003 - mean_io_u: 0.4062 - precision: 0.4050 - recall: 0.1508/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.497927, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588943442066). Please specif
  y value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 139s 4s/step - loss: 1.3997 - mean_io_u: 0.4061 - precision: 0.4134 - recall: 0.1530 - val_loss: 1.4979 - val_mean_io_u: 0.4137 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 134s 4s/step - loss: 1.3425 - mean_io_u: 0.4005 - precision: 0.6062 - recall: 0.2561 - val_loss: 1.4643 - val_mean_io_u: 0.3848 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 4/10
  32/32 [==============================] - 132s 4s/step - loss: 1.3102 - mean_io_u: 0.3982 - precision: 0.6693 - recall: 0.3802 - val_loss: 1.4749 - val_mean_io_u: 0.4106 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 5/10
  32/32 [==============================] - 133s 4s/step - loss: 1.2738 - mean_io_u: 0.3999 - precision: 0.6858 - recall: 0.5133 - val_loss: 1.5032 - val_mean_io_u: 0.3820 - val_precision: 0.2813 - val_recall:
   0.2903
  Epoch 6/10
  32/32 [==============================] - 133s 4s/step - loss: 1.2496 - mean_io_u: 0.4049 - precision: 0.6634 - recall: 0.6284 - val_loss: 1.7162 - val_mean_io_u: 0.4237 - val_precision: 0.1578 - val_recall:
   0.8926
  Epoch 7/10
  32/32 [==============================] - 143s 4s/step - loss: 1.2230 - mean_io_u: 0.4051 - precision: 0.6847 - recall: 0.6793 - val_loss: 1.9898 - val_mean_io_u: 0.4048 - val_precision: 0.1904 - val_recall:
   0.9998
  Epoch 8/10
  32/32 [==============================] - 139s 4s/step - loss: 1.1948 - mean_io_u: 0.4042 - precision: 0.7137 - recall: 0.7155 - val_loss: 2.4641 - val_mean_io_u: 0.3941 - val_precision: 0.2117 - val_recall:
   0.9998
  Epoch 9/10
  32/32 [==============================] - 142s 4s/step - loss: 1.1701 - mean_io_u: 0.4010 - precision: 0.7509 - recall: 0.7258 - val_loss: 2.9713 - val_mean_io_u: 0.3751 - val_precision: 0.2497 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 135s 4s/step - loss: 1.1252 - mean_io_u: 0.3996 - precision: 0.7899 - recall: 0.7900 - val_loss: 3.6660 - val_mean_io_u: 0.4050 - val_precision: 0.1901 - val_recall:
   0.9998
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 96, in <module>
      mlflow.log_metrics(metrics, step=i)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 271, in log_metrics
      MlflowClient().log_batch(run_id=run_id, metrics=metrics_arr, params=[], tags=[])
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 249, in log_batch
      self._tracking_client.log_batch(run_id, metrics, params, tags)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 229, in log_batch
      _validate_metric(metric.key, metric.value, metric.timestamp, metric.step)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/validation.py", line 70, in _validate_metric
      INVALID_PARAMETER_VALUE)
  mlflow.exceptions.MlflowException: Got invalid value tf.Tensor(1.5356212, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588944533682). Please specify value as a valid double (64-bit floating po
  int)
  2020/05/08 15:28:54 ERROR mlflow.cli: === Run (ID 'f360fcfaeb7f4750bdc5ef8326d2240a') failed ===
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  commit 5319f00ac246f426ea266d07f94effa8a18068a8
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Fri May 8 15:59:18 2020 +0200

      try to make log_metrics work
#+end_example

Two things changed: now running tensorflow nightly

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  2020/05/08 16:23:44 INFO mlflow.projects: === Created directory /tmp/tmp6tg_wyna for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/08 16:23:44 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'aeacaed2624a4e3ebbe240ff97e74fd0' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  fluotracify path:  /beegfs/ye53nis/drmed-git/src
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-08 16:23:54.416673: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
  2020-05-08 16:23:54.427207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
  2020-05-08 16:23:54.428400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556200e8fe40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-08 16:23:54.428430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-08 16:23:54.428559: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='aeacaed2624a4e3ebbe240ff97e74fd0'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-08 16:24:20.043922: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 156s 5s/step - loss: 1.5595 - mean_io_u: 0.4046 - precision: 0.2138 - recall: 0.4436 - val_loss: 1.5276 - val_mean_io_u: 0.3947 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 2/10
  31/32 [============================>.] - ETA: 4s - loss: 1.4620 - mean_io_u: 0.4036 - precision: 0.3204 - recall: 0.6043/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.5336354, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588948133109). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 140s 4s/step - loss: 1.4617 - mean_io_u: 0.4027 - precision: 0.3222 - recall: 0.6023 - val_loss: 1.5336 - val_mean_io_u: 0.4152 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 135s 4s/step - loss: 1.3917 - mean_io_u: 0.3939 - precision: 0.4246 - recall: 0.6836 - val_loss: 1.5311 - val_mean_io_u: 0.4055 - val_precision: 0.1513 - val_recall:
   0.0404
  Epoch 4/10
  32/32 [==============================] - 143s 4s/step - loss: 1.3645 - mean_io_u: 0.4012 - precision: 0.4491 - recall: 0.7378 - val_loss: 1.5464 - val_mean_io_u: 0.3922 - val_precision: 0.2166 - val_recall:
   0.5154
  Epoch 5/10
  32/32 [==============================] - 136s 4s/step - loss: 1.3427 - mean_io_u: 0.4034 - precision: 0.4764 - recall: 0.7502 - val_loss: 1.6451 - val_mean_io_u: 0.4045 - val_precision: 0.1937 - val_recall:
   0.7729
  Epoch 6/10
  32/32 [==============================] - 136s 4s/step - loss: 1.2957 - mean_io_u: 0.4052 - precision: 0.5425 - recall: 0.7886 - val_loss: 1.9099 - val_mean_io_u: 0.3994 - val_precision: 0.2013 - val_recall:
   0.9999
  Epoch 7/10
  32/32 [==============================] - 140s 4s/step - loss: 1.2704 - mean_io_u: 0.4004 - precision: 0.5900 - recall: 0.7747 - val_loss: 2.4546 - val_mean_io_u: 0.3892 - val_precision: 0.2216 - val_recall:
   0.9999
  Epoch 8/10
  32/32 [==============================] - 141s 4s/step - loss: 1.2297 - mean_io_u: 0.3955 - precision: 0.6516 - recall: 0.7727 - val_loss: 3.6472 - val_mean_io_u: 0.4207 - val_precision: 0.1586 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 137s 4s/step - loss: 1.2099 - mean_io_u: 0.4049 - precision: 0.6759 - recall: 0.8141 - val_loss: 4.4598 - val_mean_io_u: 0.4071 - val_precision: 0.1859 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 136s 4s/step - loss: 1.1920 - mean_io_u: 0.3994 - precision: 0.7333 - recall: 0.7710 - val_loss: 5.2335 - val_mean_io_u: 0.4005 - val_precision: 0.1991 - val_recall:
   0.9999
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 92, in <module>
      mlflow.log_metrics(metrics, step=i)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 271, in log_metrics
      MlflowClient().log_batch(run_id=run_id, metrics=metrics_arr, params=[], tags=[])
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 249, in log_batch
      self._tracking_client.log_batch(run_id, metrics, params, tags)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 229, in log_batch
      _validate_metric(metric.key, metric.value, metric.timestamp, metric.step)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/validation.py", line 70, in _validate_metric
      INVALID_PARAMETER_VALUE)
  mlflow.exceptions.MlflowException: Got invalid value tf.Tensor(1.5594830736517906, shape=(), dtype=float64) for metric 'loss' (timestamp=1588949235987). Please specify value as a valid double (64-bit floati
  ng point)
  2020/05/08 16:47:16 ERROR mlflow.cli: === Run (ID 'aeacaed2624a4e3ebbe240ff97e74fd0') failed ===
  (tensorflow_nightly) [ye53nis@node262 drmed-git]$
#+end_example

** run  mlflow model after some work
   :LOGBOOK:
   CLOCK: [2020-05-18 Mo 14:55]--[2020-05-18 Mo 16:09] =>  1:14
   CLOCK: [2020-05-18 Mo 14:11]--[2020-05-18 Mo 14:33] =>  0:22
   CLOCK: [2020-05-18 Mo 12:35]--[2020-05-18 Mo 13:40] =>  1:05
   CLOCK: [2020-05-18 Mo 10:48]--[2020-05-18 Mo 11:00] =>  0:12
   :END:

*** Make mlflow ready
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  /beegfs/ye53nis/drmed-git
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node154 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  #   (use "git add <file>..." to include in what will be committed)
  #
  #       data/exp-devtest/
  #       data/mlruns/1/07dba5bcb5f7442a8aeb5a09b63d1e14/
  #       data/mlruns/1/0fcf9dc61b3148d6b535b5e66a8a3db0/
  #       data/mlruns/1/3867a0d7bdd0424aab72165e7af25d69/
  #       data/mlruns/1/a04de21fa0bf4692aade01ecbf4828d0/
  #       data/mlruns/1/a71abaad77dd4fae8c78c629cc450834/
  #       data/mlruns/1/c87de59ce9b848bc8d3d198fa63f9738/
  #       data/mlruns/1/dbd0106d180042ce8eb7a2ede38cc985/
  #       mlruns/
  #       tramp.YDPCnB
  nothing added to commit but untracked files present (use "git add" to track)

  (base) [ye53nis@node154 drmed-git]$ git log -1
  commit 8ebdd343fc404fe06ef3446fd941255c0103cd46
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Mon May 18 12:49:41 2020 +0200

      Move to tf-nightly in conda.yaml
      (base) [ye53nis@node154 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda activate tensorflow_nightly
  cd /beegfs/ye53nis/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns

#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$
#+end_example

*** First run: on login node (bad, but necessary)
For the run mlflow had to create a new conda environment, since I used
tf-nightly now. This took some time, since tf-nightly had to install via pip.
Executing this following =mlflow run= command on the compute node (here:
node154) was not successfull, it complained about missing disk space. I did
=conda clean= and removed some prior environments with the goal of making space,
but it still complained. So I ran it on the login node instead (you should never
do this normally) - and here =pip= worked. I guess that some access restrictions
were the problem. Now that the right mlflow conda env exists, I can run the code
on the compute nodes as before.

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
(base) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/05/18 13:31:30 INFO mlflow.projects: === Creating conda environment mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 ===
  Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they
   may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.
  Collecting package metadata (repodata.json): done
  Solving environment: done
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  Ran pip subprocess with arguments:
  ['/home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt']
  Pip subprocess output:
  Collecting tf-nightly
    Using cached tf_nightly-2.3.0.dev20200518-cp38-cp38-manylinux2010_x86_64.whl (522.5 MB)
  Collecting google-pasta>=0.1.8
    Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
  Collecting keras-preprocessing<1.2,>=1.1.1
    Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
  Collecting scipy==1.4.1
    Using cached scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)
  Collecting gast==0.3.3
    Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
  Processing /home/ye53nis/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73/wrapt-1.12.1-cp38-cp38-linux_x86_64.whl
  Collecting opt-einsum>=2.3.2
    Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)
  Processing /home/ye53nis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl
  Collecting grpcio>=1.8.6
    Downloading grpcio-1.29.0-cp38-cp38-manylinux2010_x86_64.whl (3.0 MB)
  Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53
  nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.18.1)
  Processing /home/ye53nis/.cache/pip/wheels/1d/10/8e/2f79b924179ff1e6510933d63eb851bea01054fff262343b7a/absl_py-0.9.0-py3-none-any.whl
  Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (0.34.2)
  Collecting astunparse==1.6.3
    Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
  Collecting tb-nightly<2.4.0a0,>=2.3.0a0
    Using cached tb_nightly-2.3.0a20200517-py3-none-any.whl (3.0 MB)
  Collecting tf-estimator-nightly
    Downloading tf_estimator_nightly-2.3.0.dev2020051801-py2.py3-none-any.whl (456 kB)
  Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.14.0)
  Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis
  /drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (3.11.4)
  Collecting h5py<2.11.0,>=2.10.0
    Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)
  Collecting google-auth<2,>=1.6.3
    Downloading google_auth-1.14.3-py2.py3-none-any.whl (89 kB)
  Collecting markdown>=2.6.8
    Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)
  Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a0
  ->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.0.1)
  Collecting google-auth-oauthlib<0.5,>=0.4.1
    Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
  Collecting tensorboard-plugin-wit>=1.6.0
    Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)
  Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0
  a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2.23.0)
  Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a
  0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (46.2.0.post20200511)
  Collecting pyasn1-modules>=0.2.1
    Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
  Collecting rsa<4.1,>=3.1.4
    Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)
  Collecting cachetools<5.0,>=2.0.0
    Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)
  Collecting requests-oauthlib>=0.7.0
    Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
  Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nig
  htly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2020.4.5.1)
  Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nightly<2
  .4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2.9)
  Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nigh
  tly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (3.0.4)
  Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from reques
  ts<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.25.8)
  Collecting pyasn1<0.5.0,>=0.4.6
    Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
  Collecting oauthlib>=3.0.0
    Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
  Installing collected packages: google-pasta, keras-preprocessing, scipy, gast, wrapt, opt-einsum, termcolor, grpcio, absl-py, astunparse, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, markdown, oaut
  hlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tb-nightly, tf-estimator-nightly, h5py, tf-nightly
  Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.14.3 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdow
  n-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tb-nightly-2.3.0a20200517 tensorboard-plugin-wit-1.6.0.post3 termcolor-1.1.0 tf-estimato
  r-nightly-2.3.0.dev2020051801 tf-nightly-2.3.0.dev20200518 wrapt-1.12.1

  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/05/18 13:33:38 INFO mlflow.projects: === Created directory /tmp/tmpvurkkck7 for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/18 13:33:38 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '6030cbbeacbb4dfab851ac8429488ba9' ===
  2020-05-18 13:33:47.083652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200518
  2020-05-18 13:33:49.854423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
  2020-05-18 13:33:50.730828: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  2020-05-18 13:33:50.730912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-18 13:33:59.814688: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-18 13:33:59.829739: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199950000 Hz
  2020-05-18 13:33:59.832684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bdc80342d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-18 13:33:59.832729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  2020-05-18 13:34:04.449018: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5955 - precision: 0.2521 - recall: 0.67672020-05-18 13:34:20.946147: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session start
  ed.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-18 13:34:23.531770: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23
  2020-05-18 13:34:23.550586: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.trace.
  json.gz
  2020-05-18 13:34:23.583376: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23
  2020-05-18 13:34:23.583511: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login
  01.memory_profile.json.gz
  2020-05-18 13:34:23.585938: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23Dumped tool data for xplane.pb to /tm
  p/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.kernel_stats.pb

  32/32 [==============================] - 88s 3s/step - loss: 1.6827 - precision: 0.1826 - recall: 0.5827 - val_loss: 1.5554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 2/10
  32/32 [==============================] - 91s 3s/step - loss: 1.5697 - precision: 0.2669 - recall: 0.6891 - val_loss: 1.5072 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 101s 3s/step - loss: 1.5357 - precision: 0.2908 - recall: 0.7327 - val_loss: 1.5211 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 4/10
  32/32 [==============================] - 102s 3s/step - loss: 1.4519 - precision: 0.3782 - recall: 0.7689 - val_loss: 1.5255 - val_precision: 0.2251 - val_recall: 0.1232
  Epoch 5/10
  32/32 [==============================] - 101s 3s/step - loss: 1.4212 - precision: 0.4075 - recall: 0.7919 - val_loss: 1.6413 - val_precision: 0.1982 - val_recall: 0.9612
  Epoch 6/10
  32/32 [==============================] - 98s 3s/step - loss: 1.3310 - precision: 0.5277 - recall: 0.7944 - val_loss: 1.9848 - val_precision: 0.2311 - val_recall: 0.9998
  Epoch 7/10
  32/32 [==============================] - 100s 3s/step - loss: 1.3171 - precision: 0.5449 - recall: 0.8033 - val_loss: 3.1224 - val_precision: 0.2024 - val_recall: 0.9998
  Epoch 8/10
  32/32 [==============================] - 99s 3s/step - loss: 1.2777 - precision: 0.6249 - recall: 0.7834 - val_loss: 4.5112 - val_precision: 0.1568 - val_recall: 0.9999
  Epoch 9/10
  32/32 [==============================] - 94s 3s/step - loss: 1.2667 - precision: 0.6519 - recall: 0.7669 - val_loss: 5.7424 - val_precision: 0.1783 - val_recall: 0.9999
  Epoch 10/10
  32/32 [==============================] - 92s 3s/step - loss: 1.2452 - precision: 0.6915 - recall: 0.7438 - val_loss: 7.1441 - val_precision: 0.1718 - val_recall: 0.9999
  20/20 [==============================] - 10s 507ms/step - loss: 6.5700 - precision: 0.2301 - recall: 0.9999
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:467: set_learning_phase (from tensorflow.pyth
  on.keras.backend) is deprecated and will be removed after 2020-10-11.
  Instructions for updating:
  Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:105: Model.state_updates (from t
  ensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
  Instructions for updating:
  This property should not be used in TensorFlow 2.0, as updates are applied automatically.
  2020-05-18 13:51:19.183519: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  2020/05/18 13:51:53 INFO mlflow.projects: === Run (ID '6030cbbeacbb4dfab851ac8429488ba9') succeeded ===
  (base) [ye53nis@login01 drmed-git]$ srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
#+end_example

now another run on the compute node:

*** Second run: on compute node node154

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  2020/05/18 14:26:02 INFO mlflow.projects: === Created directory /tmp/tmpde53ox06 for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/18 14:26:02 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '47b870b8fdcb4445956635c6758caff3' ===
  2020-05-18 14:26:04.138662: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No
   such file or directory
  2020-05-18 14:26:04.138707: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200518
  2020-05-18 14:26:06.305976: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file
   or directory
  2020-05-18 14:26:06.306047: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
  2020-05-18 14:26:06.306099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node154): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-18 14:26:12.857798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 AVX512F FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-18 14:26:12.868945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
  2020-05-18 14:26:12.870348: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603d3478fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-18 14:26:12.870375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  2020-05-18 14:26:15.904378: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 2.0230 - precision: 0.0936 - recall: 0.88482020-05-18 14:26:26.530926: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session start
  ed.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-18 14:26:28.032343: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28
  2020-05-18 14:26:28.045887: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.trace.
  json.gz
  2020-05-18 14:26:28.070875: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28
  2020-05-18 14:26:28.070984: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node1
  54.memory_profile.json.gz
  2020-05-18 14:26:28.072919: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28Dumped tool data for xplane.pb to /tm
  p/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.kernel_stats.pb

  32/32 [==============================] - 50s 2s/step - loss: 1.7921 - precision: 0.2086 - recall: 0.8982 - val_loss: 1.5784 - val_precision: 0.2057 - val_recall: 1.0000
  Epoch 2/10
  32/32 [==============================] - 48s 2s/step - loss: 1.6970 - precision: 0.2366 - recall: 0.9222 - val_loss: 1.6132 - val_precision: 0.1891 - val_recall: 1.0000
  Epoch 3/10
  32/32 [==============================] - 48s 2s/step - loss: 1.6142 - precision: 0.2712 - recall: 0.9049 - val_loss: 1.6398 - val_precision: 0.1917 - val_recall: 1.0000
  Epoch 4/10
  32/32 [==============================] - 48s 2s/step - loss: 1.5621 - precision: 0.2899 - recall: 0.8792 - val_loss: 1.6188 - val_precision: 0.2525 - val_recall: 1.0000
  Epoch 5/10
  32/32 [==============================] - 48s 1s/step - loss: 1.4915 - precision: 0.3355 - recall: 0.8279 - val_loss: 1.7816 - val_precision: 0.1860 - val_recall: 1.0000
  Epoch 6/10
  32/32 [==============================] - 48s 2s/step - loss: 1.4568 - precision: 0.3536 - recall: 0.8211 - val_loss: 1.9675 - val_precision: 0.1700 - val_recall: 1.0000
  Epoch 7/10
  32/32 [==============================] - 47s 1s/step - loss: 1.4014 - precision: 0.4098 - recall: 0.8084 - val_loss: 2.1148 - val_precision: 0.2111 - val_recall: 1.0000
  Epoch 8/10
  32/32 [==============================] - 48s 1s/step - loss: 1.3445 - precision: 0.4934 - recall: 0.7803 - val_loss: 2.6163 - val_precision: 0.1837 - val_recall: 1.0000
  Epoch 9/10
  32/32 [==============================] - 47s 1s/step - loss: 1.3220 - precision: 0.5309 - recall: 0.7776 - val_loss: 3.3168 - val_precision: 0.1834 - val_recall: 1.0000
  Epoch 10/10
  32/32 [==============================] - 47s 1s/step - loss: 1.3392 - precision: 0.5165 - recall: 0.7429 - val_loss: 3.9804 - val_precision: 0.1917 - val_recall: 1.0000
  20/20 [==============================] - 6s 285ms/step - loss: 3.7660 - precision: 0.2301 - recall: 1.0000
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:467: set_learning_phase (from tensorflow.pyth
  on.keras.backend) is deprecated and will be removed after 2020-10-11.
  Instructions for updating:
  Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:105: Model.state_updates (from t
  ensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
  Instructions for updating:
  This property should not be used in TensorFlow 2.0, as updates are applied automatically.
  2020-05-18 14:34:57.167560: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  2020/05/18 14:35:15 INFO mlflow.projects: === Run (ID '47b870b8fdcb4445956635c6758caff3') succeeded ===
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$
#+end_example

*** Analyzing and comparing the runs
- comparison run on compute node vs run on login node: same results
- comparison run on compute node now on 2020/05/18
  (47b870b8fdcb4445956635c6758caff3) vs run on 2020/05/02
  (cda4eec66a6947c38ec2ee2006563ae5)
  - =malformed experiment '1'= error in beginning gone
  - mlflow env activation changed
  #+BEGIN_SRC sh
  source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2
  #+END_SRC
  became
  #+BEGIN_SRC sh
  source /cluster/miniconda3/bin/../etc/profile.d/conda.sh &&
  conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2
  #+END_SRC
- new warning: =libcudart=, =libcuda=, etc, because I use
  ~tf.config.list_physical_devices('GPU')~ to check if GPUs are on the machine
- same deprecation warning of for =imp= → I think that's an mlflow thing,
  which they have to change
- message about available intel / amd extensions, if you compile tf manually
  changed:
  #+BEGIN_SRC sh
  # Your CPU supports instructions that this TensorFlow binary was not compiled to
  # use: SSE4.1 SSE4.2 AVX AVX2 FMA

  #+END_SRC
  became
  #+BEGIN_SRC sh
  # This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following
  # CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
  # To enable them in other operations, rebuild TensorFlow with the appropriate
  # compiler flags.
  #+END_SRC
  which, taken together, seems to imply that *AVX2* and *FMA* speed-ups are now
  used automatically?
- still =collections.abc= warning → mlflow has to fix this
- still deprecation warning: =inspect.getargspec()= → has to be fixed by mlflow
- =batch_param= logging failed warning → gone :)
- model serialization → works :) → new =profiler= / =I= stdout messages from
  tensorflow seem to come from the feedback on model logging etc.
- new deprecation warning: =tensorflow.python.eager.profiler.stop= → use
  =tf.profiler.experimental.stop= instead → mlflow has to fix this
- =mlflow.log_metrics= warning → Metrics after epoch are working now :)
- new deprecation warning: =tensorflow.python.keras.backend.set_learning.phase=
  → instead pass a True/False value to `training` argument of the `__call__`
  method of your layer or model
  + see [[https://www.tensorflow.org/api_docs/python/tf/keras/Model][here]]: you can optionally have =training= argument where you can specify
    different behaviour fo rtraining and inference:
    #+BEGIN_SRC python
    import tensorflow as tf

    class MyModel(tf.keras.Model):

      def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
        self.dropout = tf.keras.layers.Dropout(0.5)

      def call(self, inputs, training=False):
        x = self.dense1(inputs)
        if training:
          x = self.dropout(x, training=training)
        return self.dense2(x)

    model = MyModel()
    #+END_SRC
  + Probably I should check if I pass the =training= argument for
    =tf.keras.layers.BatchNormalization=, which behave differnetly during inference
  + looks like I don't use =tf.keras.layers.Dropout= in my current UNET → check if
    that might be a good idea and if a =training= argument should be used as well
- on that note: check if I should pass `data_format='channels_last'` to
  =tf.keras.layers.MaxPool1D()=, it could be that this needs to be specified
- deprecation warning:
  =tensorflow.python.keras.engine.training.Model.state_updates= should not be
  used in TF 2.0, as updates are applied automatically → I think thats a mlflow thing


** Reading out mlflow logs
*** Read out mlflow logs using CLI

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
  cd Programme/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  mlflow experiments list
#+END_SRC

#+RESULTS:
#+begin_example
    Experiment Id  Name         Artifact Location
  ---------------  -----------  --------------------
                0  Default      file:./data/mlruns/0
                1  exp-devtest  file:./data/mlruns/1
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow runs list --experiment-id 1
#+END_SRC

#+RESULTS:
#+begin_example
  Date                      Name    ID
  ------------------------  ------  --------------------------------
  2020-05-18 14:26:01 CEST          47b870b8fdcb4445956635c6758caff3
  2020-05-02 14:46:59 CEST          cda4eec66a6947c38ec2ee2006563ae5
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a model
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a model_summary.txt
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a tensorboard_logs/train/
#+END_SRC

#+RESULTS:
#+begin_example
  [{
    "path": "model",
    "is_dir": true
  }, {
    "path": "model_summary.txt",
    "is_dir": false,
    "file_size": "10895"
  }, {
    "path": "tensorboard_logs",
    "is_dir": true
  }]

  [{
    "path": "model/MLmodel",
    "is_dir": false,
    "file_size": "317"
  }, {
    "path": "model/conda.yaml",
    "is_dir": false,
    "file_size": "125"
  }, {
    "path": "model/data",
    "is_dir": true
  }]

  []

  [{
    "path": "tensorboard_logs/train/events.out.tfevents.1589804775.node154.340188.9307.v2",
    "is_dir": false,
    "file_size": "1316019"
  }, {
    "path": "tensorboard_logs/train/events.out.tfevents.1589804788.node154.profile-empty",
    "is_dir": false,
    "file_size": "40"
  }, {
    "path": "tensorboard_logs/train/plugins",
    "is_dir": true
  }]

#+end_example

#+BEGIN_SRC tmux :session local
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a model
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a model_summary.txt
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model_summary.txt
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow runs describe --run-id 47b870b8fdcb4445956635c6758caff3
#+END_SRC

#+RESULTS:
#+begin_example
  {
      "info": {
          "artifact_uri": "file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts",
          "end_time": 1589805315615,
          "experiment_id": "1",
          "lifecycle_stage": "active",
          "run_id": "47b870b8fdcb4445956635c6758caff3",
          "run_uuid": "47b870b8fdcb4445956635c6758caff3",
          "start_time": 1589804761334,
          "status": "FINISHED",
          "user_id": "ye53nis"
      },
      "data": {
          "metrics": {
              "val_loss": 3.980361223220825,
              "precision": 0.5165262222290039,
              "loss": 1.3392401933670044,
              "recall": 0.7429076433181763,
              "val_precision": 0.19168148934841156,
              "val_recall": 0.999984085559845
          },
          "params": {
              "opt_beta_1": "0.9",
              "validation_steps": "8",
              "opt_learning_rate": "1e-05",
              "fluotracify_path": "/beegfs/ye53nis/drmed-git/src/",
              "opt_amsgrad": "False",
              "frac_val": "0.2",
              "batch_size": "5",
              "epochs": "10",
              "opt_decay": "0.0",
              "steps_per_epoch": "32",
              "length_delimiter": "16384",
              "opt_name": "Adam",
              "opt_beta_2": "0.999",
              "csv_path": "/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/",
              "learning_rate": "1e-5",
              "opt_epsilon": "1e-07"
          },
          "tags": {
              "mlflow.source.git.repoURL": "https://github.com/aseltmann/fluotracify",
              "mlflow.source.type": "PROJECT",
              "mlflow.source.name": "file:///beegfs/ye53nis/drmed-git",
              "mlflow.user": "ye53nis",
              "mlflow.source.git.commit": "8ebdd343fc404fe06ef3446fd941255c0103cd46",
              "mlflow.gitRepoURL": "https://github.com/aseltmann/fluotracify",
              "mlflow.project.backend": "local",
              "mlflow.project.env": "conda",
              "mlflow.project.entryPoint": "main",
              "mlflow.log-model.history": "[{\"run_id\":
              \"47b870b8fdcb4445956635c6758caff3\", \"artifact_path\": \"model\",
              \"utc_time_created\": \"2020-05-18 12:34:40.557190\", \"flavors\": {\"keras\":
              {\"keras_module\": \"tensorflow.keras\", \"keras_version\": \"2.2.4-tf\",
              \"data\": \"data\"}, \"python_function\": {\"loader_module\":
              \"mlflow.keras\", \"python_version\": \"3.8.2\", \"data\": \"data\", \"env\":
              \"conda.yaml\"}}}]"
          }
      }
  }

#+end_example


#+BEGIN_SRC tmux :session local
  tensorboard --logdir=data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
  TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow ui --backend-store-uri file:///home/lex/Programme/drmed-git/data/mlruns
#+END_SRC

#+RESULTS:
#+begin_example
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Starting gunicorn 20.0.4
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Listening at: http://127.0.0.1:5000 (17669)
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Using worker: sync
  [2020-05-19 02:39:46 +0200] [17672] [INFO] Booting worker with pid: 17672
  [2020-05-19 02:44:24 +0200] [17669] [INFO] Handling signal: int
  [2020-05-19 02:44:24 +0200] [17672] [INFO] Worker exiting (pid: 17672)

  Aborted!
  [2020-05-19 02:44:24 +0200] [17669] [INFO] Shutting down: Master

#+end_example

*** Reading out mlflow logs with Python API
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:6a1a0d19-628d-46a2-b9e0-bacf4f087ead
   :END:
   :LOGBOOK:
   CLOCK: [2020-05-19 Di 16:37]--[2020-05-19 Di 17:06] =>  0:29
   CLOCK: [2020-05-19 Di 14:38]--[2020-05-19 Di 16:17] =>  1:39
   :END:

I started a local jupyter session 83f7c448-cc36-44cd-81f9-749b3b4b2d0c.

The following codesnippet comming originally from [[https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks][ob-ipython]] sets up =tabulate=
to display pandas DataFrames as org tables.

#+BEGIN_SRC jupyter-python
  import IPython
  from tabulate import tabulate

  class OrgFormatter(IPython.core.formatters.BaseFormatter):
      def __call__(self, obj):
          try:
              return tabulate(obj, headers='keys',
                              tablefmt='orgtbl', showindex='always')
          except:
              return None

  ip = get_ipython()
  ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  import mlflow
  %cd /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
: /home/lex/Programme/drmed-git

#+BEGIN_SRC jupyter-python
  uri = 'file:///home/lex/Programme/drmed-git/data/mlruns'
  mlflow.set_tracking_uri(uri)
  runs = mlflow.search_runs(experiment_ids='1')
  print('run_id of first in list: ', runs.iloc[0].run_id)
  print('no of runs in list: ', len(runs))
  print()
  runs
#+END_SRC

#+RESULTS:
:RESULTS:
: run_id of first in list:  47b870b8fdcb4445956635c6758caff3
: no of runs in list:  2
:
|    | run_id                           |   experiment_id | status   | artifact_uri                                                    | start_time                       | end_time                         |   metrics.val_loss |   metrics.recall |   metrics.precision |   metrics.val_recall |   metrics.loss |   metrics.val_precision |   params.opt_beta_2 |   params.opt_beta_1 |   params.frac_val | params.fluotracify_path        |   params.epochs | params.opt_name   |   params.length_delimiter | params.csv_path                                        |   params.learning_rate |   params.opt_decay | params.opt_amsgrad   | params.validation_steps                 | params.steps_per_epoch                   |   params.opt_learning_rate |   params.batch_size |   params.opt_epsilon | tags.mlflow.log-model.history                                                                                                                                                                                                                                                                                                                               | tags.mlflow.project.backend   | tags.mlflow.user   | tags.mlflow.project.env   | tags.mlflow.source.name          | tags.mlflow.gitRepoURL                   | tags.mlflow.source.git.repoURL           | tags.mlflow.project.entryPoint   | tags.mlflow.source.type   | tags.mlflow.source.git.commit            |
|----+----------------------------------+-----------------+----------+-----------------------------------------------------------------+----------------------------------+----------------------------------+--------------------+------------------+---------------------+----------------------+----------------+-------------------------+---------------------+---------------------+-------------------+--------------------------------+-----------------+-------------------+---------------------------+--------------------------------------------------------+------------------------+--------------------+----------------------+-----------------------------------------+------------------------------------------+----------------------------+---------------------+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+--------------------+---------------------------+----------------------------------+------------------------------------------+------------------------------------------+----------------------------------+---------------------------+------------------------------------------|
|  0 | 47b870b8fdcb4445956635c6758caff3 |               1 | FINISHED | file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts | 2020-05-18 12:26:01.334000+00:00 | 2020-05-18 12:35:15.615000+00:00 |            3.98036 |         0.742908 |            0.516526 |             0.999984 |        1.33924 |                0.191681 |               0.999 |                 0.9 |               0.2 | /beegfs/ye53nis/drmed-git/src/ |              10 | Adam              |                     16384 | /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/ |                  1e-05 |                  0 | False                | 8                                       | 32                                       |                      1e-05 |                   5 |                1e-07 | [{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}] | local                         | ye53nis            | conda                     | file:///beegfs/ye53nis/drmed-git | https://github.com/aseltmann/fluotracify | https://github.com/aseltmann/fluotracify | main                             | PROJECT                   | 8ebdd343fc404fe06ef3446fd941255c0103cd46 |
|  1 | cda4eec66a6947c38ec2ee2006563ae5 |               1 | FINISHED | file:./data/mlruns/1/cda4eec66a6947c38ec2ee2006563ae5/artifacts | 2020-05-02 12:46:59.699000+00:00 | 2020-05-02 13:07:38.258000+00:00 |          nan       |       nan        |          nan        |           nan        |      nan       |              nan        |               0.999 |                 0.9 |               0.2 | /beegfs/ye53nis/drmed-git/src/ |              10 | Adam              |                     16384 | /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/ |                  1e-05 |                  0 | False                | tf.Tensor(8.0, shape=(), dtype=float32) | tf.Tensor(32.0, shape=(), dtype=float32) |                      1e-05 |                   5 |                1e-07 |                                                                                                                                                                                                                                                                                                                                                             | local                         | ye53nis            | conda                     | file:///beegfs/ye53nis/drmed-git | https://github.com/aseltmann/fluotracify | https://github.com/aseltmann/fluotracify | main                             | PROJECT                   | 9e6182fbeae831a151342827efa59581e4310ae6 |
:END:

#+BEGIN_SRC jupyter-python
  client = mlflow.tracking.MlflowClient(tracking_uri=uri)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  # mlflow.entities.Experiment
  exps = client.list_experiments()
  print('client.list_experiments()\n', exps, '\n')

  exp = client.get_experiment('1')
  # Nice printing as protocol buffer:
  print('client.get_experiment("1")\n', exp.to_proto())

  # get mlflow.entities.RunInfo (see below) for all exps
  print('client.list_run_infos(exp_id)\n', client.list_run_infos(exp.experiment_id))

  # you can also rename experiments
  #client.rename_experiment()
#+END_SRC

#+RESULTS:
#+begin_example
  client.list_experiments()
   [<Experiment: artifact_location='file:./data/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='file:./data/mlruns/1', experiment_id='1', lifecycle_stage='active', name='exp-devtest', tags={}>]

  client.get_experiment("1")
   experiment_id: "1"
  name: "exp-devtest"
  artifact_location: "file:./data/mlruns/1"
  lifecycle_stage: "active"

  client.list_run_infos(exp_id)
   [<RunInfo: artifact_uri='file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts', end_time=1589805315615, experiment_id='1', lifecycle_stage='active', run_id='47b870b8fdcb4445956635c6758caff3', run_uuid='47b870b8fdcb4445956635c6758caff3', start_time=1589804761334, status='FINISHED', user_id='ye53nis'>, <RunInfo: artifact_uri='file:./data/mlruns/1/cda4eec66a6947c38ec2ee2006563ae5/artifacts', end_time=1588424858258, experiment_id='1', lifecycle_stage='active', run_id='cda4eec66a6947c38ec2ee2006563ae5', run_uuid='cda4eec66a6947c38ec2ee2006563ae5', start_time=1588423619699, status='FINISHED', user_id='ye53nis'>]
#+end_example

#+BEGIN_SRC jupyter-python
  # mlflow.entities.Metric
  metent = client.get_metric_history(run_id=runs.iloc[0].run_id, key='loss')

  for i in metent:
      print(i)
#+END_SRC

#+RESULTS:
: <Metric: key='loss', step=0, timestamp=1589804835950, value=1.7921358346939087>
: <Metric: key='loss', step=1, timestamp=1589804886131, value=1.6969826221466064>
: <Metric: key='loss', step=2, timestamp=1589804936042, value=1.6142021417617798>
: <Metric: key='loss', step=3, timestamp=1589804985594, value=1.5620886087417603>
: <Metric: key='loss', step=4, timestamp=1589805034880, value=1.4914946556091309>
: <Metric: key='loss', step=5, timestamp=1589805084727, value=1.4567521810531616>
: <Metric: key='loss', step=6, timestamp=1589805133659, value=1.4014478921890259>
: <Metric: key='loss', step=7, timestamp=1589805182769, value=1.3445260524749756>
: <Metric: key='loss', step=8, timestamp=1589805231560, value=1.3219550848007202>
: <Metric: key='loss', step=9, timestamp=1589805280539, value=1.3392401933670044>

#+BEGIN_SRC jupyter-python
# mlflow.entities.Run
# with two display methods to_proto and to_dictionary
# and two properties which return another entity:
# mlflow.entities.RunInfo and mlflow.entities.RunData
print('- - - mlflow.entities.Run - - -')
run = client.get_run(runs.iloc[0].run_id)

# mlflow.entities.RunData has 3 properties, accessing them
# directly is the same as calling to_dictionary()
print('- - - mlflow.entities.RunData - - - ')
print('run.data.metrics\n', run.data.metrics, '\n')
print('run.data.params\n', run.data.params, '\n')
print('run.data.tags\n', run.data.tags, '\n')
print('run.data.to_dictionary()["tags"]\n', run.data.to_dictionary()['tags'], '\n')
# Accessing as a Google protocol buffer
print('run.data.to_proto()\n', run.data.to_proto(), '\n')

# mlflow.entities.RunInfo has 9 properties. Accessing them
# directly gives you their values
print('- - - mlflow.entities.RunInfo - - -')
print('run.info.experiment_id\n', run.info.experiment_id, '\n')
print('run.info.run_id\n', run.info.run_id, '\n')

print('run.info.to_proto\n', run.info.to_proto())
print('run.info.get_searchable_attributes\n', run.info.get_searchable_attributes())
print('run.info.get_orderable_attributes\n', run.info.get_orderable_attributes())

# mlflow.entities.RunStatus is one of the 9 properties of RunInfo
# it can one of five states:
print('- - - mlflow.entities.RunStatus - - -')
allstats = mlflow.entities.RunStatus.all_status()
print({i: mlflow.entities.RunStatus.to_string(i) for i in allstats}, '\n')
print('run.info.status\n', run.info.status, '\n')
print('mlflow.entities.RunStatus.from_string(run.info.status)')
print(mlflow.entities.RunStatus.from_string(run.info.status), '\n')
#+END_SRC

#+RESULTS:
#+begin_example
  - - - mlflow.entities.Run - - -
  - - - mlflow.entities.RunData - - -
  run.data.metrics
   {'val_loss': 3.980361223220825, 'precision': 0.5165262222290039, 'loss': 1.3392401933670044, 'recall': 0.7429076433181763, 'val_precision': 0.19168148934841156, 'val_recall': 0.999984085559845}

  run.data.params
   {'opt_beta_1': '0.9', 'validation_steps': '8', 'opt_learning_rate': '1e-05', 'fluotracify_path': '/beegfs/ye53nis/drmed-git/src/', 'opt_amsgrad': 'False', 'frac_val': '0.2', 'batch_size': '5', 'epochs': '10', 'opt_decay': '0.0', 'steps_per_epoch': '32', 'length_delimiter': '16384', 'opt_name': 'Adam', 'opt_beta_2': '0.999', 'csv_path': '/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/', 'learning_rate': '1e-5', 'opt_epsilon': '1e-07'}

  run.data.tags
   {'mlflow.source.git.repoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.source.type': 'PROJECT', 'mlflow.source.name': 'file:///beegfs/ye53nis/drmed-git', 'mlflow.user': 'ye53nis', 'mlflow.source.git.commit': '8ebdd343fc404fe06ef3446fd941255c0103cd46', 'mlflow.gitRepoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.project.backend': 'local', 'mlflow.project.env': 'conda', 'mlflow.project.entryPoint': 'main', 'mlflow.log-model.history': '[{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}]'}

  run.data.to_dictionary()["tags"]
   {'mlflow.source.git.repoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.source.type': 'PROJECT', 'mlflow.source.name': 'file:///beegfs/ye53nis/drmed-git', 'mlflow.user': 'ye53nis', 'mlflow.source.git.commit': '8ebdd343fc404fe06ef3446fd941255c0103cd46', 'mlflow.gitRepoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.project.backend': 'local', 'mlflow.project.env': 'conda', 'mlflow.project.entryPoint': 'main', 'mlflow.log-model.history': '[{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}]'}

  run.data.to_proto()
   metrics {
    key: "val_loss"
    value: 3.980361223220825
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "precision"
    value: 0.5165262222290039
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "loss"
    value: 1.3392401933670044
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "recall"
    value: 0.7429076433181763
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "val_precision"
    value: 0.19168148934841156
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "val_recall"
    value: 0.999984085559845
    timestamp: 1589805280539
    step: 9
  }
  params {
    key: "opt_beta_1"
    value: "0.9"
  }
  params {
    key: "validation_steps"
    value: "8"
  }
  params {
    key: "opt_learning_rate"
    value: "1e-05"
  }
  params {
    key: "fluotracify_path"
    value: "/beegfs/ye53nis/drmed-git/src/"
  }
  params {
    key: "opt_amsgrad"
    value: "False"
  }
  params {
    key: "frac_val"
    value: "0.2"
  }
  params {
    key: "batch_size"
    value: "5"
  }
  params {
    key: "epochs"
    value: "10"
  }
  params {
    key: "opt_decay"
    value: "0.0"
  }
  params {
    key: "steps_per_epoch"
    value: "32"
  }
  params {
    key: "length_delimiter"
    value: "16384"
  }
  params {
    key: "opt_name"
    value: "Adam"
  }
  params {
    key: "opt_beta_2"
    value: "0.999"
  }
  params {
    key: "csv_path"
    value: "/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/"
  }
  params {
    key: "learning_rate"
    value: "1e-5"
  }
  params {
    key: "opt_epsilon"
    value: "1e-07"
  }
  tags {
    key: "mlflow.source.git.repoURL"
    value: "https://github.com/aseltmann/fluotracify"
  }
  tags {
    key: "mlflow.source.type"
    value: "PROJECT"
  }
  tags {
    key: "mlflow.source.name"
    value: "file:///beegfs/ye53nis/drmed-git"
  }
  tags {
    key: "mlflow.user"
    value: "ye53nis"
  }
  tags {
    key: "mlflow.source.git.commit"
    value: "8ebdd343fc404fe06ef3446fd941255c0103cd46"
  }
  tags {
    key: "mlflow.gitRepoURL"
    value: "https://github.com/aseltmann/fluotracify"
  }
  tags {
    key: "mlflow.project.backend"
    value: "local"
  }
  tags {
    key: "mlflow.project.env"
    value: "conda"
  }
  tags {
    key: "mlflow.project.entryPoint"
    value: "main"
  }
  tags {
    key: "mlflow.log-model.history"
    value: "[{\"run_id\": \"47b870b8fdcb4445956635c6758caff3\", \"artifact_path\": \"model\", \"utc_time_created\": \"2020-05-18 12:34:40.557190\", \"flavors\": {\"keras\": {\"keras_module\": \"tensorflow.keras\", \"keras_version\": \"2.2.4-tf\", \"data\": \"data\"}, \"python_function\": {\"loader_module\": \"mlflow.keras\", \"python_version\": \"3.8.2\", \"data\": \"data\", \"env\": \"conda.yaml\"}}}]"
  }


  - - - mlflow.entities.RunInfo - - -
  run.info.experiment_id
   1

  run.info.run_id
   47b870b8fdcb4445956635c6758caff3

  run.info.to_proto
   run_uuid: "47b870b8fdcb4445956635c6758caff3"
  experiment_id: "1"
  user_id: "ye53nis"
  status: FINISHED
  start_time: 1589804761334
  end_time: 1589805315615
  artifact_uri: "file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts"
  lifecycle_stage: "active"
  run_id: "47b870b8fdcb4445956635c6758caff3"

  run.info.get_searchable_attributes
   ['artifact_uri', 'status']
  run.info.get_orderable_attributes
   ['artifact_uri', 'end_time', 'start_time', 'status']
  - - - mlflow.entities.RunStatus - - -
  {1: 'RUNNING', 2: 'SCHEDULED', 3: 'FINISHED', 4: 'FAILED', 5: 'KILLED'}

  run.info.status
   FINISHED

  mlflow.entities.RunStatus.from_string(run.info.status)
  3
#+end_example

#+BEGIN_SRC jupyter-python :results scalar
run_idx = 0
# mlflow.entities.FileInfo
# 3 properties, to_proto() available
finfo = client.list_artifacts(run_id=runs.iloc[run_idx].run_id)
finfo
#+END_SRC

#+RESULTS:
: [<FileInfo: file_size=None, is_dir=True, path='model'>,
:  <FileInfo: file_size=10895, is_dir=False, path='model_summary.txt'>,
:  <FileInfo: file_size=None, is_dir=True, path='tensorboard_logs'>]

# FIXME: Why does client.list_artifacts() not work here? It works in Jupyter notebooks.

#+BEGIN_SRC jupyter-python
model_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='model')
tensorboard_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='tensorboard_logs')
summary_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='model_summary.txt')
print(model_path)
print(tensorboard_path)
print(summary_path)
#+END_SRC

#+RESULTS:
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model_summary.txt

#+BEGIN_SRC jupyter-python
  !ls $model_path
  print()
  !ls $model_path/data
#+END_SRC

#+RESULTS:
: conda.yaml  data  MLmodel
:
: keras_module.txt  model.h5

#+BEGIN_SRC jupyter-python
  %cat $model_path/MLmodel
  print()
  %cat $model_path/conda.yaml
  print()
  %cat $model_path/data/keras_module.txt
#+END_SRC

#+RESULTS:
#+begin_example
  artifact_path: model
  flavors:
    keras:
      data: data
      keras_module: tensorflow.keras
      keras_version: 2.2.4-tf
    python_function:
      data: data
      env: conda.yaml
      loader_module: mlflow.keras
      python_version: 3.8.2
  run_id: 47b870b8fdcb4445956635c6758caff3
  utc_time_created: '2020-05-18 12:34:40.557190'

  channels:
  - defaults
  dependencies:
  - python=3.8.2
  - pip
  - pip:
    - mlflow
    - tensorflow==2.3.0-dev20200518
  name: mlflow-env

  tensorflow.keras
#+end_example

#+BEGIN_SRC jupyter-python
  %cat $summary_path
#+END_SRC

#+RESULTS:
#+begin_example
  Model: "functional_1"
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            [(None, 16384, 1)]   0
  __________________________________________________________________________________________________
  encode0 (Sequential)            (None, 16384, 64)    13120       input_1[0][0]
  __________________________________________________________________________________________________
  mp_encode0 (MaxPooling1D)       (None, 8192, 64)     0           encode0[0][0]
  __________________________________________________________________________________________________
  encode1 (Sequential)            (None, 8192, 128)    75008       mp_encode0[0][0]
  __________________________________________________________________________________________________
  mp_encode1 (MaxPooling1D)       (None, 4096, 128)    0           encode1[0][0]
  __________________________________________________________________________________________________
  encode2 (Sequential)            (None, 4096, 256)    297472      mp_encode1[0][0]
  __________________________________________________________________________________________________
  mp_encode2 (MaxPooling1D)       (None, 2048, 256)    0           encode2[0][0]
  __________________________________________________________________________________________________
  encode3 (Sequential)            (None, 2048, 512)    1184768     mp_encode2[0][0]
  __________________________________________________________________________________________________
  mp_encode3 (MaxPooling1D)       (None, 1024, 512)    0           encode3[0][0]
  __________________________________________________________________________________________________
  encode4 (Sequential)            (None, 1024, 512)    1577984     mp_encode3[0][0]
  __________________________________________________________________________________________________
  mp_encode4 (MaxPooling1D)       (None, 512, 512)     0           encode4[0][0]
  __________________________________________________________________________________________________
  encode5 (Sequential)            (None, 512, 512)     1577984     mp_encode4[0][0]
  __________________________________________________________________________________________________
  mp_encode5 (MaxPooling1D)       (None, 256, 512)     0           encode5[0][0]
  __________________________________________________________________________________________________
  encode6 (Sequential)            (None, 256, 512)     1577984     mp_encode5[0][0]
  __________________________________________________________________________________________________
  mp_encode6 (MaxPooling1D)       (None, 128, 512)     0           encode6[0][0]
  __________________________________________________________________________________________________
  encode7 (Sequential)            (None, 128, 512)     1577984     mp_encode6[0][0]
  __________________________________________________________________________________________________
  mp_encode7 (MaxPooling1D)       (None, 64, 512)      0           encode7[0][0]
  __________________________________________________________________________________________________
  encode8 (Sequential)            (None, 64, 512)      1577984     mp_encode7[0][0]
  __________________________________________________________________________________________________
  mp_encode8 (MaxPooling1D)       (None, 32, 512)      0           encode8[0][0]
  __________________________________________________________________________________________________
  two_conv_center (Sequential)    (None, 32, 1024)     4728832     mp_encode8[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder8 (Sequen (None, 64, 512)      1051136     two_conv_center[0][0]
  __________________________________________________________________________________________________
  decoder8 (Concatenate)          (None, 64, 1024)     0           encode8[0][0]
                                                                   conv_transpose_decoder8[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder8 (Sequential)  (None, 64, 512)      2364416     decoder8[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder7 (Sequen (None, 128, 512)     526848      two_conv_decoder8[0][0]
  __________________________________________________________________________________________________
  decoder7 (Concatenate)          (None, 128, 1024)    0           encode7[0][0]
                                                                   conv_transpose_decoder7[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder7 (Sequential)  (None, 128, 512)     2364416     decoder7[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder6 (Sequen (None, 256, 512)     526848      two_conv_decoder7[0][0]
  __________________________________________________________________________________________________
  decoder6 (Concatenate)          (None, 256, 1024)    0           encode6[0][0]
                                                                   conv_transpose_decoder6[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder6 (Sequential)  (None, 256, 512)     2364416     decoder6[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder5 (Sequen (None, 512, 512)     526848      two_conv_decoder6[0][0]
  __________________________________________________________________________________________________
  decoder5 (Concatenate)          (None, 512, 1024)    0           encode5[0][0]
                                                                   conv_transpose_decoder5[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder5 (Sequential)  (None, 512, 512)     2364416     decoder5[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder4 (Sequen (None, 1024, 512)    526848      two_conv_decoder5[0][0]
  __________________________________________________________________________________________________
  decoder4 (Concatenate)          (None, 1024, 1024)   0           encode4[0][0]
                                                                   conv_transpose_decoder4[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder4 (Sequential)  (None, 1024, 512)    2364416     decoder4[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder3 (Sequen (None, 2048, 512)    526848      two_conv_decoder4[0][0]
  __________________________________________________________________________________________________
  decoder3 (Concatenate)          (None, 2048, 1024)   0           encode3[0][0]
                                                                   conv_transpose_decoder3[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder3 (Sequential)  (None, 2048, 512)    2364416     decoder3[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder2 (Sequen (None, 4096, 256)    263424      two_conv_decoder3[0][0]
  __________________________________________________________________________________________________
  decoder2 (Concatenate)          (None, 4096, 512)    0           encode2[0][0]
                                                                   conv_transpose_decoder2[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder2 (Sequential)  (None, 4096, 256)    592384      decoder2[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder1 (Sequen (None, 8192, 128)    66176       two_conv_decoder2[0][0]
  __________________________________________________________________________________________________
  decoder1 (Concatenate)          (None, 8192, 256)    0           encode1[0][0]
                                                                   conv_transpose_decoder1[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder1 (Sequential)  (None, 8192, 128)    148736      decoder1[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder0 (Sequen (None, 16384, 64)    16704       two_conv_decoder1[0][0]
  __________________________________________________________________________________________________
  decoder0 (Concatenate)          (None, 16384, 128)   0           encode0[0][0]
                                                                   conv_transpose_decoder0[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder0 (Sequential)  (None, 16384, 64)    37504       decoder0[0][0]
  __________________________________________________________________________________________________
  conv1d_38 (Conv1D)              (None, 16384, 1)     65          two_conv_decoder0[0][0]
  ==================================================================================================
  Total params: 33,185,985
  Trainable params: 33,146,689
  Non-trainable params: 39,296
  __________________________________________________________________________________________________
#+end_example

*** Reading out tensorboard logs from mlflow logs
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:83f7c448-cc36-44cd-81f9-749b3b4b2d0c
   :END:
#+BEGIN_SRC jupyter-python
  !ls $tensorboard_path
#+END_SRC

#+RESULTS:
: train  validation

#+BEGIN_SRC jupyter-python
 # https://stackoverflow.com/questions/41074688/how-do-you-read-tensorboard-files-programmatically
from tensorboard.backend.event_processing import event_accumulator
path = str(tensorboard_path) + '/train'
print(path)
ea = event_accumulator.EventAccumulator(path=path,
    size_guidance={ # see below regarding this argument
        event_accumulator.COMPRESSED_HISTOGRAMS: 500,
        event_accumulator.IMAGES: 4,
        event_accumulator.AUDIO: 4,
        event_accumulator.SCALARS: 0,
        event_accumulator.HISTOGRAMS: 1,
    })

ea.Reload() # loads events from file
#+END_SRC

#+RESULTS:
:RESULTS:
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs/train
: /home/lex/Programme/miniconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_file_loader.py:61: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()
:   get_next_args = inspect.getargspec(self._reader.GetNext).args  # pylint: disable=deprecated-method
: <tensorboard.backend.event_processing.event_accumulator.EventAccumulator at 0x7faf9815dc90>
:END:

#+BEGIN_SRC jupyter-python :results scalar
  ea.Tags()
#+END_SRC

#+RESULTS:
: {'images': [],
:  'audio': [],
:  'histograms': [],
:  'scalars': ['epoch_loss', 'epoch_precision', 'epoch_recall'],
:  'distributions': [],
:  'tensors': ['keras', 'batch_2'],
:  'graph': True,
:  'meta_graph': False,
:  'run_metadata': []}

#+BEGIN_SRC jupyter-python
  ea.Scalars('epoch_loss')
#+END_SRC

#+RESULTS:
|    |   wall_time |   step |   value |
|----+-------------+--------+---------|
|  0 | 1.5898e+09  |      0 | 1.79214 |
|  1 | 1.5898e+09  |      1 | 1.69698 |
|  2 | 1.5898e+09  |      2 | 1.6142  |
|  3 | 1.5898e+09  |      3 | 1.56209 |
|  4 | 1.58981e+09 |      4 | 1.49149 |
|  5 | 1.58981e+09 |      5 | 1.45675 |
|  6 | 1.58981e+09 |      6 | 1.40145 |
|  7 | 1.58981e+09 |      7 | 1.34453 |
|  8 | 1.58981e+09 |      8 | 1.32196 |
|  9 | 1.58981e+09 |      9 | 1.33924 |

*** Load model from mlflow logs and predict separately loaded data
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:6a1a0d19-628d-46a2-b9e0-bacf4f087ead
   :END:

First, check if the model file has to be downloaded via git lfs

#+BEGIN_SRC tmux :session local
  cd /home/lex/Programme/drmed-git/
  git lfs ls-files
  git lfs checkout
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex drmed-git]$ git lfs ls-files
  6526c5abca - data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5

  (base) [lex@Topialex drmed-git]$ git lfs checkout
  Skipped checkout for
  "data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5",
  content not local. Use fetch to download.
  Checking out LFS objects: 100% (1/1), 399 MB | 0 B/s, done.
#+end_example

#+BEGIN_SRC tmux :session local
  git lfs pull
#+END_SRC

#+RESULTS:
#+begin_example
  fetch: Fetching reference refs/heads/develop
  Username for 'https://github.com': aseltmann B/s
  Password for 'https://aseltmann@github.com':
  (base) [lex@Topialex drmed-git]$ 1), 399 MB | 1.9 MB/s
#+end_example

#+BEGIN_SRC jupyter-python
  import mlflow.keras
  import mlflow.tensorflow
  import sys
  import numpy as np
  import tensorflow as tf

  fluotracify_path = '/home/lex/Programme/drmed-git/src/'
  sys.path.append(fluotracify_path)

  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
bm.binary_ce_dice_loss()
#+END_SRC

#+RESULTS:
: <function fluotracify.training.build_model.binary_ce_dice_loss.<locals>.binary_ce_dice(y_true, y_pred)>

#+BEGIN_SRC jupyter-python
  # mlflow.keras module
  model_keras = mlflow.keras.load_model(model_uri=model_path,
                                        custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()})
  model_keras
#+END_SRC

#+RESULTS:
: <tensorflow.python.keras.engine.functional.Functional at 0x7fc97830c790>

#+BEGIN_SRC jupyter-python
  data, _, nsamples, experiment_params = isfc.import_from_csv(
      path='/home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/',
      header=12,
      frac_train=1,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')
#+END_SRC

#+RESULTS:
: train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set003.csv
: train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set002.csv
: train 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set001.csv



#+BEGIN_SRC jupyter-python :results scalar
  prediction = model_keras.predict(np.array(data.iloc[:2048, 0]).reshape(1, -1, 1))
#+END_SRC

#+RESULTS:

I noticed one problem: directly outputting the =prediction= array for large
predictions (e.g. 16384 time steps), will freeze emacs. Especially with my setup
with conversion to org tables. It is possible to output it in the REPL, or print
it using =print(prediction)=, because there the output gets truncated, e.g. like
this:
#+begin_example
array([[[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]]], dtype=float32)
#+end_example
While here it tries to print everything (I guess). Maybe I should test the
=:pandoc t= argument instead of the =OrgFormatter= class

Basically, no matter if I choosnpe the =:results= header argument, it always gets
printed with =:display org= like this.

#+BEGIN_SRC jupyter-python :display org
  prediction
#+END_SRC

#+RESULTS:
|    |   0 |   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |   10 |   11 |   2043 |   2044 |   2045 |   2046 |   2047 |
|----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+--------+--------+--------+--------+--------|
|  0 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |    1 |    1 |      1 |      1 |      1 |      1 |      1 |

To make the output work the desired way (like in the REPL or =print()= and
without freezing emacs for large tables), use =:display plain=

#+BEGIN_SRC jupyter-python :display plain
  prediction
#+END_SRC

#+RESULTS:
: array([[[1.],
:         [1.],
:         [1.],
:         ...,
:         [1.],
:         [1.],
:         [1.]]], dtype=float32)


** checking some things off the TODO list
*** DONE Update mlflow and tensorflow in tensorflow_env
     CLOSED: [2020-05-20 Mi 13:46]

*** DONE Export pandas DataFrames as org tables instead of html
     CLOSED: [2020-05-20 Mi 16:08]
- see https://github.com/dzop/emacs-jupyter/issues/88
- see
  https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks

#+NAME: jp-org-formatter
#+BEGIN_SRC jupyter-python
  import IPython
  from tabulate import tabulate

  class OrgFormatter(IPython.core.formatters.BaseFormatter):
      def __call__(self, obj):
          try:
              return tabulate(obj, headers='keys',
                              tablefmt='orgtbl', showindex='always')
          except:
              return None

  ip = get_ipython()
  ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC

This script works - but it is easier to just use the =:pandoc t= header argument

*** DONE Inline-display of plots → use =C-c C-x C-v= for inline display of links to images
     CLOSED: [2020-05-20 Mi 16:09]
*** DONE transform ML training ipynb to py files as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
     CLOSED: [2020-05-20 Mi 16:10]
*** DONE [#A] Further setup of git branching model
     CLOSED: [2020-05-20 Mi 16:11]
** Changing Appearance of this org-mode document and the html export LabBook.html
   :LOGBOOK:
   CLOCK: [2020-05-12 Di 19:04]--[2020-05-12 Di 22:16] =>  3:12
   CLOCK: [2020-05-12 Di 16:59]--[2020-05-12 Di 16:59] =>  0:00
   CLOCK: [2020-05-12 Di 13:38]--[2020-05-12 Di 15:30] =>  1:52
   CLOCK: [2020-05-12 Di 12:30]--[2020-05-12 Di 13:07] =>  0:37
   :END:
I try to make it easy to distinguish different org source code blocks by visual
cues. Let's take the [[https://github.com/ozh/github-colors/blob/master/colors.json][colours Github uses]]:

- emacs-lisp: #c065db
- shell: #89e051
- python: #3572A5
- jupyter: #DA5B0B

Then I went to https://htmlcolorcodes.com/color-picker/

for tmux I chose a different *tone* coming from shell's #89e051
- #85bc62
for example blocks I chose a light yellow (html export only). Ideally this would
be set for all =#+results= - I opened a github issue with =ox-twbs= [[https://github.com/marsmining/ox-twbs/issues/59 ][here]].

- #FBFBBF

then to get lighter versions of these colours in html export i chose *tints*
coming from the respective original colour:
- emacs-lisp: #efd8f6 #F7ECFB
- shell: #d3f3be #F0FBE9
- tmux: #94c476 #E1EED8
- python: #b3cadd #E6EDF4
- jupyter-python: #f1c1a4 #FAEAE1

for colouring of code blocks inside my dark-themed Emacs setup, I chose
different *shades* coming from the respective original colour
- emacs-lisp: #482652
- shell: #223814
- tmux: #324725
- python: #142b3e
- jupyter-python: #522204 #371703 #6d2d05


#+BEGIN_SRC emacs-lisp
  (setq org-src-block-faces '(("emacs-lisp" (:background "#482652"))
                              ("sh" (:background "#223814"))
                              ("tmux" (:background "#324725"))
                              ("python" (:background "#142b3e"))
                              ("jupyter-python" (:background "#371703"))
                              ))
#+END_SRC

#+RESULTS:
| emacs-lisp     | (:background #482652) |
| sh             | (:background #223814) |
| tmux           | (:background #324725) |
| python         | (:background #142b3e) |
| jupyter-python | (:background #371703) |


Also, I found this interesting javascript export option - thats how the org mode
documentation is made
https://orgmode.org/manual/JavaScript-support.html#JavaScript-support

** Turning the attention back to =TensorBoard= logging
   :LOGBOOK:
   CLOCK: [2020-05-25 Mo 16:10]--[2020-05-25 Mo 18:07] =>  1:57
   CLOCK: [2020-05-25 Mo 14:03]--[2020-05-25 Mo 14:33] =>  0:30
   CLOCK: [2020-05-25 Mo 13:10]--[2020-05-25 Mo 13:46] =>  0:36
   CLOCK: [2020-05-23 Sa 18:52]--[2020-05-23 Sa 19:23] =>  0:31
   CLOCK: [2020-05-23 Sa 18:31]--[2020-05-23 Sa 18:52] =>  0:21
   CLOCK: [2020-05-23 Sa 18:09]--[2020-05-23 Sa 18:20] =>  0:11
   CLOCK: [2020-05-23 Sa 16:30]--[2020-05-23 Sa 16:50] =>  0:20
   CLOCK: [2020-05-22 Fr 21:57]--[2020-05-22 Fr 23:38] =>  1:41
   :END:
#+BEGIN_SRC python
  tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,
    update_freq='epoch', profile_batch=2, embeddings_freq=0,
    embeddings_metadata=None, **kwargs
)
#+END_SRC
*** about: profiler
this is automatically logged by mlflow - but i'm not sure I really need it - not
to speak of the fact, that I could not read it out yet, since tensorboard always
froze. → I should check it with a tunneled tensorboard running on a compute node.

*** DONE idea: histograms of activation and weights to debug the amount of layers etc
    CLOSED: [2020-05-23 Sa 00:12]

    - State "DONE"       from "TODO"    [2020-05-23 Sa 00:12] \\
      It just worked out of the box :)

idea: histogram_freq is frequency in epochs at which to compute activation and
weight histograms for the layers of the model. I would say get max. 10
histograms in total → for 100 epochs, freq=10?

*** DONE idea: write_images=True - difference to histograms??
    CLOSED: [2020-05-23 Sa 00:12]

It just worked out of the box - I'm still not sure if these weight plots tell me
anything more than the histograms - but I'll try to evaluate them further after
real training.

I might look into [[https://stackoverflow.com/questions/47232779/how-to-extract-and-save-images-from-tensorboard-event-summary][this]] SO issue to read out the images directly in Python.
Alternatively, I could just save them manually from TensorBoard.

*** DONE idea: image logging
    CLOSED: [2020-05-24 So 00:16]

I want a plot of a test curve with the prediction to see how more refined the
prediction gets during training.

With mlflow doing an automatic logging, it should be enough to only specify my
desired extensions, e.g. like this:

#+BEGIN_SRC python
  file_writer = tf.summary.create_file_writer(logdir + '/image')
  def log_image(epoch, logs):
      # Do a function which returns a matplotlib plot
      figure = ...
      # convert matplotlib figure to image
      image = plot_to_image(figure)
      # Log the image as an image summary.
      with file_writer.as_default():
          tf.summary.image("My image", image, step=epoch)
  image_callback = tf.keras.callbacks.LambdaCallback(
      on_epoch_end=log_image)
#+END_SRC

With the following helper function which turns a matplotlib plot into an image:

#+BEGIN_SRC python
  def plot_to_image(figure):
      """Converts the matplotlib plot specified by 'figure' to a PNG image and
      returns it. The supplied figure is closed and inaccessible after this call."""
      # Save the plot to a PNG in memory.
      buf = io.BytesIO()
      plt.savefig(buf, format='png')
      # Closing the figure prevents it from being displayed directly inside
      # the notebook.
      plt.close(figure)
      buf.seek(0)
      # Convert PNG buffer to TF image
      image = tf.image.decode_png(buf.getvalue(), channels=4)
      # Add the batch dimension
      image = tf.expand_dims(image, 0)
      return image
#+END_SRC

I wrote to functions - one for using the =test_data= pandas DataFrame, and one
for using the =dataset_test= TF dataset for extracting the desired number of
traces to predict and plot:

#+BEGIN_SRC python
def plot_trace_and_pred_from_df(df, ntraces):
    fig, ax = plt.subplots(ntraces, figsize=(16, ntraces*2))

    for i in range(ntraces):
        pred_trace = df.iloc[:16384, i].to_numpy().reshape(1, -1, 1)
        prediction = model.predict(pred_trace)
        prediction = prediction.flatten()
        pred_trace = pred_trace.flatten()
        ax[i].plot(pred_trace / np.max(pred_trace))
        ax[i].plot(prediction)
    return fig

def plot_trace_and_pred_from_tfds(dataset, ntraces):
    fig, ax = plt.subplots(ntraces, figsize=(16, ntraces*2))
    pred_iterator = dataset.unbatch().take(ntraces).as_numpy_iterator()

    for i in range(ntraces):
        pred_data = pred_iterator.next()
        pred_trace = pred_data[0].reshape(1, -1, 1)
        prediction = model.predict(pred_trace)
        prediction = prediction.flatten()
        pred_trace = pred_trace.flatten()
        pred_label = pred_data[1].flatten()
        ax[i].plot(pred_trace / np.max(pred_trace))
        ax[i].plot(prediction)
        ax[i].plot(pred_label * 0.9)
    plt.tight_layout()
    return fig
#+END_SRC

The callback looks for now like this:

#+BEGIN_SRC python
file_writer = tf.summary.create_file_writer(log_dir + '/image')

def log_plots(epoch, logs):
    figure = plot_trace_and_pred_from_tfds(dataset=dataset_test, ntraces=5)
    # Convert matplotlib figure to image
    image = plot_to_image(figure)
    # Log the image as an image summary
    with file_writer.as_default():
        tf.summary.image('Prediction plots', image, step=epoch)

image_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_plots)
#+END_SRC

*** DONE idea: learning rate scheduler
    CLOSED: [2020-05-28 Do 00:38]

I think that should speed up training. Something like this should work:

#+BEGIN_SRC python
file_writer = tf.summary.create_file_writer(logdir + "/metrics")
file_writer.set_as_default()

def lr_schedule(epoch):
  """
  Returns a custom learning rate that decreases as epochs progress.
  """
  learning_rate = 0.2
  if epoch > 10:
    learning_rate = 0.02
  if epoch > 20:
    learning_rate = 0.01
  if epoch > 50:
    learning_rate = 0.005

  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)
  return learning_rate

lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)
#+END_SRC

Alternative: the =tf.summary.scalar= is ONLY for logging, I think. It might be
better to substitute it with the =mlflow= alternative - since I use mlflow to
read out the metrics.

I encountered some errors.

*** DONE Check: what if =tf.summary.create_file_writer= is used for multiple callbacks
    CLOSED: [2020-05-28 Do 00:39]
e.g. I want lr_schedule AND image logging? → Works by using two differee file_writers

*** CANCELED idea: use TensorBoards Fairness examination, e.g. see [[https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/documentation/examples/Fairness_Indicators_Lineage_Case_Study.ipynb][here]]+
    CLOSED: [2020-05-25 Mo 23:48]

    - State "CANCELED"   from "TODO"       [2020-05-25 Mo 23:48] \\
      Dataset splicing to check for unfairness is interesting, but 1) not as relevant
      for my data and 2) didn't seem straightforward to implement. Would have to dive
      into tfma (tf model analysis) and install some additional things...
So, I checked out the documentation on FairnessIndicators by TensorFlow, and
there are multiple layers to it:
- What are Fairness Indicators:
  - idea comes from when AI's impact people: e.g. you have a toxicity model
    deployed on a website to filter offensive comments - what are the risks,
    effects, opportunities?  → it's about ethical considerations
  - you examine this by looking at different metrics and user groups and
    evaluate over different /slices/ of your data → you want to check, if
    overall strong metrics can obscure poor performance for certain subgroups
- Which groups to slice by:
  - as many as there are → if not feasible, conside especially sensitive
    characteristics such as race, ethnicity, gender, nationality, income, sexual
    orientation, disability status
  - subgroups are not awlays the best way to classify individuals → consider
    multiracial people. Particular interactions, such as race and gender, may
    show unintended bias
  - in my case of binary segmentation: check for "with artifact" and "without
    artifact", I guess
- Which metrics should I choose?
  - consider who will be experiencing your model, how it will be experienced,
    and the effects of that experience → does the model give people more dignity
    or autonomy → not very relevant for my traces :)
  - Good practice: slice all your existing performance metrics. Evaluate your
    metrics across multiple thresholds
- Critical fairness metrics for classification
  - think about the effects of /errors/ (differences between ground truth and
    prediction) → if some errors may pose more opportunity or harm → evaluate
    the rates of these errors across groups of users.
- Which metrics are available in Fairness Indicators:
  - *Positivity Rate / Negativity rate* = percentage of data points that are
    classified as positive or negative, independent of ground truth
    - when to use: where having equal final percentages of groups is important
    - for trace classification: NO
  - *True Positive Rate = Recall / False Negative Rate* = percentage of data
    points labeled positive, which are /correctly labeled positive/. Percentage
    of positive  data points that are /incorrectly labeled negative/
    - when to use: when it is important that the same % of qualified candidates
      are rated positive in each group, so when you are classifying positive
      outcomes, such as loan applications, school admissions, whether content is
      kid-friendly
  - *True Negative Rate = Selectivity / False Positive Rate* = percentage of
    negative data points /correctly labeled negative/. percentage of negative
    data points /incorrectly labeled positive/.
    - when to use: when error rates (misclassifying something as positive) are
      more concerning than classifying the positives, so where /positives lead
      to negative actions/, such as face detection
*** Note: extract images from tf logs programmatically: [[https://stackoverflow.com/questions/47232779/how-to-extract-and-save-images-from-tensorboard-event-summary][here]]
intro: [[https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/documentation/guidance.md][here]]
** run mlflow model after TensorBoard logs
   :LOGBOOK:
   CLOCK: [2020-05-27 Mi 16:29]--[2020-05-27 Mi 16:29] =>  0:00
   CLOCK: [2020-05-27 Mi 13:00]--[2020-05-27 Mi 16:06] =>  3:06
   CLOCK: [2020-05-26 Di 19:10]--[2020-05-26 Di 19:35] =>  0:25
   :END:
*** make mlflow ready
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node146 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
  (base) [ye53nis@node146 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda activate tensorflow_nightly
  cd /beegfs/ye53nis/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns

#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$
#+end_example

*** First run:  on login node because pip install

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  # ...
  nothing added to commit but untracked files present (use "git add" to track)

  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git log -1
  commit 4d9eb24de2b838d079f516e1b87a776ea087be72
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Wed May 27 15:05:16 2020 +0200

      Make None input for LEARNING_RATE possible
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_su
  bsample/
  2020/05/27 15:08:20 INFO mlflow.projects: === Creating conda environment mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b ===
  Collecting package metadata (repodata.json): done
  Solving environment: done
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  Ran pip subprocess with arguments:
  ['/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt']
  Pip subprocess output:
  Collecting tf-nightly
    Using cached tf_nightly-2.3.0.dev20200527-cp38-cp38-manylinux2010_x86_64.whl (523.9 MB)
  Collecting gast==0.3.3
    Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
  Collecting google-pasta>=0.1.8
    Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
  Processing /home/ye53nis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl
  Collecting opt-einsum>=2.3.2
    Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)
  Processing /home/ye53nis/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73/wrapt-1.12.1-cp38-cp38-linux_x86_64.whl
  Collecting grpcio>=1.8.6
    Using cached grpcio-1.29.0-cp38-cp38-manylinux2010_x86_64.whl (3.0 MB)
  Collecting tb-nightly<2.4.0a0,>=2.3.0a0
    Using cached tb_nightly-2.3.0a20200527-py3-none-any.whl (2.9 MB)
  Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53
  nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.18.1)
  Processing /home/ye53nis/.cache/pip/wheels/1d/10/8e/2f79b924179ff1e6510933d63eb851bea01054fff262343b7a/absl_py-0.9.0-py3-none-any.whl
  Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.14.0)
  Collecting h5py<2.11.0,>=2.10.0
    Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)
  Collecting keras-preprocessing<1.2,>=1.1.1
    Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
  Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (0.34.2)
  Collecting scipy==1.4.1
    Using cached scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)
  Collecting astunparse==1.6.3
    Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
  Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis
  /drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (3.11.4)
  Collecting tf-estimator-nightly
    Using cached tf_estimator_nightly-2.3.0.dev2020052701-py2.py3-none-any.whl (459 kB)
  Collecting google-auth<2,>=1.6.3
    Using cached google_auth-1.15.0-py2.py3-none-any.whl (89 kB)
  Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0
  a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2.23.0)
  Collecting markdown>=2.6.8
    Using cached Markdown-3.2.2-py3-none-any.whl (88 kB)
  Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a0
  ->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.0.1)
  Collecting google-auth-oauthlib<0.5,>=0.4.1
    Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
  Collecting tensorboard-plugin-wit>=1.6.0
    Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)
  Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a
  0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (46.4.0.post20200518)
  Collecting rsa<4.1,>=3.1.4
    Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)
  Collecting cachetools<5.0,>=2.0.0
    Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)
  Collecting pyasn1-modules>=0.2.1
    Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
  Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nig
  htly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2020.4.5.1)
  Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from reques
  ts<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.25.8)
  Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nigh
  tly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (3.0.4)
  Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nightly<2
  .4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2.9)
  Collecting requests-oauthlib>=0.7.0
    Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
  Collecting pyasn1>=0.1.3
    Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
  Collecting oauthlib>=3.0.0
    Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
  Installing collected packages: gast, google-pasta, termcolor, opt-einsum, wrapt, grpcio, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, markdown, absl-py, oauthlib, requests-oauthlib, google-auth-oau
  thlib, tensorboard-plugin-wit, tb-nightly, h5py, keras-preprocessing, scipy, astunparse, tf-estimator-nightly, tf-nightly
  Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.15.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdow
  n-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tb-nightly-2.3.0a20200527 tensorboard-plugin-wit-1.6.0.post3 termcolor-1.1.0 tf-estimato
  r-nightly-2.3.0.dev2020052701 tf-nightly-2.3.0.dev20200527 wrapt-1.12.1

  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/05/27 15:11:00 INFO mlflow.projects: === Created directory /tmp/tmpv29_ayk_ for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/27 15:11:00 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'a934f2e603014f77b17462f1e4ca9bae' ===
  2020-05-27 15:11:03.143020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200527
  2020-05-27 15:11:06.317633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
  2020-05-27 15:11:07.188926: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  2020-05-27 15:11:07.188997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-27 15:11:20.905207: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-27 15:11:20.917673: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199950000 Hz
  2020-05-27 15:11:20.920689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dbefe5e8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-27 15:11:20.920721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  2020-05-27 15:11:25.038117: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  Epoch 1/2
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5588 - tp: 19173.0000 - fp: 38933.0000 - tn: 14836.0000 - fn: 8978.0000 - precision: 0.3300 - recall: 0.6811 - accuracy: 0.4151 - auc: 0.50792020-0
  5-27 15:11:41.545898: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-27 15:11:44.135919: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44
  2020-05-27 15:11:44.155947: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.trace.json.gz
  2020-05-27 15:11:44.192046: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44
  2020-05-27 15:11:44.192223: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.memory
  _profile.json.gz
  2020-05-27 15:11:44.194889: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44Dumped tool data for xplane.pb to /tmp/tb/trai
  n/plugins/profile/2020_05_27_15_11_44/login01.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.kernel_stats.pb

  32/32 [==============================] - ETA: 0s - loss: 1.4530 - tp: 125782.0000 - fp: 204775.0000 - tn: 1917683.0000 - fn: 373200.0000 - precision: 0.3805 - recall: 0.2521 - accuracy: 0.7795 - auc: 0.6085
  qt.qpa.screen: QXcbConnection: Could not connect to display :0
  Could not connect to any X display.
  2020/05/27 15:13:10 ERROR mlflow.cli: === Run (ID 'a934f2e603014f77b17462f1e4ca9bae') failed ===
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

We have found this error:

#+BEGIN_SRC sh
  qt.qpa.screen: QXcbConnection: Could not connect to display :0
  Could not connect to any X display.
#+END_SRC

This seems to be a problem with =matplotlib=. According to [[https://github.com/ipython/ipython/issues/10627][this thread]] the fix
seems to be to insert a =import matplotlib; matplotlib.use('agg')=

*** Second run: on compute node with correct conda env and matplotlib fixed
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  #       ...
  nothing added to commit but untracked files present (use "git add" to track)

  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ git log -1
  commit e6b99f1a1408e47b481419b0e27a28c97ed59e3b
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Wed May 27 15:28:14 2020 +0200

      Fix matplotlib-related error

      Error message when trying to call plt.plot on server:
      qt.qpa.screen: QXcbConnection: Could not connect to display :0
      Could not connect to any X display.
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  2020/05/27 15:35:09 INFO mlflow.projects: === Created directory /tmp/tmp7nb75v_s for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/27 15:35:09 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'e54a6138a1c94873b2fb0c399bf42edc' ===
  2020-05-27 15:35:11.393370: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No
   such file or directory
  2020-05-27 15:35:11.393459: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200527
  2020-05-27 15:35:14.163172: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file
   or directory
  2020-05-27 15:35:14.163212: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
  2020-05-27 15:35:14.163237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node146): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-27 15:35:21.044261: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 AVX512F FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-27 15:35:21.063498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
  2020-05-27 15:35:21.065386: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560557fdf500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-27 15:35:21.065443: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  2020-05-27 15:35:24.293439: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5921 - tp: 4422.0000 - fp: 14942.0000 - tn: 44154.0000 - fn: 18402.0000 - precision: 0.2284 - recall: 0.1937 - accuracy: 0.5930 - auc: 0.41302020-0
  5-27 15:35:36.900052: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-27 15:35:38.755304: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38
  2020-05-27 15:35:38.771792: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.trace.json.gz
  2020-05-27 15:35:38.811277: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38
  2020-05-27 15:35:38.811457: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.memory
  _profile.json.gz
  2020-05-27 15:35:38.814088: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38Dumped tool data for xplane.pb to /tmp/tb/trai
  n/plugins/profile/2020_05_27_15_35_38/node146.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.kernel_stats.pb

  32/32 [==============================] - 63s 2s/step - loss: 1.5140 - tp: 45656.0000 - fp: 78324.0000 - tn: 1999623.0000 - fn: 497837.0000 - precision: 0.3683 - recall: 0.0840 - accuracy: 0.7802 - auc: 0.56
  78 - val_loss: 622806451643763130368.0000 - val_tp: 115044.0000 - val_fp: 540316.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1755 - val_recall: 1.0000 - val_accuracy: 0.1755 - val_auc:
   0.5000
  Epoch 2/10
  32/32 [==============================] - 57s 2s/step - loss: 1.3910 - tp: 42987.0000 - fp: 29799.0000 - tn: 2078052.0000 - fn: 470602.0000 - precision: 0.5906 - recall: 0.0837 - accuracy: 0.8091 - auc: 0.64
  52 - val_loss: 6545756127232.0000 - val_tp: 91530.0000 - val_fp: 563830.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1397 - val_recall: 1.0000 - val_accuracy: 0.1397 - val_auc: 0.5000
  Epoch 3/10
  32/32 [==============================] - 57s 2s/step - loss: 1.3078 - tp: 112631.0000 - fp: 11795.0000 - tn: 2102980.0000 - fn: 394034.0000 - precision: 0.9052 - recall: 0.2223 - accuracy: 0.8452 - auc: 0.7
  767 - val_loss: 21700208.0000 - val_tp: 112388.0000 - val_fp: 542972.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1715 - val_recall: 1.0000 - val_accuracy: 0.1715 - val_auc: 0.5000
  Epoch 4/10
  32/32 [==============================] - 57s 2s/step - loss: 1.1607 - tp: 333193.0000 - fp: 77797.0000 - tn: 2027264.0000 - fn: 183186.0000 - precision: 0.8107 - recall: 0.6452 - accuracy: 0.9004 - auc: 0.8
  807 - val_loss: 157728.7812 - val_tp: 136439.0000 - val_fp: 518921.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.2082 - val_recall: 1.0000 - val_accuracy: 0.2082 - val_auc: 0.5000
  Epoch 5/10
  32/32 [==============================] - 56s 2s/step - loss: 1.1154 - tp: 369131.0000 - fp: 129187.0000 - tn: 2007562.0000 - fn: 115560.0000 - precision: 0.7408 - recall: 0.7616 - accuracy: 0.9066 - auc: 0.
  9105 - val_loss: 2942.4502 - val_tp: 123087.0000 - val_fp: 532273.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1878 - val_recall: 1.0000 - val_accuracy: 0.1878 - val_auc: 0.5000
  Epoch 6/10
  32/32 [==============================] - 58s 2s/step - loss: 1.0467 - tp: 415752.0000 - fp: 82888.0000 - tn: 2020886.0000 - fn: 101914.0000 - precision: 0.8338 - recall: 0.8031 - accuracy: 0.9295 - auc: 0.9
  423 - val_loss: 426.9106 - val_tp: 165483.0000 - val_fp: 489877.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.2525 - val_recall: 1.0000 - val_accuracy: 0.2525 - val_auc: 0.5000
  Epoch 7/10
  32/32 [==============================] - 56s 2s/step - loss: 1.0459 - tp: 425824.0000 - fp: 136085.0000 - tn: 1985980.0000 - fn: 73551.0000 - precision: 0.7578 - recall: 0.8527 - accuracy: 0.9200 - auc: 0.9
  489 - val_loss: 66.3730 - val_tp: 121274.0000 - val_fp: 533859.0000 - val_tn: 210.0000 - val_fn: 17.0000 - val_precision: 0.1851 - val_recall: 0.9999 - val_accuracy: 0.1854 - val_auc: 0.5002
  Epoch 8/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0201 - tp: 415212.0000 - fp: 74474.0000 - tn: 2046769.0000 - fn: 84985.0000 - precision: 0.8479 - recall: 0.8301 - accuracy: 0.9392 - auc: 0.95
  21 - val_loss: 16.7654 - val_tp: 139272.0000 - val_fp: 489110.0000 - val_tn: 26913.0000 - val_fn: 65.0000 - val_precision: 0.2216 - val_recall: 0.9995 - val_accuracy: 0.2536 - val_auc: 0.5504
  Epoch 9/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0049 - tp: 430732.0000 - fp: 74493.0000 - tn: 2040293.0000 - fn: 75922.0000 - precision: 0.8526 - recall: 0.8502 - accuracy: 0.9426 - auc: 0.96
  02 - val_loss: 8.2851 - val_tp: 161996.0000 - val_fp: 413277.0000 - val_tn: 78219.0000 - val_fn: 1868.0000 - val_precision: 0.2816 - val_recall: 0.9886 - val_accuracy: 0.3665 - val_auc: 0.5933
  Epoch 10/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0267 - tp: 416052.0000 - fp: 107470.0000 - tn: 2032480.0000 - fn: 65438.0000 - precision: 0.7947 - recall: 0.8641 - accuracy: 0.9340 - auc: 0.9
  544 - val_loss: 4.8570 - val_tp: 93516.0000 - val_fp: 458191.0000 - val_tn: 103041.0000 - val_fn: 612.0000 - val_precision: 0.1695 - val_recall: 0.9935 - val_accuracy: 0.2999 - val_auc: 0.7206
  20/20 [==============================] - 7s 337ms/step - loss: 1.6838 - tp: 371677.0000 - fp: 484970.0000 - tn: 776428.0000 - fn: 5325.0000 - precision: 0.4339 - recall: 0.9859 - accuracy: 0.7007 - auc: 0.9
  482
  2020/05/27 15:45:38 INFO mlflow.projects: === Run (ID 'e54a6138a1c94873b2fb0c399bf42edc') succeeded ===
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$
#+end_example

No new errors! If reading out the logs works now, it's ready to read out from
the experimental branch!

First, commit the run to git - but important: don't commit on the compute node,
because git-lfs is not installed there. So first exit the compute node and go to
the file

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  exit
  cd /beegfs/ye53nis/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

Now, add the run:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git add data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc
  git commit -m 'run mlflow with tensorboard callbacks and more metrics'
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git add data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git commit -m 'run mlflow with tensorboard callbacks and more metrics'
  [develop 5e5ba85] run mlflow with tensorboard callbacks and more metrics
   64 files changed, 1037 insertions(+)
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/MLmodel
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/conda.yaml
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/keras_module.txt
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model_summary.txt
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/image/events.out.tfevents.1590586524.node146.141413.9064.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/metrics/events.out.tfevents.1590586524.node146.141413.9072.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/events.out.tfevents.1590586524.node146.141413.9206.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/events.out.tfevents.1590586538.node146.profile-empty
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.input_pipeline.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.kernel_stats.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.memory_profile.json.gz
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.overview_page.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.tensorflow_stats.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.trace.json.gz
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.xplane.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/validation/events.out.tfevents.1590586590.node146.141413.28229.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/meta.yaml
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/accuracy
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/auc
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/fn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/fp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/learning rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/loss
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/lr
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/precision
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/recall
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/tn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/tp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_accuracy
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_auc
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_fn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_fp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_loss
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_precision
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_recall
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_tn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_tp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/batch_size
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/csv_path
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/epochs
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/fluotracify_path
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/frac_val
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/learning_rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/length_delimiter
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_amsgrad
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_beta_1
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_beta_2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_decay
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_epsilon
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_learning_rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_name
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/steps_per_epoch
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/validation_steps
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.gitRepoURL
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.log-model.history
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.backend
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.entryPoint
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.env
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.git.commit
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.git.repoURL
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.name
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.type
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.user
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

Now push to github. Notice the use of git-lfs for big files. git-lfs is also the
reason, that I have to enter the username and password three times.

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git push origin develop
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git push origin develop
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Uploading LFS objects: 100% (1/1), 399 MB | 25 MB/s, done
  Counting objects: 62, done.
  Delta compression using up to 48 threads.
  Compressing objects: 100% (51/51), done.
  Writing objects: 100% (58/58), 3.64 MiB | 2.61 MiB/s, done.
  Total 58 (delta 3), reused 0 (delta 0)
  remote: Resolving deltas: 100% (3/3), completed with 1 local object.
  To https://github.com/aseltmann/fluotracify
     e6b99f1..5e5ba85  develop -> develop
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

*** Read out logs

#+BEGIN_SRC tmux :session local
  cd ~/Programme/drmed-git/
  conda activate tf-nightly-lab
  tensorboard --logdir=data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  2020-05-28 00:03:05.639160: W tensorflow/stream_executor/platform/default/dso_loader.cc:55]
    Could not load dynamic library 'libcudart.so.10.1';
    dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
  2020-05-28 00:03:05.639231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29]
    Ignore above cudart dlerror if you do not have a GPU set up on your machine.

  Serving TensorBoard on localhost; to expose to the network, use a proxy or pass
  --bind_all
  TensorBoard 2.3.0a20200519 at http://localhost:6006/ (Press CTRL+C to quit)
#+end_example

#+BEGIN_SRC tmux :session local2
  cd ~/Programme/drmed-git
  conda activate tf-nightly-lab
  mlflow ui --backend-store-uri file:///home/lex/Programme/drmed-git/data/mlruns
#+END_SRC

#+RESULTS:
#+begin_example
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Starting gunicorn 20.0.4
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Listening at: http://127.0.0.1:5000 (25472)
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Using worker: sync
  [2020-05-28 00:14:45 +0200] [25474] [INFO] Booting worker with pid: 25474
#+end_example

*** Load model after improved saving
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:92f8b689-feb1-44c9-b8a3-7182711e0c58
   :END:
#+BEGIN_SRC tmux :session local
  cd /home/lex/Programme/drmed-git/
  git lfs ls-files
#+END_SRC

#+RESULTS:
#+begin_example
  (tf-nightly-lab) [lex@Topialex drmed-git]$ git lfs ls-files
  6526c5abca * data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5
  4bb6295e4e * data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
#+end_example

#+BEGIN_SRC jupyter-python
  import mlflow.keras
  import mlflow.tensorflow
  import sys
  import numpy as np
  import tensorflow as tf

  fluotracify_path = '/home/lex/Programme/drmed-git/src/'
  sys.path.append(fluotracify_path)

  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  # mlflow.keras module
  model_path = '/home/lex/Programme/drmed-git/data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model'
  model_keras = mlflow.keras.load_model(model_uri=model_path,
                                        custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()})
  model_keras
#+END_SRC

#+RESULTS:
:RESULTS:
: /home/lex/Programme/miniconda3/envs/tf-nightly-lab/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
:   if not isinstance(wrapped_dict, collections.Mapping):
: <tensorflow.python.keras.engine.functional.Functional at 0x7f5ed9dd64c0>
:END:

#+BEGIN_SRC jupyter-python
  data, _, nsamples, experiment_params = isfc.import_from_csv(
      path='/home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/',
      header=12,
      frac_train=1,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')
#+END_SRC

#+RESULTS:
: train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set003.csv
: train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set002.csv
: train 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set001.csv

#+BEGIN_SRC jupyter-python :results scalar
  prediction = model_keras.predict(np.array(data.iloc[:2048, 0]).reshape(1, -1, 1))
#+END_SRC

#+RESULTS:
#+begin_example
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 1) for input Tensor("input_1_1:0", shape=(None, 16384, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 1).
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 1) for input Tensor("conv1d_input_1:0", shape=(None, 16384, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 1).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 64) for input Tensor("conv1d_2_input_1:0", shape=(None, 8192, 64), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 64).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 128) for input Tensor("conv1d_4_input_1:0", shape=(None, 4096, 128), dtype=float32), but it was called on an input with incompatible shape (None, 512, 128).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 256) for input Tensor("conv1d_6_input_1:0", shape=(None, 2048, 256), dtype=float32), but it was called on an input with incompatible shape (None, 256, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 512) for input Tensor("conv1d_8_input_1:0", shape=(None, 1024, 512), dtype=float32), but it was called on an input with incompatible shape (None, 128, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 512) for input Tensor("conv1d_10_input_1:0", shape=(None, 512, 512), dtype=float32), but it was called on an input with incompatible shape (None, 64, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 512) for input Tensor("conv1d_12_input_1:0", shape=(None, 256, 512), dtype=float32), but it was called on an input with incompatible shape (None, 32, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 512) for input Tensor("conv1d_14_input_1:0", shape=(None, 128, 512), dtype=float32), but it was called on an input with incompatible shape (None, 16, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 512) for input Tensor("conv1d_16_input_1:0", shape=(None, 64, 512), dtype=float32), but it was called on an input with incompatible shape (None, 8, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 32, 512) for input Tensor("conv1d_18_input_1:0", shape=(None, 32, 512), dtype=float32), but it was called on an input with incompatible shape (None, 4, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 32, 1024) for input Tensor("conv1d_transpose_input_1:0", shape=(None, 32, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 4, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 1024) for input Tensor("conv1d_20_input_1:0", shape=(None, 64, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 8, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 512) for input Tensor("conv1d_transpose_1_input_1:0", shape=(None, 64, 512), dtype=float32), but it was called on an input with incompatible shape (None, 8, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 1024) for input Tensor("conv1d_22_input_1:0", shape=(None, 128, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 16, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 512) for input Tensor("conv1d_transpose_2_input_1:0", shape=(None, 128, 512), dtype=float32), but it was called on an input with incompatible shape (None, 16, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 1024) for input Tensor("conv1d_24_input_1:0", shape=(None, 256, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 32, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 512) for input Tensor("conv1d_transpose_3_input_1:0", shape=(None, 256, 512), dtype=float32), but it was called on an input with incompatible shape (None, 32, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 1024) for input Tensor("conv1d_26_input_1:0", shape=(None, 512, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 64, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 512) for input Tensor("conv1d_transpose_4_input_1:0", shape=(None, 512, 512), dtype=float32), but it was called on an input with incompatible shape (None, 64, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 1024) for input Tensor("conv1d_28_input_1:0", shape=(None, 1024, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 512) for input Tensor("conv1d_transpose_5_input_1:0", shape=(None, 1024, 512), dtype=float32), but it was called on an input with incompatible shape (None, 128, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 1024) for input Tensor("conv1d_30_input_1:0", shape=(None, 2048, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 256, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 512) for input Tensor("conv1d_transpose_6_input_1:0", shape=(None, 2048, 512), dtype=float32), but it was called on an input with incompatible shape (None, 256, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 512) for input Tensor("conv1d_32_input_1:0", shape=(None, 4096, 512), dtype=float32), but it was called on an input with incompatible shape (None, 512, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 256) for input Tensor("conv1d_transpose_7_input_1:0", shape=(None, 4096, 256), dtype=float32), but it was called on an input with incompatible shape (None, 512, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 256) for input Tensor("conv1d_34_input_1:0", shape=(None, 8192, 256), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 128) for input Tensor("conv1d_transpose_8_input_1:0", shape=(None, 8192, 128), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 128).
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 128) for input Tensor("conv1d_36_input_1:0", shape=(None, 16384, 128), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 128).
#+end_example

#+BEGIN_SRC jupyter-python :results plain :pandoc t
  import pandas as pd
  pd.DataFrame(prediction.flatten())
#+END_SRC

#+RESULTS:
:RESULTS:
|        | 0     |
|--------+-------|
| 0      | 1.0   |
| 1      | 1.0   |
| 2      | 1.0   |
| 3      | 1.0   |
| 4      | 1.0   |
| ...    | ...   |
| 2043   | 1.0   |
| 2044   | 1.0   |
| 2045   | 1.0   |
| 2046   | 1.0   |
| 2047   | 1.0   |

2048 rows × 1 columns
:END:

Yippieeeeh, I don't need the complicated =OrgFormatter!=
**** DONE test =:pandoc t= instead of custom =OrgFormatter= class
     CLOSED: [2020-05-28 Do 01:21]
**** DONE Add =os.environ=
     CLOSED: [2020-05-28 Do 14:12]
** Coming back to the lab after STEX2 <2020-11-02 Mo>
   :LOGBOOK:
   CLOCK: [2020-12-06 So 23:53]--[2020-12-06 So 23:53] =>  0:00
   CLOCK: [2020-12-02 Mi 23:06]--[2020-12-06 So 21:19] => 94:13
   CLOCK: [2020-12-01 Di 11:19]--[2020-12-01 Di 11:57] =>  0:38
   CLOCK: [2020-12-01 Di 10:27]--[2020-12-01 Di 10:44] =>  0:17
   CLOCK: [2020-11-06 Fr 21:11]--[2020-11-06 Fr 21:11] =>  0:00
   CLOCK: [2020-11-06 Fr 15:04]--[2020-11-06 Fr 15:26] =>  0:22

   CLOCK: [2020-11-06 Fr 14:14]--[2020-11-06 Fr 14:19] =>  0:05
   CLOCK: [2020-11-06 Fr 12:44]--[2020-11-06 Fr 13:24] =>  0:40
   CLOCK: [2020-11-06 Fr 12:10]--[2020-11-06 Fr 12:13] =>  0:03
   CLOCK: [2020-11-05 Do 17:24]--[2020-11-05 Do 17:25] =>  0:01
   CLOCK: [2020-11-05 Do 13:02]--[2020-11-05 Do 13:52] =>  0:50
   CLOCK: [2020-11-05 Do 01:12]--[2020-11-05 Do 01:12] =>  0:00
   CLOCK: [2020-11-04 Mi 22:34]--[2020-11-04 Mi 23:07] =>  0:33
   CLOCK: [2020-11-04 Mi 18:24]--[2020-11-04 Mi 18:35] =>  0:11
   CLOCK: [2020-11-04 Mi 17:35]--[2020-11-04 Mi 18:01] =>  0:26
   CLOCK: [2020-11-04 Mi 16:19]--[2020-11-04 Mi 17:18] =>  0:59
   CLOCK: [2020-11-04 Mi 15:34]--[2020-11-04 Mi 15:44] =>  0:10
   CLOCK: [2020-11-04 Mi 14:51]--[2020-11-04 Mi 15:04] =>  0:13
   CLOCK: [2020-11-04 Mi 13:20]--[2020-11-04 Mi 14:01] =>  0:41
   CLOCK: [2020-11-04 Mi 11:38]--[2020-11-04 Mi 11:53] =>  0:15
   CLOCK: [2020-11-03 Di 20:16]--[2020-11-03 Di 20:16] =>  0:00
   CLOCK: [2020-11-03 Di 15:50]--[2020-11-03 Di 16:12] =>  0:22
   CLOCK: [2020-11-03 Di 14:01]--[2020-11-03 Di 14:15] =>  0:14
   CLOCK: [2020-11-03 Di 13:03]--[2020-11-03 Di 13:45] =>  0:42
   CLOCK: [2020-11-03 Di 11:11]--[2020-11-03 Di 11:19] =>  0:08
   CLOCK: [2020-11-02 Mo 14:43]--[2020-11-02 Mo 17:01] =>  2:18
   :END:
*** upate tensorflow and mlflow in tensorflow_nightly environment on ara

    - we need:
    - numpy
    - pandas
    - matplotlib
    - seaborn
    - mlflow
    - jupyterlab
    - pip
    - pip:
      - tf-nightly
      - fcsfiles
      - multipletau

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  (base) [ye53nis@node181 drmed-git]$ conda create -n tf-nightly numpy pandas matplotlib seaborn tifffile jupyterlab pip
  (base) [ye53nis@node181 drmed-git]$ conda install -n tf-nightly -c conda-forge mlflow=1.11.0
  (base) [ye53nis@node181 drmed-git]$ conda activate tf-nightly
  (tf-nightly) [ye53nis@node181 drmed-git]$ pip install fcsfiles multipletau tf-nightly
#+END_SRC

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (tf-nightly) [ye53nis@node181 drmed-git]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      absl-py                   0.11.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
      argon2-cffi               20.1.0           py38h7b6447c_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10                       py_0
      attrs                     20.2.0                     py_0
      azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
      azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
      backcall                  0.2.0                      py_0
      blas                      1.0                         mkl
      bleach                    3.2.1                      py_0
      blinker                   1.4                        py_1    conda-forge
      brotlipy                  0.7.0           py38h7b6447c_1000
      ca-certificates           2020.6.20            hecda079_0    conda-forge
      cachetools                4.1.1                    pypi_0    pypi
      certifi                   2020.6.20        py38h924ce5b_2    conda-forge
      cffi                      1.14.3           py38he30daa8_0
      chardet                   3.0.4                 py38_1003
      click                     7.1.2              pyh9f0ad1d_0    conda-forge
      cloudpickle               1.6.0                      py_0    conda-forge
      configparser              5.0.1                      py_0    conda-forge
      cryptography              3.1.1            py38h1ba5d50_0
      cycler                    0.10.0                   py38_0
      databricks-cli            0.9.1                      py_0    conda-forge
      dbus                      1.13.18              hb2f20db_0
      decorator                 4.4.2                      py_0
      defusedxml                0.6.0                      py_0
      docker-py                 4.3.1            py38h32f6830_1    conda-forge
      docker-pycreds            0.4.0                      py_0    conda-forge
      entrypoints               0.3                      py38_0
      expat                     2.2.10               he6710b0_2
+++   fcsfiles                  2020.9.18                pypi_0    pypi
      flask                     1.1.2              pyh9f0ad1d_0    conda-forge
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.0               h9420a91_0
      freetype                  2.10.4               h5ab3b9f_0
      gast                      0.3.3                    pypi_0    pypi
      gitdb                     4.0.5                      py_0    conda-forge
      gitpython                 3.1.11                     py_0    conda-forge
      glib                      2.66.1               h92f7085_0
      google-auth               1.23.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.2                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      gorilla                   0.3.0                      py_0    conda-forge
      grpcio                    1.32.0                   pypi_0    pypi
      gst-plugins-base          1.14.0               hbbd80ab_1
      gstreamer                 1.14.0               hb31296c_0
      gunicorn                  20.0.4           py38h32f6830_2    conda-forge
      h5py                      2.10.0                   pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10                       py_0
      importlib-metadata        2.0.0                      py_1
      importlib_metadata        2.0.0                         1
      intel-openmp              2020.2                      254
      ipykernel                 5.3.4            py38h5ca1d4c_0
      ipython                   7.18.1           py38h5ca1d4c_0
      ipython_genutils          0.2.0                    py38_0
      isodate                   0.6.0                      py_1    conda-forge
      itsdangerous              1.1.0                      py_0    conda-forge
      jedi                      0.17.2                   py38_0
      jinja2                    2.11.2                     py_0
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.5                      py_0
      jsonschema                3.2.0                      py_2
      jupyter_client            6.1.7                      py_0
      jupyter_core              4.6.3                    py38_0
+++   jupyterlab                2.2.6                      py_0
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         1.2.0                      py_0
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.0            py38h2531618_0
      lcms2                     2.11                 h396b838_0
      ld_impl_linux-64          2.33.1               h53a641e_7
      libedit                   3.1.20191231         h14c3975_1
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.1.0                hdf63c60_0
      libgfortran-ng            7.3.0                hdf63c60_0
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.13.0.1             h8b12597_0    conda-forge
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.1.0                hdf63c60_0
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.10               hb55368b_3
      lz4-c                     1.9.2                heb0550a_3
      mako                      1.1.3              pyh9f0ad1d_0    conda-forge
      markdown                  3.3.3                    pypi_0    pypi
      markupsafe                1.1.1            py38h7b6447c_0
      matplotlib                3.3.2                         0
      matplotlib-base           3.3.2            py38h817c723_0
      mistune                   0.8.4           py38h7b6447c_1000
      mkl                       2020.2                      256
      mkl-service               2.3.0            py38he904b0f_0
      mkl_fft                   1.2.0            py38h23d657b_0
      mkl_random                1.1.1            py38h0573a6f_0
+++   mlflow                    1.11.0           py38h32f6830_1    conda-forge
      msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
+++   multipletau               0.3.3                    pypi_0    pypi
      nbclient                  0.5.1                      py_0
      nbconvert                 6.0.7                    py38_0
      nbformat                  5.0.8                      py_0
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.4.1                      py_0
      notebook                  6.1.4                    py38_0
+++   numpy                     1.19.2           py38h54aff64_0
      numpy-base                1.19.2           py38hfa32c7d_0
      oauthlib                  3.0.1                      py_0    conda-forge
      olefile                   0.46                       py_0
      openssl                   1.1.1h               h516909a_0    conda-forge
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 20.4                       py_0
+++   pandas                    1.1.3            py38he6710b0_0
      pandoc                    2.11                 hb0f4dca_0
      pandocfilters             1.4.2                    py38_1
      parso                     0.7.0                      py_0
      pcre                      8.44                 he6710b0_0
      pexpect                   4.8.0                    py38_0
      pickleshare               0.7.5                 py38_1000
      pillow                    8.0.1            py38he98fc37_0
+++   pip                       20.2.4                   py38_0
      prometheus_client         0.8.0                      py_0
      prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
      prompt-toolkit            3.0.8                      py_0
      protobuf                  3.13.0.1         py38h950e882_1    conda-forge
      ptyprocess                0.6.0                    py38_0
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.7.2              pyhd3eb1b0_0
      pyjwt                     1.7.1                      py_0    conda-forge
      pyopenssl                 19.1.0                     py_1
      pyparsing                 2.4.7                      py_0
      pyqt                      5.9.2            py38h05f1152_4
      pyrsistent                0.17.3           py38h7b6447c_0
      pysocks                   1.7.1                    py38_0
      python                    3.8.5                h7579374_1
      python-dateutil           2.8.1                      py_0
      python-editor             1.0.4                      py_0    conda-forge
      python_abi                3.8                      1_cp38    conda-forge
      pytz                      2020.1                     py_0
      pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
      pyzmq                     19.0.2           py38he6710b0_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge
      readline                  8.0                  h7b6447c_0
      requests                  2.24.0                     py_0
      requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
      rsa                       4.6                      pypi_0    pypi
+++   scipy                     1.5.2            py38h0b6359f_0
      seaborn                   0.11.0                     py_0
      send2trash                1.5.0                    py38_0
      setuptools                50.3.0           py38hb0f4dca_1
      sip                       4.19.13          py38he6710b0_0
      six                       1.15.0                     py_0
      smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
      sqlalchemy                1.3.13           py38h516909a_0    conda-forge
      sqlite                    3.33.0               h62c20be_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
      tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
+++   tb-nightly                2.4.0a20201102           pypi_0    pypi
      tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.1                    py38_0
      testpath                  0.4.4                      py_0
      tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
+++   tf-nightly                2.5.0.dev20201029          pypi_0    pypi
+++   tifffile                  2020.10.1        py38hdd07704_2
      tk                        8.6.10               hbc83047_0
      tornado                   6.0.4            py38h7b6447c_1
      traitlets                 5.0.5                      py_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      urllib3                   1.25.11                    py_0
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1                    py38_1
      websocket-client          0.57.0           py38h32f6830_3    conda-forge
      werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
      wheel                     0.35.1                     py_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge
      zeromq                    4.3.3                he6710b0_3
      zipp                      3.4.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.5                h9ceee32_0
      (tf-nightly) [ye53nis@node181 drmed-git]$
    #+end_example

*** planning next experiments
**** DONE new simulations with different transit times
     CLOSED: [2020-12-30 Mi 14:55]
***** some theoretical calculations
     - for now I've got:
     - $0.5 \frac{\mu m^2}{s} ~ 22.54ms$ → we need a trace length of 2-3 orders
       of magnitude longer, so $2.25s…7.13s…22.54s$ (10^2, 10^2.5, 10^3)
     - $1 \frac{\mu m^2}{s} ~ 11.27ms$ → $1.13s…3.56s…11.27s$
     - $2 \frac{\mu m^2}{s} ~ 5.64ms$ → $0.56s…1.78s…5.64s$
     - $3 \frac{\mu m^2}{s} ~ 3.76ms$ → $0.38s…1.19s…3.76s$
     - $4 \frac{\mu m^2}{s} ~ 2.82ms$ → $0.28s…0.89s…2.82s$
     - $5 \frac{\mu m^2}{s} ~ 2.25ms$ → $0.23s…0.71s…2.25s$
     - now Falk said the most important processes are between $0.1…1 \frac{\mu
       m^2}{s}$ and
       the maximum amplitudes are between $10^{-3}…1(10)\frac{\mu
       m^2}{s}$ which means:
     - $0.001 \frac{\mu m^2}{s} ~ 11271ms$ → $1127s(18.8min)…3564s(59.4min)…11271s(188min)$
     - $0.01 \frac{\mu m^2}{s} ~ 1127ms$ → $113s…356s(6min)…1127s(18.8min)$
     - $0.0113 \frac{\mu m^2}{s} ~ 997ms$ → $\bold{100s}…315s(5.3min)…997s(16.6min)$
     - $0.02 \frac{\mu m^2}{s} ~ 563ms$ → $56s…178s…564s(9.4min)$
     - $0.0225 \frac{\mu m^2}{s} ~ 501ms$ → $\bold{50s}…158s…501s(8.4min)$
     - $0.03 \frac{\mu m^2}{s} ~ 376ms$ → $38s…119s…376s$
     - $0.035 \frac{\mu m^2}{s} ~ 322ms$ → $32s…\bold{102s}…322s$
     - $0.04 \frac{\mu m^2}{s} ~ 282ms$ → $28s…89s…282s(4.7min)$
     - $0.056 \frac{\mu m^2}{s} ~ 201ms$ → $\bold{20s}…63.6s…201s$
     - $0.06 \frac{\mu m^2}{s} ~ 188ms$ → $19s…59s…188s$
     - $0.069 \frac{\mu m^2}{s} ~ 163ms$ → $\bold{16.3s}…52s…163s \to 2^{14}$
       for unet
     - $0.071 \frac{\mu m^2}{s} ~ 159ms$ → $15.9s…\bold{50s}…159s$
     - $0.08 \frac{\mu m^2}{s} ~ 141ms$ → $14.1s…45s…141s$
     - $0.1 \frac{\mu m^2}{s} ~ 112.7ms$ → $11.3s…35.6s…112.7s$
     - $0.113 \frac{\mu m^2}{s} ~ 99.7ms$ → $9.97s…31.5s…\bold{99.7s}$
     - $0.18 \frac{\mu m^2}{s} ~ 62.6ms$ → $6.26s…\bold{19.8s}…63s}$
     - $0.2 \frac{\mu m^2}{s} ~ 56.36ms$ → $5.64s…17.8s…56.4s$
     - $0.225 \frac{\mu m^2}{s} ~ 50.1ms$ → $5.01s…15.8s…\bold{50.1s}$
     - $0.56 \frac{\mu m^2}{s} ~ 20.1ms$ → $2.01s…6.36s…\bold{20.1s}$
     - $1.12 \frac{\mu m^2}{s} ~ 10.1ms$ → $1.01s…3.19s…\bold{10.1s}$
     - $2.25 \frac{\mu m^2}{s} ~ 5.01ms$ → $0.5s…1.58s…\bold{5.01s}$
     - $10 \frac{\mu m^2}{s} ~ 1.13ms$ → $0.11s…0.36s…\bold{1.13s}$
     - $50 \frac{\mu m^2}{s} ~ \boldsymbol{0.225ms}$ → $0.023s…0.071s…\bold{0.225s}$
     - for 100s trace length we have the following constraints:
       - conservative (3-fold): $0.113\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.035\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.0113\frac{\mu m^2}{s}$
     - for 50s trace length we have the following constraints:
       - conservative (3-fold): $0.225\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.071\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.0225\frac{\mu m^2}{s}$
     - for 20s trace length we have the following constraints:
       - conservative (3-fold): $0.56\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.18\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.056\frac{\mu m^2}{s}$
***** Coming back to my project
      - Pablo fitted the 400 Hs-PEX5-eGFP samples and got an average transit
        time of 0.225ms
      - which simulations have I got already?

      |   D | sim | where   | max 5000 Intensity                 |
      |-----+-----+---------+------------------------------------|
      | 0.5 |  11 | Sep2019 | 10, 25, 39, 60, 74, 84, 85, 86     |
      |   1 |   8 | Sep2019 | 16, 20, 43, 46, 87, 90, 98         |
      | 1.5 |   7 | Sep2019 | 1, 6, 18                           |
      |   2 |   9 | Sep2019 | 2, 15, 22, 33, 53, 72              |
      | 2.5 |  18 | Sep2019 | 11, 27, 34, 51, 79, 81, 92, 95     |
      |   3 |  13 | Sep2019 | 23, 36, 38, 50, 55, 58, 78, 80, 99 |
      | 3.5 |   7 | Sep2019 | 68                                 |
      |   4 |   6 | Sep2019 | 30, 52, 66, 82                     |
      | 4.5 |  11 | Sep2019 | 5, 12, 41, 76                      |
      |   5 |  10 | Sep2019 | 0, 4, 32, 42, 96                   |
      |     |     |         |                                    |
***** DONE uninstall git lfs (annoying 3 authentications and no benefit...)
      CLOSED: [2020-12-14 Mo 13:33]
      1. =git lfs uninstall=
      2. remove lfs stuff from =.gitattributes=:
         #+begin_example
         *.tf filter=lfs diff=lfs merge=lfs -text
         data/**/*.tf/** filter=lfs diff=lfs merge=lfs -text
         *.h5 filter=lfs diff=lfs merge=lfs -text
         #+end_example
      3. do =git rm --cached= for each of the files stored in git lfs
         #+begin_example
         data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5
         data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
         #+end_example
      4. since I don't need these runs, I don't add them manually, but leave
         them where they are (at the =/beegfs= at the hpc)
      5. commit everything
      6. remove junk with =rm -rf .git/lfs=
***** DONE Changes in Simulation
      CLOSED: [2020-12-30 Mi 14:51]
      - took nmol_arr out of =produce_training_data=:
        #+begin_example
        nmol_arr : list or tuple
          Number of fast molecules used for simulation. For each set, one will
          be drawn using random.choice()
        #+end_example
        and fixed it to the following:
        #+begin_src python
        nmol = random.choice([500, 1000, 1500, 2000, 2500, 3000, 3500])
        #+end_src
      - fixed printing: if you want to print out to the same line (e.g. in a
        for-loop), just use the string marker =\r=, e.g.:
        #+begin_src python
          import sys
          num_of_mol = 500
          for b in range(0, num_of_mol):
              per = int((float(b) / float(num_of_mol)) * 100)
              sys.stdout.write("\rProcessing tracks: [{:20}] {}% complete".format('=' * int(per / 5), per))
        #+end_src
***** DONE do scaling in =integrate_over_psf=
      CLOSED: [2020-12-30 Mi 14:54]
      - I chose now to ditch the random offset augmentation on the traces, since
        the offset is only determined by the number of molecules.
      - instead, I chose the number of molecules to be a random integer between
        500 and 3500, that gives enough random trace heights while keeping the
        fake intensity levels kind of realistic.
      - it has to be stressed, that in this case, the number of molecules should
        not matter really for the physical calculation, but is meant to make the
        trained model more robust to different data it might get presented
***** DONE Idea: save out trace + label 1 = brightclust + label 2 = trace without artifacts
      CLOSED: [2020-12-30 Mi 14:53]
      - like this there would always be an inbuilt control
      - downside: bigger files, revamp almost all functions
***** DONE fork nanosimpy functions into my own package
     CLOSED: [2020-11-30 Mo 10:21]
     - always dealing with the unmaintained nanosimpy package is tedious
**** now do the simulation from the emacs notebook
     :PROPERTIES:
     :header-args:jupyter-python: :session /jpy:localhost#9999:a37e524a-8134-4d8f-b24a-367acaf1bdd3
     :END:
     #+BEGIN_SRC  emacs-lisp
       (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
     #+END_SRC

     #+BEGIN_SRC jupyter-python
       %cd /beegfs/ye53nis/drmed-git/
       !git log -1
     #+END_SRC

     #+RESULTS:
     : /beegfs/ye53nis/drmed-git
     : commit 387c3e9309caa203938d397218e27d4f01bdad84
     : Author: Apoplex <oligolex@vivaldi.net>
     : Date:   Tue Dec 29 19:11:34 2020 +0100
     :
     :     Add module docs; now use sys.exit instead exit

     #+BEGIN_SRC jupyter-python
       %conda list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       absl-py                   0.11.0                   pypi_0    pypi
       alembic                   1.4.1                      py_0    conda-forge
       appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
       argon2-cffi               20.1.0           py38h7b6447c_1
       asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
       asteval                   0.9.16             pyh5ca1d4c_0    conda-forge
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10                       py_0
       attrs                     20.2.0                     py_0
       azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
       azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
       backcall                  0.2.0                      py_0
       blas                      1.0                         mkl
       bleach                    3.2.1                      py_0
       blinker                   1.4                        py_1    conda-forge
       brotlipy                  0.7.0           py38h7b6447c_1000
       ca-certificates           2020.12.5            ha878542_0    conda-forge
       cachetools                4.1.1                    pypi_0    pypi
       certifi                   2020.12.5        py38h578d9bd_0    conda-forge
       cffi                      1.14.3           py38he30daa8_0
       chardet                   3.0.4                 py38_1003
       click                     7.1.2              pyh9f0ad1d_0    conda-forge
       cloudpickle               1.6.0                      py_0    conda-forge
       configparser              5.0.1                      py_0    conda-forge
       cryptography              3.1.1            py38h1ba5d50_0
       cycler                    0.10.0                   py38_0
       databricks-cli            0.9.1                      py_0    conda-forge
       dbus                      1.13.18              hb2f20db_0
       decorator                 4.4.2                      py_0
       defusedxml                0.6.0                      py_0
       docker-py                 4.3.1            py38h32f6830_1    conda-forge
       docker-pycreds            0.4.0                      py_0    conda-forge
       entrypoints               0.3                      py38_0
       expat                     2.2.10               he6710b0_2
       fcsfiles                  2020.9.18                pypi_0    pypi
       flask                     1.1.2              pyh9f0ad1d_0    conda-forge
       flatbuffers               1.12                     pypi_0    pypi
       fontconfig                2.13.0               h9420a91_0
       freetype                  2.10.4               h5ab3b9f_0
       future                    0.18.2           py38h578d9bd_2    conda-forge
       gast                      0.3.3                    pypi_0    pypi
       gitdb                     4.0.5                      py_0    conda-forge
       gitpython                 3.1.11                     py_0    conda-forge
       glib                      2.66.1               h92f7085_0
       google-auth               1.23.0                   pypi_0    pypi
       google-auth-oauthlib      0.4.2                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       gorilla                   0.3.0                      py_0    conda-forge
       grpcio                    1.32.0                   pypi_0    pypi
       gst-plugins-base          1.14.0               hbbd80ab_1
       gstreamer                 1.14.0               hb31296c_0
       gunicorn                  20.0.4           py38h32f6830_2    conda-forge
       h5py                      2.10.0                   pypi_0    pypi
       icu                       58.2                 he6710b0_3
       idna                      2.10                       py_0
       importlib-metadata        2.0.0                      py_1
       importlib_metadata        2.0.0                         1
       intel-openmp              2020.2                      254
       ipykernel                 5.3.4            py38h5ca1d4c_0
       ipython                   7.18.1           py38h5ca1d4c_0
       ipython_genutils          0.2.0                    py38_0
       isodate                   0.6.0                      py_1    conda-forge
       itsdangerous              1.1.0                      py_0    conda-forge
       jedi                      0.17.2                   py38_0
       jinja2                    2.11.2                     py_0
       jpeg                      9b                   h024ee3a_2
       json5                     0.9.5                      py_0
       jsonschema                3.2.0                      py_2
       jupyter_client            6.1.7                      py_0
       jupyter_core              4.6.3                    py38_0
       jupyterlab                2.2.6                      py_0
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         1.2.0                      py_0
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.0            py38h2531618_0
       lcms2                     2.11                 h396b838_0
       ld_impl_linux-64          2.33.1               h53a641e_7
       libedit                   3.1.20191231         h14c3975_1
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.1.0                hdf63c60_0
       libgfortran-ng            7.3.0                hdf63c60_0
       libpng                    1.6.37               hbc83047_0
       libprotobuf               3.13.0.1             h8b12597_0    conda-forge
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.1.0                hdf63c60_0
       libtiff                   4.1.0                h2733197_1
       libuuid                   1.0.3                h1bed415_2
       libxcb                    1.14                 h7b6447c_0
       libxml2                   2.9.10               hb55368b_3
       lmfit                     1.0.1                      py_1    conda-forge
       lz4-c                     1.9.2                heb0550a_3
       mako                      1.1.3              pyh9f0ad1d_0    conda-forge
       markdown                  3.3.3                    pypi_0    pypi
       markupsafe                1.1.1            py38h7b6447c_0
       matplotlib                3.3.2                         0
       matplotlib-base           3.3.2            py38h817c723_0
       mistune                   0.8.4           py38h7b6447c_1000
       mkl                       2020.2                      256
       mkl-service               2.3.0            py38he904b0f_0
       mkl_fft                   1.2.0            py38h23d657b_0
       mkl_random                1.1.1            py38h0573a6f_0
       mlflow                    1.11.0           py38h32f6830_1    conda-forge
       msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
       multipletau               0.3.3                    pypi_0    pypi
       nbclient                  0.5.1                      py_0
       nbconvert                 6.0.7                    py38_0
       nbformat                  5.0.8                      py_0
       ncurses                   6.2                  he6710b0_1
       nest-asyncio              1.4.1                      py_0
       notebook                  6.1.4                    py38_0
       numpy                     1.19.2           py38h54aff64_0
       numpy-base                1.19.2           py38hfa32c7d_0
       oauthlib                  3.0.1                      py_0    conda-forge
       olefile                   0.46                       py_0
       openssl                   1.1.1h               h516909a_0    conda-forge
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 20.4                       py_0
       pandas                    1.1.3            py38he6710b0_0
       pandoc                    2.11                 hb0f4dca_0
       pandocfilters             1.4.2                    py38_1
       parso                     0.7.0                      py_0
       pcre                      8.44                 he6710b0_0
       pexpect                   4.8.0                    py38_0
       pickleshare               0.7.5                 py38_1000
       pillow                    8.0.1            py38he98fc37_0
       pip                       20.2.4                   py38_0
       prometheus_client         0.8.0                      py_0
       prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
       prompt-toolkit            3.0.8                      py_0
       protobuf                  3.13.0.1         py38h950e882_1    conda-forge
       ptyprocess                0.6.0                    py38_0
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.20                       py_2
       pygments                  2.7.2              pyhd3eb1b0_0
       pyjwt                     1.7.1                      py_0    conda-forge
       pyopenssl                 19.1.0                     py_1
       pyparsing                 2.4.7                      py_0
       pyqt                      5.9.2            py38h05f1152_4
       pyrsistent                0.17.3           py38h7b6447c_0
       pysocks                   1.7.1                    py38_0
       python                    3.8.5                h7579374_1
       python-dateutil           2.8.1                      py_0
       python-editor             1.0.4                      py_0    conda-forge
       python_abi                3.8                      1_cp38    conda-forge
       pytz                      2020.1                     py_0
       pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
       pyzmq                     19.0.2           py38he6710b0_1
       qt                        5.9.7                h5867ecd_1
       querystring_parser        1.2.4                      py_0    conda-forge
       readline                  8.0                  h7b6447c_0
       requests                  2.24.0                     py_0
       requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
       rsa                       4.6                      pypi_0    pypi
       scipy                     1.5.2            py38h0b6359f_0
       seaborn                   0.11.0                     py_0
       send2trash                1.5.0                    py38_0
       setuptools                50.3.0           py38hb0f4dca_1
       sip                       4.19.13          py38he6710b0_0
       six                       1.15.0                     py_0
       smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
       sqlalchemy                1.3.13           py38h516909a_0    conda-forge
       sqlite                    3.33.0               h62c20be_0
       sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
       tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
       tb-nightly                2.4.0a20201102           pypi_0    pypi
       tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.1                    py38_0
       testpath                  0.4.4                      py_0
       tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
       tf-nightly                2.5.0.dev20201029          pypi_0    pypi
       tifffile                  2020.10.1        py38hdd07704_2
       tk                        8.6.10               hbc83047_0
       tornado                   6.0.4            py38h7b6447c_1
       traitlets                 5.0.5                      py_0
       typing-extensions         3.7.4.3                  pypi_0    pypi
       uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge
       urllib3                   1.25.11                    py_0
       wcwidth                   0.2.5                      py_0
       webencodings              0.5.1                    py38_1
       websocket-client          0.57.0           py38h32f6830_3    conda-forge
       werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
       wheel                     0.35.1                     py_0
       wrapt                     1.12.1                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       yaml                      0.2.5                h516909a_0    conda-forge
       zeromq                    4.3.3                he6710b0_3
       zipp                      3.4.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7b6447c_3
       zstd                      1.4.5                h9ceee32_0
       Note: you may need to restart the kernel to use updated packages.
       # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       absl-py                   0.11.0                   pypi_0    pypi
       alembic                   1.4.1                      py_0    conda-forge
       appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
       argon2-cffi               20.1.0           py38h7b6447c_1
       asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
       asteval                   0.9.16             pyh5ca1d4c_0    conda-forge
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10                       py_0
       attrs                     20.2.0                     py_0
       azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
       azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
       backcall                  0.2.0                      py_0
       blas                      1.0                         mkl
       bleach                    3.2.1                      py_0
       blinker                   1.4                        py_1    conda-forge
       brotlipy                  0.7.0           py38h7b6447c_1000
       ca-certificates           2020.12.5            ha878542_0    conda-forge
       cachetools                4.1.1                    pypi_0    pypi
       certifi                   2020.12.5        py38h578d9bd_0    conda-forge
       cffi                      1.14.3           py38he30daa8_0
       chardet                   3.0.4                 py38_1003
       click                     7.1.2              pyh9f0ad1d_0    conda-forge
       cloudpickle               1.6.0                      py_0    conda-forge
       configparser              5.0.1                      py_0    conda-forge
       cryptography              3.1.1            py38h1ba5d50_0
       cycler                    0.10.0                   py38_0
       databricks-cli            0.9.1                      py_0    conda-forge
       dbus                      1.13.18              hb2f20db_0
       decorator                 4.4.2                      py_0
       defusedxml                0.6.0                      py_0
       docker-py                 4.3.1            py38h32f6830_1    conda-forge
       docker-pycreds            0.4.0                      py_0    conda-forge
       entrypoints               0.3                      py38_0
       expat                     2.2.10               he6710b0_2
       fcsfiles                  2020.9.18                pypi_0    pypi
       flask                     1.1.2              pyh9f0ad1d_0    conda-forge
       flatbuffers               1.12                     pypi_0    pypi
       fontconfig                2.13.0               h9420a91_0
       freetype                  2.10.4               h5ab3b9f_0
       future                    0.18.2           py38h578d9bd_2    conda-forge
       gast                      0.3.3                    pypi_0    pypi
       gitdb                     4.0.5                      py_0    conda-forge
       gitpython                 3.1.11                     py_0    conda-forge
       glib                      2.66.1               h92f7085_0
       google-auth               1.23.0                   pypi_0    pypi
       google-auth-oauthlib      0.4.2                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       gorilla                   0.3.0                      py_0    conda-forge
       grpcio                    1.32.0                   pypi_0    pypi
       gst-plugins-base          1.14.0               hbbd80ab_1
       gstreamer                 1.14.0               hb31296c_0
       gunicorn                  20.0.4           py38h32f6830_2    conda-forge
       h5py                      2.10.0                   pypi_0    pypi
       icu                       58.2                 he6710b0_3
       idna                      2.10                       py_0
       importlib-metadata        2.0.0                      py_1
       importlib_metadata        2.0.0                         1
       intel-openmp              2020.2                      254
       ipykernel                 5.3.4            py38h5ca1d4c_0
       ipython                   7.18.1           py38h5ca1d4c_0
       ipython_genutils          0.2.0                    py38_0
       isodate                   0.6.0                      py_1    conda-forge
       itsdangerous              1.1.0                      py_0    conda-forge
       jedi                      0.17.2                   py38_0
       jinja2                    2.11.2                     py_0
       jpeg                      9b                   h024ee3a_2
       json5                     0.9.5                      py_0
       jsonschema                3.2.0                      py_2
       jupyter_client            6.1.7                      py_0
       jupyter_core              4.6.3                    py38_0
       jupyterlab                2.2.6                      py_0
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         1.2.0                      py_0
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.0            py38h2531618_0
       lcms2                     2.11                 h396b838_0
       ld_impl_linux-64          2.33.1               h53a641e_7
       libedit                   3.1.20191231         h14c3975_1
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.1.0                hdf63c60_0
       libgfortran-ng            7.3.0                hdf63c60_0
       libpng                    1.6.37               hbc83047_0
       libprotobuf               3.13.0.1             h8b12597_0    conda-forge
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.1.0                hdf63c60_0
       libtiff                   4.1.0                h2733197_1
       libuuid                   1.0.3                h1bed415_2
       libxcb                    1.14                 h7b6447c_0
       libxml2                   2.9.10               hb55368b_3
       lmfit                     1.0.1                      py_1    conda-forge
       lz4-c                     1.9.2                heb0550a_3
       mako                      1.1.3              pyh9f0ad1d_0    conda-forge
       markdown                  3.3.3                    pypi_0    pypi
       markupsafe                1.1.1            py38h7b6447c_0
       matplotlib                3.3.2                         0
       matplotlib-base           3.3.2            py38h817c723_0
       mistune                   0.8.4           py38h7b6447c_1000
       mkl                       2020.2                      256
       mkl-service               2.3.0            py38he904b0f_0
       mkl_fft                   1.2.0            py38h23d657b_0
       mkl_random                1.1.1            py38h0573a6f_0
       mlflow                    1.11.0           py38h32f6830_1    conda-forge
       msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
       multipletau               0.3.3                    pypi_0    pypi
       nbclient                  0.5.1                      py_0
       nbconvert                 6.0.7                    py38_0
       nbformat                  5.0.8                      py_0
       ncurses                   6.2                  he6710b0_1
       nest-asyncio              1.4.1                      py_0
       notebook                  6.1.4                    py38_0
       numpy                     1.19.2           py38h54aff64_0
       numpy-base                1.19.2           py38hfa32c7d_0
       oauthlib                  3.0.1                      py_0    conda-forge
       olefile                   0.46                       py_0
       openssl                   1.1.1h               h516909a_0    conda-forge
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 20.4                       py_0
       pandas                    1.1.3            py38he6710b0_0
       pandoc                    2.11                 hb0f4dca_0
       pandocfilters             1.4.2                    py38_1
       parso                     0.7.0                      py_0
       pcre                      8.44                 he6710b0_0
       pexpect                   4.8.0                    py38_0
       pickleshare               0.7.5                 py38_1000
       pillow                    8.0.1            py38he98fc37_0
       pip                       20.2.4                   py38_0
       prometheus_client         0.8.0                      py_0
       prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
       prompt-toolkit            3.0.8                      py_0
       protobuf                  3.13.0.1         py38h950e882_1    conda-forge
       ptyprocess                0.6.0                    py38_0
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.20                       py_2
       pygments                  2.7.2              pyhd3eb1b0_0
       pyjwt                     1.7.1                      py_0    conda-forge
       pyopenssl                 19.1.0                     py_1
       pyparsing                 2.4.7                      py_0
       pyqt                      5.9.2            py38h05f1152_4
       pyrsistent                0.17.3           py38h7b6447c_0
       pysocks                   1.7.1                    py38_0
       python                    3.8.5                h7579374_1
       python-dateutil           2.8.1                      py_0
       python-editor             1.0.4                      py_0    conda-forge
       python_abi                3.8                      1_cp38    conda-forge
       pytz                      2020.1                     py_0
       pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
       pyzmq                     19.0.2           py38he6710b0_1
       qt                        5.9.7                h5867ecd_1
       querystring_parser        1.2.4                      py_0    conda-forge
       readline                  8.0                  h7b6447c_0
       requests                  2.24.0                     py_0
       requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
       rsa                       4.6                      pypi_0    pypi
       scipy                     1.5.2            py38h0b6359f_0
       seaborn                   0.11.0                     py_0
       send2trash                1.5.0                    py38_0
       setuptools                50.3.0           py38hb0f4dca_1
       sip                       4.19.13          py38he6710b0_0
       six                       1.15.0                     py_0
       smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
       sqlalchemy                1.3.13           py38h516909a_0    conda-forge
       sqlite                    3.33.0               h62c20be_0
       sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
       tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
       tb-nightly                2.4.0a20201102           pypi_0    pypi
       tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.1                    py38_0
       testpath                  0.4.4                      py_0
       tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
       tf-nightly                2.5.0.dev20201029          pypi_0    pypi
       tifffile                  2020.10.1        py38hdd07704_2
       tk                        8.6.10               hbc83047_0
       tornado                   6.0.4            py38h7b6447c_1
       traitlets                 5.0.5                      py_0
       typing-extensions         3.7.4.3                  pypi_0    pypi
       uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge
       urllib3                   1.25.11                    py_0
       wcwidth                   0.2.5                      py_0
       webencodings              0.5.1                    py38_1
       websocket-client          0.57.0           py38h32f6830_3    conda-forge
       werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
       wheel                     0.35.1                     py_0
       wrapt                     1.12.1                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       yaml                      0.2.5                h516909a_0    conda-forge
       zeromq                    4.3.3                he6710b0_3
       zipp                      3.4.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7b6447c_3
       zstd                      1.4.5                h9ceee32_0

       Note: you may need to restart the kernel to use updated packages.
     #+end_example

     #+BEGIN_SRC jupyter-python
       import sys
       sys.path.append('/beegfs/ye53nis/drmed-git/src/')
       from fluotracify.simulations import simulate_trace_with_artifact as stwa
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       folder = '/beegfs/ye53nis/saves/firstartifact_Nov2020/'
       file_name = 'traces_brightclust_Nov2020'
       total_sim_time = 16384
       d_mol_arr = [100]
       col_per_example = 3
       label_for = 'both'
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       sys.stdout = open('/dev/stdout', 'w')
     #+END_SRC

     #+RESULTS:



     #+BEGIN_SRC jupyter-python :results drawer
       stwa.produce_training_data(folder=folder,
                                  file_name=file_name,
                                  col_per_example=col_per_example,
                                  number_of_sets=2,
                                  traces_per_set=2,
                                  total_sim_time=total_sim_time,
                                  artifact=1,
                                  d_mol_arr=d_mol_arr,
                                  label_for=label_for)
     #+END_SRC

     #+RESULTS:
     :results:
     : 188c4766-8d0a-4c1d-97ef-ab2d2e218d33
     :end:

*** Reading End-to-End Lung cancer screening (Ardila, Kiraly, Bharadwaj, Choi et al, 2019)
    - link: [[docview:~/Dokumente/Forschung/Literatur/ML-applications/Ardila, D.
      End-to-end lung cancer screening 3D DL on low-dose chest CT_PRINTED.pdf]]


    - try Focal Loss [[docview:~/Dokumente/Forschung/Literatur/maths/Lin, T-Y et
      al (Facebook). Focal Loss for Dense Object Detection.pdf]]
      - they used it for a CNN that took whole-CT volumes instead of the regular
        (balanced) Cross entropy to mitigate the sparsity of positive examples
    - use localization metrics! such as their self-defined Hit@N (although this
      is compared with a manual labelling - not sure, maybe in some subset of
      self-taken FCS curves? Maybe ask 5 FCS researchers to check?? :D)
    - In the end it was an ensemble of 10? networks or so working together. And
      I think *All* of them were pretrained!! Important! Probably because there
      were only 398 cancer-positives for training this was even more important.
      - e.g. for Cancer ROI detection first a general dataset for *nodule
        detection* then the specific dataset to only detect *malignant nodules*
      - e.g. full volume model was pretained on imagenet.
    - interesting: the end-score for prediction was combined from the two most
      malignous ROIs using the *noisy-or* equation $1 - (1 -
      p_1)(1 - p_2)$
    - also interesting: statistical evaluation
      - confidence intervals computed bassed on the percentiles of 1000 random
        resamplings (bootstraps) of the data
      - for comparison reader-model differences the metrics were computed after
        these 1000 resamplings as well
      - P values for sensitivity and specifity based on
        - standard permutation test using 10,000 random resamplings
        - for each resampling, randomly swapped reader and model results for
          each case
        - then performed a two-sided hypothesis test comparing model-reader
          difference with distribution of 10,000 model-reader differences across
          the resampled data
        - result: empirical p-value

** TODOs
*** TODO use =mlflow.keras.log_model()= instead of tf =model.save=
#+BEGIN_SRC python
  mlflow.keras.log_model(keras_model,
                         artifact_path,
                         conda_env=None,
                         custom_objects=None,
                         keras_module=None,
                         registered_model_name=None,
                         **kwargs)
#+END_SRC
- keras_model=model
- artifact_path='model'
- conda_env=None (loads mlflow.keras.get_default_conda_env())
- custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()}
*** TODO Choosing some additional metrics
Which measures make sense for Artifact classification / segmentation:
- Recall! - I want all the artifacts
- Precision - slightly less important
- Combining the two, but giving recall a higher weight is possible with the
  *F-Measure*
  \[F_{\beta} = (1 + \beta^2) \cdot
  \frac{\text{precision}\cdot\text{recall}}{\beta^2\cdot\text{precision} +
  \text{recall}}\]
  - To get an evenly weighted version, we could use the \[F_{1} = 2 \cdot \frac{\text{precision}\cdot\text{recall}}{\text{precision} + \text{recall}}\], but even
    better is probably the measure \[F_{2} = 5
    \cdot\frac{\text{precision}\cdot\text{recall}}{4\cdot\text{precision} + \text{recall}}\]
  - just note that if using $F_2$ the outcome depends even stronger on the used
    threshold for deciding if a predicted probability is 1 or 0 → *there is a
    =threshold= argument for the =tf.keras.metrics= :)*
  - PROBLEM: no tf.keras.metrics.Fmeasure (or similar) - mmmh...
- AUC = Area Under the ROC Curve
  - is scale-invariante → measures how well predictions are ranked, rather than
    their absolute values
    - Cave: not always desirable, e.g. if we do need well calibrated probability outputs
  - is classification-threshold-invariant
    - Cave: not always desirable, e.g. when there are wide disparities in the
      cost of false negatives vs false positives, it may be critical to minimize
      one type of classification error → this is actually a thing in artifact
      classification, since we want to minimize the false negatives

This is the list I came up with:

#+BEGIN_SRC python
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
metrics = [tf.keras.metrics.TruePositives(name='tp', thresholds=thresholds),
           tf.keras.metrics.FalsePositives(name='fp', thresholds=thresholds),
           tf.keras.metrics.TrueNegatives(name='tn', thresholds=thresholds),
           tf.keras.metrics.FalseNegatives(name='fn', thresholds=thresholds),
           tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5),
           tf.keras.metrics.Precision(name='precision', thresholds=thresholds),
           tf.keras.metrics.Recall(name='recall', thresholds=thresholds),
           tf.keras.metrics.AUC(num_thresholds=100, name='auc')]
#+END_SRC
*** TODO compute metrics vs threshold → there is a =thresholds= argument for =tf.keras.metrics= :)
*** TODO Investigate Error on GPU node
- 2020-04-13 02:45:28.216446: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open
#  shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217069: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6:
  cannot open shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217123: W
  tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some
  TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please
  make sure the missing libraries mentioned above are installed properly
*** TODO fix pydot and graphviz to make model plotting work
*** TODO check out python module =argparser= as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
*** PENDING Fix isort and sys.path conflicts
    - State "PENDING"    from "TODO"       [2020-05-02 Sa 13:06] \\
      Waiting for isort 5.0.0 release
See here: https://github.com/timothycrosley/isort/issues/468#issuecomment-570899233
*** TODO Implement talos 1.0 with mlflow, see [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*Querying runs programmatically][here]] - or other Hyperparameter optimization
- an implementation of hyperopt + unet training [[https://www.kaggle.com/yassinealouini/mlflow-hyperopt-u-net-workflo][here]]
*** TODO [#C] Set up nice package using cookiecutter, poetry, See [[https://stackoverflow.com/questions/49474575/how-to-install-my-own-python-module-package-via-conda-and-watch-its-changes][here]]
* Reconnect
  :LOGBOOK:
  CLOCK: [2020-05-04 Mo 14:59]--[2020-05-04 Mo 14:59] =>  0:00
  :END:
** Tmux on Ara, Login node for git pull
#+CALL: setup-tmux[:session local]

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

Test:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session local
  cd /beegfs/ye53nis/drmed-git/
  git pull
#+END_SRC

#+RESULTS:
#+begin_example
#+end_example

** Compute node for script execution
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
#+end_example

** Jupyter on Ara
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#9999:a37e524a-8134-4d8f-b24a-367acaf1bdd3
   :END:

1. Request compute node via tmux
   #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
   cd /
   srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
   #+END_SRC

2.
#+CALL: jpt-tmux[:session jpmux]

   #+RESULTS:
   #+begin_example
     (tf-nightly) [ye53nis@node146 /]$ jupyter lab --no-browser --port=$PORT
     [I 00:02:39.372 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf-nightly/lib/python3.8/site-packages/jupyterlab
     [I 00:02:39.372 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf-nightly/share/jupyter/lab
     [I 00:02:39.375 LabApp] Serving notebooks from local directory: /
     [I 00:02:39.375 LabApp] Jupyter Notebook 6.1.4 is running at:
     [I 00:02:39.375 LabApp] http://localhost:9999/?token=93791464f12bacd92a8343c1a3be84117c0674d5703fd278
     [I 00:02:39.375 LabApp]  or http://127.0.0.1:9999/?token=93791464f12bacd92a8343c1a3be84117c0674d5703fd278
     [I 00:02:39.375 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
     [C 00:02:39.380 LabApp]

         To access the notebook, open this file in a browser:
             file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-54410-open.html
         Or copy and paste one of these URLs:
             http://localhost:9999/?token=93791464f12bacd92a8343c1a3be84117c0674d5703fd278
          or http://127.0.0.1:9999/?token=93791464f12bacd92a8343c1a3be84117c0674d5703fd278
   #+end_example

#+CALL: ssh-tunnel(port="9999", node="node146")

#+RESULTS:
| sh-5.0$           | sh-5.0$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |    |          |      |      |             |
| ye53nis@node146's | password: |                                      |           |    |          |      |      |             |
| Last              | login:    | Thu                                  | Dec       | 31 | 00:03:16 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           a37e524a-8134-4d8f-b24a-367acaf1bdd3   a few seconds ago    starting   0
#+end_example

Test:

#+CALL: jp-metadata(_long='True)

#+RESULTS:
#+begin_example
  No of CPUs in system: 72
  No of CPUs the current process can use: 24
  load average: (16.06, 15.99, 15.97)
  os.uname():  posix.uname_result(sysname='Linux', nodename='node146', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 56294
  RAM total: 199G, RAM used: 6.1G, RAM free: 163G
  the current directory: /
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  3.2G   47G   7% /
  devtmpfs              94G     0   94G   0% /dev
  tmpfs                 94G  297M   94G   1% /dev/shm
  tmpfs                 94G  195M   94G   1% /run
  tmpfs                 94G     0   94G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  473G  1.6T  24% /cluster
  nfs03-ib:/pool/work  100T   70T   31T  70% /nfsdata
  nfs02-ib:/data01      88T   71T   17T  81% /data01
  nfs01-ib:/home        80T   71T  9.8T  88% /home
  /dev/sda3            6.0G  436M  5.6G   8% /var
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G   12G  157G   7% /local
  beegfs_nodev         524T  433T   92T  83% /beegfs
  tmpfs                 19G     0   19G   0% /run/user/67339
  /bin/bash: conda: command not found
  {'SLURM_CHECKPOINT_IMAGE_DIR': '/var/slurm/checkpoint',
   'SLURM_NODELIST': 'node146',
   'SLURM_JOB_NAME': 'bash',
   'XDG_SESSION_ID': '9639',
   'SLURMD_NODENAME': 'node146',
   'SLURM_TOPOLOGY_ADDR': 'node146',
   'SLURM_NTASKS_PER_NODE': '24',
   'HOSTNAME': 'login01',
   'SLURM_PRIO_PROCESS': '0',
   'SLURM_SRUN_COMM_PORT': '43120',
   'SHELL': '/bin/bash',
   'TERM': 'xterm-color',
   'SLURM_JOB_QOS': 'qstand',
   'SLURM_PTY_WIN_ROW': '24',
   'HISTSIZE': '1000',
   'TMPDIR': '/tmp',
   'SLURM_TOPOLOGY_ADDR_PATTERN': 'node',
   'SSH_CLIENT': '10.231.210.198 43508 22',
   'CONDA_SHLVL': '2',
   'CONDA_PROMPT_MODIFIER': '(tf-nightly) ',
   'WINDOWID': '0',
   'QTDIR': '/usr/lib64/qt-3.3',
   'QTINC': '/usr/lib64/qt-3.3/include',
   'SSH_TTY': '/dev/pts/5',
   'QT_GRAPHICSSYSTEM_CHECKED': '1',
   'SLURM_NNODES': '1',
   'USER': 'ye53nis',
   'http_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
   'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',
   'CONDA_EXE': '/cluster/miniconda3/bin/conda',
   'SLURM_STEP_NUM_NODES': '1',
   'SLURM_JOBID': '534856',
   'SRUN_DEBUG': '3',
   'SLURM_NTASKS': '24',
   'SLURM_LAUNCH_NODE_IPADDR': '192.168.192.5',
   'SLURM_STEP_ID': '0',
   'TMUX': '/tmp/tmux-67339/default,27827,6',
   '_CE_CONDA': '',
   'CONDA_PREFIX_1': '/cluster/miniconda3',
   'SLURM_STEP_LAUNCHER_PORT': '43120',
   'SLURM_TASKS_PER_NODE': '24',
   'MAIL': '/var/spool/mail/ye53nis',
   'PATH': '/home/ye53nis/.conda/envs/tf-nightly/bin:/home/lex/Programme/miniconda3/envs/tf-nightly-lab/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/home/lex/Programme/miniconda3/bin:/usr/sbin:/home/ye53nis/.local/bin:/home/ye53nis/bin',
   'SLURM_WORKING_CLUSTER': 'hpc:192.168.192.1:6817:8448',
   'SLURM_JOB_ID': '534856',
   'CONDA_PREFIX': '/home/ye53nis/.conda/envs/tf-nightly',
   'SLURM_JOB_USER': 'ye53nis',
   'SLURM_STEPID': '0',
   'PWD': '/',
   'SLURM_SRUN_COMM_HOST': '192.168.192.5',
   'LANG': 'en_US.UTF-8',
   'SLURM_PTY_WIN_COL': '80',
   'SLURM_UMASK': '0022',
   'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles',
   'SLURM_JOB_UID': '67339',
   'LOADEDMODULES': '',
   'SLURM_NODEID': '0',
   'TMUX_PANE': '%6',
   'SLURM_SUBMIT_DIR': '/',
   'SLURM_TASK_PID': '53476',
   'SLURM_NPROCS': '24',
   'SLURM_CPUS_ON_NODE': '24',
   'SLURM_DISTRIBUTION': 'block',
   'https_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
   'SLURM_PROCID': '0',
   'HISTCONTROL': 'ignoredups',
   '_CE_M': '',
   'SLURM_JOB_NODELIST': 'node146',
   'SLURM_PTY_PORT': '46638',
   'HOME': '/home/ye53nis',
   'SHLVL': '3',
   'SLURM_LOCALID': '0',
   'SLURM_JOB_GID': '13280',
   'SLURM_JOB_CPUS_PER_NODE': '24',
   'SLURM_CLUSTER_NAME': 'hpc',
   'SLURM_GTIDS': '0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23',
   'SLURM_SUBMIT_HOST': 'login01',
   'SLURM_JOB_PARTITION': 's_standard',
   'MATHEMATICA_HOME': '/cluster/apps/mathematica/11.3',
   'CONDA_PYTHON_EXE': '/cluster/miniconda3/bin/python',
   'LOGNAME': 'ye53nis',
   'SLURM_STEP_NUM_TASKS': '24',
   'QTLIB': '/usr/lib64/qt-3.3/lib',
   'SLURM_JOB_ACCOUNT': 'iaob',
   'SLURM_JOB_NUM_NODES': '1',
   'MODULESHOME': '/usr/share/Modules',
   'CONDA_DEFAULT_ENV': 'tf-nightly',
   'LESSOPEN': '||/usr/bin/lesspipe.sh %s',
   'SLURM_STEP_TASKS_PER_NODE': '24',
   'PORT': '9999',
   'SLURM_STEP_NODELIST': 'node146',
   'DISPLAY': ':0',
   'XDG_RUNTIME_DIR': '',
   'XAUTHORITY': '/home/lex/.Xauthority',
   'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\n}',
   '_': '/home/ye53nis/.conda/envs/tf-nightly/bin/jupyter',
   'JPY_PARENT_PID': '54410',
   'CLICOLOR': '1',
   'PAGER': 'cat',
   'GIT_PAGER': 'cat',
   'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'}
#+end_example

** Tensorboard tunnel, Mlflow ui tunnel
#+CALL: ssh-tunnel[:session local](port="6006", node="node146")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |    |          |      |      |             |
| ye53nis@node146's | password:                            |           |     |    |          |      |      |             |
| Last              | login:                               | Mon       | May | 25 | 13:13:33 | 2020 | from | login01.ara |


#+CALL: ssh-tunnel[:session local2](port="5000", node="node181")

#+RESULTS:
| sh-5.0$           | sh-5.0$     | ye53nis@ara-login01.rz.uni-jena.de's | password:                 |         |    |     |      |    |       |        |   |
| Warning:          | Permanently | added                                | 'node181,192.168.193.181' | (ECDSA) | to | the | list | of | known | hosts. |   |
| ye53nis@node181's | password:   |                                      |                           |         |    |     |      |    |       |        |   |
|                   |             |                                      |                           |         |    |     |      |    |       |        |   |
|                   |             |                                      |                           |         |    |     |      |    |       |        |   |
