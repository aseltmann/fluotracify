#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both

* README
** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks
   - It contains explanations of how things are organized, of the workflow for
     doing experiments, changes made to the code, and the observed behavior in
     the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Following this, if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch. The /master/ branch is clean from any results, it contains only
     source code and the analysis.
** Experiments workflow:
   1) Create a new branch
   2) Make sure everything is commited
   3) ...
   4) Do the analysis
   5) Add to this file into "* Data" section the entry for the results, using
      the template described below
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote "data" branch
** Example for experimental setup procedure
*** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

*** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

    1. =M-x jupyter-server-list-kernels=
       1. set server URL, e.g. =http://localhost:8889=
       2. set websocket URL, e.g. =http://localhost:8889=
    2. two possibilities
       1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
       2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
          *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    3. In subtree where you want to use =jupyter-python= blocks with =org
       babel=, set the =:header-args:jupyter-python :session
       /jpy:localhost#kernel:8889-ID=
** tools used (notes)
*** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
*** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
*** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
*** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

** Example for ...
* Template for data entry:
** exp-#date-#title
*** git:
#+begin_src sh
git log -1
#+end_src

*** System Metadata:
#+NAME: jupyter-python-metadata
#+BEGIN_SRC jupyter-python :var conda_list="true"
  import os

  ramlist = os.popen('free -th').readlines()[-1].split()[1:]

  print('No of CPUs in system:', os.cpu_count())
  print('No of CPUs the current process can use:',
        len(os.sched_getaffinity(0)))
  print('load average:', os.getloadavg())
  print(os.uname())
  print('PID of process:', os.getpid())
  print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
      ramlist[0], ramlist[1], ramlist[2]))

  !echo the current directory: $PWD
  !echo My disk usage:
  !df -h
  if conda_list:
      !conda list
#+END_SRC

**** TODO Add =os.environ=
*** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:
#+NAME: setup-tmux
#+BEGIN_SRC sh :session local
rm ~/.tmux-local-socket-remote-machine
REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
echo $REMOTE_SOCKET
ssh ara -tfN \
    -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
#+END_SRC

#+RESULTS: setup-tmux
|         |                                      |           |
| sh-5.0$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
| >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

A script which allows to print the output from the tmux session
in an =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
C-v C-o= when the pointer is inside the tmux block. See [[https://github.com/ahendriksen/ob-tmux/issues/6#issuecomment-613914400][here]].

#+BEGIN_SRC emacs-lisp
  (defun ob-tmux--insert-result ()
    (interactive)
    (let ((info (org-babel-get-src-block-info 'light)))
      (when (and info (string-equal "tmux" (nth 0 info)))
        (let* ((params (nth 2 info))
               (org-session (cdr (assq :session params)))
               (socket (cdr (assq :socket params)))
               (socket (when socket (expand-file-name socket)))
               (ob-session (ob-tmux--from-org-session org-session socket)))
          (org-babel-insert-result
               (ob-tmux--execute-string ob-session
                                        "capture-pane"
                                        "-p" ;; print to stdout
                                        "-S" "-" ;; start at beginning of history
                                        "-t" (ob-tmux--session ob-session))
               '("replace"))))))

  (defun ob-tmux--edit-result ()
    (interactive)
    (pcase (org-babel-get-src-block-info 'light)
      (`(,_ ,_ ,arguments ,_ ,_ ,start ,_)
       (save-excursion
         ;; Go to the results, if there aren't any then run the block.
         (goto-char start)
         (goto-char (or (org-babel-where-is-src-block-result)
                        (progn (org-babel-execute-src-block)
                               (org-babel-where-is-src-block-result))))
         (end-of-line)
         (skip-chars-forward " \r\t\n")
         (org-edit-special)
         (delete-trailing-whitespace)
         (end-of-buffer)
         t))
      (_ nil)))

  (defun ob-tmux--open-src-block-result (orig-fun &rest args)
    (let ((info (org-babel-get-src-block-info 'light)))
      (if (and info (string-equal "tmux" (nth 0 info)))
          (progn
            (ob-tmux--insert-result)
            (ob-tmux--edit-result))
        (apply orig-fun args))))

  (advice-add 'org-babel-open-src-block-result
                 :around #'ob-tmux--open-src-block-result)
#+END_SRC

#+RESULTS:

*** jupyter setup and ssh tunneling

On the compute node of the HPC, the users' environment is managed through module
files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements are needed
because of a jupyter bug which did not let it start. Right now, =ob-tmux= does
not support a =:var= header like normal =org-babel= does. So the =$port=
variable has to be set before calling a block similar to this one:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
export PORT=8889
#+END_SRC

Then call:

#+NAME: jpt-tmux
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
module load tools/python/3.7
export XDG_RUNTIME_DIR=''
export XDG_RUNTIME_DIR=""
jupyter notebook --no-browser --port=$PORT
#+END_SRC

Now this port has to be tunnelled on our local computer. While the tmux session
above keeps running, no matter if Emacs is running or not, this following ssh
tunnel needs to be active locally to connect to the notebook. If Emacs crashes,
it would need to be reestablished.

#+NAME: jpt-tunnel
#+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
#+END_SRC

*** Notes:
    ######################

* Organization of git
** remote/origin/master branch:
   - Has all the source, analysis, scripts
** remote/origin/xp# branches:
   - Have all the data connected to specific experiments
   - Also some important (not all) .pdf files
** remote/origin/data branch:
   - Merging all the data and source branches
** Git TAGs
*** Stable versions:
**** stable13
    StarPU version: trunk 14405
    Simgrid: c78eee2
    qrm_starpu: r1393
    new_magmamorse: r1799
**** stable13.1
    StarPU version: trunk 14405
    Simgrid: c78eee2
    qrm_starpu: r1443
    new_magmamorse: r1799
*** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
* Organization of code
** scripts:
** src/
*** fluotracify/
**** imports/
**** simulations/
**** training/
**** applications/
**** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

*** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

* Changes in this repository (without "* Data" in this file)
** Changes in LabBook.org (without "* Data")
*** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
*** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
** Changes in src/fluotracify

* DEVELOPMENT TESTING (don't merge in master)
  :LOGBOOK:
  CLOCK: [2020-04-23 Do 13:35]--[2020-04-23 Do 14:57] =>  1:22
  :END:
** configured custom yasnippets,
   - check =yas-describe-tables= for current snippets
   - use =C-c & C-n= to create new snippet (its put in =.emacs.d/snippets/=)

#+BEGIN_SRC sh :session local
  ls -Rl ~/.emacs.d/snippets/
#+END_SRC

#+RESULTS:
| /home/lex/.emacs.d/snippets/:         |     |    |       |                       |
| total                                 |     |    |       |                       |
| drwxr-xr-x                            | Apr | 23 | 15:23 | org-mode              |
| /home/lex/.emacs.d/snippets/org-mode: |     |    |       |                       |
| total                                 |     |    |       |                       |
| -rw-r--r--                            | Apr | 23 | 14:32 | jupyter-python-block  |
| -rw-r--r--                            | Apr | 23 | 14:35 | jupyter-python-header |
| -rw-r--r--                            | Apr | 23 | 15:23 | lmod-srun             |
| -rw-r--r--                            | Apr | 23 | 14:53 | src2                  |
| -rw-r--r--                            | Apr | 23 | 15:00 | tmux                  |

** fix hardlinks of org-files outside =Dokumente/org=
#+BEGIN_SRC sh :session local :results verbatim
  cd Dokumente/org/linkedfiles
  ls -li
  find / -samefile LabBook.org
#+END_SRC

#+RESULTS:
#+begin_example
total 84
4992947 -rw-r--r-- 2 lex lex 11786 Apr 23 14:14 LabBook.org
 404446 -rw-r--r-- 1 lex lex 21544 Apr  4 22:53 LabBook.org~
 404411 -rw-r--r-- 2 lex lex 23355 Apr 20 01:44 lexbn-source.org
4328628 -rw-r--r-- 1 lex lex 20829 Apr 19 14:37 lexbn-source.org~

/home/lex/Dokumente/org/linkedfiles/LabBook.org
/home/lex/Programme/drmed-git/LabBook.org
#+end_example

** connect LabBook to HPC with jupyter etc
   :LOGBOOK:
   CLOCK: [2020-04-23 Do 17:30]--[2020-04-23 Do 17:46] =>  0:16
   CLOCK: [2020-04-23 Do 16:05]--[2020-04-23 Do 16:38] =>  0:33
   CLOCK: [2020-04-23 Do 15:20]--[2020-04-23 Do 15:50] =>  0:30
   CLOCK: [2020-04-23 Do 14:57]--[2020-04-23 Do 15:07] =>  0:10
   :END:
*** connect to compute node
#+BEGIN_SRC sh :session org-ssh :results verbatim
  ssh ara
#+END_SRC

#+RESULTS:
: ssh: Could not resolve hostname ara: Name or service not known

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    48 | mix   | node[003,007-008,023-026,029,031,033-038,040,053,063-064,066-072,075-078,083-085,090-094,117-119,121-125,131,133]                                                                                 |
| b_standard* | up    | 8-08:00:00 |    82 | alloc | node[002,004-006,009-022,027-028,030,032,039,041-045,047-052,054-062,065,073-074,079-082,086-089,095-116,120,126,132,134-136]                                                                     |
| b_standard* | up    | 8-08:00:00 |     1 | idle  | node046                                                                                                                                                                                           |
| gpu_test    | up    |    1:00:00 |     1 | idle  | node127                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | idle  | node130                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     4 | mix   | node[137-140]                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | idle  | node141                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    68 | mix   | node[144,151,162-163,167,169,171-172,177-181,186,191,196-198,200,203-209,212-214,216,218,221-222,224-231,233,235-237,241-249,255,257,259-260,265-268,297,303-304,309-310,315]                     |
| s_standard  | up    | 8-08:00:00 |    83 | alloc | node[142-143,145-150,152-161,164-166,168,170,173-176,182-185,187-190,192-195,199,201-202,210-211,215,217,219-220,223,232,234,238-240,250-254,256,258,261-264,293-296,298-302,305-308,311-314,316] |
| s_fat       | up    | 8-08:00:00 |     3 | mix   | node[269-270,272]                                                                                                                                                                                 |
| s_fat       | up    | 8-08:00:00 |     1 | alloc | node271                                                                                                                                                                                           |

#+BEGIN_SRC sh :session org-ssh
  tmux ls
#+END_SRC

#+RESULTS:
|       0: | 1 | windows | (created | Mon | Apr | 13 | 19:54:44 | 2020 |
| ob-tmux: | 1 | windows | (created | Mon | Apr | 13 | 19:55:21 | 2020 |


#+CALL:setup-tmux

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  echo test
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ echo test
  test
  [ye53nis@login01 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 -
  -pty bash
  [ye53nis@node018 ~]$
#+end_example

*** start and connect to jupyter
:PROPERTIES:
:header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
:END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  export PORT=8889
#+END_SRC

#+CALL: jpt-tmux[:session ob-tmux]

#+RESULTS:
#+begin_example
  [ye53nis@node018 ~]$ export PORT=8889
  [ye53nis@node018 ~]$ module load tools/python/3.7
  [ye53nis@node018 ~]$ export XDG_RUNTIME_DIR=''
  [ye53nis@node018 ~]$ export XDG_RUNTIME_DIR=""
  [ye53nis@node018 ~]$ jupyter notebook --no-browser --port=$PORT
  [I 16:09:30.912 NotebookApp] Serving notebooks from local directory: /home/ye53n
  is
  [I 16:09:30.912 NotebookApp] The Jupyter Notebook is running at:
  [I 16:09:30.912 NotebookApp] http://localhost:8889/?token=8cd6a262f7384ed4780611
  af96fb9cb4db8733a4cf654eaf
  [I 16:09:30.912 NotebookApp] Use Control-C to stop this server and shut down all
   kernels (twice to skip confirmation).
  [C 16:09:30.957 NotebookApp]

      To access the notebook, open this file in a browser:
          file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-50353-open.ht
  ml
      Or copy and paste one of these URLs:
          http://localhost:8889/?token=8cd6a262f7384ed4780611af96fb9cb4db8733a4cf6
  54eaf
#+end_example

#+CALL: jpt-tunnel(port="8889", node="node018")

#+RESULTS:
| sh-5.0$           | sh-5.0$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |    |          |      |      |             |
| ye53nis@node018's | password: |                                      |           |    |          |      |      |             |
| Last              | login:    | Thu                                  | Apr       | 23 | 16:20:50 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           6be3aedd-62d4-4fc2-b816-af41e3986de9   2 minutes ago        starting   0
#+end_example

Passing a boolean value to a variable in =org-babel= was not trivial: you have to
use the infamous *single quote '* from emacs-lisp programming to show that the
expression should be returned as written, not evaluated.

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 48
  No of CPUs the current process can use: 48
  load average: (0.08, 0.03, 0.05)
  posix.uname_result(sysname='Linux', nodename='node018', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 86937
  RAM total: 137G, RAM used: 1.7G, RAM free: 126G
  the current directory: /home/ye53nis
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  4.3G   46G   9% /
  devtmpfs              63G     0   63G   0% /dev
  tmpfs                 63G  559M   63G   1% /dev/shm
  tmpfs                 63G   59M   63G   1% /run
  tmpfs                 63G     0   63G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  nfs01-ib:/home        80T   59T   22T  73% /home
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  3.9G  165G   3% /local
  /dev/sda3            6.0G  481M  5.6G   8% /var
  beegfs_nodev         524T  421T  104T  81% /beegfs
  tmpfs                 13G     0   13G   0% /run/user/67339
#+end_example

** set up mlflow
   :LOGBOOK:
   CLOCK: [2020-04-24 Fr 13:09]--[2020-04-24 Fr 13:52] =>  0:43
   CLOCK: [2020-04-24 Fr 11:07]--[2020-04-24 Fr 11:30] =>  0:23
   CLOCK: [2020-04-23 Do 19:05]--[2020-04-23 Do 19:50] =>  0:45
   CLOCK: [2020-04-23 Do 17:59]--[2020-04-23 Do 18:49] =>  0:50
   CLOCK: [2020-04-23 Do 17:46]--[2020-04-23 Do 17:51] =>  0:05
   :END:
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
   :END:

*** how do I submit mlflow jobs?
- I will need two sessions
  - one *tmux session* for running the jupyter kernel, having a REPL, fast and
    interactive coding. I need tmux bc the connection to the node would break if
    I log out of ssh.
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
      echo tüdelü
    #+END_SRC
  - one *sh ssh session* for sending command line commands. SLURM handles the
    job and outputs files - so it should continue, even if I log out
- alternative solution: tmux windows (*note: after using tmux windows, the
  normal =:session tmux= without window specification doesn't work anymore*)
  - this is window =mlflow= for sending mlflow commands. we have to request some
    computation power by SLURM again
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
      echo pwd
    #+END_SRC
  - this is window =ob1= (name automatically created when you don't specify a
    window name) where our jupyter kernel runs:
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:ob1
      echo testö
    #+END_SRC
**** Failed approaches:
- then jobs are submitted e.g. as bash scripts (this is just an example from the
  wiki):
  #+BEGIN_SRC sh
    #!/bin/bash
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_standard
    #SBATCH --nodes=4
    #SBATCH --ntasks-per-node=36
    #SBATCH --time=1:00
    module purge
    module load tools/python/3.7 mpi/intel/2019-Update5
    srun python intro.py
  #+END_SRC
- test:
  #+NAME: sh-test-script
  #+BEGIN_SRC sh :shebang "#!/bin/bash"
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_test
    #SBATCH --nodes=1
    hostname
  #+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow :noweb yes
  sbatch <<sh-test-script>>
#+END_SRC

  #+BEGIN_SRC sh :session org-ssh :noweb yes :tangle yes
    sbatch <<sh-test-script>>
  #+END_SRC

  #+RESULTS:
  |                                                   |
  | sbatch: error: Unable to open file sh-test-script |

Note: t

**** Note: do it like for jupyter: srun a bash script, then execute mlflow
*** Reading the docs: mlflow
- searched for papers, found [[http://sites.computer.org/debull/A18dec/A18DEC-CD.pdf#page=41][two]] [[https://mlsys.org/Conferences/2019/doc/2019/demo_33.pdf][papers]], but they don't seem very exhaustive.
- took notes [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*<2020-04-16 Do 12:57> =mlflow=][here]]
- shall I keep MLflow files in a folder inside the =data/exp#= folder for each
  experiment or do a central =data/mlflow= folder? → I tend towards the second
  option. MLflow has an environment variable =MLFLOW_EXPERIMENT_NAME= which
  would be the same as =exp#=.
- Inside the folder, should I use "normal" files or a database for saving stuff?
  → I tend towards normal files, since I have no experiments with databases..
- MLflow Tracking Service API might be useful for accessing the results from
  inside org documents.

*** Reading Barredo Arrieta et al: Explainable Artificial Intelligence (XIA)
*** Set up git on HPC
    :LOGBOOK:
    CLOCK: [2020-04-24 Fr 14:35]--[2020-04-24 Fr 17:53] =>  3:18
    CLOCK: [2020-04-24 Fr 13:53]--[2020-04-24 Fr 14:15] =>  0:22
    :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
  git clone https://github.com/aseltmann/fluotracify
#+END_SRC

Wanted to git pull my repository on HPC, noticed that it already exists - and
has uncommited changes. Have to sort that out.

Git runs now on HPC, but had to resolve merge conflicts in code → used *Magit*
and especially Ediff. Watched these resources:
- https://www.youtube.com/watch?v=9S2pMZ6U5Tc&t=715s - short resource on smerge
  and ediff
- https://www.youtube.com/watch?v=j-k-lkilbEs - nice intro to magit in general

*** run mlflow test
**** Use a local tmux session:

#+BEGIN_SRC tmux :session local
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ pwd
  /home/lex
#+end_example

#+BEGIN_SRC tmux :session local
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_EXPERIMENT_ID=0.1
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow run .
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run .
  Specify only one of 'experiment-name' or 'experiment-id' options.
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local2
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  mlflow run /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run /home/lex/Programme/drmed-git/
  2020/04/28 01:17:01 INFO mlflow.projects: === Created directory /tmp/tmp_goyesz7
   for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/28 01:17:01 INFO mlflow.projects: === Running command 'source /home/lex/
  Programme/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114
  b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/tra
  in.py 5 0.2 16384 1e-5 10' in run with ID 'c0f7e64fdda64801860e9805948db29d' ===

  /home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709
  c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_interna
  l.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib
  ; see the module's documentation for alternative uses
    import imp
  2.1.0
  train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set003.csv
  train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set002.csv
  test 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tra
  ces_brightclust_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted time
  steps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-28 01:17:15.293658: I tensorflow/core/platform/cpu_feature_guard.cc:142]
   Your CPU supports instructions that this TensorFlow binary was not compiled to
  use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-28 01:17:15.340845: I tensorflow/core/platform/profile_utils/cpu_utils.c
  c:94] CPU Frequency: 2400500000 Hz
  2020-04-28 01:17:15.342222: I tensorflow/compiler/xla/service/service.cc:168] XL
  A service 0x5654fb291850 initialized for platform Host (this does not guarantee
  that XLA will be used). Devices:
  2020-04-28 01:17:15.342284: I tensorflow/compiler/xla/service/service.cc:176]
  StreamExecutor device (0): Host, Default Version
  2020-04-28 01:17:15.344811: I tensorflow/core/common_runtime/process_util.cc:147
  ] Creating new thread pool with default inter op setting: 2. Tune using inter_op
  _parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 65, in <module>
      with mlflow.start_run():
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 122, in
   start_run
      active_run_obj = MlflowClient().get_run(existing_run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 96, in
  get_run
      return self._tracking_client.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client
  .py", line 49, in get_run
      return self.store.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 423, in get_run
      run_info = self._get_run_info(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 442, in _get_run_info
      databricks_pb2.RESOURCE_DOES_NOT_EXIST)
  mlflow.exceptions.MlflowException: Run 'c0f7e64fdda64801860e9805948db29d' not fo
  und
  Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7fb42c4
  f4440>
  Traceback (most recent call last):
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_
  ops.py", line 3462, in __del__
  AttributeError: 'NoneType' object has no attribute 'device'
  2020/04/28 01:17:16 ERROR mlflow.cli: === Run (ID 'c0f7e64fdda64801860e9805948db
  29d') failed ===
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

**** use remote tmux
#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+RESULTS:
| Permission                           | denied,   | please | try    | again. |          |          |      |                |            |                |    |           |
| ye53nis@ara-login01.rz.uni-jena.de's | password: |        |        |        |          |          |      |                |            |                |    |           |
| Last                                 | failed    | login: | Tue    | Apr    |       28 | 11:05:11 | CEST |           2020 | from       | 10.231.181.150 | on | ssh:notty |
| There                                | was       | 1      | failed | login  |  attempt |    since | the  |           last | successful |         login. |    |           |
| Last                                 | login:    | Tue    | Apr    | 28     | 10:57:34 |     2020 | from | 10.231.181.150 |            |                |    |           |

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | down* | node001                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    30 | mix   | node[005-006,008,010,014,016,023,025,029,031,039,043,046,063-066,069-071,086,108,110,120,126,131-132,134-136]                                                                     |
| b_standard* | up    | 8-08:00:00 |    93 | alloc | node[002-004,009,011-013,015,017-022,024,026-028,030,032-038,040-042,044-045,047-062,072-084,087-107,109,111-114,117-118,121-123,125,133]                                         |
| b_standard* | up    | 8-08:00:00 |     8 | idle  | node[007,067-068,085,115-116,119,124]                                                                                                                                             |
| gpu_test    | up    |    1:00:00 |     1 | idle  | node127                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | idle  | node[128-129]                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | mix   | node130                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     1 | mix   | node139                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     3 | alloc | node[137-138,140]                                                                                                                                                                 |
| s_test      | up    |    3:00:00 |     1 | idle  | node141                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    44 | mix   | node[151,155,167,169,177,186,191,196-200,203,216,218,224-231,233,235,241-246,249,255,259-260,265-268,297,303,309-310,315]                                                         |
| s_standard  | up    | 8-08:00:00 |   107 | alloc | node[142-150,152-154,156-166,168,170-176,178-185,187-190,192-195,201-202,204-215,217,219-223,232,234,236-240,247-248,250-254,256-258,261-264,293-296,298-302,304-308,311-314,316] |
| s_fat       | up    | 8-08:00:00 |     1 | mix   | node269                                                                                                                                                                           |
| s_fat       | up    | 8-08:00:00 |     3 | alloc | node[270-272]                                                                                                                                                                     |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    srun -p b_standard --time=7-08:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 drmed-git]$ srun -p b_standard --time=7-08:00:00 --ntasks-per-node 48 --pty bash
  [ye53nis@node007 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load tools/python/3.7
  module load module-git
  mlflow --version
  git --version
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow --version
  git --version
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    from collections import Mapping
  mlflow, version 1.7.0
  [ye53nis@node007 drmed-git]$ git --version
  git version 1.8.3.1
  [ye53nis@node007 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . --no-conda
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node001 drmed-git]$ mlflow run .
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated
   since Python 3.3,and in 3.9 it will stop working
    from collections import Mapping
  Notice: failed to import Git (the git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
  The git executable must be specified in one of the following ways:
      - be included in your $PATH
      - be set via $GIT_PYTHON_GIT_EXECUTABLE
      - explicitly set via git.refresh()

  All git commands will error until this is rectified.

  This initial warning can be silenced or aggravated in the future by setting the
  $GIT_PYTHON_REFRESH environment variable. Use one of the following values:
      - quiet|q|silence|s|none|n|0: for no warning or exception
      - warn|w|warning|1: for a printed warning
      - error|e|raise|r|2: for a raised exception

  Example:
      export GIT_PYTHON_REFRESH=quiet

  2020/04/28 11:13:04 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to in
  itialize: Bad git executable.
  The git executable must be specified in one of the following ways:
      - be included in your $PATH
      - be set via $GIT_PYTHON_GIT_EXECUTABLE
      - explicitly set via git.refresh()

  All git commands will error until this is rectified.

  This initial warning can be silenced or aggravated in the future by setting the
  $GIT_PYTHON_REFRESH environment variable. Use one of the following values:
      - quiet|q|silence|s|none|n|0: for no warning or exception
      - warn|w|warning|1: for a printed warning
      - error|e|raise|r|2: for a raised exception

  Example:
      export GIT_PYTHON_REFRESH=quiet

  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/git/__init__.py", line 83, in <module>
      refresh()
    File "/cluster/miniconda3/lib/python3.7/site-packages/git/__init__.py", line 73, in refresh
      if not Git.refresh(path=path):
    File "/cluster/miniconda3/lib/python3.7/site-packages/git/cmd.py", line 278, in refresh
      raise ImportError(err)
  ImportError: Bad git executable.
  The git executable must be specified in one of the following ways:
      - be included in your $PATH
      - be set via $GIT_PYTHON_GIT_EXECUTABLE
      - explicitly set via git.refresh()

  All git commands will error until this is rectified.

  This initial warning can be silenced or aggravated in the future by setting the
  $GIT_PYTHON_REFRESH environment variable. Use one of the following values:
      - quiet|q|silence|s|none|n|0: for no warning or exception
      - warn|w|warning|1: for a printed warning
      - error|e|raise|r|2: for a raised exception

  Example:
      export GIT_PYTHON_REFRESH=quiet


  During handling of the above exception, another exception occurred:

  Traceback (most recent call last):
    File "/cluster/miniconda3/bin/mlflow", line 10, in <module>
      sys.exit(cli())
    File "/cluster/miniconda3/lib/python3.7/site-packages/click/core.py", line 764, in __call__
      return self.main(*args, **kwargs)
    File "/cluster/miniconda3/lib/python3.7/site-packages/click/core.py", line 717, in main
      rv = self.invoke(ctx)
    File "/cluster/miniconda3/lib/python3.7/site-packages/click/core.py", line 1137, in invoke
      return _process_result(sub_ctx.command.invoke(sub_ctx))
    File "/cluster/miniconda3/lib/python3.7/site-packages/click/core.py", line 956, in invoke
      return ctx.invoke(self.callback, **ctx.params)
    File "/cluster/miniconda3/lib/python3.7/site-packages/click/core.py", line 555, in invoke
      return callback(*args, **kwargs)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/cli.py", line 138, in run
      run_id=run_id
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/projects/__init__.py", line 288, in run
      use_conda=use_conda, storage_dir=storage_dir, synchronous=synchronous, run_id=run_id)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/projects/__init__.py", line 120, in _run
      repo_url = _get_git_repo_url(work_dir)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/projects/utils.py", line 34, in _get_git_repo_url
      from git import Repo
    File "/cluster/miniconda3/lib/python3.7/site-packages/git/__init__.py", line 85, in <module>
      raise ImportError('Failed to initialize: {0}'.format(exc))
  ImportError: Failed to initialize: Bad git executable.
  The git executable must be specified in one of the following ways:
      - be included in your $PATH
      - be set via $GIT_PYTHON_GIT_EXECUTABLE
      - explicitly set via git.refresh()

  All git commands will error until this is rectified.

  This initial warning can be silenced or aggravated in the future by setting the
  $GIT_PYTHON_REFRESH environment variable. Use one of the following values:
      - quiet|q|silence|s|none|n|0: for no warning or exception
      - warn|w|warning|1: for a printed warning
      - error|e|raise|r|2: for a raised exception

  Example:
      export GIT_PYTHON_REFRESH=quiet

  [ye53nis@node001 drmed-git]$
#+end_example


#+BEGIN_SRC sh :dir ~/Programme/drmed-git :session local

#+END_SRC

#+RESULTS:
|                               |
| /home/lex/Programme/drmed-git |

** TODOs
**** TODO Investigate Error on GPU node
- 2020-04-13 02:45:28.216446: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open
  shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217069: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6:
  cannot open shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217123: W
  tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some
  TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please
  make sure the missing libraries mentioned above are installed properly
**** TODO Export pandas DataFrames as org tables instead of html
- see https://github.com/dzop/emacs-jupyter/issues/88
- see
  https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks
**** TODO Inline-display of plots
**** TODO fix pydot and graphviz to make model plotting work
**** TODO transform ML training ipynb to py files as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
**** TODO check out python module =argparser= as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
**** TODO check out Talos 1.0 with MLflow for Hyperparameter optimization
*** TODO Take a look into =org-ref= for reference management and citing inside this labbook
*** TODO [#A] Further setup of git branching model
*** TODO [#C] Set up Dropbox or git annex
* Reconnect
#+CALL: setup-tmux[:session local]

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

#+CALL: jpt-tunnel(port="8889", node="node018")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |    |          |      |      |             |
| ye53nis@node018's | password:                            |           |     |    |          |      |      |             |
| Last              | login:                               | Sat       | Apr | 25 | 13:40:36 | 2020 | from | login01.ara |

#+CALL: jupyter-python-metadata(conda_list='False)
