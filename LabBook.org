#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:4
#+OPTIONS: H:4
#+HTML_HEAD_EXTRA: <style type="text/css">.example {background-color: #FBFBBF;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-emacs-lisp {background-color: #F7ECFB;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-sh {background-color: #F0FBE9;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-tmux {background-color: #E1EED8;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-python {background-color: #E6EDF4;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-jupyter-python {background-color: #FAEAE1;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details {padding: 1em; background-color: #f0f0f0; border-radius: 15px; color: hsl(157 75% 20%); font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em  #00000057;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details:hover {background:pink;}</style>


* Technical Notes
** README
*** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks. It also contains notes taken
     during the process of setting up this workflow for reproducible research.
   - This file contains explanations of how things are organized, of the
     workflow for doing experiments, changes made to the code, and the observed
     behavior in the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Therefore: if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch of the repository. The /main/ branch is clean from any results, it
     contains only source code and the analysis.
   - This project is my take on [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]]. The idea was postulated in
     a blog post in 2006:
     #+BEGIN_QUOTE
     ... there is a URL to a laboratory notebook that is freely available and
     indexed on common search engines. It does not necessarily have to look like
     a paper notebook but it is essential that all of the information available
     to the researchers to make their conclusions is equally available to the
     rest of the world ---Jean-Claude Bradley
     #+END_QUOTE
   - Proposal on how to deal with truly private data (e.g. notes from a
     confidential meeting with a colleague), which might otherwise be noted in a
     normal Lab notebook: do not include them here. Only notes relevant to the
     current project should be taken
*** Code block languages used in this document

   #+BEGIN_SRC sh
     # This is a sh block for shell / bash scripting. In the context of this file,
     # these blocks are mainly used for operations on my local computer.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light green colour (#F0FBE9)
   #+END_SRC

   #+BEGIN_SRC tmux
     # This block can open and access tmux sessions, used for shell scripting on
     # remote computing clusters.
     # In the LabBook.html rendering of this document, these blocks will have a
     # distinct light green colour (#E1EED8)
   #+END_SRC

   #+BEGIN_SRC python
     # This is a python block. In the context of this file, it is seldomly used
     # (only for examplary scripts.)
     # In the LabBook.html rendering of this document, these blocks will have a
     # light blue colour (#E6EDF4)
   #+END_SRC

   #+BEGIN_SRC jupyter-python :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
     # This is a jupyter-python block. The code is sent to a jupyter kernel running
     # on a remote high performance computing cluster. Most of my jupyter code is
     # executed this way.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light orange colour (#FAEAE1)
   #+END_SRC

   #+BEGIN_SRC emacs-lisp
     ;; This is a emacs-lisp block, the language used to customize Emacs, which is
     ;; sometimes necessary, since the reproducible workflow of this LabBook is
     ;; tightly integrated with Emacs and org-mode.
     ;; In the LabBook.html rendering of this document, these blocks will have a
     ;; light violet colour (#F7ECFB)
   #+END_SRC

   #+begin_example
     This is a literal example block. It can be used very flexibly - in the context
     of this document the output of most code blocks is displayed this way.
     In the LabBook.html rendering of this document, these blocks will have a light
     yellow colour (#FBFBBF)
   #+end_example

   #+begin_details
   #+begin_example
     This is a literal example block enclosed in a details block. This is useful to
     make the page more readable by collapsing large amounts of output.
     In the Labbook.html rendering of this document, the details block will have a
     light grey colour (#f0f0f0) and a pink color when hovering above it.
   #+end_example
   #+end_details

*** Experiments workflow:
   1) Create a new branch from =main=
   2) Print out the git log from the latest commit and the metadata
   3) Call the analysis scripts, follow the principles outlined in
      [[* Organization of code]]
   4) All machine learning runs are saved in =data/mlruns=, all other data in
      =data/#experiment-name=
   5) Add a ~** exp-<date>-<name>~" section to this file under [[* Data]]
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote =data= branch
*** Example for experimental setup procedure

**** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

*** tools used (notes)
**** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
**** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
**** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
**** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

** Template for data entry and setup notes:
*** exp-#date-#title
**** git:

    #+begin_src sh
    git log -1
    #+end_src

**** System Metadata:

    #+NAME: jp-metadata
    #+BEGIN_SRC jupyter-python :var _long="true"
      import os
      import pprint

      ramlist = os.popen('free -th').readlines()[-1].split()[1:]

      print('No of CPUs in system:', os.cpu_count())
      print('No of CPUs the current process can use:',
            len(os.sched_getaffinity(0)))
      print('load average:', os.getloadavg())
      print('os.uname(): ', os.uname())
      print('PID of process:', os.getpid())
      print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
          ramlist[0], ramlist[1], ramlist[2]))

      !echo the current directory: $PWD
      !echo My disk usage:
      !df -h
      if _long:
          %conda list
          pprint.pprint(dict(os.environ), sort_dicts=False)

    #+END_SRC

**** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:

    #+NAME: setup-tmux
    #+BEGIN_SRC sh :session local
    rm ~/.tmux-local-socket-remote-machine
    REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
    echo $REMOTE_SOCKET
    ssh ara -tfN \
        -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
    #+END_SRC

    #+RESULTS: setup-tmux
    | rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
    | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
    | /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
    | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

**** SSH tunneling
    :PROPERTIES:
    :CUSTOM_ID: ssh-tunneling
    :END:

    Different applications can be run on the remote compute node. If I want to
    access them at the local machine, and open them with the browser, I use this
    tunneling script.

    #+NAME: ssh-tunnel
    #+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
    ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
    #+END_SRC

    #+RESULTS: ssh-tunnel
    | sh-5.0$           | sh-5.0$   | ye53nis@ara-login01.rz.uni-jena.de's | password:        |     |      |    |        |      |    |      |      |
    | ye53nis@node001's | password: |                                      |                  |     |      |    |        |      |    |      |      |
    | Access            | denied    | by                                   | pam_slurm_adopt: | you | have | no | active | jobs | on | this | node |
    | Authentication    | failed.   |                                      |                  |     |      |    |        |      |    |      |      |
    | Connection        | to        | ara-login01.rz.uni-jena.de           | closed.          |     |      |    |        |      |    |      |      |

    Apps I use that way:
    - Jupyter lab for running Python 3-Kernels
    - TensorBoard
    - Mlflow ui

**** jupyter scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-jp
    :END:

    Starting a jupyter instance on a server where the necessary libraries are
    installed is easy using this script:

    #+NAME: jpt-tmux
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
    conda activate tf
    export PORT=9999
    export XDG_RUNTIME_DIR=''
    export XDG_RUNTIME_DIR=""
    jupyter lab --no-browser --port=$PORT
    #+END_SRC

    On the compute node of the HPC, the users' environment is managed through
    module files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements
    are needed because of a jupyter bug which did not let it start. Right now,
    =ob-tmux= does not support a =:var= header like normal =org-babel= does. So
    the =$port= variable has to be set here in the template.

    Now this port has to be tunnelled on our local computer (See
    [[#ssh-tunneling]]). While the tmux session above keeps running, no matter if
    Emacs is running or not, this following ssh tunnel needs to be active
    locally to connect to the notebook. If you close Emacs, it would need to be
    reestablished

*** Setup notes
**** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

**** =emacs-jupyter= Setup

    =Emacs-jupyter= aims to be an API for a lot of functionalities of the
    =jupyter= project. The documentation can be found on [[https://github.com/dzop/emacs-jupyter][GitHub]].

    1. For the *whole document*: connect to a running jupyter instance
       1. =M-x jupyter-server-list-kernels=
          1. set server URL, e.g. =http://localhost:8889=
          2. set websocket URL, e.g. =http://localhost:8889=
       2. two possibilities
          1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
          2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
             *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    2. In the *subtree* where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. customize the output folder using the following org-mode variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/plots
    3. For each *individual block*, the following customizations might be useful
       1. jupyter kernels can return multiple kinds of rich output (images,
          html, ...) or scalar data (plain text, numbers, lists, ...). To force
          a plain output, use =:results scalar=. To show the output in the
          minibuffer only, use =:results silent=
       2. to change the priority of different rich outputs, use =:display=
          header argument, e.g. =:display text/plain text/html= prioritizes
          plain text over html. All supported mimetypes in default order:
          1. text/org
          2. image/svg+xml, image/jpeg, image/png
          3. text/html
          4. text/markdown
          5. text/latex
          6. text/plain
       3. We can set jupyter to output pandas DataFrames as org tables
          automatically using the source block header argument =:pandoc t=
       4. useful keybindings
          - =M-i= to open the documentation for wherever your pointer is (like
            pressing =Shift-TAB= in Jupyter notebooks)
          - =C-c C-i= to interrupt the kernel, =C-c C-r= to restart the kernel

*** Notes on archiving
**** Exporting the LabBook.org to html in a twbs style
     - I am partial to the twitter bootstrap theme of html, since I like it's
       simple design, but clear structure with a nice table of contents at the
       side → the following org mode extension supports a seemless export to
       twitter bootstrap html: https://github.com/marsmining/ox-twbs
     - when installed, the export can be triggered via the command
       =(org-twbs-export-as-html)= or via the keyboard shortcut for export =C-c
       C-e= followed by =w= for Twitter bootstrap and =h= for saving the .html
     - _Things to configure:_
       - in general, there are multiple export options:
         https://orgmode.org/manual/Export-Settings.html
       - E.g. I set 2 =#+OPTIONS= keywords at the begin of the file: =toc:4= and
         =H:4= which make sure that in my export my sidebar table of contents
         will show numbered headings till a depth of 4.
       - I configured my code blocks so that they will not be evaluated when
         exporting (I would recommend this especially if you only export for
         archiving) and that both the code block and the output will be exported
         with the keyword: =#+PROPERTY: header-args :eval never-export :exports
         both=
       - To discriminate between code blocks for different languages I gave each
         of them a distinct colour using =#+HTML_HEAD_EXTRA: <style...= (see
         above)
     - _Things to do before exporting / Troubleshooting while exporting:_
       - when using a dark theme for you emacs, the export of the code blocks
         might show some ugly dark backgrounds from the theme. If this becomes
         an issue, change to a light theme for the export with =M-x
         (load-theme)= and choose =solarized-light=
       - only in the =data= branch you set the git tags after merging. If you
         want to show them here, execute the corresponding function in [[Git TAGs]]
       - make sure your file links work properly! I recommend referencing your
         files relatively (e.g. [ [ f ile:./data/exp-XXXXXX-test/test.png]]
         without spaces). Otherwise there will be errors in your /*Messages*/
         buffer
       - There might be errors with your code blocks
         - e.g. the export function expects you to assign a default variable to
           your functions
         - if you call a function via the =#+CALL= mechanism, it wants you to
           include two parentheses for the function, e.g. =#+CALL: test()=
       - check indentation of code blocks inside lists
       - add a =details= block around large output cells. This makes them
         expandable. I added some =#+HTML_HEAD_EXTRA: <style...= inspired by
         [[https://alhassy.github.io/org-special-block-extras/#Folded-Details][alhassy]]. That's how the =details= block looks like:
         #+begin_example
         #+begin_details

         #+end_details
         #+end_example
         If you want an
     - _Things to do after exporting:_
       - In my workflow, I put the exported =LabBook.html= into the =data=
         folder. If you move the file, you will have to fix the file links for
         the new location, e.g. via "Find and replace" =M-%= with find:
         =[[file:./data/= and replace: =[[=
** Organization of git

*** remote/origin/main branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
*** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *main* in an *#experiment-name* branch, ### meaning some meaningful
    descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/#experiment-name**, except
    machine learning-specific data and metadata from `mlflow` runs, which are
    saved under **data/mlruns** (this allows easily comparing machine learning
    runs with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
*** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
*** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *#experiment-name* branches are merged here. Afterwards the original
    branch is deleted and on the data branch there is a *Git tag* which shows
    the merge commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

*** Git TAGs
**** Stable versions:
**** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
   : exp-200520-unet Merge branch 'exp-310520-unet' into data
   : exp-200531-unet Merge branch 'heads/exp-310520-unet' into data
   : exp-201231-clustsim exp-201231-clustsim
   : exp-210204-unet Add exp-210204-unet LabBook part 3
   : exp-310520-unet move exp-310520-unet to data branch manually
** Organization of code
*** scripts:
*** src/
**** fluotracify/
***** imports/
***** simulations/
***** training/
***** applications/
***** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

**** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

** Changes in this repository (without "* Data" in this file)
*** Changes in LabBook.org (without "* Data")
**** 2021-12-16
     - Add =details= blocks, corresponding =#+HTML_HEAD_EXTRA: <style...= and
       documentation in  [[Notes on archiving]]
**** 2021-08-05
     - Rename =master= branch to =main= branch
**** 2021-04-04
     - Add =#+OPTIONS: H:4= and =#+OPTIONS: toc:4= to show up to 4 levels of
       depth in the html (twbs) export of this LabBook in the table of contents
       at the side
     - I added [[Notes on archiving]]
**** 2020-11-04
    - update "jupyter scripts" in [[Template for data entry and setup notes:]]
      for new conda environment on server (now =conda activate tf-nightly=)
**** 2020-05-31
    - extend general documentation in README
    - Add code block examples
    - extend documentation on experiment workflow
    - move setup notes from README to "Template for data entry and setup notes"
    - remove emacs-lisp code for custom tmux block functions (not relevant
      enough)
    - change named "jpt-tmux" from starting a jupyter notebook to starting
      jupyter lab. Load a conda environment instead of using Lmod's =module
      load=
**** 2020-05-07
    - extend documentation on git model
    - extend documentation on jupyter setup
**** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
**** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
*** Changes in src/fluotracify

* DEVELOPMENT TESTING (don't merge in master)
  :LOGBOOK:
  CLOCK: [2020-04-23 Do 13:35]--[2020-04-23 Do 14:57] =>  1:22
  :END:
** configured custom yasnippets,
   - check =yas-describe-tables= for current snippets
   - use =C-c & C-n= to create new snippet (its put in =.emacs.d/snippets/=)

#+BEGIN_SRC sh :session local
  ls -Rl ~/.emacs.d/snippets/
#+END_SRC

#+RESULTS:
| /home/lex/.emacs.d/snippets/:         |     |    |       |                       |
| total                                 |     |    |       |                       |
| drwxr-xr-x                            | Apr | 23 | 15:23 | org-mode              |
| /home/lex/.emacs.d/snippets/org-mode: |     |    |       |                       |
| total                                 |     |    |       |                       |
| -rw-r--r--                            | Apr | 23 | 14:32 | jupyter-python-block  |
| -rw-r--r--                            | Apr | 23 | 14:35 | jupyter-python-header |
| -rw-r--r--                            | Apr | 23 | 15:23 | lmod-srun             |
| -rw-r--r--                            | Apr | 23 | 14:53 | src2                  |
| -rw-r--r--                            | Apr | 23 | 15:00 | tmux                  |

** fix hardlinks of org-files outside =Dokumente/org=
#+BEGIN_SRC sh :session local :results verbatim
  cd Dokumente/org/linkedfiles
  ls -li
  find / -samefile LabBook.org
#+END_SRC

#+RESULTS:
#+begin_example
total 84
4992947 -rw-r--r-- 2 lex lex 11786 Apr 23 14:14 LabBook.org
 404446 -rw-r--r-- 1 lex lex 21544 Apr  4 22:53 LabBook.org~
 404411 -rw-r--r-- 2 lex lex 23355 Apr 20 01:44 lexbn-source.org
4328628 -rw-r--r-- 1 lex lex 20829 Apr 19 14:37 lexbn-source.org~

/home/lex/Dokumente/org/linkedfiles/LabBook.org
/home/lex/Programme/drmed-git/LabBook.org
#+end_example

** connect LabBook to HPC with jupyter etc
   :LOGBOOK:
   CLOCK: [2020-04-23 Do 17:30]--[2020-04-23 Do 17:46] =>  0:16
   CLOCK: [2020-04-23 Do 16:05]--[2020-04-23 Do 16:38] =>  0:33
   CLOCK: [2020-04-23 Do 15:20]--[2020-04-23 Do 15:50] =>  0:30
   CLOCK: [2020-04-23 Do 14:57]--[2020-04-23 Do 15:07] =>  0:10
   :END:
*** connect to compute node
#+BEGIN_SRC sh :session org-ssh :results verbatim
  ssh ara
#+END_SRC

#+RESULTS:
: ssh: Could not resolve hostname ara: Name or service not known

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    48 | mix   | node[003,007-008,023-026,029,031,033-038,040,053,063-064,066-072,075-078,083-085,090-094,117-119,121-125,131,133]                                                                                 |
| b_standard* | up    | 8-08:00:00 |    82 | alloc | node[002,004-006,009-022,027-028,030,032,039,041-045,047-052,054-062,065,073-074,079-082,086-089,095-116,120,126,132,134-136]                                                                     |
| b_standard* | up    | 8-08:00:00 |     1 | idle  | node046                                                                                                                                                                                           |
| gpu_test    | up    |    1:00:00 |     1 | idle  | node127                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | idle  | node130                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     4 | mix   | node[137-140]                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | idle  | node141                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    68 | mix   | node[144,151,162-163,167,169,171-172,177-181,186,191,196-198,200,203-209,212-214,216,218,221-222,224-231,233,235-237,241-249,255,257,259-260,265-268,297,303-304,309-310,315]                     |
| s_standard  | up    | 8-08:00:00 |    83 | alloc | node[142-143,145-150,152-161,164-166,168,170,173-176,182-185,187-190,192-195,199,201-202,210-211,215,217,219-220,223,232,234,238-240,250-254,256,258,261-264,293-296,298-302,305-308,311-314,316] |
| s_fat       | up    | 8-08:00:00 |     3 | mix   | node[269-270,272]                                                                                                                                                                                 |
| s_fat       | up    | 8-08:00:00 |     1 | alloc | node271                                                                                                                                                                                           |

#+BEGIN_SRC sh :session org-ssh
  tmux ls
#+END_SRC

#+RESULTS:
|       0: | 1 | windows | (created | Mon | Apr | 13 | 19:54:44 | 2020 |
| ob-tmux: | 1 | windows | (created | Mon | Apr | 13 | 19:55:21 | 2020 |


#+CALL:setup-tmux[:session local]

#+RESULTS:
| ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
| /tmp/tmux-67339/default              |                                      |           |
| >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  echo test
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ echo test
  test
  [ye53nis@login01 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
  srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@login01 ~]$ srun -p b_standard --time=7-10:00:00 --ntasks-per-node 48 -
  -pty bash
  [ye53nis@node018 ~]$
#+end_example

*** start and connect to jupyter
:PROPERTIES:
:header-args:jupyter-python: :session /jpy:localhost#8889:2912b27f-1dbe-4a8e-9c59-6cc02f5434cf
:END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export PORT=8889
#+END_SRC


#+CALL: jpt-tmux[:session tmux]

#+RESULTS:
#+begin_example
[ye53nis@node007 drmed-git]$ export PORT=8889
[ye53nis@node007 drmed-git]$ module load tools/python/3.7
[ye53nis@node007 drmed-git]$ export XDG_RUNTIME_DIR=''
[ye53nis@node007 drmed-git]$ export XDG_RUNTIME_DIR=""
[ye53nis@node007 drmed-git]$ jupyter notebook --no-browser --port=$PORT
[I 16:44:59.413 NotebookApp] Serving notebooks from local directory: /beegfs/ye53nis/drmed-git
[I 16:44:59.413 NotebookApp] The Jupyter Notebook is running at:
[I 16:44:59.413 NotebookApp] http://localhost:8889/?token=552a9cff48203d5a263cb083b80b939dbbc856758df651dd
[I 16:44:59.413 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 16:44:59.425 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///home/ye53nis/.local/share/jupyter/runtime/nbserver-84165-open.html
    Or copy and paste one of these URLs:
        http://localhost:8889/?token=552a9cff48203d5a263cb083b80b939dbbc856758df651dd
#+end_example

#+CALL: jpt-tunnel(port="8889", node="node007")

#+RESULTS:
| Connection        | closed                               | by        |          10.138.225.252 | port    | 22 |     |      |    |       |        |
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |                         |         |    |     |      |    |       |        |
| Warning:          | Permanently                          | added     | 'node007,192.168.193.7' | (ECDSA) | to | the | list | of | known | hosts. |
| ye53nis@node007's | password:                            |           |                         |         |    |     |      |    |       |        |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           2912b27f-1dbe-4a8e-9c59-6cc02f5434cf   2 minutes ago        starting   0
#+end_example

Passing a boolean value to a variable in =org-babel= was not trivial: you have to
use the infamous *single quote '* from emacs-lisp programming to show that the
expression should be returned as written, not evaluated.

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 48
  No of CPUs the current process can use: 48
  load average: (0.08, 0.03, 0.05)
  posix.uname_result(sysname='Linux', nodename='node007', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 92855
  RAM total: 137G, RAM used: 1.3G, RAM free: 120G
  the current directory: /beegfs/ye53nis/drmed-git
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  4.3G   46G   9% /
  devtmpfs              63G     0   63G   0% /dev
  tmpfs                 63G  199M   63G   1% /dev/shm
  tmpfs                 63G   59M   63G   1% /run
  tmpfs                 63G     0   63G   0% /sys/fs/cgroup
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs01-ib:/home        80T   59T   22T  73% /home
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  /dev/sda3            6.0G  441M  5.6G   8% /var
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  5.5G  163G   4% /local
  beegfs_nodev         524T  427T   98T  82% /beegfs
  tmpfs                 13G     0   13G   0% /run/user/67339
#+end_example

** set up mlflow
   :LOGBOOK:
   CLOCK: [2020-04-24 Fr 13:09]--[2020-04-24 Fr 13:52] =>  0:43
   CLOCK: [2020-04-24 Fr 11:07]--[2020-04-24 Fr 11:30] =>  0:23
   CLOCK: [2020-04-23 Do 19:05]--[2020-04-23 Do 19:50] =>  0:45
   CLOCK: [2020-04-23 Do 17:59]--[2020-04-23 Do 18:49] =>  0:50
   CLOCK: [2020-04-23 Do 17:46]--[2020-04-23 Do 17:51] =>  0:05
   :END:
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:6be3aedd-62d4-4fc2-b816-af41e3986de9
   :END:

*** how do I submit mlflow jobs?
- I will need two sessions
  - one *tmux session* for running the jupyter kernel, having a REPL, fast and
    interactive coding. I need tmux bc the connection to the node would break if
    I log out of ssh.
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux
      echo tüdelü
    #+END_SRC
  - one *sh ssh session* for sending command line commands. SLURM handles the
    job and outputs files - so it should continue, even if I log out
- alternative solution: tmux windows (*note: after using tmux windows, the
  normal =:session tmux= without window specification doesn't work anymore*)
  - this is window =mlflow= for sending mlflow commands. we have to request some
    computation power by SLURM again
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
      echo pwd
    #+END_SRC
  - this is window =ob1= (name automatically created when you don't specify a
    window name) where our jupyter kernel runs:
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:ob1
      echo testö
    #+END_SRC
**** Failed approaches:
- then jobs are submitted e.g. as bash scripts (this is just an example from the
  wiki):
  #+BEGIN_SRC sh
    #!/bin/bash
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_standard
    #SBATCH --nodes=4
    #SBATCH --ntasks-per-node=36
    #SBATCH --time=1:00
    module purge
    module load tools/python/3.7 mpi/intel/2019-Update5
    srun python intro.py
  #+END_SRC
- test:
  #+NAME: sh-test-script
  #+BEGIN_SRC sh :shebang "#!/bin/bash"
    #SBATCH --job-name=pc1-intro
    #SBATCH --partition=s_test
    #SBATCH --nodes=1
    hostname
  #+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow :noweb yes
  sbatch <<sh-test-script>>
#+END_SRC

  #+BEGIN_SRC sh :session org-ssh :noweb yes :tangle yes
    sbatch <<sh-test-script>>
  #+END_SRC

  #+RESULTS:
  |                                                   |
  | sbatch: error: Unable to open file sh-test-script |

Note: t

**** Note: do it like for jupyter: srun a bash script, then execute mlflow
*** Reading the docs: mlflow
- searched for papers, found [[http://sites.computer.org/debull/A18dec/A18DEC-CD.pdf#page=41][two]] [[https://mlsys.org/Conferences/2019/doc/2019/demo_33.pdf][papers]], but they don't seem very exhaustive.
- took notes [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*<2020-04-16 Do 12:57> =mlflow=][here]]
- shall I keep MLflow files in a folder inside the =data/exp#= folder for each
  experiment or do a central =data/mlflow= folder? → I tend towards the second
  option. MLflow has an environment variable =MLFLOW_EXPERIMENT_NAME= which
  would be the same as =exp#=.
- Inside the folder, should I use "normal" files or a database for saving stuff?
  → I tend towards normal files, since I have no experiments with databases..
- MLflow Tracking Service API might be useful for accessing the results from
  inside org documents.

*** Reading Barredo Arrieta et al: Explainable Artificial Intelligence (XIA)
*** Set up git on HPC
    :LOGBOOK:
    CLOCK: [2020-04-24 Fr 14:35]--[2020-04-24 Fr 17:53] =>  3:18
    CLOCK: [2020-04-24 Fr 13:53]--[2020-04-24 Fr 14:15] =>  0:22
    :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session ob-tmux:mlflow
  git clone https://github.com/aseltmann/fluotracify
#+END_SRC

Wanted to git pull my repository on HPC, noticed that it already exists - and
has uncommited changes. Have to sort that out.

Git runs now on HPC, but had to resolve merge conflicts in code → used *Magit*
and especially Ediff. Watched these resources:
- https://www.youtube.com/watch?v=9S2pMZ6U5Tc&t=715s - short resource on smerge
  and ediff
- https://www.youtube.com/watch?v=j-k-lkilbEs - nice intro to magit in general

*** run mlflow test
**** Use a local tmux session:

#+BEGIN_SRC tmux :session local
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ pwd
  /home/lex
#+end_example

#+BEGIN_SRC tmux :session local
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_EXPERIMENT_ID=0.1
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow run .
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run .
  Specify only one of 'experiment-name' or 'experiment-id' options.
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local2
  conda activate tensorflow_env
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex ~]$ conda activate tensorflow_env
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

#+BEGIN_SRC tmux :session local2
  mlflow run /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_env) [lex@Topialex ~]$ mlflow run /home/lex/Programme/drmed-git/
  2020/04/28 01:17:01 INFO mlflow.projects: === Created directory /tmp/tmp_goyesz7
   for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/28 01:17:01 INFO mlflow.projects: === Running command 'source /home/lex/
  Programme/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114
  b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/tra
  in.py 5 0.2 16384 1e-5 10' in run with ID 'c0f7e64fdda64801860e9805948db29d' ===

  /home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709
  c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_interna
  l.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib
  ; see the module's documentation for alternative uses
    import imp
  2.1.0
  train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set003.csv
  train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tr
  aces_brightclust_rand_Sep2019_set002.csv
  test 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/tra
  ces_brightclust_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted time
  steps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-28 01:17:15.293658: I tensorflow/core/platform/cpu_feature_guard.cc:142]
   Your CPU supports instructions that this TensorFlow binary was not compiled to
  use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-28 01:17:15.340845: I tensorflow/core/platform/profile_utils/cpu_utils.c
  c:94] CPU Frequency: 2400500000 Hz
  2020-04-28 01:17:15.342222: I tensorflow/compiler/xla/service/service.cc:168] XL
  A service 0x5654fb291850 initialized for platform Host (this does not guarantee
  that XLA will be used). Devices:
  2020-04-28 01:17:15.342284: I tensorflow/compiler/xla/service/service.cc:176]
  StreamExecutor device (0): Host, Default Version
  2020-04-28 01:17:15.344811: I tensorflow/core/common_runtime/process_util.cc:147
  ] Creating new thread pool with default inter op setting: 2. Tune using inter_op
  _parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 65, in <module>
      with mlflow.start_run():
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 122, in
   start_run
      active_run_obj = MlflowClient().get_run(existing_run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 96, in
  get_run
      return self._tracking_client.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client
  .py", line 49, in get_run
      return self.store.get_run(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 423, in get_run
      run_info = self._get_run_info(run_id)
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", li
  ne 442, in _get_run_info
      databricks_pb2.RESOURCE_DOES_NOT_EXIST)
  mlflow.exceptions.MlflowException: Run 'c0f7e64fdda64801860e9805948db29d' not fo
  und
  Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7fb42c4
  f4440>
  Traceback (most recent call last):
    File "/home/lex/Programme/miniconda3/envs/mlflow-1114b06fb561908fc3f52e89d8342
  d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_
  ops.py", line 3462, in __del__
  AttributeError: 'NoneType' object has no attribute 'device'
  2020/04/28 01:17:16 ERROR mlflow.cli: === Run (ID 'c0f7e64fdda64801860e9805948db
  29d') failed ===
  (tensorflow_env) [lex@Topialex ~]$
#+end_example

**** use remote tmux
#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+RESULTS:
| Permission                           | denied,   | please | try    | again. |          |          |      |                |            |                |    |           |
| ye53nis@ara-login01.rz.uni-jena.de's | password: |        |        |        |          |          |      |                |            |                |    |           |
| Last                                 | failed    | login: | Tue    | Apr    |       28 | 11:05:11 | CEST |           2020 | from       | 10.231.181.150 | on | ssh:notty |
| There                                | was       | 1      | failed | login  |  attempt |    since | the  |           last | successful |         login. |    |           |
| Last                                 | login:    | Tue    | Apr    | 28     | 10:57:34 |     2020 | from | 10.231.181.150 |            |                |    |           |

#+BEGIN_SRC sh :session org-ssh
  sinfo
#+END_SRC

#+RESULTS:
| PARTITION   | AVAIL |  TIMELIMIT | NODES | STATE | NODELIST                                                                                                                                                                                                          |
| b_test      | up    |    3:00:00 |     1 | idle  | node001                                                                                                                                                                                                           |
| b_standard* | up    | 8-08:00:00 |    26 | mix   | node[005-006,008,014,018,025-026,029,031,039,043,046,063-064,070-071,085-086,108,110,120,126,132,134-136]                                                                                                         |
| b_standard* | up    | 8-08:00:00 |    96 | alloc | node[002-004,009-013,015-017,019-024,027-028,030,032-037,040-042,045,047-062,065,067-068,072-082,084,087-107,109,111-116,119,121-125,131]                                                                         |
| b_standard* | up    | 8-08:00:00 |     9 | idle  | node[007,038,044,066,069,083,117-118,133]                                                                                                                                                                         |
| gpu_test    | up    |    1:00:00 |     1 | mix   | node127                                                                                                                                                                                                           |
| gpu_p100    | up    | 8-08:00:00 |     2 | mix   | node[128-129]                                                                                                                                                                                                     |
| gpu_v100    | up    | 8-08:00:00 |     1 | mix   | node130                                                                                                                                                                                                           |
| b_fat       | up    | 8-08:00:00 |     2 | mix   | node[139-140]                                                                                                                                                                                                     |
| b_fat       | up    | 8-08:00:00 |     2 | alloc | node[137-138]                                                                                                                                                                                                     |
| s_test      | up    |    3:00:00 |     1 | alloc | node141                                                                                                                                                                                                           |
| s_standard  | up    | 8-08:00:00 |    50 | mix   | node[146,151,155,157,162-163,167,169,177,183,186,191,196-200,203,219,224-231,233,235,239,241-246,249,255,257,259-260,265-268,297,303,309-310,315]                                                                 |
| s_standard  | up    | 8-08:00:00 |    97 | alloc | node[142-145,147-150,154,156,158-161,164-166,168,170-176,178-182,184-185,187-190,192-195,201-202,204-218,220-223,232,234,236-238,240,247-248,250-254,256,258,261-264,293-296,298-301,304-305,307-308,311-314,316] |
| s_standard  | up    | 8-08:00:00 |     4 | idle  | node[152-153,302,306]                                                                                                                                                                                             |
| s_fat       | up    | 8-08:00:00 |     4 | alloc | node[269-272]                                                                                                                                                                                                     |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    srun -p b_standard --time=7-08:00:00 --ntasks-per-node 48 --pty bash
#+END_SRC

#+RESULTS:
: server version is too old for client

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC emacs-lisp
  (setq org-babel-tmux-location "/usr/local/bin/tmux")
#+END_SRC

#+RESULTS:
: /usr/local/bin/tmux


#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load tools/python/3.7
  module load module-git
  mlflow --version
  git --version
  cd drmed-git
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow --version
  git --version
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  mlflow, version 1.7.0
  [ye53nis@node007 ~]$ git --version
  git version 1.8.3.1
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . --no-conda
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 ~]$ mlflow run . --no-conda
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  2020/04/29 13:31:21 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===
  [ye53nis@node007 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=~/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/04/30 17:56:53 INFO mlflow.projects: === Creating conda environment mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 ===
  Collecting package metadata (repodata.json): done
  Solving environment: done

  Downloading and Extracting Packages
  gorilla-0.3.0        | 11 KB     | ################################################################################################################################################################### | 100%
  pyasn1-0.4.8         | 58 KB     | ################################################################################################################################################################### | 100%
  mako-1.1.2           | 63 KB     | ################################################################################################################################################################### | 100%
  flask-1.1.2          | 74 KB     | ################################################################################################################################################################### | 100%
  tensorboard-2.1.0    | 3.3 MB    | ################################################################################################################################################################### | 100%
  google-auth-1.13.1   | 57 KB     | ################################################################################################################################################################### | 100%
  tensorflow-estimator | 251 KB    | ################################################################################################################################################################### | 100%
  ncurses-6.2          | 817 KB    | ################################################################################################################################################################### | 100%
  intel-openmp-2020.0  | 756 KB    | ################################################################################################################################################################### | 100%
  cloudpickle-1.4.0    | 29 KB     | ################################################################################################################################################################### | 100%
  mlflow-1.8.0         | 3.2 MB    | ################################################################################################################################################################### | 100%
  databricks-cli-0.9.1 | 48 KB     | ################################################################################################################################################################### | 100%
  mkl-service-2.3.0    | 218 KB    | ################################################################################################################################################################### | 100%
  markupsafe-1.1.1     | 29 KB     | ################################################################################################################################################################### | 100%
  libstdcxx-ng-9.1.0   | 3.1 MB    | ################################################################################################################################################################### | 100%
  prometheus_client-0. | 42 KB     | ################################################################################################################################################################### | 100%
  appdirs-1.4.3        | 15 KB     | ################################################################################################################################################################### | 100%
  libprotobuf-3.11.4   | 2.9 MB    | ################################################################################################################################################################### | 100%
  protobuf-3.11.4      | 636 KB    | ################################################################################################################################################################### | 100%
  tensorflow-2.1.0     | 4 KB      | ################################################################################################################################################################### | 100%
  configparser-3.7.4   | 43 KB     | ################################################################################################################################################################### | 100%
  opt_einsum-3.1.0     | 54 KB     | ################################################################################################################################################################### | 100%
  oauthlib-3.1.0       | 88 KB     | ################################################################################################################################################################### | 100%
  python-dateutil-2.8. | 224 KB    | ################################################################################################################################################################### | 100%
  werkzeug-1.0.1       | 240 KB    | ################################################################################################################################################################### | 100%
  tabulate-0.8.3       | 39 KB     | ################################################################################################################################################################### | 100%
  jinja2-2.11.2        | 103 KB    | ################################################################################################################################################################### | 100%
  c-ares-1.15.0        | 89 KB     | ################################################################################################################################################################### | 100%
  requests-oauthlib-1. | 22 KB     | ################################################################################################################################################################### | 100%
  docker-pycreds-0.4.0 | 14 KB     | ################################################################################################################################################################### | 100%
  packaging-20.3       | 36 KB     | ################################################################################################################################################################### | 100%
  keras-preprocessing- | 36 KB     | ################################################################################################################################################################### | 100%
  itsdangerous-1.1.0   | 28 KB     | ################################################################################################################################################################### | 100%
  mkl-2020.0           | 128.9 MB  | ################################################################################################################################################################### | 100%
  keras-applications-1 | 33 KB     | ################################################################################################################################################################### | 100%
  scipy-1.4.1          | 14.5 MB   | ################################################################################################################################################################### | 100%
  blinker-1.4          | 22 KB     | ################################################################################################################################################################### | 100%
  google-auth-oauthlib | 20 KB     | ################################################################################################################################################################### | 100%
  wrapt-1.12.1         | 49 KB     | ################################################################################################################################################################### | 100%
  click-7.1.1          | 71 KB     | ################################################################################################################################################################### | 100%
  h5py-2.10.0          | 1.0 MB    | ################################################################################################################################################################### | 100%
  rsa-4.0              | 29 KB     | ################################################################################################################################################################### | 100%
  pyjwt-1.7.1          | 33 KB     | ################################################################################################################################################################### | 100%
  pyasn1-modules-0.2.7 | 63 KB     | ################################################################################################################################################################### | 100%
  google-pasta-0.2.0   | 44 KB     | ################################################################################################################################################################### | 100%
  mkl_fft-1.0.15       | 154 KB    | ################################################################################################################################################################### | 100%
  alembic-1.4.2        | 117 KB    | ################################################################################################################################################################### | 100%
  backports-1.0        | 139 KB    | ################################################################################################################################################################### | 100%
  entrypoints-0.3      | 12 KB     | ################################################################################################################################################################### | 100%
  pyyaml-5.3.1         | 181 KB    | ################################################################################################################################################################### | 100%
  querystring_parser-1 | 10 KB     | ################################################################################################################################################################### | 100%
  prometheus_flask_exp | 15 KB     | ################################################################################################################################################################### | 100%
  cachetools-3.1.1     | 14 KB     | ################################################################################################################################################################### | 100%
  smmap-3.0.2          | 26 KB     | ################################################################################################################################################################### | 100%
  simplejson-3.17.0    | 101 KB    | ################################################################################################################################################################### | 100%
  pyparsing-2.4.6      | 64 KB     | ################################################################################################################################################################### | 100%
  pytz-2019.3          | 231 KB    | ################################################################################################################################################################### | 100%
  sqlalchemy-1.3.13    | 1.4 MB    | ################################################################################################################################################################### | 100%
  absl-py-0.9.0        | 167 KB    | ################################################################################################################################################################### | 100%
  numpy-base-1.18.1    | 4.2 MB    | ################################################################################################################################################################### | 100%
  mkl_random-1.1.0     | 321 KB    | ################################################################################################################################################################### | 100%
  python-editor-1.0.4  | 11 KB     | ################################################################################################################################################################### | 100%
  gunicorn-20.0.4      | 123 KB    | ################################################################################################################################################################### | 100%
  tensorflow-base-2.1. | 95.2 MB   | ################################################################################################################################################################### | 100%
  markdown-3.1.1       | 118 KB    | ################################################################################################################################################################### | 100%
  astor-0.8.0          | 46 KB     | ################################################################################################################################################################### | 100%
  grpcio-1.27.2        | 1.3 MB    | ################################################################################################################################################################### | 100%
  sqlparse-0.3.1       | 34 KB     | ################################################################################################################################################################### | 100%
  gitdb-4.0.2          | 49 KB     | ################################################################################################################################################################### | 100%
  pandas-1.0.3         | 8.6 MB    | ################################################################################################################################################################### | 100%
  docker-py-4.2.0      | 188 KB    | ################################################################################################################################################################### | 100%
  websocket-client-0.5 | 62 KB     | ################################################################################################################################################################### | 100%
  numpy-1.18.1         | 5 KB      | ################################################################################################################################################################### | 100%
  gitpython-3.1.1      | 328 KB    | ################################################################################################################################################################### | 100%
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/04/30 18:00:02 INFO mlflow.projects: === Created directory /tmp/tmpbcxyzo3m for downloading remote URIs passed to arguments of type 'path' ===
  2020/04/30 18:00:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /home/ye53nis/drmed-git/src 5
  0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '09b669bd51ba4317a6ba4db833a3abb1' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  /home/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-04-30 18:00:19.551555: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-04-30 18:00:19.563688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-04-30 18:00:19.566795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b0cba23c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-04-30 18:00:19.566832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-04-30 18:00:19.567000: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='09b669bd51ba4317a6ba4db833a3abb1'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-04-30 18:00:46.639927: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6587 - mean_io_u: 0.4028 - precision: 0.2306 - recall: 0.7511 - val_loss: 1.5574 - val_mean_io_u: 0.3914 - val_precision: 0.1894 - val_recall:
   0.6051
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.6133 - mean_io_u: 0.4082 - precision: 0.2488 - recall: 0.7948/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.6116152, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588262662579). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 107s 3s/step - loss: 1.6042 - mean_io_u: 0.4055 - precision: 0.2566 - recall: 0.7927 - val_loss: 1.6116 - val_mean_io_u: 0.4122 - val_precision: 0.1641 - val_recall:
   0.8504
  Epoch 3/10
  32/32 [==============================] - 107s 3s/step - loss: 1.5036 - mean_io_u: 0.3934 - precision: 0.3298 - recall: 0.8165 - val_loss: 1.6282 - val_mean_io_u: 0.4021 - val_precision: 0.1870 - val_recall:
   0.9343
  Epoch 4/10
  32/32 [==============================] - 105s 3s/step - loss: 1.4783 - mean_io_u: 0.4014 - precision: 0.3343 - recall: 0.8179 - val_loss: 1.6338 - val_mean_io_u: 0.3861 - val_precision: 0.2262 - val_recall:
   0.9908
  Epoch 5/10
  32/32 [==============================] - 106s 3s/step - loss: 1.4398 - mean_io_u: 0.4006 - precision: 0.3735 - recall: 0.8220 - val_loss: 1.7444 - val_mean_io_u: 0.4101 - val_precision: 0.1798 - val_recall:
   0.9999
  Epoch 6/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3941 - mean_io_u: 0.3988 - precision: 0.4144 - recall: 0.8005 - val_loss: 1.8832 - val_mean_io_u: 0.4179 - val_precision: 0.1642 - val_recall:
   0.9999
  Epoch 7/10
  32/32 [==============================] - 107s 3s/step - loss: 1.3660 - mean_io_u: 0.4000 - precision: 0.4544 - recall: 0.8108 - val_loss: 2.0017 - val_mean_io_u: 0.3885 - val_precision: 0.2230 - val_recall:
   0.9999
  Epoch 8/10
  32/32 [==============================] - 106s 3s/step - loss: 1.3169 - mean_io_u: 0.3993 - precision: 0.5203 - recall: 0.8057 - val_loss: 2.5556 - val_mean_io_u: 0.4147 - val_precision: 0.1706 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3050 - mean_io_u: 0.4047 - precision: 0.5429 - recall: 0.8009 - val_loss: 3.0439 - val_mean_io_u: 0.3991 - val_precision: 0.2017 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2911 - mean_io_u: 0.4098 - precision: 0.5691 - recall: 0.7966 - val_loss: 3.6402 - val_mean_io_u: 0.3934 - val_precision: 0.2132 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 843ms/step - loss: 3.5632 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-04-30 18:19:28.557139: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/04/30 18:19:46 INFO mlflow.projects: === Run (ID '09b669bd51ba4317a6ba4db833a3abb1') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Success!!!
** Find solution for large file problem
   :LOGBOOK:
   CLOCK: [2020-05-02 Sa 13:17]--[2020-05-02 Sa 13:43] =>  0:26
   :END:
*** using =git-lfs=
    :LOGBOOK:
    CLOCK: [2020-05-05 Di 13:37]--[2020-05-05 Di 13:38] =>  0:01
    CLOCK: [2020-05-02 Sa 14:41]--[2020-05-02 Sa 16:13] =>  1:32
    :END:
Problem: the deep network =unet.tf= is too big (>300MB) and github only allows a
maximum file size of 100MB. Two possible solutions:
- *Git Large File Storage*: https://git-lfs.github.com/ replace large files with text pointers inside
  Git. Configured with a =.gitattributes= file per project. Git commands stay
  the same
- *Git-annex*: https://git-annex.branchable.com/ own git annex command line
  tool. "stupid filename and metadata tracker".
- See [[file:~/Dokumente/org/04_Digital-und-Technik/software-setup.org::*=git-annex= vs =git-lfs=][here]] for notes

NOTE: *git commands should not be done on compute node, it's easier on login
node via normal ssh*

#+BEGIN_SRC sh :session org-ssh
  ssh ara
#+END_SRC

#+BEGIN_SRC sh :session org-ssh :results output
  pwd
  git status
#+END_SRC

#+RESULTS:
#+begin_example
/home/ye53nis/drmed-git
# On branch develop
Your branch is ahead of 'origin/develop' by 1 commit.
(use "git push" to publish your local commits)

Untracked files:
(use "git add <file>..." to include in what will be committed)

data/exp-devtest/
nothing added to commit but untracked files present (use "git add" to track)
#+end_example

Encountered problem: git-lfs only syncs files *inside* the repo. The advised way
to save large files on the HPC is to use the dedicated =/beegfs= file system,
which is optimised for that stuff. My current repo is in =/home=
- version 1: migrate git repo to beegfs - effectively abandoning =/home=
- version 2: stay at =/home= and keep track of =/beegfs= using tools like
  =git-annex=

I am trying version 1 now

Works!!

My =-gitattributes= file has the following line to track all contents of a
folder which contains ".tf" somewhere in =data/=
#+begin_example
  data/**/*.tf/** filter=lfs diff=lfs merge=lfs -text
#+end_example

** run mlflow model as above, but save everything on =/beegfs=

   :LOGBOOK:
   CLOCK: [2020-05-02 Sa 16:13]--[2020-05-02 Sa 16:15] =>  0:02
   :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
: server exited unexpectedly

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ git status
  # On branch develop
  nothing to commit, working directory clean
  [ye53nis@node007 drmed-git]$ git log -1
  commit 9e6182fbeae831a151342827efa59581e4310ae6
  Author: Alex Seltmann <seltmann@posteo.de>
  Date:   Sat May 2 13:23:42 2020 +0200

      first successful mlflow run without trained net
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  INFO: 'exp-devtest' does not exist. Creating a new experiment
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  WARNING:root:Malformed experiment '1'. Detailed error Yaml file './data/mlruns/1/meta.yaml' does not exist.
  Traceback (most recent call last):
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
      experiment = self._get_experiment(exp_id, view_type)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 256, in _get_experiment
      meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
    File "/cluster/miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py", line 160, in read_yaml
      raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
  mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/1/meta.yaml' does not exist.
  2020/05/02 14:47:02 INFO mlflow.projects: === Created directory /tmp/tmp7uyf926z for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/02 14:47:02 INFO mlflow.projects: === Running command 'source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src
  5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'cda4eec66a6947c38ec2ee2006563ae5' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  ^[[B^[[B^[[B^[[B^[[B^[[B2.1.0
  /beegfs/ye53nis/drmed-git/src
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a41791e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-02 14:48:28.731100: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 133s 4s/step - loss: 1.6869 - mean_io_u: 0.4035 - precision: 0.1949 - recall: 0.6740 - val_loss: 1.5778 - val_mean_io_u: 0.4210 - val_precision: 0.1500 - val_recall:
   5.7965e-05
  Epoch 2/10
  31/32 [============================>.] - ETA: 3s - loss: 1.5936 - mean_io_u: 0.4047 - precision: 0.2461 - recall: 0.7594/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588423924159). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 106s 3s/step - loss: 1.5935 - mean_io_u: 0.4051 - precision: 0.2456 - recall: 0.7601 - val_loss: 1.5412 - val_mean_io_u: 0.3977 - val_precision: 0.3000 - val_recall:
   8.9508e-05
  Epoch 3/10
  32/32 [==============================] - 108s 3s/step - loss: 1.5357 - mean_io_u: 0.4039 - precision: 0.2901 - recall: 0.8025 - val_loss: 1.5201 - val_mean_io_u: 0.3834 - val_precision: 0.2500 - val_recall:
   6.5409e-05
  Epoch 4/10
  32/32 [==============================] - 109s 3s/step - loss: 1.4929 - mean_io_u: 0.4041 - precision: 0.3227 - recall: 0.8099 - val_loss: 1.5400 - val_mean_io_u: 0.3990 - val_precision: 0.2011 - val_recall:
   0.0535
  Epoch 5/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4589 - mean_io_u: 0.4054 - precision: 0.3445 - recall: 0.7970 - val_loss: 1.5471 - val_mean_io_u: 0.3927 - val_precision: 0.2178 - val_recall:
   0.3854
  Epoch 6/10
  32/32 [==============================] - 108s 3s/step - loss: 1.4293 - mean_io_u: 0.4059 - precision: 0.3692 - recall: 0.7784 - val_loss: 1.6078 - val_mean_io_u: 0.4057 - val_precision: 0.1891 - val_recall:
   0.9730
  Epoch 7/10
  32/32 [==============================] - 108s 3s/step - loss: 1.3821 - mean_io_u: 0.4005 - precision: 0.4276 - recall: 0.7645 - val_loss: 1.7784 - val_mean_io_u: 0.4182 - val_precision: 0.1636 - val_recall:
   0.9998
  Epoch 8/10
  32/32 [==============================] - 109s 3s/step - loss: 1.3219 - mean_io_u: 0.3993 - precision: 0.5042 - recall: 0.8182 - val_loss: 1.9800 - val_mean_io_u: 0.3925 - val_precision: 0.2150 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 107s 3s/step - loss: 1.2852 - mean_io_u: 0.3930 - precision: 0.5602 - recall: 0.7957 - val_loss: 2.5127 - val_mean_io_u: 0.4206 - val_precision: 0.1587 - val_recall:
   1.0000
  Epoch 10/10
  32/32 [==============================] - 108s 3s/step - loss: 1.2926 - mean_io_u: 0.4057 - precision: 0.5469 - recall: 0.8147 - val_loss: 2.9090 - val_mean_io_u: 0.3916 - val_precision: 0.2169 - val_recall:
   1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  20/20 [==============================] - 17s 865ms/step - loss: 2.9045 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:544: DeprecationWarning: Using or importing the
   ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(inputs, collections.Sequence):
  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVa
  riable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
  Instructions for updating:
  If using Keras pass *_constraint arguments to layers.
  2020/05/02 15:07:38 INFO mlflow.projects: === Run (ID 'cda4eec66a6947c38ec2ee2006563ae5') succeeded ===
  [ye53nis@node007 drmed-git]$
#+end_example

Comparison to run at =/home=:
- some "misformed experiment" warning. Probably bc I tried to rebase the repo on
  the remote, because I committed the big =unet.tf= folder and wanted to redo
  that (it seemed that failed and my first test run got lost)
- same conda env got loaded, and the run seems to have conducted without
  problems, jippieh!

*** checking out mlflow error messages [3/5]
    :LOGBOOK:
    CLOCK: [2020-05-05 Di 14:30]--[2020-05-05 Di 15:38] =>  1:08
    CLOCK: [2020-05-05 Di 13:43]--[2020-05-05 Di 14:09] =>  0:26
    CLOCK: [2020-05-02 Sa 16:15]--[2020-05-02 Sa 18:06] =>  1:51
    :END:

**** TODO 1. tensorflow: your CPU supports instructions that this TF binary was not compiled to use

#+begin_example
  2020-05-02 14:48:01.189272: I tensorflow/core/platform/cpu_feature_guard.cc:142]
    Your CPU supports instructions that this TensorFlow binary was not
    compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  2020-05-02 14:48:01.222648: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94]
    CPU Frequency: 2194920000 Hz
  2020-05-02 14:48:01.226156: I tensorflow/compiler/xla/service/service.cc:168]
    XLA service 0x563a41791e20 initialized for platform Host (this does not
    guarantee that XLA will be used). Devices:
  2020-05-02 14:48:01.226237: I tensorflow/compiler/xla/service/service.cc:176]
    StreamExecutor device (0): Host, Default Version
  2020-05-02 14:48:01.226502: I tensorflow/core/common_runtime/process_util.cc:147]
    Creating new thread pool with default inter op setting: 2.
    Tune using inter_op_parallelism_threads for best performance.

  2020-05-02 15:07:19.835685: W tensorflow/python/util/util.cc:319]
    Sets are not currently considered sequences, but this may change in the future,
    so consider avoiding using them.
#+end_example

See [[https://github.com/tensorflow/tensorflow/issues/34369][this Github issue]]: the second part of the error is related to the first one,
and thus can be ignored (or solved following one of the paths below)

See [[https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u][here]]: It's only an issue if you run the code on a CPU!

The mentioned SSE, AVX, FMA etc are extensions from Intel and AMD to
speed up linear algebra computation, e.g. dot-product, matrix multiply,
convolution, etc. AVX and FMA speed them up on a CPU up to 300%. The warning
states that the CPU does support them, but =tensorflow= does not with the
default installation.

If you have a GPU:
- don't care about AVX etc support, because running on a GPU is way better
- you can ignore this warning by:
  #+BEGIN_SRC python
    # Just disables the warning, doesn't enable AVX/FMA
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
  #+END_SRC
  or
  #+BEGIN_SRC sh
    export TF_CPP_MIN_LOG_LEVEL=2
  #+END_SRC

If you don't have a GPU / don't want to use it:
- default tensorflow is intended to be compatible with as many CPUs as possible,
  that's why these libraries are note preinstalled
- *build tensorflow from the source optimized for /your/ CPU* - that's quite
  some additional work... if I should do this, here is TF [[https://www.tensorflow.org/install/source][guide]]
***** TODO Run this code on a GPU node, then decide. Maybe use docker to easily use TF on the nodes
**** TODO 2. mlflow: ABCs from 'collections'

  #+begin_example
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389:
      DeprecationWarning: Using or importing the ABCs from 'collections' instead of from
      'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
      if isinstance(sample_weight_mode, collections.Mapping):
    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60:
      DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0,
      use inspect.signature() or inspect.getfullargspec()
  #+end_example

I suspect these will be solved with an =mlflow= update.

**** DONE 3. calling BaseResourceVariable.__init__
     CLOSED: [2020-05-18 Mo 10:44]

     - State "DONE"       from "PENDING"    [2020-05-18 Mo 10:44] \\
       Use tf.nightly
     - State "PENDING"    from "TODO"       [2020-05-05 Di 15:01] \\
       Wait till this commit
       https://github.com/tensorflow/tensorflow/commit/1e2c8c6873770a70ace0613a65c11826666c4623#diff-aa6c341a4b212afc57b49be73e689dc2
       which introduces Conv1DTranspose officially is released. If it takes too long:
       install tf-nightly, but this might be unstable.
#+begin_example
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786:
      calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops)
      with constraint is deprecated and will be removed in a future version.
      Instructions for updating:
      If using Keras pass *_constraint arguments to layers.
    WARNING:tensorflow:Model failed to serialize as JSON.
      Ignoring... Layers with arguments in `__init__` must override `get_config`.

    /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552:
      UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` must override `get_config`.
      try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
#+end_example

The =BaseResourceVariable= one seems to be connected to keras' SavedModel
 format and happens in the [[https://www.tensorflow.org/tutorials/keras/save_and_load][official TF keras tutorial]] when using
=model.save('saved_model/my_model')=.

I am still not settled on how to save models anyway. I think I will use
[[https://mlflow.org/docs/latest/python_api/mlflow.tensorflow.html#mlflow.tensorflow.save_model][mlflow.tensorflow.save_model()]] or =mlflow.tensorflow.log_model= (not sure what
the difference is). BUT this needs a /serialized/ collection of TF graphs and
variables. Maybe I have to do some more work, see below...

from [[https://www.tensorflow.org/guide/keras/save_and_serialize][TF keras guide]]:
- Saving the architecture (= layers and how these layers are connected) → model
  can be created with freshly initialized state for weights and no compilation
  info
  - Sequential model / functional API model: are explicit graphs of layers,
    config always available in a structured form.
    - =layer.get_config()= or =model.get_config()= will return Python dict
      containing the config of the model
    - Model can be reconstructed
      - Sequential model: =Sequential.from_config(config)=
      - Functional API model: =Model.from_config(config)=
  - Custom objects
    - Models and layers: In order to save/load a model with custom-defined
      layers, or a subclassed model, you should overwrite the =get_config= and
      optionally =from_config= methods. Additionally, you should use register
      the custom object so that Keras is aware of it.
    - Custom functions (e.g. activation loss...) do not need =get_config=,
      function name is sufficient for loading as long as it is registered as a
      custom object
    - defining =Get_config=: should return a JSON-serializable dict in order to
      be compatible with Keras architecture- and model-saving APIs
    - defining =from_config(config)=: should return a new layer or model object
      that is created from the config. Default implementation returns
      =cls(**config)=

See [[https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf][this SO question]]:
- an example for a class which makes =model.save= fail:
  #+BEGIN_SRC python
    class encoder(tf.keras.layers.Layer):

        def __init__(
            self,
            vocab_size, num_layers, units, d_model, num_heads, dropout,
            ,**kwargs,
        ):
            super().__init__(**kwargs)
            self.vocab_size = vocab_size
            self.num_layers = num_layers
            self.units = units
            self.d_model = d_model
            self.num_heads = num_heads
            self.dropout = dropout

        # Other methods etc.
  #+END_SRC
- and now you need to override this method:
  #+BEGIN_SRC python
        def get_config(self):

            config = super().get_config().copy()
            config.update({
                'vocab_size': self.vocab_size,
                'num_layers': self.num_layers,
                'units': self.units,
                'd_model': self.d_model,
                'num_heads': self.num_heads,
                'dropout': self.dropout,
            })
            return config
  #+END_SRC
- and for =layer.from_config=:
  #+BEGIN_SRC python
        @classmethod
        def from_config(cls, config):
            return cls(**config)
  #+END_SRC
**** DONE 4. Logging to MLflow failed: Changing param values is not allowed
     CLOSED: [2020-05-28 Do 00:38]

     - State "DONE"       from "PENDING"    [2020-05-28 Do 00:38]
     - State "PENDING"    from "TODO"       [2020-05-05 Di 13:46] \\
       Renamed batch_size to _batch_size to emphasize the local character. let's see if
       the error still occurs

#+BEGIN_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70:
    UserWarning: Logging to MLflow failed:
    Changing param values is not allowed.
    Param with key='batch_size' was already logged with value='5' for run ID='cda4eec66a6947c38ec2ee2006563ae5'.
    Attempted logging new value 'None'.
  try_mlflow_log(mlflow.log_params, defaults)
#+END_example

Couldn't find anything googling that. Probably has something to do with naming
the variable =batch_size=, which may be a variable the autologging feature
already uses?

**** DONE 5. invalid value tf.Tensor(..., dtype=float32). Please specify value as a valid double
     CLOSED: [2020-05-18 Mo 10:46]

     - State "DONE"       from "PENDING"    [2020-05-18 Mo 10:46] \\
       Use mlflow.tensorflow.autolog(every_n_iter=1), now metric logging on end
       of epoch works (this every_n_iter value is working different for TF 2.0)
     - State "TODO"       from "PENDING"    [2020-05-05 Di 15:26]
     - State "PENDING"    from "TODO"       [2020-05-05 Di 13:53] \\
       I added tf.keras.backend.set_floatx('float64')
#+begin_example
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:549:
    UserWarning: Logging to MLflow failed:
    Got invalid value tf.Tensor(1.5411952, shape=(), dtype=float32) for metric 'val_loss'
    (timestamp=1588423924159). Please specify value as a valid double (64-bit floating point)
  try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
#+end_example

Check out if val_loss got logged in the end. → doesn't seem so. It can be found
under =artifacts/tensorboard_logs= and these are not text files, but some binary
files.

In theory, validation loss and training loss should be logged by mlflow as well
(and custom metrics as well) → check that they are a valid 64-bit integer value.

**** Test run 1: fixing 4. and 5.

     :LOGBOOK:
     CLOCK: [2020-05-06 Mi 16:10]--[2020-05-06 Mi 17:17] =>  1:07
     :END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  [ye53nis@node007 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
  [ye53nis@node007 drmed-git]$ git log -1
  commit e9983783a946d57f95b3a28405c5a2d74108f6b9
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Tue May 5 15:07:02 2020 +0200

      Set tf.keras standard to float64; rename var
  [ye53nis@node007 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 79, in <module>
      tf.keras.metrics.Recall()
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
      result = method(self, *args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 439, in compile
      masks=self._prepare_output_masks())
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 2004, in _handle_metrics
      target, output, output_mask))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 1955, in _handle_per_output_metrics
      metric_fn, y_true, y_pred, weights=weights, mask=mask)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1155, in call_metric_function
      return metric_fn(y_true, y_pred, sample_weight=weights)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 196, in __call__
      replica_local_fn, *args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py", line 1135, in call_repli
  ca_local_fn
      return fn(*args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 179, in replica_local_fn
      update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 76, in decorated
      update_op = update_state_fn(*args, **kwargs)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py", line 1216, in update_state
      sample_weight=sample_weight)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 440, in update_confusion_matrix_varia
  bles
      variables_to_update[matrix_cond]))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 416, in weighted_assign_add
      return var.assign_add(math_ops.reduce_sum(label_and_pred, 1))
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 785, in assign_add
      self.handle, ops.convert_to_tensor(delta, dtype=self.dtype),
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py", line 1290, in convert_to_tensor
      (dtype.name, value.dtype.name, value))
  ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics/precision/Sum:0' shape=(1,) dtype=float32>
  2020/05/05 15:16:13 ERROR mlflow.cli: === Run (ID '0fcf9dc61b3148d6b535b5e66a8a3db0') failed ===
  [ye53nis@node007 drmed-git]$
#+end_example

there is an issue with tf.metrics see [[https://github.com/tensorflow/tensorflow/issues/36790][here]]. For now,
tf.keras.backend.set_floatx('float64') doesn't work.

Next try: log the metrics manually and see if that works.
Or: Check first if the tensorboard metrics stored in =mlruns/artifacts= is maybe enough

I found a [[https://medium.com/@ij_82957/how-to-reduce-mlflow-logging-overhead-by-using-log-batch-b61301cc540f][nice article]] dealing with how to log metrics from a history object.
For now I implement a approach based on =mlflow.log_metrics()=. There is a
faster approch using =mlflow.entities.Metric=, =mlflow.tracking.MlflowClient=
and =mlflow_client.log_batch()=. But I want to try the naive approach first.

**** Test run 2: do dynamic testing using jupyter
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
   :END:
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p gpu_test --time=1:00:00 --gres=gpu:2 --mem-per-cpu=1000 --ntasks-per-node=48 --pty bash
#+END_SRC

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  module load nvidia/cuda/10.1.168
  module load nvidia/cudnn/7.5.1.10
  conda activate tensorflow_nightly
  export PORT=8889
  export XDG_RUNTIME_DIR=''
  export XDG_RUNTIME_DIR=""
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/cluster/nvidia/cuda/10.1.168/extras/CUPTI/lib64
  jupyter notebook --no-browser --port=$PORT
#+END_SRC

#+CALL: jpt-tunnel(port="8889", node="node127")

#+RESULTS:
| sh-5.0$           | ye53nis@ara-login01.rz.uni-jena.de's | password: |     |   |          |      |      |             |
| ye53nis@node127's | password:                            |           |     |   |          |      |      |             |
| Last              | login:                               | Wed       | May | 6 | 23:16:52 | 2020 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3          9e7e4701-35b1-4031-8f44-ed2586b82d49   2 minutes ago        starting   0
#+end_example

#+CALL: jupyter-python-metadata(conda_list='False)

#+RESULTS:
#+begin_example
  No of CPUs in system: 72
  No of CPUs the current process can use: 24
  load average: (0.09, 1.05, 11.15)
  posix.uname_result(sysname='Linux', nodename='node243', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 448659
  RAM total: 199G, RAM used: 2.3G, RAM free: 154G
  the current directory: /home/ye53nis
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  3.2G   47G   7% /
  devtmpfs              94G     0   94G   0% /dev
  tmpfs                 94G 1018M   93G   2% /dev/shm
  tmpfs                 94G   59M   94G   1% /run
  tmpfs                 94G     0   94G   0% /sys/fs/cgroup
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  nfs01-ib:/home        80T   59T   22T  73% /home
  nfs01-ib:/cluster    2.0T  316G  1.7T  16% /cluster
  nfs02-ib:/data01      88T   59T   29T  68% /data01
  /dev/sda5            2.0G   34M  2.0G   2% /tmp
  /dev/sda6            169G  4.3G  165G   3% /local
  /dev/sda3            6.0G  404M  5.6G   7% /var
  beegfs_nodev         524T  425T  100T  82% /beegfs
  tmpfs                 19G     0   19G   0% /run/user/67339
#+end_example

#+BEGIN_SRC jupyter-python
  %cd /beegfs/ye53nis/drmed-git
#+END_SRC

#+RESULTS:
: /beegfs/ye53nis/drmed-git

#+BEGIN_SRC jupyter-python
  import sys
  import matplotlib.pyplot as plt
  import tensorflow as tf
  sys.path.append('/beegfs/ye53nis/drmed-git/src/')
  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
  tf.config.list_physical_devices('GPU')
#+END_SRC

#+RESULTS:
: []

#+BEGIN_SRC jupyter-python
  _batch_size = 5
  frac_val = 0.2
  length_delimiter = 16384
  learning_rate = 1e-5
  epochs = 2
  csv_path = '/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/'
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  train, test, nsamples, experiment_params = isfc.import_from_csv(
      path=csv_path,
      header=12,
      frac_train=0.8,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')

  train_data, train_labels = isfc.separate_data_and_labels(array=train,
                                                           nsamples=nsamples)
  test_data, test_labels = isfc.separate_data_and_labels(array=test,
                                                         nsamples=nsamples)

  # get bool as ground truth
  train_labels_bool = train_labels > 0.04

  test_labels_bool = test_labels > 0.04
  print(
      '\nfor each 20,000 timestap trace there are the following numbers '
      'of corrupted timesteps:\n',
      test_labels_bool.sum(axis=0).head())

  # Cleanup
  del train, test
#+END_SRC

#+RESULTS:
#+begin_example
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
#+end_example

#+BEGIN_SRC jupyter-python
  dataset_train, dataset_val, num_train_examples, num_val_examples = ppd.tfds_from_pddf_for_unet(
      features_df=train_data,
      labels_df=train_labels_bool,
      is_training=True,
      batch_size=_batch_size,
      length_delimiter=length_delimiter,
      frac_val=frac_val)

  dataset_test, num_test_examples = ppd.tfds_from_pddf_for_unet(
      features_df=test_data,
      labels_df=test_labels_bool,
      is_training=False,
      batch_size=_batch_size,
      length_delimiter=length_delimiter)
#+END_SRC

#+RESULTS:
: number of training examples: 160, number of validation examples: 40
:
: ------------------------
: number of test examples: 100
:

#+BEGIN_SRC jupyter-python
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
#+END_SRC

#+RESULTS:
: WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
: INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
: Number of devices: 1

#+BEGIN_SRC jupyter-python
  model = bm.unet_1d_alt(input_size=length_delimiter)
  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
  loss = bm.binary_ce_dice_loss

  model.compile(loss=loss,
                optimizer=optimizer,
                metrics=[
                    tf.keras.metrics.MeanIoU(num_classes=2),
                    tf.keras.metrics.Precision(),
                    tf.keras.metrics.Recall()
                ])

  history = model.fit(
      x=dataset_train,
      epochs=epochs,
      steps_per_epoch=tf.math.ceil(num_train_examples / _batch_size),
      validation_data=dataset_val,
      validation_steps=tf.math.ceil(num_val_examples / _batch_size))
#+END_SRC

#+RESULTS:
: input - shape:	 (None, 16384, 1)
: output - shape:	 (None, 16384, 1)
: Epoch 1/2
: 32/32 [==============================] - 50s 2s/step - loss: 1.6011 - mean_io_u: 0.4080 - precision: 0.2163 - recall: 0.6183 - val_loss: 1.5998 - val_mean_io_u: 0.4234 - val_precision: 0.1501 - val_recall: 0.8740
: Epoch 2/2
: 32/32 [==============================] - 49s 2s/step - loss: 1.5107 - mean_io_u: 0.3981 - precision: 0.3011 - recall: 0.6895 - val_loss: 1.6026 - val_mean_io_u: 0.4151 - val_precision: 0.1624 - val_recall: 0.8894

These GPU modules were missing:
libcublas.so.10 - I wrote to Sabine Irmer about that
libcudnn.so.7 - There was an extra =module load nvidia/cudnn/7.5.1.10= available

#+BEGIN_SRC jupyter-python :results scalar
  history.history
#+END_SRC

#+RESULTS:
#+begin_example
  {'loss': [1.5873368978500366,
    1.5292785167694092,
    1.4659773111343384,
    1.416449785232544,
    1.345642328262329,
    1.3310154676437378,
    1.2963486909866333,
    1.2417198419570923,
    1.2305928468704224,
    1.2321150302886963],
   'mean_io_u': [0.0,
    3985559344291687.4037455916404724,
    0.4071432948112488,
    0.40351858735084534,
    0.39908209443092346,
    0.41106948256492615,
    0.4076460599899292,
    0.40254250168800354,
    0.4079275131225586,
    0.41036319732666016],
   'precision': [0.2488986849784851,
    0.30270472168922424,
    0.34654930233955383,
    0.4073646366596222,
    0.49564093351364136,
    0.5083103179931641,
    0.5742575526237488,
    0.6650815606117249,
    0.6706622838973999,
    0.671720564365387],
   'recall': [0.537831723690033,
    0.6538828611373901,
    0.7087317705154419,
    0.7070884108543396,
    0.7108414173126221,
    0.7444652915000916,
    0.7134528160095215,
    0.7382367849349976,
    0.7559362649917603,
    0.741098940372467],
   'val_loss': [1.49961519241333,
    1.48013174533844,
    1.473410964012146,
    1.4653061628341675,
    1.4866881370544434,
    1.5756771564483643,
    1.785191297531128,
    2.664144515991211,
    3.5446887016296387,
    4.201501369476318],
   'val_mean_io_u': [0.3783065676689148,
    0.37820738554000854,
    0.3933570981025696,
    0.3894149661064148,
    0.42156678438186646,
    0.3901313841342926,
    0.3508506715297699,
    0.3951469361782074,
    0.4056693911552429,
    0.38204270601272583],
   'val_precision': [0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.24144163727760315,
    0.2983255386352539,
    0.2097124308347702,
    0.18867774307727814,
    0.23592336475849152],
   'val_recall': [0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.9312672019004822,
    0.9996521472930908,
    0.9997889995574951,
    0.9999595880508423,
    0.9999547004699707]}
#+end_example

#+BEGIN_SRC jupyter-python :results scalar
  model.evaluate(dataset_test,
                 steps=tf.math.ceil(num_test_examples / _batch_size))
#+END_SRC

#+RESULTS:
:RESULTS:
: 20/20 [==============================] - 10s 519ms/step - loss: 4.2488 - mean_io_u: 0.3849 - precision: 0.2301 - recall: 1.0000
: [4.248773097991943,
:  0.38494813442230225,
:  0.23011629283428192,
:  0.9999707937240601]
:END:

#+BEGIN_SRC jupyter-python :display image
  it = iter(dataset_test)

  fig, ax = plt.subplots(5, figsize=(16, 12))
  count = 0
  while count < 5:
      example = next(it)
      ax[count].plot(example[0][0])
      prediction = model.predict(example[0])
      prediction = prediction[0] > 0.5
      ax[count].plot(prediction*2)
      ax[count].plot(example[1][0])
      count += 1
#+END_SRC

#+RESULTS:
: 0c67d91d-f101-4868-b9a4-ed8cee57bee9

**** Test run 3: fixing 4. and 5. part 2
     :LOGBOOK:
     CLOCK: [2020-05-08 Fr 21:41]--[2020-05-08 Fr 21:41] =>  0:00
     CLOCK: [2020-05-08 Fr 20:07]--[2020-05-08 Fr 20:54] =>  0:47
     CLOCK: [2020-05-08 Fr 17:56]--[2020-05-08 Fr 18:08] =>  0:12
     CLOCK: [2020-05-08 Fr 15:41]--[2020-05-08 Fr 16:23] =>  0:42
     CLOCK: [2020-05-08 Fr 14:55]--[2020-05-08 Fr 15:25] =>  0:30
     :END:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p s_standard --time=7-10:00:00 --ntasks-per-node=36 --mem-per-cpu=2000 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 ~]$ srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
  (base) [ye53nis@node262 ~]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  cd /beegfs/ye53nis/drmed-git
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  commit 00cf780bf75e57ef38c5fcf06cbbbb18abc38a13
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Thu May 7 19:00:51 2020 +0200

      Mention LabBook.html; fix links
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node262 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/05/08 15:04:40 INFO mlflow.projects: === Created directory /tmp/tmps8r9h7ee for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/08 15:04:40 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'f360fcfaeb7f4750bdc5ef8326d2240a' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  fluotracify path:  /beegfs/ye53nis/drmed-git/src
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-08 15:05:42.782717: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
  2020-05-08 15:05:42.797518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
  2020-05-08 15:05:42.800274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564142ebde50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-08 15:05:42.800378: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-08 15:05:42.800727: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='f360fcfaeb7f4750bdc5ef8326d2240a'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-08 15:06:09.400241: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 157s 5s/step - loss: 1.4794 - mean_io_u: 0.4027 - precision: 0.1746 - recall: 0.0652 - val_loss: 1.5356 - val_mean_io_u: 0.4155 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 2/10
  31/32 [============================>.] - ETA: 4s - loss: 1.4003 - mean_io_u: 0.4062 - precision: 0.4050 - recall: 0.1508/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.497927, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588943442066). Please specif
  y value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 139s 4s/step - loss: 1.3997 - mean_io_u: 0.4061 - precision: 0.4134 - recall: 0.1530 - val_loss: 1.4979 - val_mean_io_u: 0.4137 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 134s 4s/step - loss: 1.3425 - mean_io_u: 0.4005 - precision: 0.6062 - recall: 0.2561 - val_loss: 1.4643 - val_mean_io_u: 0.3848 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 4/10
  32/32 [==============================] - 132s 4s/step - loss: 1.3102 - mean_io_u: 0.3982 - precision: 0.6693 - recall: 0.3802 - val_loss: 1.4749 - val_mean_io_u: 0.4106 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 5/10
  32/32 [==============================] - 133s 4s/step - loss: 1.2738 - mean_io_u: 0.3999 - precision: 0.6858 - recall: 0.5133 - val_loss: 1.5032 - val_mean_io_u: 0.3820 - val_precision: 0.2813 - val_recall:
   0.2903
  Epoch 6/10
  32/32 [==============================] - 133s 4s/step - loss: 1.2496 - mean_io_u: 0.4049 - precision: 0.6634 - recall: 0.6284 - val_loss: 1.7162 - val_mean_io_u: 0.4237 - val_precision: 0.1578 - val_recall:
   0.8926
  Epoch 7/10
  32/32 [==============================] - 143s 4s/step - loss: 1.2230 - mean_io_u: 0.4051 - precision: 0.6847 - recall: 0.6793 - val_loss: 1.9898 - val_mean_io_u: 0.4048 - val_precision: 0.1904 - val_recall:
   0.9998
  Epoch 8/10
  32/32 [==============================] - 139s 4s/step - loss: 1.1948 - mean_io_u: 0.4042 - precision: 0.7137 - recall: 0.7155 - val_loss: 2.4641 - val_mean_io_u: 0.3941 - val_precision: 0.2117 - val_recall:
   0.9998
  Epoch 9/10
  32/32 [==============================] - 142s 4s/step - loss: 1.1701 - mean_io_u: 0.4010 - precision: 0.7509 - recall: 0.7258 - val_loss: 2.9713 - val_mean_io_u: 0.3751 - val_precision: 0.2497 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 135s 4s/step - loss: 1.1252 - mean_io_u: 0.3996 - precision: 0.7899 - recall: 0.7900 - val_loss: 3.6660 - val_mean_io_u: 0.4050 - val_precision: 0.1901 - val_recall:
   0.9998
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 96, in <module>
      mlflow.log_metrics(metrics, step=i)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 271, in log_metrics
      MlflowClient().log_batch(run_id=run_id, metrics=metrics_arr, params=[], tags=[])
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 249, in log_batch
      self._tracking_client.log_batch(run_id, metrics, params, tags)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 229, in log_batch
      _validate_metric(metric.key, metric.value, metric.timestamp, metric.step)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/validation.py", line 70, in _validate_metric
      INVALID_PARAMETER_VALUE)
  mlflow.exceptions.MlflowException: Got invalid value tf.Tensor(1.5356212, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588944533682). Please specify value as a valid double (64-bit floating po
  int)
  2020/05/08 15:28:54 ERROR mlflow.cli: === Run (ID 'f360fcfaeb7f4750bdc5ef8326d2240a') failed ===
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  commit 5319f00ac246f426ea266d07f94effa8a18068a8
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Fri May 8 15:59:18 2020 +0200

      try to make log_metrics work
#+end_example

Two things changed: now running tensorflow nightly

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  2020/05/08 16:23:44 INFO mlflow.projects: === Created directory /tmp/tmp6tg_wyna for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/08 16:23:44 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'aeacaed2624a4e3ebbe240ff97e74fd0' ===
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecate
  d in favour of importlib; see the module's documentation for alternative uses
    import imp
  2.1.0
  fluotracify path:  /beegfs/ye53nis/drmed-git/src
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-08 16:23:54.416673: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
  2020-05-08 16:23:54.427207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
  2020-05-08 16:23:54.428400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556200e8fe40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-08 16:23:54.428430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  2020-05-08 16:23:54.428559: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:1389: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
    if isinstance(sample_weight_mode, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/autologging_utils.py:70: UserWarning: Logging to MLflow failed: Changing param values is no
  t allowed. Param with key='batch_size' was already logged with value='5' for run ID='aeacaed2624a4e3ebbe240ff97e74fd0'. Attempted logging new value 'None'.
    try_mlflow_log(mlflow.log_params, defaults)
  Train for 32.0 steps, validate for 8.0 steps
  WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.
  Epoch 1/10
  2020-05-08 16:24:20.043922: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
  32/32 [==============================] - 156s 5s/step - loss: 1.5595 - mean_io_u: 0.4046 - precision: 0.2138 - recall: 0.4436 - val_loss: 1.5276 - val_mean_io_u: 0.3947 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 2/10
  31/32 [============================>.] - ETA: 4s - loss: 1.4620 - mean_io_u: 0.4036 - precision: 0.3204 - recall: 0.6043/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.
  7/site-packages/mlflow/tensorflow.py:549: UserWarning: Logging to MLflow failed: Got invalid value tf.Tensor(1.5336354, shape=(), dtype=float32) for metric 'val_loss' (timestamp=1588948133109). Please speci
  fy value as a valid double (64-bit floating point)
    try_mlflow_log(mlflow.log_metrics, logs, step=epoch)
  32/32 [==============================] - 140s 4s/step - loss: 1.4617 - mean_io_u: 0.4027 - precision: 0.3222 - recall: 0.6023 - val_loss: 1.5336 - val_mean_io_u: 0.4152 - val_precision: 0.0000e+00 - val_rec
  all: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 135s 4s/step - loss: 1.3917 - mean_io_u: 0.3939 - precision: 0.4246 - recall: 0.6836 - val_loss: 1.5311 - val_mean_io_u: 0.4055 - val_precision: 0.1513 - val_recall:
   0.0404
  Epoch 4/10
  32/32 [==============================] - 143s 4s/step - loss: 1.3645 - mean_io_u: 0.4012 - precision: 0.4491 - recall: 0.7378 - val_loss: 1.5464 - val_mean_io_u: 0.3922 - val_precision: 0.2166 - val_recall:
   0.5154
  Epoch 5/10
  32/32 [==============================] - 136s 4s/step - loss: 1.3427 - mean_io_u: 0.4034 - precision: 0.4764 - recall: 0.7502 - val_loss: 1.6451 - val_mean_io_u: 0.4045 - val_precision: 0.1937 - val_recall:
   0.7729
  Epoch 6/10
  32/32 [==============================] - 136s 4s/step - loss: 1.2957 - mean_io_u: 0.4052 - precision: 0.5425 - recall: 0.7886 - val_loss: 1.9099 - val_mean_io_u: 0.3994 - val_precision: 0.2013 - val_recall:
   0.9999
  Epoch 7/10
  32/32 [==============================] - 140s 4s/step - loss: 1.2704 - mean_io_u: 0.4004 - precision: 0.5900 - recall: 0.7747 - val_loss: 2.4546 - val_mean_io_u: 0.3892 - val_precision: 0.2216 - val_recall:
   0.9999
  Epoch 8/10
  32/32 [==============================] - 141s 4s/step - loss: 1.2297 - mean_io_u: 0.3955 - precision: 0.6516 - recall: 0.7727 - val_loss: 3.6472 - val_mean_io_u: 0.4207 - val_precision: 0.1586 - val_recall:
   0.9999
  Epoch 9/10
  32/32 [==============================] - 137s 4s/step - loss: 1.2099 - mean_io_u: 0.4049 - precision: 0.6759 - recall: 0.8141 - val_loss: 4.4598 - val_mean_io_u: 0.4071 - val_precision: 0.1859 - val_recall:
   0.9999
  Epoch 10/10
  32/32 [==============================] - 136s 4s/step - loss: 1.1920 - mean_io_u: 0.3994 - precision: 0.7333 - recall: 0.7710 - val_loss: 5.2335 - val_mean_io_u: 0.4005 - val_precision: 0.1991 - val_recall:
   0.9999
  /home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tensorflow.py:552: UserWarning: Logging to MLflow failed: Layers with arguments in `__init__` mus
  t override `get_config`.
    try_mlflow_log(mlflow.keras.log_model, self.model, artifact_path='model')
  Traceback (most recent call last):
    File "src/fluotracify/training/train.py", line 92, in <module>
      mlflow.log_metrics(metrics, step=i)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/fluent.py", line 271, in log_metrics
      MlflowClient().log_batch(run_id=run_id, metrics=metrics_arr, params=[], tags=[])
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/client.py", line 249, in log_batch
      self._tracking_client.log_batch(run_id, metrics, params, tags)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 229, in log_batch
      _validate_metric(metric.key, metric.value, metric.timestamp, metric.step)
    File "/home/ye53nis/.conda/envs/mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81/lib/python3.7/site-packages/mlflow/utils/validation.py", line 70, in _validate_metric
      INVALID_PARAMETER_VALUE)
  mlflow.exceptions.MlflowException: Got invalid value tf.Tensor(1.5594830736517906, shape=(), dtype=float64) for metric 'loss' (timestamp=1588949235987). Please specify value as a valid double (64-bit floati
  ng point)
  2020/05/08 16:47:16 ERROR mlflow.cli: === Run (ID 'aeacaed2624a4e3ebbe240ff97e74fd0') failed ===
  (tensorflow_nightly) [ye53nis@node262 drmed-git]$
#+end_example

** run  mlflow model after some work
   :LOGBOOK:
   CLOCK: [2020-05-18 Mo 14:55]--[2020-05-18 Mo 16:09] =>  1:14
   CLOCK: [2020-05-18 Mo 14:11]--[2020-05-18 Mo 14:33] =>  0:22
   CLOCK: [2020-05-18 Mo 12:35]--[2020-05-18 Mo 13:40] =>  1:05
   CLOCK: [2020-05-18 Mo 10:48]--[2020-05-18 Mo 11:00] =>  0:12
   :END:

*** Make mlflow ready
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  /beegfs/ye53nis/drmed-git
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node154 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  #   (use "git add <file>..." to include in what will be committed)
  #
  #       data/exp-devtest/
  #       data/mlruns/1/07dba5bcb5f7442a8aeb5a09b63d1e14/
  #       data/mlruns/1/0fcf9dc61b3148d6b535b5e66a8a3db0/
  #       data/mlruns/1/3867a0d7bdd0424aab72165e7af25d69/
  #       data/mlruns/1/a04de21fa0bf4692aade01ecbf4828d0/
  #       data/mlruns/1/a71abaad77dd4fae8c78c629cc450834/
  #       data/mlruns/1/c87de59ce9b848bc8d3d198fa63f9738/
  #       data/mlruns/1/dbd0106d180042ce8eb7a2ede38cc985/
  #       mlruns/
  #       tramp.YDPCnB
  nothing added to commit but untracked files present (use "git add" to track)

  (base) [ye53nis@node154 drmed-git]$ git log -1
  commit 8ebdd343fc404fe06ef3446fd941255c0103cd46
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Mon May 18 12:49:41 2020 +0200

      Move to tf-nightly in conda.yaml
      (base) [ye53nis@node154 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda activate tensorflow_nightly
  cd /beegfs/ye53nis/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns

#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$
#+end_example

*** First run: on login node (bad, but necessary)
For the run mlflow had to create a new conda environment, since I used
tf-nightly now. This took some time, since tf-nightly had to install via pip.
Executing this following =mlflow run= command on the compute node (here:
node154) was not successfull, it complained about missing disk space. I did
=conda clean= and removed some prior environments with the goal of making space,
but it still complained. So I ran it on the login node instead (you should never
do this normally) - and here =pip= worked. I guess that some access restrictions
were the problem. Now that the right mlflow conda env exists, I can run the code
on the compute nodes as before.

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
(base) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  /cluster/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py:318: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and
   in 3.9 it will stop working
    from collections import Mapping
  2020/05/18 13:31:30 INFO mlflow.projects: === Creating conda environment mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 ===
  Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they
   may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.
  Collecting package metadata (repodata.json): done
  Solving environment: done
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  Ran pip subprocess with arguments:
  ['/home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt']
  Pip subprocess output:
  Collecting tf-nightly
    Using cached tf_nightly-2.3.0.dev20200518-cp38-cp38-manylinux2010_x86_64.whl (522.5 MB)
  Collecting google-pasta>=0.1.8
    Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
  Collecting keras-preprocessing<1.2,>=1.1.1
    Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
  Collecting scipy==1.4.1
    Using cached scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)
  Collecting gast==0.3.3
    Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
  Processing /home/ye53nis/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73/wrapt-1.12.1-cp38-cp38-linux_x86_64.whl
  Collecting opt-einsum>=2.3.2
    Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)
  Processing /home/ye53nis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl
  Collecting grpcio>=1.8.6
    Downloading grpcio-1.29.0-cp38-cp38-manylinux2010_x86_64.whl (3.0 MB)
  Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53
  nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.18.1)
  Processing /home/ye53nis/.cache/pip/wheels/1d/10/8e/2f79b924179ff1e6510933d63eb851bea01054fff262343b7a/absl_py-0.9.0-py3-none-any.whl
  Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (0.34.2)
  Collecting astunparse==1.6.3
    Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
  Collecting tb-nightly<2.4.0a0,>=2.3.0a0
    Using cached tb_nightly-2.3.0a20200517-py3-none-any.whl (3.0 MB)
  Collecting tf-estimator-nightly
    Downloading tf_estimator_nightly-2.3.0.dev2020051801-py2.py3-none-any.whl (456 kB)
  Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.14.0)
  Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis
  /drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (3.11.4)
  Collecting h5py<2.11.0,>=2.10.0
    Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)
  Collecting google-auth<2,>=1.6.3
    Downloading google_auth-1.14.3-py2.py3-none-any.whl (89 kB)
  Collecting markdown>=2.6.8
    Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)
  Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a0
  ->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.0.1)
  Collecting google-auth-oauthlib<0.5,>=0.4.1
    Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
  Collecting tensorboard-plugin-wit>=1.6.0
    Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)
  Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0
  a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2.23.0)
  Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a
  0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (46.2.0.post20200511)
  Collecting pyasn1-modules>=0.2.1
    Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
  Collecting rsa<4.1,>=3.1.4
    Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)
  Collecting cachetools<5.0,>=2.0.0
    Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)
  Collecting requests-oauthlib>=0.7.0
    Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
  Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nig
  htly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2020.4.5.1)
  Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nightly<2
  .4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (2.9)
  Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nigh
  tly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (3.0.4)
  Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages (from reques
  ts<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.bxzjsa6y.requirements.txt (line 1)) (1.25.8)
  Collecting pyasn1<0.5.0,>=0.4.6
    Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
  Collecting oauthlib>=3.0.0
    Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
  Installing collected packages: google-pasta, keras-preprocessing, scipy, gast, wrapt, opt-einsum, termcolor, grpcio, absl-py, astunparse, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, markdown, oaut
  hlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tb-nightly, tf-estimator-nightly, h5py, tf-nightly
  Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.14.3 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdow
  n-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tb-nightly-2.3.0a20200517 tensorboard-plugin-wit-1.6.0.post3 termcolor-1.1.0 tf-estimato
  r-nightly-2.3.0.dev2020051801 tf-nightly-2.3.0.dev20200518 wrapt-1.12.1

  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/05/18 13:33:38 INFO mlflow.projects: === Created directory /tmp/tmpvurkkck7 for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/18 13:33:38 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '6030cbbeacbb4dfab851ac8429488ba9' ===
  2020-05-18 13:33:47.083652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200518
  2020-05-18 13:33:49.854423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
  2020-05-18 13:33:50.730828: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  2020-05-18 13:33:50.730912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-18 13:33:59.814688: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-18 13:33:59.829739: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199950000 Hz
  2020-05-18 13:33:59.832684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bdc80342d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-18 13:33:59.832729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  2020-05-18 13:34:04.449018: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5955 - precision: 0.2521 - recall: 0.67672020-05-18 13:34:20.946147: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session start
  ed.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-18 13:34:23.531770: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23
  2020-05-18 13:34:23.550586: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.trace.
  json.gz
  2020-05-18 13:34:23.583376: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23
  2020-05-18 13:34:23.583511: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login
  01.memory_profile.json.gz
  2020-05-18 13:34:23.585938: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23Dumped tool data for xplane.pb to /tm
  p/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tmp5xzpvngh/train/plugins/profile/2020_05_18_13_34_23/login01.kernel_stats.pb

  32/32 [==============================] - 88s 3s/step - loss: 1.6827 - precision: 0.1826 - recall: 0.5827 - val_loss: 1.5554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 2/10
  32/32 [==============================] - 91s 3s/step - loss: 1.5697 - precision: 0.2669 - recall: 0.6891 - val_loss: 1.5072 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 3/10
  32/32 [==============================] - 101s 3s/step - loss: 1.5357 - precision: 0.2908 - recall: 0.7327 - val_loss: 1.5211 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
  Epoch 4/10
  32/32 [==============================] - 102s 3s/step - loss: 1.4519 - precision: 0.3782 - recall: 0.7689 - val_loss: 1.5255 - val_precision: 0.2251 - val_recall: 0.1232
  Epoch 5/10
  32/32 [==============================] - 101s 3s/step - loss: 1.4212 - precision: 0.4075 - recall: 0.7919 - val_loss: 1.6413 - val_precision: 0.1982 - val_recall: 0.9612
  Epoch 6/10
  32/32 [==============================] - 98s 3s/step - loss: 1.3310 - precision: 0.5277 - recall: 0.7944 - val_loss: 1.9848 - val_precision: 0.2311 - val_recall: 0.9998
  Epoch 7/10
  32/32 [==============================] - 100s 3s/step - loss: 1.3171 - precision: 0.5449 - recall: 0.8033 - val_loss: 3.1224 - val_precision: 0.2024 - val_recall: 0.9998
  Epoch 8/10
  32/32 [==============================] - 99s 3s/step - loss: 1.2777 - precision: 0.6249 - recall: 0.7834 - val_loss: 4.5112 - val_precision: 0.1568 - val_recall: 0.9999
  Epoch 9/10
  32/32 [==============================] - 94s 3s/step - loss: 1.2667 - precision: 0.6519 - recall: 0.7669 - val_loss: 5.7424 - val_precision: 0.1783 - val_recall: 0.9999
  Epoch 10/10
  32/32 [==============================] - 92s 3s/step - loss: 1.2452 - precision: 0.6915 - recall: 0.7438 - val_loss: 7.1441 - val_precision: 0.1718 - val_recall: 0.9999
  20/20 [==============================] - 10s 507ms/step - loss: 6.5700 - precision: 0.2301 - recall: 0.9999
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:467: set_learning_phase (from tensorflow.pyth
  on.keras.backend) is deprecated and will be removed after 2020-10-11.
  Instructions for updating:
  Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:105: Model.state_updates (from t
  ensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
  Instructions for updating:
  This property should not be used in TensorFlow 2.0, as updates are applied automatically.
  2020-05-18 13:51:19.183519: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  2020/05/18 13:51:53 INFO mlflow.projects: === Run (ID '6030cbbeacbb4dfab851ac8429488ba9') succeeded ===
  (base) [ye53nis@login01 drmed-git]$ srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
#+end_example

now another run on the compute node:

*** Second run: on compute node node154

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  2020/05/18 14:26:02 INFO mlflow.projects: === Created directory /tmp/tmpde53ox06 for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/18 14:26:02 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 1e-5 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID '47b870b8fdcb4445956635c6758caff3' ===
  2020-05-18 14:26:04.138662: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No
   such file or directory
  2020-05-18 14:26:04.138707: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200518
  2020-05-18 14:26:06.305976: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file
   or directory
  2020-05-18 14:26:06.306047: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
  2020-05-18 14:26:06.306099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node154): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-18 14:26:12.857798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 AVX512F FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-18 14:26:12.868945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
  2020-05-18 14:26:12.870348: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603d3478fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-18 14:26:12.870375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  2020-05-18 14:26:15.904378: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 2.0230 - precision: 0.0936 - recall: 0.88482020-05-18 14:26:26.530926: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session start
  ed.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-18 14:26:28.032343: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28
  2020-05-18 14:26:28.045887: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.trace.
  json.gz
  2020-05-18 14:26:28.070875: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28
  2020-05-18 14:26:28.070984: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node1
  54.memory_profile.json.gz
  2020-05-18 14:26:28.072919: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28Dumped tool data for xplane.pb to /tm
  p/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tmp30e0prh8/train/plugins/profile/2020_05_18_14_26_28/node154.kernel_stats.pb

  32/32 [==============================] - 50s 2s/step - loss: 1.7921 - precision: 0.2086 - recall: 0.8982 - val_loss: 1.5784 - val_precision: 0.2057 - val_recall: 1.0000
  Epoch 2/10
  32/32 [==============================] - 48s 2s/step - loss: 1.6970 - precision: 0.2366 - recall: 0.9222 - val_loss: 1.6132 - val_precision: 0.1891 - val_recall: 1.0000
  Epoch 3/10
  32/32 [==============================] - 48s 2s/step - loss: 1.6142 - precision: 0.2712 - recall: 0.9049 - val_loss: 1.6398 - val_precision: 0.1917 - val_recall: 1.0000
  Epoch 4/10
  32/32 [==============================] - 48s 2s/step - loss: 1.5621 - precision: 0.2899 - recall: 0.8792 - val_loss: 1.6188 - val_precision: 0.2525 - val_recall: 1.0000
  Epoch 5/10
  32/32 [==============================] - 48s 1s/step - loss: 1.4915 - precision: 0.3355 - recall: 0.8279 - val_loss: 1.7816 - val_precision: 0.1860 - val_recall: 1.0000
  Epoch 6/10
  32/32 [==============================] - 48s 2s/step - loss: 1.4568 - precision: 0.3536 - recall: 0.8211 - val_loss: 1.9675 - val_precision: 0.1700 - val_recall: 1.0000
  Epoch 7/10
  32/32 [==============================] - 47s 1s/step - loss: 1.4014 - precision: 0.4098 - recall: 0.8084 - val_loss: 2.1148 - val_precision: 0.2111 - val_recall: 1.0000
  Epoch 8/10
  32/32 [==============================] - 48s 1s/step - loss: 1.3445 - precision: 0.4934 - recall: 0.7803 - val_loss: 2.6163 - val_precision: 0.1837 - val_recall: 1.0000
  Epoch 9/10
  32/32 [==============================] - 47s 1s/step - loss: 1.3220 - precision: 0.5309 - recall: 0.7776 - val_loss: 3.3168 - val_precision: 0.1834 - val_recall: 1.0000
  Epoch 10/10
  32/32 [==============================] - 47s 1s/step - loss: 1.3392 - precision: 0.5165 - recall: 0.7429 - val_loss: 3.9804 - val_precision: 0.1917 - val_recall: 1.0000
  20/20 [==============================] - 6s 285ms/step - loss: 3.7660 - precision: 0.2301 - recall: 1.0000
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:467: set_learning_phase (from tensorflow.pyth
  on.keras.backend) is deprecated and will be removed after 2020-10-11.
  Instructions for updating:
  Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:105: Model.state_updates (from t
  ensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
  Instructions for updating:
  This property should not be used in TensorFlow 2.0, as updates are applied automatically.
  2020-05-18 14:34:57.167560: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
  2020/05/18 14:35:15 INFO mlflow.projects: === Run (ID '47b870b8fdcb4445956635c6758caff3') succeeded ===
  (tensorflow_nightly) [ye53nis@node154 drmed-git]$
#+end_example

*** Analyzing and comparing the runs
- comparison run on compute node vs run on login node: same results
- comparison run on compute node now on 2020/05/18
  (47b870b8fdcb4445956635c6758caff3) vs run on 2020/05/02
  (cda4eec66a6947c38ec2ee2006563ae5)
  - =malformed experiment '1'= error in beginning gone
  - mlflow env activation changed
  #+BEGIN_SRC sh
  source activate mlflow-1114b06fb561908fc3f52e89d8342d7e52709c81 1>&2
  #+END_SRC
  became
  #+BEGIN_SRC sh
  source /cluster/miniconda3/bin/../etc/profile.d/conda.sh &&
  conda activate mlflow-a02811ca246852d9cc2ea76b29e8e63c7df57898 1>&2
  #+END_SRC
- new warning: =libcudart=, =libcuda=, etc, because I use
  ~tf.config.list_physical_devices('GPU')~ to check if GPUs are on the machine
- same deprecation warning of for =imp= → I think that's an mlflow thing,
  which they have to change
- message about available intel / amd extensions, if you compile tf manually
  changed:
  #+BEGIN_SRC sh
  # Your CPU supports instructions that this TensorFlow binary was not compiled to
  # use: SSE4.1 SSE4.2 AVX AVX2 FMA

  #+END_SRC
  became
  #+BEGIN_SRC sh
  # This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following
  # CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
  # To enable them in other operations, rebuild TensorFlow with the appropriate
  # compiler flags.
  #+END_SRC
  which, taken together, seems to imply that *AVX2* and *FMA* speed-ups are now
  used automatically?
- still =collections.abc= warning → mlflow has to fix this
- still deprecation warning: =inspect.getargspec()= → has to be fixed by mlflow
- =batch_param= logging failed warning → gone :)
- model serialization → works :) → new =profiler= / =I= stdout messages from
  tensorflow seem to come from the feedback on model logging etc.
- new deprecation warning: =tensorflow.python.eager.profiler.stop= → use
  =tf.profiler.experimental.stop= instead → mlflow has to fix this
- =mlflow.log_metrics= warning → Metrics after epoch are working now :)
- new deprecation warning: =tensorflow.python.keras.backend.set_learning.phase=
  → instead pass a True/False value to `training` argument of the `__call__`
  method of your layer or model
  + see [[https://www.tensorflow.org/api_docs/python/tf/keras/Model][here]]: you can optionally have =training= argument where you can specify
    different behaviour fo rtraining and inference:
    #+BEGIN_SRC python
    import tensorflow as tf

    class MyModel(tf.keras.Model):

      def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
        self.dropout = tf.keras.layers.Dropout(0.5)

      def call(self, inputs, training=False):
        x = self.dense1(inputs)
        if training:
          x = self.dropout(x, training=training)
        return self.dense2(x)

    model = MyModel()
    #+END_SRC
  + Probably I should check if I pass the =training= argument for
    =tf.keras.layers.BatchNormalization=, which behave differnetly during inference
  + looks like I don't use =tf.keras.layers.Dropout= in my current UNET → check if
    that might be a good idea and if a =training= argument should be used as well
- on that note: check if I should pass `data_format='channels_last'` to
  =tf.keras.layers.MaxPool1D()=, it could be that this needs to be specified
- deprecation warning:
  =tensorflow.python.keras.engine.training.Model.state_updates= should not be
  used in TF 2.0, as updates are applied automatically → I think thats a mlflow thing


** Reading out mlflow logs
*** Read out mlflow logs using CLI

#+BEGIN_SRC tmux :session local
  conda activate tensorflow_env
  cd Programme/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns
#+END_SRC

#+BEGIN_SRC tmux :session local
  mlflow experiments list
#+END_SRC

#+RESULTS:
#+begin_example
    Experiment Id  Name         Artifact Location
  ---------------  -----------  --------------------
                0  Default      file:./data/mlruns/0
                1  exp-devtest  file:./data/mlruns/1
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow runs list --experiment-id 1
#+END_SRC

#+RESULTS:
#+begin_example
  Date                      Name    ID
  ------------------------  ------  --------------------------------
  2020-05-18 14:26:01 CEST          47b870b8fdcb4445956635c6758caff3
  2020-05-02 14:46:59 CEST          cda4eec66a6947c38ec2ee2006563ae5
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a model
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a model_summary.txt
  mlflow artifacts list -r 47b870b8fdcb4445956635c6758caff3 -a tensorboard_logs/train/
#+END_SRC

#+RESULTS:
#+begin_example
  [{
    "path": "model",
    "is_dir": true
  }, {
    "path": "model_summary.txt",
    "is_dir": false,
    "file_size": "10895"
  }, {
    "path": "tensorboard_logs",
    "is_dir": true
  }]

  [{
    "path": "model/MLmodel",
    "is_dir": false,
    "file_size": "317"
  }, {
    "path": "model/conda.yaml",
    "is_dir": false,
    "file_size": "125"
  }, {
    "path": "model/data",
    "is_dir": true
  }]

  []

  [{
    "path": "tensorboard_logs/train/events.out.tfevents.1589804775.node154.340188.9307.v2",
    "is_dir": false,
    "file_size": "1316019"
  }, {
    "path": "tensorboard_logs/train/events.out.tfevents.1589804788.node154.profile-empty",
    "is_dir": false,
    "file_size": "40"
  }, {
    "path": "tensorboard_logs/train/plugins",
    "is_dir": true
  }]

#+end_example

#+BEGIN_SRC tmux :session local
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a model
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a model_summary.txt
  mlflow artifacts download -r 47b870b8fdcb4445956635c6758caff3 -a tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model_summary.txt
  /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow runs describe --run-id 47b870b8fdcb4445956635c6758caff3
#+END_SRC

#+RESULTS:
#+begin_example
  {
      "info": {
          "artifact_uri": "file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts",
          "end_time": 1589805315615,
          "experiment_id": "1",
          "lifecycle_stage": "active",
          "run_id": "47b870b8fdcb4445956635c6758caff3",
          "run_uuid": "47b870b8fdcb4445956635c6758caff3",
          "start_time": 1589804761334,
          "status": "FINISHED",
          "user_id": "ye53nis"
      },
      "data": {
          "metrics": {
              "val_loss": 3.980361223220825,
              "precision": 0.5165262222290039,
              "loss": 1.3392401933670044,
              "recall": 0.7429076433181763,
              "val_precision": 0.19168148934841156,
              "val_recall": 0.999984085559845
          },
          "params": {
              "opt_beta_1": "0.9",
              "validation_steps": "8",
              "opt_learning_rate": "1e-05",
              "fluotracify_path": "/beegfs/ye53nis/drmed-git/src/",
              "opt_amsgrad": "False",
              "frac_val": "0.2",
              "batch_size": "5",
              "epochs": "10",
              "opt_decay": "0.0",
              "steps_per_epoch": "32",
              "length_delimiter": "16384",
              "opt_name": "Adam",
              "opt_beta_2": "0.999",
              "csv_path": "/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/",
              "learning_rate": "1e-5",
              "opt_epsilon": "1e-07"
          },
          "tags": {
              "mlflow.source.git.repoURL": "https://github.com/aseltmann/fluotracify",
              "mlflow.source.type": "PROJECT",
              "mlflow.source.name": "file:///beegfs/ye53nis/drmed-git",
              "mlflow.user": "ye53nis",
              "mlflow.source.git.commit": "8ebdd343fc404fe06ef3446fd941255c0103cd46",
              "mlflow.gitRepoURL": "https://github.com/aseltmann/fluotracify",
              "mlflow.project.backend": "local",
              "mlflow.project.env": "conda",
              "mlflow.project.entryPoint": "main",
              "mlflow.log-model.history": "[{\"run_id\":
              \"47b870b8fdcb4445956635c6758caff3\", \"artifact_path\": \"model\",
              \"utc_time_created\": \"2020-05-18 12:34:40.557190\", \"flavors\": {\"keras\":
              {\"keras_module\": \"tensorflow.keras\", \"keras_version\": \"2.2.4-tf\",
              \"data\": \"data\"}, \"python_function\": {\"loader_module\":
              \"mlflow.keras\", \"python_version\": \"3.8.2\", \"data\": \"data\", \"env\":
              \"conda.yaml\"}}}]"
          }
      }
  }

#+end_example


#+BEGIN_SRC tmux :session local
  tensorboard --logdir=data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
  TensorBoard 2.0.0 at http://localhost:6006/ (Press CTRL+C to quit)
#+end_example

#+BEGIN_SRC tmux :session local
  mlflow ui --backend-store-uri file:///home/lex/Programme/drmed-git/data/mlruns
#+END_SRC

#+RESULTS:
#+begin_example
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Starting gunicorn 20.0.4
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Listening at: http://127.0.0.1:5000 (17669)
  [2020-05-19 02:39:46 +0200] [17669] [INFO] Using worker: sync
  [2020-05-19 02:39:46 +0200] [17672] [INFO] Booting worker with pid: 17672
  [2020-05-19 02:44:24 +0200] [17669] [INFO] Handling signal: int
  [2020-05-19 02:44:24 +0200] [17672] [INFO] Worker exiting (pid: 17672)

  Aborted!
  [2020-05-19 02:44:24 +0200] [17669] [INFO] Shutting down: Master

#+end_example

*** Reading out mlflow logs with Python API
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:6a1a0d19-628d-46a2-b9e0-bacf4f087ead
   :END:
   :LOGBOOK:
   CLOCK: [2020-05-19 Di 16:37]--[2020-05-19 Di 17:06] =>  0:29
   CLOCK: [2020-05-19 Di 14:38]--[2020-05-19 Di 16:17] =>  1:39
   :END:

I started a local jupyter session 83f7c448-cc36-44cd-81f9-749b3b4b2d0c.

The following codesnippet comming originally from [[https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks][ob-ipython]] sets up =tabulate=
to display pandas DataFrames as org tables.

#+BEGIN_SRC jupyter-python
  import IPython
  from tabulate import tabulate

  class OrgFormatter(IPython.core.formatters.BaseFormatter):
      def __call__(self, obj):
          try:
              return tabulate(obj, headers='keys',
                              tablefmt='orgtbl', showindex='always')
          except:
              return None

  ip = get_ipython()
  ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  import mlflow
  %cd /home/lex/Programme/drmed-git/
#+END_SRC

#+RESULTS:
: /home/lex/Programme/drmed-git

#+BEGIN_SRC jupyter-python
  uri = 'file:///home/lex/Programme/drmed-git/data/mlruns'
  mlflow.set_tracking_uri(uri)
  runs = mlflow.search_runs(experiment_ids='1')
  print('run_id of first in list: ', runs.iloc[0].run_id)
  print('no of runs in list: ', len(runs))
  print()
  runs
#+END_SRC

#+RESULTS:
:RESULTS:
: run_id of first in list:  47b870b8fdcb4445956635c6758caff3
: no of runs in list:  2
:
|    | run_id                           |   experiment_id | status   | artifact_uri                                                    | start_time                       | end_time                         |   metrics.val_loss |   metrics.recall |   metrics.precision |   metrics.val_recall |   metrics.loss |   metrics.val_precision |   params.opt_beta_2 |   params.opt_beta_1 |   params.frac_val | params.fluotracify_path        |   params.epochs | params.opt_name   |   params.length_delimiter | params.csv_path                                        |   params.learning_rate |   params.opt_decay | params.opt_amsgrad   | params.validation_steps                 | params.steps_per_epoch                   |   params.opt_learning_rate |   params.batch_size |   params.opt_epsilon | tags.mlflow.log-model.history                                                                                                                                                                                                                                                                                                                               | tags.mlflow.project.backend   | tags.mlflow.user   | tags.mlflow.project.env   | tags.mlflow.source.name          | tags.mlflow.gitRepoURL                   | tags.mlflow.source.git.repoURL           | tags.mlflow.project.entryPoint   | tags.mlflow.source.type   | tags.mlflow.source.git.commit            |
|----+----------------------------------+-----------------+----------+-----------------------------------------------------------------+----------------------------------+----------------------------------+--------------------+------------------+---------------------+----------------------+----------------+-------------------------+---------------------+---------------------+-------------------+--------------------------------+-----------------+-------------------+---------------------------+--------------------------------------------------------+------------------------+--------------------+----------------------+-----------------------------------------+------------------------------------------+----------------------------+---------------------+----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+--------------------+---------------------------+----------------------------------+------------------------------------------+------------------------------------------+----------------------------------+---------------------------+------------------------------------------|
|  0 | 47b870b8fdcb4445956635c6758caff3 |               1 | FINISHED | file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts | 2020-05-18 12:26:01.334000+00:00 | 2020-05-18 12:35:15.615000+00:00 |            3.98036 |         0.742908 |            0.516526 |             0.999984 |        1.33924 |                0.191681 |               0.999 |                 0.9 |               0.2 | /beegfs/ye53nis/drmed-git/src/ |              10 | Adam              |                     16384 | /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/ |                  1e-05 |                  0 | False                | 8                                       | 32                                       |                      1e-05 |                   5 |                1e-07 | [{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}] | local                         | ye53nis            | conda                     | file:///beegfs/ye53nis/drmed-git | https://github.com/aseltmann/fluotracify | https://github.com/aseltmann/fluotracify | main                             | PROJECT                   | 8ebdd343fc404fe06ef3446fd941255c0103cd46 |
|  1 | cda4eec66a6947c38ec2ee2006563ae5 |               1 | FINISHED | file:./data/mlruns/1/cda4eec66a6947c38ec2ee2006563ae5/artifacts | 2020-05-02 12:46:59.699000+00:00 | 2020-05-02 13:07:38.258000+00:00 |          nan       |       nan        |          nan        |           nan        |      nan       |              nan        |               0.999 |                 0.9 |               0.2 | /beegfs/ye53nis/drmed-git/src/ |              10 | Adam              |                     16384 | /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/ |                  1e-05 |                  0 | False                | tf.Tensor(8.0, shape=(), dtype=float32) | tf.Tensor(32.0, shape=(), dtype=float32) |                      1e-05 |                   5 |                1e-07 |                                                                                                                                                                                                                                                                                                                                                             | local                         | ye53nis            | conda                     | file:///beegfs/ye53nis/drmed-git | https://github.com/aseltmann/fluotracify | https://github.com/aseltmann/fluotracify | main                             | PROJECT                   | 9e6182fbeae831a151342827efa59581e4310ae6 |
:END:

#+BEGIN_SRC jupyter-python
  client = mlflow.tracking.MlflowClient(tracking_uri=uri)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  # mlflow.entities.Experiment
  exps = client.list_experiments()
  print('client.list_experiments()\n', exps, '\n')

  exp = client.get_experiment('1')
  # Nice printing as protocol buffer:
  print('client.get_experiment("1")\n', exp.to_proto())

  # get mlflow.entities.RunInfo (see below) for all exps
  print('client.list_run_infos(exp_id)\n', client.list_run_infos(exp.experiment_id))

  # you can also rename experiments
  #client.rename_experiment()
#+END_SRC

#+RESULTS:
#+begin_example
  client.list_experiments()
   [<Experiment: artifact_location='file:./data/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='file:./data/mlruns/1', experiment_id='1', lifecycle_stage='active', name='exp-devtest', tags={}>]

  client.get_experiment("1")
   experiment_id: "1"
  name: "exp-devtest"
  artifact_location: "file:./data/mlruns/1"
  lifecycle_stage: "active"

  client.list_run_infos(exp_id)
   [<RunInfo: artifact_uri='file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts', end_time=1589805315615, experiment_id='1', lifecycle_stage='active', run_id='47b870b8fdcb4445956635c6758caff3', run_uuid='47b870b8fdcb4445956635c6758caff3', start_time=1589804761334, status='FINISHED', user_id='ye53nis'>, <RunInfo: artifact_uri='file:./data/mlruns/1/cda4eec66a6947c38ec2ee2006563ae5/artifacts', end_time=1588424858258, experiment_id='1', lifecycle_stage='active', run_id='cda4eec66a6947c38ec2ee2006563ae5', run_uuid='cda4eec66a6947c38ec2ee2006563ae5', start_time=1588423619699, status='FINISHED', user_id='ye53nis'>]
#+end_example

#+BEGIN_SRC jupyter-python
  # mlflow.entities.Metric
  metent = client.get_metric_history(run_id=runs.iloc[0].run_id, key='loss')

  for i in metent:
      print(i)
#+END_SRC

#+RESULTS:
: <Metric: key='loss', step=0, timestamp=1589804835950, value=1.7921358346939087>
: <Metric: key='loss', step=1, timestamp=1589804886131, value=1.6969826221466064>
: <Metric: key='loss', step=2, timestamp=1589804936042, value=1.6142021417617798>
: <Metric: key='loss', step=3, timestamp=1589804985594, value=1.5620886087417603>
: <Metric: key='loss', step=4, timestamp=1589805034880, value=1.4914946556091309>
: <Metric: key='loss', step=5, timestamp=1589805084727, value=1.4567521810531616>
: <Metric: key='loss', step=6, timestamp=1589805133659, value=1.4014478921890259>
: <Metric: key='loss', step=7, timestamp=1589805182769, value=1.3445260524749756>
: <Metric: key='loss', step=8, timestamp=1589805231560, value=1.3219550848007202>
: <Metric: key='loss', step=9, timestamp=1589805280539, value=1.3392401933670044>

#+BEGIN_SRC jupyter-python
# mlflow.entities.Run
# with two display methods to_proto and to_dictionary
# and two properties which return another entity:
# mlflow.entities.RunInfo and mlflow.entities.RunData
print('- - - mlflow.entities.Run - - -')
run = client.get_run(runs.iloc[0].run_id)

# mlflow.entities.RunData has 3 properties, accessing them
# directly is the same as calling to_dictionary()
print('- - - mlflow.entities.RunData - - - ')
print('run.data.metrics\n', run.data.metrics, '\n')
print('run.data.params\n', run.data.params, '\n')
print('run.data.tags\n', run.data.tags, '\n')
print('run.data.to_dictionary()["tags"]\n', run.data.to_dictionary()['tags'], '\n')
# Accessing as a Google protocol buffer
print('run.data.to_proto()\n', run.data.to_proto(), '\n')

# mlflow.entities.RunInfo has 9 properties. Accessing them
# directly gives you their values
print('- - - mlflow.entities.RunInfo - - -')
print('run.info.experiment_id\n', run.info.experiment_id, '\n')
print('run.info.run_id\n', run.info.run_id, '\n')

print('run.info.to_proto\n', run.info.to_proto())
print('run.info.get_searchable_attributes\n', run.info.get_searchable_attributes())
print('run.info.get_orderable_attributes\n', run.info.get_orderable_attributes())

# mlflow.entities.RunStatus is one of the 9 properties of RunInfo
# it can one of five states:
print('- - - mlflow.entities.RunStatus - - -')
allstats = mlflow.entities.RunStatus.all_status()
print({i: mlflow.entities.RunStatus.to_string(i) for i in allstats}, '\n')
print('run.info.status\n', run.info.status, '\n')
print('mlflow.entities.RunStatus.from_string(run.info.status)')
print(mlflow.entities.RunStatus.from_string(run.info.status), '\n')
#+END_SRC

#+RESULTS:
#+begin_example
  - - - mlflow.entities.Run - - -
  - - - mlflow.entities.RunData - - -
  run.data.metrics
   {'val_loss': 3.980361223220825, 'precision': 0.5165262222290039, 'loss': 1.3392401933670044, 'recall': 0.7429076433181763, 'val_precision': 0.19168148934841156, 'val_recall': 0.999984085559845}

  run.data.params
   {'opt_beta_1': '0.9', 'validation_steps': '8', 'opt_learning_rate': '1e-05', 'fluotracify_path': '/beegfs/ye53nis/drmed-git/src/', 'opt_amsgrad': 'False', 'frac_val': '0.2', 'batch_size': '5', 'epochs': '10', 'opt_decay': '0.0', 'steps_per_epoch': '32', 'length_delimiter': '16384', 'opt_name': 'Adam', 'opt_beta_2': '0.999', 'csv_path': '/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/', 'learning_rate': '1e-5', 'opt_epsilon': '1e-07'}

  run.data.tags
   {'mlflow.source.git.repoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.source.type': 'PROJECT', 'mlflow.source.name': 'file:///beegfs/ye53nis/drmed-git', 'mlflow.user': 'ye53nis', 'mlflow.source.git.commit': '8ebdd343fc404fe06ef3446fd941255c0103cd46', 'mlflow.gitRepoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.project.backend': 'local', 'mlflow.project.env': 'conda', 'mlflow.project.entryPoint': 'main', 'mlflow.log-model.history': '[{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}]'}

  run.data.to_dictionary()["tags"]
   {'mlflow.source.git.repoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.source.type': 'PROJECT', 'mlflow.source.name': 'file:///beegfs/ye53nis/drmed-git', 'mlflow.user': 'ye53nis', 'mlflow.source.git.commit': '8ebdd343fc404fe06ef3446fd941255c0103cd46', 'mlflow.gitRepoURL': 'https://github.com/aseltmann/fluotracify', 'mlflow.project.backend': 'local', 'mlflow.project.env': 'conda', 'mlflow.project.entryPoint': 'main', 'mlflow.log-model.history': '[{"run_id": "47b870b8fdcb4445956635c6758caff3", "artifact_path": "model", "utc_time_created": "2020-05-18 12:34:40.557190", "flavors": {"keras": {"keras_module": "tensorflow.keras", "keras_version": "2.2.4-tf", "data": "data"}, "python_function": {"loader_module": "mlflow.keras", "python_version": "3.8.2", "data": "data", "env": "conda.yaml"}}}]'}

  run.data.to_proto()
   metrics {
    key: "val_loss"
    value: 3.980361223220825
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "precision"
    value: 0.5165262222290039
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "loss"
    value: 1.3392401933670044
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "recall"
    value: 0.7429076433181763
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "val_precision"
    value: 0.19168148934841156
    timestamp: 1589805280539
    step: 9
  }
  metrics {
    key: "val_recall"
    value: 0.999984085559845
    timestamp: 1589805280539
    step: 9
  }
  params {
    key: "opt_beta_1"
    value: "0.9"
  }
  params {
    key: "validation_steps"
    value: "8"
  }
  params {
    key: "opt_learning_rate"
    value: "1e-05"
  }
  params {
    key: "fluotracify_path"
    value: "/beegfs/ye53nis/drmed-git/src/"
  }
  params {
    key: "opt_amsgrad"
    value: "False"
  }
  params {
    key: "frac_val"
    value: "0.2"
  }
  params {
    key: "batch_size"
    value: "5"
  }
  params {
    key: "epochs"
    value: "10"
  }
  params {
    key: "opt_decay"
    value: "0.0"
  }
  params {
    key: "steps_per_epoch"
    value: "32"
  }
  params {
    key: "length_delimiter"
    value: "16384"
  }
  params {
    key: "opt_name"
    value: "Adam"
  }
  params {
    key: "opt_beta_2"
    value: "0.999"
  }
  params {
    key: "csv_path"
    value: "/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/"
  }
  params {
    key: "learning_rate"
    value: "1e-5"
  }
  params {
    key: "opt_epsilon"
    value: "1e-07"
  }
  tags {
    key: "mlflow.source.git.repoURL"
    value: "https://github.com/aseltmann/fluotracify"
  }
  tags {
    key: "mlflow.source.type"
    value: "PROJECT"
  }
  tags {
    key: "mlflow.source.name"
    value: "file:///beegfs/ye53nis/drmed-git"
  }
  tags {
    key: "mlflow.user"
    value: "ye53nis"
  }
  tags {
    key: "mlflow.source.git.commit"
    value: "8ebdd343fc404fe06ef3446fd941255c0103cd46"
  }
  tags {
    key: "mlflow.gitRepoURL"
    value: "https://github.com/aseltmann/fluotracify"
  }
  tags {
    key: "mlflow.project.backend"
    value: "local"
  }
  tags {
    key: "mlflow.project.env"
    value: "conda"
  }
  tags {
    key: "mlflow.project.entryPoint"
    value: "main"
  }
  tags {
    key: "mlflow.log-model.history"
    value: "[{\"run_id\": \"47b870b8fdcb4445956635c6758caff3\", \"artifact_path\": \"model\", \"utc_time_created\": \"2020-05-18 12:34:40.557190\", \"flavors\": {\"keras\": {\"keras_module\": \"tensorflow.keras\", \"keras_version\": \"2.2.4-tf\", \"data\": \"data\"}, \"python_function\": {\"loader_module\": \"mlflow.keras\", \"python_version\": \"3.8.2\", \"data\": \"data\", \"env\": \"conda.yaml\"}}}]"
  }


  - - - mlflow.entities.RunInfo - - -
  run.info.experiment_id
   1

  run.info.run_id
   47b870b8fdcb4445956635c6758caff3

  run.info.to_proto
   run_uuid: "47b870b8fdcb4445956635c6758caff3"
  experiment_id: "1"
  user_id: "ye53nis"
  status: FINISHED
  start_time: 1589804761334
  end_time: 1589805315615
  artifact_uri: "file:./data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts"
  lifecycle_stage: "active"
  run_id: "47b870b8fdcb4445956635c6758caff3"

  run.info.get_searchable_attributes
   ['artifact_uri', 'status']
  run.info.get_orderable_attributes
   ['artifact_uri', 'end_time', 'start_time', 'status']
  - - - mlflow.entities.RunStatus - - -
  {1: 'RUNNING', 2: 'SCHEDULED', 3: 'FINISHED', 4: 'FAILED', 5: 'KILLED'}

  run.info.status
   FINISHED

  mlflow.entities.RunStatus.from_string(run.info.status)
  3
#+end_example

#+BEGIN_SRC jupyter-python :results scalar
run_idx = 0
# mlflow.entities.FileInfo
# 3 properties, to_proto() available
finfo = client.list_artifacts(run_id=runs.iloc[run_idx].run_id)
finfo
#+END_SRC

#+RESULTS:
: [<FileInfo: file_size=None, is_dir=True, path='model'>,
:  <FileInfo: file_size=10895, is_dir=False, path='model_summary.txt'>,
:  <FileInfo: file_size=None, is_dir=True, path='tensorboard_logs'>]

# FIXME: Why does client.list_artifacts() not work here? It works in Jupyter notebooks.

#+BEGIN_SRC jupyter-python
model_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='model')
tensorboard_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='tensorboard_logs')
summary_path = client.download_artifacts(
    run_id=runs.iloc[run_idx].run_id,
    path='model_summary.txt')
print(model_path)
print(tensorboard_path)
print(summary_path)
#+END_SRC

#+RESULTS:
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model_summary.txt

#+BEGIN_SRC jupyter-python
  !ls $model_path
  print()
  !ls $model_path/data
#+END_SRC

#+RESULTS:
: conda.yaml  data  MLmodel
:
: keras_module.txt  model.h5

#+BEGIN_SRC jupyter-python
  %cat $model_path/MLmodel
  print()
  %cat $model_path/conda.yaml
  print()
  %cat $model_path/data/keras_module.txt
#+END_SRC

#+RESULTS:
#+begin_example
  artifact_path: model
  flavors:
    keras:
      data: data
      keras_module: tensorflow.keras
      keras_version: 2.2.4-tf
    python_function:
      data: data
      env: conda.yaml
      loader_module: mlflow.keras
      python_version: 3.8.2
  run_id: 47b870b8fdcb4445956635c6758caff3
  utc_time_created: '2020-05-18 12:34:40.557190'

  channels:
  - defaults
  dependencies:
  - python=3.8.2
  - pip
  - pip:
    - mlflow
    - tensorflow==2.3.0-dev20200518
  name: mlflow-env

  tensorflow.keras
#+end_example

#+BEGIN_SRC jupyter-python
  %cat $summary_path
#+END_SRC

#+RESULTS:
#+begin_example
  Model: "functional_1"
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            [(None, 16384, 1)]   0
  __________________________________________________________________________________________________
  encode0 (Sequential)            (None, 16384, 64)    13120       input_1[0][0]
  __________________________________________________________________________________________________
  mp_encode0 (MaxPooling1D)       (None, 8192, 64)     0           encode0[0][0]
  __________________________________________________________________________________________________
  encode1 (Sequential)            (None, 8192, 128)    75008       mp_encode0[0][0]
  __________________________________________________________________________________________________
  mp_encode1 (MaxPooling1D)       (None, 4096, 128)    0           encode1[0][0]
  __________________________________________________________________________________________________
  encode2 (Sequential)            (None, 4096, 256)    297472      mp_encode1[0][0]
  __________________________________________________________________________________________________
  mp_encode2 (MaxPooling1D)       (None, 2048, 256)    0           encode2[0][0]
  __________________________________________________________________________________________________
  encode3 (Sequential)            (None, 2048, 512)    1184768     mp_encode2[0][0]
  __________________________________________________________________________________________________
  mp_encode3 (MaxPooling1D)       (None, 1024, 512)    0           encode3[0][0]
  __________________________________________________________________________________________________
  encode4 (Sequential)            (None, 1024, 512)    1577984     mp_encode3[0][0]
  __________________________________________________________________________________________________
  mp_encode4 (MaxPooling1D)       (None, 512, 512)     0           encode4[0][0]
  __________________________________________________________________________________________________
  encode5 (Sequential)            (None, 512, 512)     1577984     mp_encode4[0][0]
  __________________________________________________________________________________________________
  mp_encode5 (MaxPooling1D)       (None, 256, 512)     0           encode5[0][0]
  __________________________________________________________________________________________________
  encode6 (Sequential)            (None, 256, 512)     1577984     mp_encode5[0][0]
  __________________________________________________________________________________________________
  mp_encode6 (MaxPooling1D)       (None, 128, 512)     0           encode6[0][0]
  __________________________________________________________________________________________________
  encode7 (Sequential)            (None, 128, 512)     1577984     mp_encode6[0][0]
  __________________________________________________________________________________________________
  mp_encode7 (MaxPooling1D)       (None, 64, 512)      0           encode7[0][0]
  __________________________________________________________________________________________________
  encode8 (Sequential)            (None, 64, 512)      1577984     mp_encode7[0][0]
  __________________________________________________________________________________________________
  mp_encode8 (MaxPooling1D)       (None, 32, 512)      0           encode8[0][0]
  __________________________________________________________________________________________________
  two_conv_center (Sequential)    (None, 32, 1024)     4728832     mp_encode8[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder8 (Sequen (None, 64, 512)      1051136     two_conv_center[0][0]
  __________________________________________________________________________________________________
  decoder8 (Concatenate)          (None, 64, 1024)     0           encode8[0][0]
                                                                   conv_transpose_decoder8[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder8 (Sequential)  (None, 64, 512)      2364416     decoder8[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder7 (Sequen (None, 128, 512)     526848      two_conv_decoder8[0][0]
  __________________________________________________________________________________________________
  decoder7 (Concatenate)          (None, 128, 1024)    0           encode7[0][0]
                                                                   conv_transpose_decoder7[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder7 (Sequential)  (None, 128, 512)     2364416     decoder7[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder6 (Sequen (None, 256, 512)     526848      two_conv_decoder7[0][0]
  __________________________________________________________________________________________________
  decoder6 (Concatenate)          (None, 256, 1024)    0           encode6[0][0]
                                                                   conv_transpose_decoder6[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder6 (Sequential)  (None, 256, 512)     2364416     decoder6[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder5 (Sequen (None, 512, 512)     526848      two_conv_decoder6[0][0]
  __________________________________________________________________________________________________
  decoder5 (Concatenate)          (None, 512, 1024)    0           encode5[0][0]
                                                                   conv_transpose_decoder5[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder5 (Sequential)  (None, 512, 512)     2364416     decoder5[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder4 (Sequen (None, 1024, 512)    526848      two_conv_decoder5[0][0]
  __________________________________________________________________________________________________
  decoder4 (Concatenate)          (None, 1024, 1024)   0           encode4[0][0]
                                                                   conv_transpose_decoder4[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder4 (Sequential)  (None, 1024, 512)    2364416     decoder4[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder3 (Sequen (None, 2048, 512)    526848      two_conv_decoder4[0][0]
  __________________________________________________________________________________________________
  decoder3 (Concatenate)          (None, 2048, 1024)   0           encode3[0][0]
                                                                   conv_transpose_decoder3[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder3 (Sequential)  (None, 2048, 512)    2364416     decoder3[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder2 (Sequen (None, 4096, 256)    263424      two_conv_decoder3[0][0]
  __________________________________________________________________________________________________
  decoder2 (Concatenate)          (None, 4096, 512)    0           encode2[0][0]
                                                                   conv_transpose_decoder2[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder2 (Sequential)  (None, 4096, 256)    592384      decoder2[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder1 (Sequen (None, 8192, 128)    66176       two_conv_decoder2[0][0]
  __________________________________________________________________________________________________
  decoder1 (Concatenate)          (None, 8192, 256)    0           encode1[0][0]
                                                                   conv_transpose_decoder1[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder1 (Sequential)  (None, 8192, 128)    148736      decoder1[0][0]
  __________________________________________________________________________________________________
  conv_transpose_decoder0 (Sequen (None, 16384, 64)    16704       two_conv_decoder1[0][0]
  __________________________________________________________________________________________________
  decoder0 (Concatenate)          (None, 16384, 128)   0           encode0[0][0]
                                                                   conv_transpose_decoder0[0][0]
  __________________________________________________________________________________________________
  two_conv_decoder0 (Sequential)  (None, 16384, 64)    37504       decoder0[0][0]
  __________________________________________________________________________________________________
  conv1d_38 (Conv1D)              (None, 16384, 1)     65          two_conv_decoder0[0][0]
  ==================================================================================================
  Total params: 33,185,985
  Trainable params: 33,146,689
  Non-trainable params: 39,296
  __________________________________________________________________________________________________
#+end_example

*** Reading out tensorboard logs from mlflow logs
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8888:83f7c448-cc36-44cd-81f9-749b3b4b2d0c
    :END:
    #+BEGIN_SRC jupyter-python
  !ls $tensorboard_path
#+END_SRC

#+RESULTS:
: train  validation

#+BEGIN_SRC jupyter-python
 # https://stackoverflow.com/questions/41074688/how-do-you-read-tensorboard-files-programmatically
from tensorboard.backend.event_processing import event_accumulator
path = str(tensorboard_path) + '/train'
print(path)
ea = event_accumulator.EventAccumulator(path=path,
    size_guidance={ # see below regarding this argument
        event_accumulator.COMPRESSED_HISTOGRAMS: 500,
        event_accumulator.IMAGES: 4,
        event_accumulator.AUDIO: 4,
        event_accumulator.SCALARS: 0,
        event_accumulator.HISTOGRAMS: 1,
    })

ea.Reload() # loads events from file
#+END_SRC

#+RESULTS:
:RESULTS:
: /home/lex/Programme/drmed-git/data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/tensorboard_logs/train
: /home/lex/Programme/miniconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorboard/backend/event_processing/event_file_loader.py:61: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()
:   get_next_args = inspect.getargspec(self._reader.GetNext).args  # pylint: disable=deprecated-method
: <tensorboard.backend.event_processing.event_accumulator.EventAccumulator at 0x7faf9815dc90>
:END:

#+BEGIN_SRC jupyter-python :results scalar
  ea.Tags()
#+END_SRC

#+RESULTS:
: {'images': [],
:  'audio': [],
:  'histograms': [],
:  'scalars': ['epoch_loss', 'epoch_precision', 'epoch_recall'],
:  'distributions': [],
:  'tensors': ['keras', 'batch_2'],
:  'graph': True,
:  'meta_graph': False,
:  'run_metadata': []}

#+BEGIN_SRC jupyter-python
  ea.Scalars('epoch_loss')
#+END_SRC

#+RESULTS:
|    |   wall_time |   step |   value |
|----+-------------+--------+---------|
|  0 | 1.5898e+09  |      0 | 1.79214 |
|  1 | 1.5898e+09  |      1 | 1.69698 |
|  2 | 1.5898e+09  |      2 | 1.6142  |
|  3 | 1.5898e+09  |      3 | 1.56209 |
|  4 | 1.58981e+09 |      4 | 1.49149 |
|  5 | 1.58981e+09 |      5 | 1.45675 |
|  6 | 1.58981e+09 |      6 | 1.40145 |
|  7 | 1.58981e+09 |      7 | 1.34453 |
|  8 | 1.58981e+09 |      8 | 1.32196 |
|  9 | 1.58981e+09 |      9 | 1.33924 |

*** Load model from mlflow logs and predict separately loaded data
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:6a1a0d19-628d-46a2-b9e0-bacf4f087ead
   :END:

First, check if the model file has to be downloaded via git lfs

#+BEGIN_SRC tmux :session local
  cd /home/lex/Programme/drmed-git/
  git lfs ls-files
  git lfs checkout
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [lex@Topialex drmed-git]$ git lfs ls-files
  6526c5abca - data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5

  (base) [lex@Topialex drmed-git]$ git lfs checkout
  Skipped checkout for
  "data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5",
  content not local. Use fetch to download.
  Checking out LFS objects: 100% (1/1), 399 MB | 0 B/s, done.
#+end_example

#+BEGIN_SRC tmux :session local
  git lfs pull
#+END_SRC

#+RESULTS:
#+begin_example
  fetch: Fetching reference refs/heads/develop
  Username for 'https://github.com': aseltmann B/s
  Password for 'https://aseltmann@github.com':
  (base) [lex@Topialex drmed-git]$ 1), 399 MB | 1.9 MB/s
#+end_example

#+BEGIN_SRC jupyter-python
  import mlflow.keras
  import mlflow.tensorflow
  import sys
  import numpy as np
  import tensorflow as tf

  fluotracify_path = '/home/lex/Programme/drmed-git/src/'
  sys.path.append(fluotracify_path)

  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
bm.binary_ce_dice_loss()
#+END_SRC

#+RESULTS:
: <function fluotracify.training.build_model.binary_ce_dice_loss.<locals>.binary_ce_dice(y_true, y_pred)>

#+BEGIN_SRC jupyter-python
  # mlflow.keras module
  model_keras = mlflow.keras.load_model(model_uri=model_path,
                                        custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()})
  model_keras
#+END_SRC

#+RESULTS:
: <tensorflow.python.keras.engine.functional.Functional at 0x7fc97830c790>

#+BEGIN_SRC jupyter-python
  data, _, nsamples, experiment_params = isfc.import_from_csv(
      path='/home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/',
      header=12,
      frac_train=1,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')
#+END_SRC

#+RESULTS:
: train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set003.csv
: train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set002.csv
: train 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set001.csv



#+BEGIN_SRC jupyter-python :results scalar
  prediction = model_keras.predict(np.array(data.iloc[:2048, 0]).reshape(1, -1, 1))
#+END_SRC

#+RESULTS:

I noticed one problem: directly outputting the =prediction= array for large
predictions (e.g. 16384 time steps), will freeze emacs. Especially with my setup
with conversion to org tables. It is possible to output it in the REPL, or print
it using =print(prediction)=, because there the output gets truncated, e.g. like
this:
#+begin_example
array([[[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]]], dtype=float32)
#+end_example
While here it tries to print everything (I guess). Maybe I should test the
=:pandoc t= argument instead of the =OrgFormatter= class

Basically, no matter if I choosnpe the =:results= header argument, it always gets
printed with =:display org= like this.

#+BEGIN_SRC jupyter-python :display org
  prediction
#+END_SRC

#+RESULTS:
|    |   0 |   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |   10 |   11 |   2043 |   2044 |   2045 |   2046 |   2047 |
|----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+--------+--------+--------+--------+--------|
|  0 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |   1 |    1 |    1 |      1 |      1 |      1 |      1 |      1 |

To make the output work the desired way (like in the REPL or =print()= and
without freezing emacs for large tables), use =:display plain=

#+BEGIN_SRC jupyter-python :display plain
  prediction
#+END_SRC

#+RESULTS:
: array([[[1.],
:         [1.],
:         [1.],
:         ...,
:         [1.],
:         [1.],
:         [1.]]], dtype=float32)


** checking some things off the TODO list
*** DONE Update mlflow and tensorflow in tensorflow_env
     CLOSED: [2020-05-20 Mi 13:46]

*** DONE Export pandas DataFrames as org tables instead of html
     CLOSED: [2020-05-20 Mi 16:08]
- see https://github.com/dzop/emacs-jupyter/issues/88
- see
  https://github.com/gregsexton/ob-ipython/blob/7147455230841744fb5b95dcbe03320313a77124/README.org#tips-and-tricks

#+NAME: jp-org-formatter
#+BEGIN_SRC jupyter-python
  import IPython
  from tabulate import tabulate

  class OrgFormatter(IPython.core.formatters.BaseFormatter):
      def __call__(self, obj):
          try:
              return tabulate(obj, headers='keys',
                              tablefmt='orgtbl', showindex='always')
          except:
              return None

  ip = get_ipython()
  ip.display_formatter.formatters['text/org'] = OrgFormatter()
#+END_SRC

This script works - but it is easier to just use the =:pandoc t= header argument

*** DONE Inline-display of plots → use =C-c C-x C-v= for inline display of links to images
     CLOSED: [2020-05-20 Mi 16:09]
*** DONE transform ML training ipynb to py files as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]]
     CLOSED: [2020-05-20 Mi 16:10]
*** DONE [#A] Further setup of git branching model
     CLOSED: [2020-05-20 Mi 16:11]
** Changing Appearance of this org-mode document and the html export LabBook.html
   :LOGBOOK:
   CLOCK: [2020-05-12 Di 19:04]--[2020-05-12 Di 22:16] =>  3:12
   CLOCK: [2020-05-12 Di 16:59]--[2020-05-12 Di 16:59] =>  0:00
   CLOCK: [2020-05-12 Di 13:38]--[2020-05-12 Di 15:30] =>  1:52
   CLOCK: [2020-05-12 Di 12:30]--[2020-05-12 Di 13:07] =>  0:37
   :END:
I try to make it easy to distinguish different org source code blocks by visual
cues. Let's take the [[https://github.com/ozh/github-colors/blob/master/colors.json][colours Github uses]]:

- emacs-lisp: #c065db
- shell: #89e051
- python: #3572A5
- jupyter: #DA5B0B

Then I went to https://htmlcolorcodes.com/color-picker/

for tmux I chose a different *tone* coming from shell's #89e051
- #85bc62
for example blocks I chose a light yellow (html export only). Ideally this would
be set for all =#+results= - I opened a github issue with =ox-twbs= [[https://github.com/marsmining/ox-twbs/issues/59 ][here]].

- #FBFBBF

then to get lighter versions of these colours in html export i chose *tints*
coming from the respective original colour:
- emacs-lisp: #efd8f6 #F7ECFB
- shell: #d3f3be #F0FBE9
- tmux: #94c476 #E1EED8
- python: #b3cadd #E6EDF4
- jupyter-python: #f1c1a4 #FAEAE1

for colouring of code blocks inside my dark-themed Emacs setup, I chose
different *shades* coming from the respective original colour
- emacs-lisp: #482652
- shell: #223814
- tmux: #324725
- python: #142b3e
- jupyter-python: #522204 #371703 #6d2d05


#+BEGIN_SRC emacs-lisp
  (setq org-src-block-faces '(("emacs-lisp" (:background "#482652"))
                              ("sh" (:background "#223814"))
                              ("tmux" (:background "#324725"))
                              ("python" (:background "#142b3e"))
                              ("jupyter-python" (:background "#371703"))
                              ))
#+END_SRC

#+RESULTS:
| emacs-lisp     | (:background #482652) |
| sh             | (:background #223814) |
| tmux           | (:background #324725) |
| python         | (:background #142b3e) |
| jupyter-python | (:background #371703) |


Also, I found this interesting javascript export option - thats how the org mode
documentation is made
https://orgmode.org/manual/JavaScript-support.html#JavaScript-support

** Turning the attention back to =TensorBoard= logging
   :LOGBOOK:
   CLOCK: [2020-05-25 Mo 16:10]--[2020-05-25 Mo 18:07] =>  1:57
   CLOCK: [2020-05-25 Mo 14:03]--[2020-05-25 Mo 14:33] =>  0:30
   CLOCK: [2020-05-25 Mo 13:10]--[2020-05-25 Mo 13:46] =>  0:36
   CLOCK: [2020-05-23 Sa 18:52]--[2020-05-23 Sa 19:23] =>  0:31
   CLOCK: [2020-05-23 Sa 18:31]--[2020-05-23 Sa 18:52] =>  0:21
   CLOCK: [2020-05-23 Sa 18:09]--[2020-05-23 Sa 18:20] =>  0:11
   CLOCK: [2020-05-23 Sa 16:30]--[2020-05-23 Sa 16:50] =>  0:20
   CLOCK: [2020-05-22 Fr 21:57]--[2020-05-22 Fr 23:38] =>  1:41
   :END:
#+BEGIN_SRC python
  tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,
    update_freq='epoch', profile_batch=2, embeddings_freq=0,
    embeddings_metadata=None, **kwargs
)
#+END_SRC
*** about: profiler
this is automatically logged by mlflow - but i'm not sure I really need it - not
to speak of the fact, that I could not read it out yet, since tensorboard always
froze. → I should check it with a tunneled tensorboard running on a compute node.

*** DONE idea: histograms of activation and weights to debug the amount of layers etc
    CLOSED: [2020-05-23 Sa 00:12]

    - State "DONE"       from "TODO"    [2020-05-23 Sa 00:12] \\
      It just worked out of the box :)

idea: histogram_freq is frequency in epochs at which to compute activation and
weight histograms for the layers of the model. I would say get max. 10
histograms in total → for 100 epochs, freq=10?

*** DONE idea: write_images=True - difference to histograms??
    CLOSED: [2020-05-23 Sa 00:12]

It just worked out of the box - I'm still not sure if these weight plots tell me
anything more than the histograms - but I'll try to evaluate them further after
real training.

I might look into [[https://stackoverflow.com/questions/47232779/how-to-extract-and-save-images-from-tensorboard-event-summary][this]] SO issue to read out the images directly in Python.
Alternatively, I could just save them manually from TensorBoard.

*** DONE idea: image logging
    CLOSED: [2020-05-24 So 00:16]

I want a plot of a test curve with the prediction to see how more refined the
prediction gets during training.

With mlflow doing an automatic logging, it should be enough to only specify my
desired extensions, e.g. like this:

#+BEGIN_SRC python
  file_writer = tf.summary.create_file_writer(logdir + '/image')
  def log_image(epoch, logs):
      # Do a function which returns a matplotlib plot
      figure = ...
      # convert matplotlib figure to image
      image = plot_to_image(figure)
      # Log the image as an image summary.
      with file_writer.as_default():
          tf.summary.image("My image", image, step=epoch)
  image_callback = tf.keras.callbacks.LambdaCallback(
      on_epoch_end=log_image)
#+END_SRC

With the following helper function which turns a matplotlib plot into an image:

#+BEGIN_SRC python
  def plot_to_image(figure):
      """Converts the matplotlib plot specified by 'figure' to a PNG image and
      returns it. The supplied figure is closed and inaccessible after this call."""
      # Save the plot to a PNG in memory.
      buf = io.BytesIO()
      plt.savefig(buf, format='png')
      # Closing the figure prevents it from being displayed directly inside
      # the notebook.
      plt.close(figure)
      buf.seek(0)
      # Convert PNG buffer to TF image
      image = tf.image.decode_png(buf.getvalue(), channels=4)
      # Add the batch dimension
      image = tf.expand_dims(image, 0)
      return image
#+END_SRC

I wrote to functions - one for using the =test_data= pandas DataFrame, and one
for using the =dataset_test= TF dataset for extracting the desired number of
traces to predict and plot:

#+BEGIN_SRC python
def plot_trace_and_pred_from_df(df, ntraces):
    fig, ax = plt.subplots(ntraces, figsize=(16, ntraces*2))

    for i in range(ntraces):
        pred_trace = df.iloc[:16384, i].to_numpy().reshape(1, -1, 1)
        prediction = model.predict(pred_trace)
        prediction = prediction.flatten()
        pred_trace = pred_trace.flatten()
        ax[i].plot(pred_trace / np.max(pred_trace))
        ax[i].plot(prediction)
    return fig

def plot_trace_and_pred_from_tfds(dataset, ntraces):
    fig, ax = plt.subplots(ntraces, figsize=(16, ntraces*2))
    pred_iterator = dataset.unbatch().take(ntraces).as_numpy_iterator()

    for i in range(ntraces):
        pred_data = pred_iterator.next()
        pred_trace = pred_data[0].reshape(1, -1, 1)
        prediction = model.predict(pred_trace)
        prediction = prediction.flatten()
        pred_trace = pred_trace.flatten()
        pred_label = pred_data[1].flatten()
        ax[i].plot(pred_trace / np.max(pred_trace))
        ax[i].plot(prediction)
        ax[i].plot(pred_label * 0.9)
    plt.tight_layout()
    return fig
#+END_SRC

The callback looks for now like this:

#+BEGIN_SRC python
file_writer = tf.summary.create_file_writer(log_dir + '/image')

def log_plots(epoch, logs):
    figure = plot_trace_and_pred_from_tfds(dataset=dataset_test, ntraces=5)
    # Convert matplotlib figure to image
    image = plot_to_image(figure)
    # Log the image as an image summary
    with file_writer.as_default():
        tf.summary.image('Prediction plots', image, step=epoch)

image_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_plots)
#+END_SRC

*** DONE idea: learning rate scheduler
    CLOSED: [2020-05-28 Do 00:38]

I think that should speed up training. Something like this should work:

#+BEGIN_SRC python
file_writer = tf.summary.create_file_writer(logdir + "/metrics")
file_writer.set_as_default()

def lr_schedule(epoch):
  """
  Returns a custom learning rate that decreases as epochs progress.
  """
  learning_rate = 0.2
  if epoch > 10:
    learning_rate = 0.02
  if epoch > 20:
    learning_rate = 0.01
  if epoch > 50:
    learning_rate = 0.005

  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)
  return learning_rate

lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)
#+END_SRC

Alternative: the =tf.summary.scalar= is ONLY for logging, I think. It might be
better to substitute it with the =mlflow= alternative - since I use mlflow to
read out the metrics.

I encountered some errors.

*** DONE Check: what if =tf.summary.create_file_writer= is used for multiple callbacks
    CLOSED: [2020-05-28 Do 00:39]
e.g. I want lr_schedule AND image logging? → Works by using two differee file_writers

*** CANCELED idea: use TensorBoards Fairness examination, e.g. see [[https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/documentation/examples/Fairness_Indicators_Lineage_Case_Study.ipynb][here]]+
    CLOSED: [2020-05-25 Mo 23:48]

    - State "CANCELED"   from "TODO"       [2020-05-25 Mo 23:48] \\
      Dataset splicing to check for unfairness is interesting, but 1) not as relevant
      for my data and 2) didn't seem straightforward to implement. Would have to dive
      into tfma (tf model analysis) and install some additional things...
So, I checked out the documentation on FairnessIndicators by TensorFlow, and
there are multiple layers to it:
- What are Fairness Indicators:
  - idea comes from when AI's impact people: e.g. you have a toxicity model
    deployed on a website to filter offensive comments - what are the risks,
    effects, opportunities?  → it's about ethical considerations
  - you examine this by looking at different metrics and user groups and
    evaluate over different /slices/ of your data → you want to check, if
    overall strong metrics can obscure poor performance for certain subgroups
- Which groups to slice by:
  - as many as there are → if not feasible, conside especially sensitive
    characteristics such as race, ethnicity, gender, nationality, income, sexual
    orientation, disability status
  - subgroups are not awlays the best way to classify individuals → consider
    multiracial people. Particular interactions, such as race and gender, may
    show unintended bias
  - in my case of binary segmentation: check for "with artifact" and "without
    artifact", I guess
- Which metrics should I choose?
  - consider who will be experiencing your model, how it will be experienced,
    and the effects of that experience → does the model give people more dignity
    or autonomy → not very relevant for my traces :)
  - Good practice: slice all your existing performance metrics. Evaluate your
    metrics across multiple thresholds
- Critical fairness metrics for classification
  - think about the effects of /errors/ (differences between ground truth and
    prediction) → if some errors may pose more opportunity or harm → evaluate
    the rates of these errors across groups of users.
- Which metrics are available in Fairness Indicators:
  - *Positivity Rate / Negativity rate* = percentage of data points that are
    classified as positive or negative, independent of ground truth
    - when to use: where having equal final percentages of groups is important
    - for trace classification: NO
  - *True Positive Rate = Recall / False Negative Rate* = percentage of data
    points labeled positive, which are /correctly labeled positive/. Percentage
    of positive  data points that are /incorrectly labeled negative/
    - when to use: when it is important that the same % of qualified candidates
      are rated positive in each group, so when you are classifying positive
      outcomes, such as loan applications, school admissions, whether content is
      kid-friendly
  - *True Negative Rate = Selectivity / False Positive Rate* = percentage of
    negative data points /correctly labeled negative/. percentage of negative
    data points /incorrectly labeled positive/.
    - when to use: when error rates (misclassifying something as positive) are
      more concerning than classifying the positives, so where /positives lead
      to negative actions/, such as face detection
*** Note: extract images from tf logs programmatically: [[https://stackoverflow.com/questions/47232779/how-to-extract-and-save-images-from-tensorboard-event-summary][here]]
intro: [[https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/documentation/guidance.md][here]]
** run mlflow model after TensorBoard logs
   :LOGBOOK:
   CLOCK: [2020-05-27 Mi 16:29]--[2020-05-27 Mi 16:29] =>  0:00
   CLOCK: [2020-05-27 Mi 13:00]--[2020-05-27 Mi 16:06] =>  3:06
   CLOCK: [2020-05-26 Di 19:10]--[2020-05-26 Di 19:35] =>  0:25
   :END:
*** make mlflow ready
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  pwd
  cd /beegfs/ye53nis/drmed-git/
  pwd
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@node146 drmed-git]$ pwd
  /beegfs/ye53nis/drmed-git
  (base) [ye53nis@node146 drmed-git]$
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda activate tensorflow_nightly
  cd /beegfs/ye53nis/drmed-git
  export MLFLOW_EXPERIMENT_NAME=exp-devtest
  export MLFLOW_TRACKING_URI=file:./data/mlruns

#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$
#+end_example

*** First run:  on login node because pip install

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  # ...
  nothing added to commit but untracked files present (use "git add" to track)

  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git log -1
  commit 4d9eb24de2b838d079f516e1b87a776ea087be72
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Wed May 27 15:05:16 2020 +0200

      Make None input for LEARNING_RATE possible
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_su
  bsample/
  2020/05/27 15:08:20 INFO mlflow.projects: === Creating conda environment mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b ===
  Collecting package metadata (repodata.json): done
  Solving environment: done
  Preparing transaction: done
  Verifying transaction: done
  Executing transaction: done
  Ran pip subprocess with arguments:
  ['/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt']
  Pip subprocess output:
  Collecting tf-nightly
    Using cached tf_nightly-2.3.0.dev20200527-cp38-cp38-manylinux2010_x86_64.whl (523.9 MB)
  Collecting gast==0.3.3
    Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)
  Collecting google-pasta>=0.1.8
    Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
  Processing /home/ye53nis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl
  Collecting opt-einsum>=2.3.2
    Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)
  Processing /home/ye53nis/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73/wrapt-1.12.1-cp38-cp38-linux_x86_64.whl
  Collecting grpcio>=1.8.6
    Using cached grpcio-1.29.0-cp38-cp38-manylinux2010_x86_64.whl (3.0 MB)
  Collecting tb-nightly<2.4.0a0,>=2.3.0a0
    Using cached tb_nightly-2.3.0a20200527-py3-none-any.whl (2.9 MB)
  Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53
  nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.18.1)
  Processing /home/ye53nis/.cache/pip/wheels/1d/10/8e/2f79b924179ff1e6510933d63eb851bea01054fff262343b7a/absl_py-0.9.0-py3-none-any.whl
  Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.14.0)
  Collecting h5py<2.11.0,>=2.10.0
    Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)
  Collecting keras-preprocessing<1.2,>=1.1.1
    Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
  Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drm
  ed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (0.34.2)
  Collecting scipy==1.4.1
    Using cached scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)
  Collecting astunparse==1.6.3
    Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
  Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis
  /drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (3.11.4)
  Collecting tf-estimator-nightly
    Using cached tf_estimator_nightly-2.3.0.dev2020052701-py2.py3-none-any.whl (459 kB)
  Collecting google-auth<2,>=1.6.3
    Using cached google_auth-1.15.0-py2.py3-none-any.whl (89 kB)
  Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0
  a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2.23.0)
  Collecting markdown>=2.6.8
    Using cached Markdown-3.2.2-py3-none-any.whl (88 kB)
  Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a0
  ->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.0.1)
  Collecting google-auth-oauthlib<0.5,>=0.4.1
    Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)
  Collecting tensorboard-plugin-wit>=1.6.0
    Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)
  Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from tb-nightly<2.4.0a0,>=2.3.0a
  0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (46.4.0.post20200518)
  Collecting rsa<4.1,>=3.1.4
    Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)
  Collecting cachetools<5.0,>=2.0.0
    Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)
  Collecting pyasn1-modules>=0.2.1
    Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
  Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nig
  htly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2020.4.5.1)
  Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from reques
  ts<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (1.25.8)
  Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nigh
  tly<2.4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (3.0.4)
  Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages (from requests<3,>=2.21.0->tb-nightly<2
  .4.0a0,>=2.3.0a0->tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.85p0qvwf.requirements.txt (line 1)) (2.9)
  Collecting requests-oauthlib>=0.7.0
    Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
  Collecting pyasn1>=0.1.3
    Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
  Collecting oauthlib>=3.0.0
    Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
  Installing collected packages: gast, google-pasta, termcolor, opt-einsum, wrapt, grpcio, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, markdown, absl-py, oauthlib, requests-oauthlib, google-auth-oau
  thlib, tensorboard-plugin-wit, tb-nightly, h5py, keras-preprocessing, scipy, astunparse, tf-estimator-nightly, tf-nightly
  Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.15.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdow
  n-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tb-nightly-2.3.0a20200527 tensorboard-plugin-wit-1.6.0.post3 termcolor-1.1.0 tf-estimato
  r-nightly-2.3.0.dev2020052701 tf-nightly-2.3.0.dev20200527 wrapt-1.12.1

  #
  # To activate this environment, use
  #
  #     $ conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b
  #
  # To deactivate an active environment, use
  #
  #     $ conda deactivate

  2020/05/27 15:11:00 INFO mlflow.projects: === Created directory /tmp/tmpv29_ayk_ for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/27 15:11:00 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'a934f2e603014f77b17462f1e4ca9bae' ===
  2020-05-27 15:11:03.143020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200527
  2020-05-27 15:11:06.317633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
  2020-05-27 15:11:07.188926: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  2020-05-27 15:11:07.188997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-27 15:11:20.905207: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-27 15:11:20.917673: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199950000 Hz
  2020-05-27 15:11:20.920689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dbefe5e8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-27 15:11:20.920721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  2020-05-27 15:11:25.038117: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  Epoch 1/2
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5588 - tp: 19173.0000 - fp: 38933.0000 - tn: 14836.0000 - fn: 8978.0000 - precision: 0.3300 - recall: 0.6811 - accuracy: 0.4151 - auc: 0.50792020-0
  5-27 15:11:41.545898: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-27 15:11:44.135919: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44
  2020-05-27 15:11:44.155947: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.trace.json.gz
  2020-05-27 15:11:44.192046: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44
  2020-05-27 15:11:44.192223: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.memory
  _profile.json.gz
  2020-05-27 15:11:44.194889: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_11_44Dumped tool data for xplane.pb to /tmp/tb/trai
  n/plugins/profile/2020_05_27_15_11_44/login01.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_11_44/login01.kernel_stats.pb

  32/32 [==============================] - ETA: 0s - loss: 1.4530 - tp: 125782.0000 - fp: 204775.0000 - tn: 1917683.0000 - fn: 373200.0000 - precision: 0.3805 - recall: 0.2521 - accuracy: 0.7795 - auc: 0.6085
  qt.qpa.screen: QXcbConnection: Could not connect to display :0
  Could not connect to any X display.
  2020/05/27 15:13:10 ERROR mlflow.cli: === Run (ID 'a934f2e603014f77b17462f1e4ca9bae') failed ===
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

We have found this error:

#+BEGIN_SRC sh
  qt.qpa.screen: QXcbConnection: Could not connect to display :0
  Could not connect to any X display.
#+END_SRC

This seems to be a problem with =matplotlib=. According to [[https://github.com/ipython/ipython/issues/10627][this thread]] the fix
seems to be to insert a =import matplotlib; matplotlib.use('agg')=

*** Second run: on compute node with correct conda env and matplotlib fixed
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git status
  git log -1
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  #       ...
  nothing added to commit but untracked files present (use "git add" to track)

  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ git log -1
  commit e6b99f1a1408e47b481419b0e27a28c97ed59e3b
  Author: Apoplex <oligolex@vivaldi.net>
  Date:   Wed May 27 15:28:14 2020 +0200

      Fix matplotlib-related error

      Error message when trying to call plt.plot on server:
      qt.qpa.screen: QXcbConnection: Could not connect to display :0
      Could not connect to any X display.
#+end_example

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/
  2020/05/27 15:35:09 INFO mlflow.projects: === Created directory /tmp/tmp7nb75v_s for downloading remote URIs passed to arguments of type 'path' ===
  2020/05/27 15:35:09 INFO mlflow.projects: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2 && python src/f
  luotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 10 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample' in run with ID 'e54a6138a1c94873b2fb0c399bf42edc' ===
  2020-05-27 15:35:11.393370: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No
   such file or directory
  2020-05-27 15:35:11.393459: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in favo
  ur of importlib; see the module's documentation for alternative uses
    import imp
  2.3.0-dev20200527
  2020-05-27 15:35:14.163172: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file
   or directory
  2020-05-27 15:35:14.163212: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
  2020-05-27 15:35:14.163237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node146): /proc/driver/nvidia/version does not exist
  GPUs:  []
  train 0 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set003.csv
  train 1 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set002.csv
  test 2 /beegfs/ye53nis/saves/firstartifact_Sep2019_subsample/traces_cluster_rand_Sep2019_set001.csv
  shapes of feature dataframe: (20000, 200) and label dataframe: (20000, 200)
  shapes of feature dataframe: (20000, 100) and label dataframe: (20000, 100)

  for each 20,000 timestap trace there are the following numbers of corrupted timesteps:
   label001_1     4124
  label002_1     2261
  label003_1       45
  label004_1    13108
  label005_1     2306
  dtype: int64
  2020-05-27 15:35:21.044261: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical opera
  tions:  AVX2 AVX512F FMA
  To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
  2020-05-27 15:35:21.063498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
  2020-05-27 15:35:21.065386: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560557fdf500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
  2020-05-27 15:35:21.065443: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  number of training examples: 160, number of validation examples: 40

  ------------------------
  number of test examples: 100

  input - shape:   (None, 16384, 1)
  output - shape:  (None, 16384, 1)
  2020-05-27 15:35:24.293439: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the A
  BCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(wrapped_dict, collections.Mapping):
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pytho
  n 3.0, use inspect.signature() or inspect.getfullargspec()
    all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
  Epoch 1/10
  /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
  'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
    if not isinstance(values, collections.Sequence):
   1/32 [..............................] - ETA: 0s - loss: 1.5921 - tp: 4422.0000 - fp: 14942.0000 - tn: 44154.0000 - fn: 18402.0000 - precision: 0.2284 - recall: 0.1937 - accuracy: 0.5930 - auc: 0.41302020-0
  5-27 15:35:36.900052: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
  WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager
  .profiler) is deprecated and will be removed after 2020-07-01.
  Instructions for updating:
  use `tf.profiler.experimental.stop` instead.
  2020-05-27 15:35:38.755304: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38
  2020-05-27 15:35:38.771792: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.trace.json.gz
  2020-05-27 15:35:38.811277: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38
  2020-05-27 15:35:38.811457: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.memory
  _profile.json.gz
  2020-05-27 15:35:38.814088: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2020_05_27_15_35_38Dumped tool data for xplane.pb to /tmp/tb/trai
  n/plugins/profile/2020_05_27_15_35_38/node146.xplane.pb
  Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.overview_page.pb
  Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.input_pipeline.pb
  Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.tensorflow_stats.pb
  Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2020_05_27_15_35_38/node146.kernel_stats.pb

  32/32 [==============================] - 63s 2s/step - loss: 1.5140 - tp: 45656.0000 - fp: 78324.0000 - tn: 1999623.0000 - fn: 497837.0000 - precision: 0.3683 - recall: 0.0840 - accuracy: 0.7802 - auc: 0.56
  78 - val_loss: 622806451643763130368.0000 - val_tp: 115044.0000 - val_fp: 540316.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1755 - val_recall: 1.0000 - val_accuracy: 0.1755 - val_auc:
   0.5000
  Epoch 2/10
  32/32 [==============================] - 57s 2s/step - loss: 1.3910 - tp: 42987.0000 - fp: 29799.0000 - tn: 2078052.0000 - fn: 470602.0000 - precision: 0.5906 - recall: 0.0837 - accuracy: 0.8091 - auc: 0.64
  52 - val_loss: 6545756127232.0000 - val_tp: 91530.0000 - val_fp: 563830.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1397 - val_recall: 1.0000 - val_accuracy: 0.1397 - val_auc: 0.5000
  Epoch 3/10
  32/32 [==============================] - 57s 2s/step - loss: 1.3078 - tp: 112631.0000 - fp: 11795.0000 - tn: 2102980.0000 - fn: 394034.0000 - precision: 0.9052 - recall: 0.2223 - accuracy: 0.8452 - auc: 0.7
  767 - val_loss: 21700208.0000 - val_tp: 112388.0000 - val_fp: 542972.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1715 - val_recall: 1.0000 - val_accuracy: 0.1715 - val_auc: 0.5000
  Epoch 4/10
  32/32 [==============================] - 57s 2s/step - loss: 1.1607 - tp: 333193.0000 - fp: 77797.0000 - tn: 2027264.0000 - fn: 183186.0000 - precision: 0.8107 - recall: 0.6452 - accuracy: 0.9004 - auc: 0.8
  807 - val_loss: 157728.7812 - val_tp: 136439.0000 - val_fp: 518921.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.2082 - val_recall: 1.0000 - val_accuracy: 0.2082 - val_auc: 0.5000
  Epoch 5/10
  32/32 [==============================] - 56s 2s/step - loss: 1.1154 - tp: 369131.0000 - fp: 129187.0000 - tn: 2007562.0000 - fn: 115560.0000 - precision: 0.7408 - recall: 0.7616 - accuracy: 0.9066 - auc: 0.
  9105 - val_loss: 2942.4502 - val_tp: 123087.0000 - val_fp: 532273.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.1878 - val_recall: 1.0000 - val_accuracy: 0.1878 - val_auc: 0.5000
  Epoch 6/10
  32/32 [==============================] - 58s 2s/step - loss: 1.0467 - tp: 415752.0000 - fp: 82888.0000 - tn: 2020886.0000 - fn: 101914.0000 - precision: 0.8338 - recall: 0.8031 - accuracy: 0.9295 - auc: 0.9
  423 - val_loss: 426.9106 - val_tp: 165483.0000 - val_fp: 489877.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 0.2525 - val_recall: 1.0000 - val_accuracy: 0.2525 - val_auc: 0.5000
  Epoch 7/10
  32/32 [==============================] - 56s 2s/step - loss: 1.0459 - tp: 425824.0000 - fp: 136085.0000 - tn: 1985980.0000 - fn: 73551.0000 - precision: 0.7578 - recall: 0.8527 - accuracy: 0.9200 - auc: 0.9
  489 - val_loss: 66.3730 - val_tp: 121274.0000 - val_fp: 533859.0000 - val_tn: 210.0000 - val_fn: 17.0000 - val_precision: 0.1851 - val_recall: 0.9999 - val_accuracy: 0.1854 - val_auc: 0.5002
  Epoch 8/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0201 - tp: 415212.0000 - fp: 74474.0000 - tn: 2046769.0000 - fn: 84985.0000 - precision: 0.8479 - recall: 0.8301 - accuracy: 0.9392 - auc: 0.95
  21 - val_loss: 16.7654 - val_tp: 139272.0000 - val_fp: 489110.0000 - val_tn: 26913.0000 - val_fn: 65.0000 - val_precision: 0.2216 - val_recall: 0.9995 - val_accuracy: 0.2536 - val_auc: 0.5504
  Epoch 9/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0049 - tp: 430732.0000 - fp: 74493.0000 - tn: 2040293.0000 - fn: 75922.0000 - precision: 0.8526 - recall: 0.8502 - accuracy: 0.9426 - auc: 0.96
  02 - val_loss: 8.2851 - val_tp: 161996.0000 - val_fp: 413277.0000 - val_tn: 78219.0000 - val_fn: 1868.0000 - val_precision: 0.2816 - val_recall: 0.9886 - val_accuracy: 0.3665 - val_auc: 0.5933
  Epoch 10/10
  32/32 [==============================] - 57s 2s/step - loss: 1.0267 - tp: 416052.0000 - fp: 107470.0000 - tn: 2032480.0000 - fn: 65438.0000 - precision: 0.7947 - recall: 0.8641 - accuracy: 0.9340 - auc: 0.9
  544 - val_loss: 4.8570 - val_tp: 93516.0000 - val_fp: 458191.0000 - val_tn: 103041.0000 - val_fn: 612.0000 - val_precision: 0.1695 - val_recall: 0.9935 - val_accuracy: 0.2999 - val_auc: 0.7206
  20/20 [==============================] - 7s 337ms/step - loss: 1.6838 - tp: 371677.0000 - fp: 484970.0000 - tn: 776428.0000 - fn: 5325.0000 - precision: 0.4339 - recall: 0.9859 - accuracy: 0.7007 - auc: 0.9
  482
  2020/05/27 15:45:38 INFO mlflow.projects: === Run (ID 'e54a6138a1c94873b2fb0c399bf42edc') succeeded ===
  (tensorflow_nightly) [ye53nis@node146 drmed-git]$
#+end_example

No new errors! If reading out the logs works now, it's ready to read out from
the experimental branch!

First, commit the run to git - but important: don't commit on the compute node,
because git-lfs is not installed there. So first exit the compute node and go to
the file

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  exit
  cd /beegfs/ye53nis/drmed-git/
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

Now, add the run:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git add data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc
  git commit -m 'run mlflow with tensorboard callbacks and more metrics'
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git add data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git commit -m 'run mlflow with tensorboard callbacks and more metrics'
  [develop 5e5ba85] run mlflow with tensorboard callbacks and more metrics
   64 files changed, 1037 insertions(+)
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/MLmodel
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/conda.yaml
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/keras_module.txt
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model_summary.txt
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/image/events.out.tfevents.1590586524.node146.141413.9064.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/metrics/events.out.tfevents.1590586524.node146.141413.9072.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/events.out.tfevents.1590586524.node146.141413.9206.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/events.out.tfevents.1590586538.node146.profile-empty
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.input_pipeline.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.kernel_stats.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.memory_profile.json.gz
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.overview_page.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.tensorflow_stats.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.trace.json.gz
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/train/plugins/profile/2020_05_27_15_35_38/node146.xplane.pb
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs/validation/events.out.tfevents.1590586590.node146.141413.28229.v2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/meta.yaml
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/accuracy
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/auc
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/fn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/fp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/learning rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/loss
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/lr
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/precision
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/recall
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/tn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/tp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_accuracy
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_auc
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_fn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_fp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_loss
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_precision
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_recall
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_tn
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/metrics/val_tp
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/batch_size
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/csv_path
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/epochs
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/fluotracify_path
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/frac_val
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/learning_rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/length_delimiter
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_amsgrad
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_beta_1
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_beta_2
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_decay
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_epsilon
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_learning_rate
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/opt_name
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/steps_per_epoch
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/params/validation_steps
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.gitRepoURL
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.log-model.history
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.backend
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.entryPoint
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.project.env
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.git.commit
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.git.repoURL
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.name
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.source.type
   create mode 100644 data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/tags/mlflow.user
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

Now push to github. Notice the use of git-lfs for big files. git-lfs is also the
reason, that I have to enter the username and password three times.

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  git push origin develop
#+END_SRC

#+RESULTS:
#+begin_example
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$ git push origin develop
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Username for 'https://github.com': aseltmann
  Password for 'https://aseltmann@github.com':
  Uploading LFS objects: 100% (1/1), 399 MB | 25 MB/s, done
  Counting objects: 62, done.
  Delta compression using up to 48 threads.
  Compressing objects: 100% (51/51), done.
  Writing objects: 100% (58/58), 3.64 MiB | 2.61 MiB/s, done.
  Total 58 (delta 3), reused 0 (delta 0)
  remote: Resolving deltas: 100% (3/3), completed with 1 local object.
  To https://github.com/aseltmann/fluotracify
     e6b99f1..5e5ba85  develop -> develop
  (tensorflow_nightly) [ye53nis@login01 drmed-git]$
#+end_example

*** Read out logs

#+BEGIN_SRC tmux :session local
  cd ~/Programme/drmed-git/
  conda activate tf-nightly-lab
  tensorboard --logdir=data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/tensorboard_logs
#+END_SRC

#+RESULTS:
#+begin_example
  2020-05-28 00:03:05.639160: W tensorflow/stream_executor/platform/default/dso_loader.cc:55]
    Could not load dynamic library 'libcudart.so.10.1';
    dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
  2020-05-28 00:03:05.639231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29]
    Ignore above cudart dlerror if you do not have a GPU set up on your machine.

  Serving TensorBoard on localhost; to expose to the network, use a proxy or pass
  --bind_all
  TensorBoard 2.3.0a20200519 at http://localhost:6006/ (Press CTRL+C to quit)
#+end_example

#+BEGIN_SRC tmux :session local2
  cd ~/Programme/drmed-git
  conda activate tf-nightly-lab
  mlflow ui --backend-store-uri file:///home/lex/Programme/drmed-git/data/mlruns
#+END_SRC

#+RESULTS:
#+begin_example
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Starting gunicorn 20.0.4
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Listening at: http://127.0.0.1:5000 (25472)
  [2020-05-28 00:14:45 +0200] [25472] [INFO] Using worker: sync
  [2020-05-28 00:14:45 +0200] [25474] [INFO] Booting worker with pid: 25474
#+end_example

*** Load model after improved saving
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8888:92f8b689-feb1-44c9-b8a3-7182711e0c58
   :END:
#+BEGIN_SRC tmux :session local
  cd /home/lex/Programme/drmed-git/
  git lfs ls-files
#+END_SRC

#+RESULTS:
#+begin_example
  (tf-nightly-lab) [lex@Topialex drmed-git]$ git lfs ls-files
  6526c5abca * data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5
  4bb6295e4e * data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
#+end_example

#+BEGIN_SRC jupyter-python
  import mlflow.keras
  import mlflow.tensorflow
  import sys
  import numpy as np
  import tensorflow as tf

  fluotracify_path = '/home/lex/Programme/drmed-git/src/'
  sys.path.append(fluotracify_path)

  from fluotracify.simulations import import_simulation_from_csv as isfc
  from fluotracify.training import build_model as bm, preprocess_data as ppd
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
  # mlflow.keras module
  model_path = '/home/lex/Programme/drmed-git/data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model'
  model_keras = mlflow.keras.load_model(model_uri=model_path,
                                        custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()})
  model_keras
#+END_SRC

#+RESULTS:
:RESULTS:
: /home/lex/Programme/miniconda3/envs/tf-nightly-lab/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
:   if not isinstance(wrapped_dict, collections.Mapping):
: <tensorflow.python.keras.engine.functional.Functional at 0x7f5ed9dd64c0>
:END:

#+BEGIN_SRC jupyter-python
  data, _, nsamples, experiment_params = isfc.import_from_csv(
      path='/home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/',
      header=12,
      frac_train=1,
      col_per_example=2,
      dropindex=None,
      dropcolumns='Unnamed: 200')
#+END_SRC

#+RESULTS:
: train 0 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set003.csv
: train 1 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set002.csv
: train 2 /home/lex/Programme/Jupyter/DOKTOR/saves/firstartefact/subsample_rand/traces_brightclust_rand_Sep2019_set001.csv

#+BEGIN_SRC jupyter-python :results scalar
  prediction = model_keras.predict(np.array(data.iloc[:2048, 0]).reshape(1, -1, 1))
#+END_SRC

#+RESULTS:
#+begin_example
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 1) for input Tensor("input_1_1:0", shape=(None, 16384, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 1).
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 1) for input Tensor("conv1d_input_1:0", shape=(None, 16384, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 1).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 64) for input Tensor("conv1d_2_input_1:0", shape=(None, 8192, 64), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 64).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 128) for input Tensor("conv1d_4_input_1:0", shape=(None, 4096, 128), dtype=float32), but it was called on an input with incompatible shape (None, 512, 128).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 256) for input Tensor("conv1d_6_input_1:0", shape=(None, 2048, 256), dtype=float32), but it was called on an input with incompatible shape (None, 256, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 512) for input Tensor("conv1d_8_input_1:0", shape=(None, 1024, 512), dtype=float32), but it was called on an input with incompatible shape (None, 128, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 512) for input Tensor("conv1d_10_input_1:0", shape=(None, 512, 512), dtype=float32), but it was called on an input with incompatible shape (None, 64, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 512) for input Tensor("conv1d_12_input_1:0", shape=(None, 256, 512), dtype=float32), but it was called on an input with incompatible shape (None, 32, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 512) for input Tensor("conv1d_14_input_1:0", shape=(None, 128, 512), dtype=float32), but it was called on an input with incompatible shape (None, 16, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 512) for input Tensor("conv1d_16_input_1:0", shape=(None, 64, 512), dtype=float32), but it was called on an input with incompatible shape (None, 8, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 32, 512) for input Tensor("conv1d_18_input_1:0", shape=(None, 32, 512), dtype=float32), but it was called on an input with incompatible shape (None, 4, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 32, 1024) for input Tensor("conv1d_transpose_input_1:0", shape=(None, 32, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 4, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 1024) for input Tensor("conv1d_20_input_1:0", shape=(None, 64, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 8, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 64, 512) for input Tensor("conv1d_transpose_1_input_1:0", shape=(None, 64, 512), dtype=float32), but it was called on an input with incompatible shape (None, 8, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 1024) for input Tensor("conv1d_22_input_1:0", shape=(None, 128, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 16, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 128, 512) for input Tensor("conv1d_transpose_2_input_1:0", shape=(None, 128, 512), dtype=float32), but it was called on an input with incompatible shape (None, 16, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 1024) for input Tensor("conv1d_24_input_1:0", shape=(None, 256, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 32, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 256, 512) for input Tensor("conv1d_transpose_3_input_1:0", shape=(None, 256, 512), dtype=float32), but it was called on an input with incompatible shape (None, 32, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 1024) for input Tensor("conv1d_26_input_1:0", shape=(None, 512, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 64, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 512, 512) for input Tensor("conv1d_transpose_4_input_1:0", shape=(None, 512, 512), dtype=float32), but it was called on an input with incompatible shape (None, 64, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 1024) for input Tensor("conv1d_28_input_1:0", shape=(None, 1024, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 1024, 512) for input Tensor("conv1d_transpose_5_input_1:0", shape=(None, 1024, 512), dtype=float32), but it was called on an input with incompatible shape (None, 128, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 1024) for input Tensor("conv1d_30_input_1:0", shape=(None, 2048, 1024), dtype=float32), but it was called on an input with incompatible shape (None, 256, 1024).
  WARNING:tensorflow:Model was constructed with shape (None, 2048, 512) for input Tensor("conv1d_transpose_6_input_1:0", shape=(None, 2048, 512), dtype=float32), but it was called on an input with incompatible shape (None, 256, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 512) for input Tensor("conv1d_32_input_1:0", shape=(None, 4096, 512), dtype=float32), but it was called on an input with incompatible shape (None, 512, 512).
  WARNING:tensorflow:Model was constructed with shape (None, 4096, 256) for input Tensor("conv1d_transpose_7_input_1:0", shape=(None, 4096, 256), dtype=float32), but it was called on an input with incompatible shape (None, 512, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 256) for input Tensor("conv1d_34_input_1:0", shape=(None, 8192, 256), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 256).
  WARNING:tensorflow:Model was constructed with shape (None, 8192, 128) for input Tensor("conv1d_transpose_8_input_1:0", shape=(None, 8192, 128), dtype=float32), but it was called on an input with incompatible shape (None, 1024, 128).
  WARNING:tensorflow:Model was constructed with shape (None, 16384, 128) for input Tensor("conv1d_36_input_1:0", shape=(None, 16384, 128), dtype=float32), but it was called on an input with incompatible shape (None, 2048, 128).
#+end_example

#+BEGIN_SRC jupyter-python :results plain :pandoc t
  import pandas as pd
  pd.DataFrame(prediction.flatten())
#+END_SRC

#+RESULTS:
:RESULTS:
|        | 0     |
|--------+-------|
| 0      | 1.0   |
| 1      | 1.0   |
| 2      | 1.0   |
| 3      | 1.0   |
| 4      | 1.0   |
| ...    | ...   |
| 2043   | 1.0   |
| 2044   | 1.0   |
| 2045   | 1.0   |
| 2046   | 1.0   |
| 2047   | 1.0   |

2048 rows × 1 columns
:END:

Yippieeeeh, I don't need the complicated =OrgFormatter!=
**** DONE test =:pandoc t= instead of custom =OrgFormatter= class
     CLOSED: [2020-05-28 Do 01:21]
**** DONE Add =os.environ=
     CLOSED: [2020-05-28 Do 14:12]
** Coming back to the lab after STEX2 <2020-11-02 Mo>
   :LOGBOOK:
   CLOCK: [2020-12-06 So 23:53]--[2020-12-06 So 23:53] =>  0:00
   CLOCK: [2020-12-02 Mi 23:06]--[2020-12-06 So 21:19] => 94:13
   CLOCK: [2020-12-01 Di 11:19]--[2020-12-01 Di 11:57] =>  0:38
   CLOCK: [2020-12-01 Di 10:27]--[2020-12-01 Di 10:44] =>  0:17
   CLOCK: [2020-11-06 Fr 21:11]--[2020-11-06 Fr 21:11] =>  0:00
   CLOCK: [2020-11-06 Fr 15:04]--[2020-11-06 Fr 15:26] =>  0:22

   CLOCK: [2020-11-06 Fr 14:14]--[2020-11-06 Fr 14:19] =>  0:05
   CLOCK: [2020-11-06 Fr 12:44]--[2020-11-06 Fr 13:24] =>  0:40
   CLOCK: [2020-11-06 Fr 12:10]--[2020-11-06 Fr 12:13] =>  0:03
   CLOCK: [2020-11-05 Do 17:24]--[2020-11-05 Do 17:25] =>  0:01
   CLOCK: [2020-11-05 Do 13:02]--[2020-11-05 Do 13:52] =>  0:50
   CLOCK: [2020-11-05 Do 01:12]--[2020-11-05 Do 01:12] =>  0:00
   CLOCK: [2020-11-04 Mi 22:34]--[2020-11-04 Mi 23:07] =>  0:33
   CLOCK: [2020-11-04 Mi 18:24]--[2020-11-04 Mi 18:35] =>  0:11
   CLOCK: [2020-11-04 Mi 17:35]--[2020-11-04 Mi 18:01] =>  0:26
   CLOCK: [2020-11-04 Mi 16:19]--[2020-11-04 Mi 17:18] =>  0:59
   CLOCK: [2020-11-04 Mi 15:34]--[2020-11-04 Mi 15:44] =>  0:10
   CLOCK: [2020-11-04 Mi 14:51]--[2020-11-04 Mi 15:04] =>  0:13
   CLOCK: [2020-11-04 Mi 13:20]--[2020-11-04 Mi 14:01] =>  0:41
   CLOCK: [2020-11-04 Mi 11:38]--[2020-11-04 Mi 11:53] =>  0:15
   CLOCK: [2020-11-03 Di 20:16]--[2020-11-03 Di 20:16] =>  0:00
   CLOCK: [2020-11-03 Di 15:50]--[2020-11-03 Di 16:12] =>  0:22
   CLOCK: [2020-11-03 Di 14:01]--[2020-11-03 Di 14:15] =>  0:14
   CLOCK: [2020-11-03 Di 13:03]--[2020-11-03 Di 13:45] =>  0:42
   CLOCK: [2020-11-03 Di 11:11]--[2020-11-03 Di 11:19] =>  0:08
   CLOCK: [2020-11-02 Mo 14:43]--[2020-11-02 Mo 17:01] =>  2:18
   :END:
*** upate tensorflow and mlflow in tensorflow_nightly environment on ara

    - we need:
    - numpy
    - pandas
    - matplotlib
    - seaborn
    - mlflow
    - jupyterlab
    - pip
    - pip:
      - tf-nightly
      - fcsfiles
      - multipletau

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  (base) [ye53nis@node181 drmed-git]$ conda create -n tf-nightly numpy pandas matplotlib seaborn tifffile jupyterlab pip
  (base) [ye53nis@node181 drmed-git]$ conda install -n tf-nightly -c conda-forge mlflow=1.11.0
  (base) [ye53nis@node181 drmed-git]$ conda activate tf-nightly
  (tf-nightly) [ye53nis@node181 drmed-git]$ pip install fcsfiles multipletau tf-nightly
#+END_SRC

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (tf-nightly) [ye53nis@node181 drmed-git]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      absl-py                   0.11.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
      argon2-cffi               20.1.0           py38h7b6447c_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10                       py_0
      attrs                     20.2.0                     py_0
      azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
      azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
      backcall                  0.2.0                      py_0
      blas                      1.0                         mkl
      bleach                    3.2.1                      py_0
      blinker                   1.4                        py_1    conda-forge
      brotlipy                  0.7.0           py38h7b6447c_1000
      ca-certificates           2020.6.20            hecda079_0    conda-forge
      cachetools                4.1.1                    pypi_0    pypi
      certifi                   2020.6.20        py38h924ce5b_2    conda-forge
      cffi                      1.14.3           py38he30daa8_0
      chardet                   3.0.4                 py38_1003
      click                     7.1.2              pyh9f0ad1d_0    conda-forge
      cloudpickle               1.6.0                      py_0    conda-forge
      configparser              5.0.1                      py_0    conda-forge
      cryptography              3.1.1            py38h1ba5d50_0
      cycler                    0.10.0                   py38_0
      databricks-cli            0.9.1                      py_0    conda-forge
      dbus                      1.13.18              hb2f20db_0
      decorator                 4.4.2                      py_0
      defusedxml                0.6.0                      py_0
      docker-py                 4.3.1            py38h32f6830_1    conda-forge
      docker-pycreds            0.4.0                      py_0    conda-forge
      entrypoints               0.3                      py38_0
      expat                     2.2.10               he6710b0_2
+++   fcsfiles                  2020.9.18                pypi_0    pypi
      flask                     1.1.2              pyh9f0ad1d_0    conda-forge
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.0               h9420a91_0
      freetype                  2.10.4               h5ab3b9f_0
      gast                      0.3.3                    pypi_0    pypi
      gitdb                     4.0.5                      py_0    conda-forge
      gitpython                 3.1.11                     py_0    conda-forge
      glib                      2.66.1               h92f7085_0
      google-auth               1.23.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.2                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      gorilla                   0.3.0                      py_0    conda-forge
      grpcio                    1.32.0                   pypi_0    pypi
      gst-plugins-base          1.14.0               hbbd80ab_1
      gstreamer                 1.14.0               hb31296c_0
      gunicorn                  20.0.4           py38h32f6830_2    conda-forge
      h5py                      2.10.0                   pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10                       py_0
      importlib-metadata        2.0.0                      py_1
      importlib_metadata        2.0.0                         1
      intel-openmp              2020.2                      254
      ipykernel                 5.3.4            py38h5ca1d4c_0
      ipython                   7.18.1           py38h5ca1d4c_0
      ipython_genutils          0.2.0                    py38_0
      isodate                   0.6.0                      py_1    conda-forge
      itsdangerous              1.1.0                      py_0    conda-forge
      jedi                      0.17.2                   py38_0
      jinja2                    2.11.2                     py_0
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.5                      py_0
      jsonschema                3.2.0                      py_2
      jupyter_client            6.1.7                      py_0
      jupyter_core              4.6.3                    py38_0
+++   jupyterlab                2.2.6                      py_0
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         1.2.0                      py_0
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.0            py38h2531618_0
      lcms2                     2.11                 h396b838_0
      ld_impl_linux-64          2.33.1               h53a641e_7
      libedit                   3.1.20191231         h14c3975_1
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.1.0                hdf63c60_0
      libgfortran-ng            7.3.0                hdf63c60_0
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.13.0.1             h8b12597_0    conda-forge
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.1.0                hdf63c60_0
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.10               hb55368b_3
      lz4-c                     1.9.2                heb0550a_3
      mako                      1.1.3              pyh9f0ad1d_0    conda-forge
      markdown                  3.3.3                    pypi_0    pypi
      markupsafe                1.1.1            py38h7b6447c_0
      matplotlib                3.3.2                         0
      matplotlib-base           3.3.2            py38h817c723_0
      mistune                   0.8.4           py38h7b6447c_1000
      mkl                       2020.2                      256
      mkl-service               2.3.0            py38he904b0f_0
      mkl_fft                   1.2.0            py38h23d657b_0
      mkl_random                1.1.1            py38h0573a6f_0
+++   mlflow                    1.11.0           py38h32f6830_1    conda-forge
      msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
+++   multipletau               0.3.3                    pypi_0    pypi
      nbclient                  0.5.1                      py_0
      nbconvert                 6.0.7                    py38_0
      nbformat                  5.0.8                      py_0
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.4.1                      py_0
      notebook                  6.1.4                    py38_0
+++   numpy                     1.19.2           py38h54aff64_0
      numpy-base                1.19.2           py38hfa32c7d_0
      oauthlib                  3.0.1                      py_0    conda-forge
      olefile                   0.46                       py_0
      openssl                   1.1.1h               h516909a_0    conda-forge
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 20.4                       py_0
+++   pandas                    1.1.3            py38he6710b0_0
      pandoc                    2.11                 hb0f4dca_0
      pandocfilters             1.4.2                    py38_1
      parso                     0.7.0                      py_0
      pcre                      8.44                 he6710b0_0
      pexpect                   4.8.0                    py38_0
      pickleshare               0.7.5                 py38_1000
      pillow                    8.0.1            py38he98fc37_0
+++   pip                       20.2.4                   py38_0
      prometheus_client         0.8.0                      py_0
      prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
      prompt-toolkit            3.0.8                      py_0
      protobuf                  3.13.0.1         py38h950e882_1    conda-forge
      ptyprocess                0.6.0                    py38_0
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.7.2              pyhd3eb1b0_0
      pyjwt                     1.7.1                      py_0    conda-forge
      pyopenssl                 19.1.0                     py_1
      pyparsing                 2.4.7                      py_0
      pyqt                      5.9.2            py38h05f1152_4
      pyrsistent                0.17.3           py38h7b6447c_0
      pysocks                   1.7.1                    py38_0
      python                    3.8.5                h7579374_1
      python-dateutil           2.8.1                      py_0
      python-editor             1.0.4                      py_0    conda-forge
      python_abi                3.8                      1_cp38    conda-forge
      pytz                      2020.1                     py_0
      pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
      pyzmq                     19.0.2           py38he6710b0_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge
      readline                  8.0                  h7b6447c_0
      requests                  2.24.0                     py_0
      requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
      rsa                       4.6                      pypi_0    pypi
+++   scipy                     1.5.2            py38h0b6359f_0
      seaborn                   0.11.0                     py_0
      send2trash                1.5.0                    py38_0
      setuptools                50.3.0           py38hb0f4dca_1
      sip                       4.19.13          py38he6710b0_0
      six                       1.15.0                     py_0
      smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
      sqlalchemy                1.3.13           py38h516909a_0    conda-forge
      sqlite                    3.33.0               h62c20be_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
      tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
+++   tb-nightly                2.4.0a20201102           pypi_0    pypi
      tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.1                    py38_0
      testpath                  0.4.4                      py_0
      tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
+++   tf-nightly                2.5.0.dev20201029          pypi_0    pypi
+++   tifffile                  2020.10.1        py38hdd07704_2
      tk                        8.6.10               hbc83047_0
      tornado                   6.0.4            py38h7b6447c_1
      traitlets                 5.0.5                      py_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      urllib3                   1.25.11                    py_0
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1                    py38_1
      websocket-client          0.57.0           py38h32f6830_3    conda-forge
      werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
      wheel                     0.35.1                     py_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge
      zeromq                    4.3.3                he6710b0_3
      zipp                      3.4.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.5                h9ceee32_0
      (tf-nightly) [ye53nis@node181 drmed-git]$
    #+end_example

*** planning next experiments
**** DONE new simulations with different transit times
     CLOSED: [2020-12-30 Mi 14:55]
***** some theoretical calculations
     - for now I've got:
     - $0.5 \frac{\mu m^2}{s} ~ 22.54ms$ → we need a trace length of 2-3 orders
       of magnitude longer, so $2.25s…7.13s…22.54s$ (10^2, 10^2.5, 10^3)
     - $1 \frac{\mu m^2}{s} ~ 11.27ms$ → $1.13s…3.56s…11.27s$
     - $2 \frac{\mu m^2}{s} ~ 5.64ms$ → $0.56s…1.78s…5.64s$
     - $3 \frac{\mu m^2}{s} ~ 3.76ms$ → $0.38s…1.19s…3.76s$
     - $4 \frac{\mu m^2}{s} ~ 2.82ms$ → $0.28s…0.89s…2.82s$
     - $5 \frac{\mu m^2}{s} ~ 2.25ms$ → $0.23s…0.71s…2.25s$
     - now Falk said the most important processes are between $0.1…1 \frac{\mu
       m^2}{s}$ and
       the maximum amplitudes are between $10^{-3}…1(10)\frac{\mu
       m^2}{s}$ which means:
     - $0.001 \frac{\mu m^2}{s} ~ 11271ms$ → $1127s(18.8min)…3564s(59.4min)…11271s(188min)$
     - $0.01 \frac{\mu m^2}{s} ~ 1127ms$ → $113s…356s(6min)…1127s(18.8min)$
     - $0.0113 \frac{\mu m^2}{s} ~ 997ms$ → $\bold{100s}…315s(5.3min)…997s(16.6min)$
     - $0.02 \frac{\mu m^2}{s} ~ 563ms$ → $56s…178s…564s(9.4min)$
     - $0.0225 \frac{\mu m^2}{s} ~ 501ms$ → $\bold{50s}…158s…501s(8.4min)$
     - $0.03 \frac{\mu m^2}{s} ~ 376ms$ → $38s…119s…376s$
     - $0.035 \frac{\mu m^2}{s} ~ 322ms$ → $32s…\bold{102s}…322s$
     - $0.04 \frac{\mu m^2}{s} ~ 282ms$ → $28s…89s…282s(4.7min)$
     - $0.056 \frac{\mu m^2}{s} ~ 201ms$ → $\bold{20s}…63.6s…201s$
     - $0.06 \frac{\mu m^2}{s} ~ 188ms$ → $19s…59s…188s$
     - $0.069 \frac{\mu m^2}{s} ~ 163ms$ → $\bold{16.3s}…52s…163s \to 2^{14}$
       for unet
     - $0.071 \frac{\mu m^2}{s} ~ 159ms$ → $15.9s…\bold{50s}…159s$
     - $0.08 \frac{\mu m^2}{s} ~ 141ms$ → $14.1s…45s…141s$
     - $0.1 \frac{\mu m^2}{s} ~ 112.7ms$ → $11.3s…35.6s…112.7s$
     - $0.113 \frac{\mu m^2}{s} ~ 99.7ms$ → $9.97s…31.5s…\bold{99.7s}$
     - $0.18 \frac{\mu m^2}{s} ~ 62.6ms$ → $6.26s…\bold{19.8s}…63s}$
     - $0.2 \frac{\mu m^2}{s} ~ 56.36ms$ → $5.64s…17.8s…56.4s$
     - $0.225 \frac{\mu m^2}{s} ~ 50.1ms$ → $5.01s…15.8s…\bold{50.1s}$
     - $0.56 \frac{\mu m^2}{s} ~ 20.1ms$ → $2.01s…6.36s…\bold{20.1s}$
     - $1.12 \frac{\mu m^2}{s} ~ 10.1ms$ → $1.01s…3.19s…\bold{10.1s}$
     - $2.25 \frac{\mu m^2}{s} ~ 5.01ms$ → $0.5s…1.58s…\bold{5.01s}$
     - $10 \frac{\mu m^2}{s} ~ 1.13ms$ → $0.11s…0.36s…\bold{1.13s}$
     - $50 \frac{\mu m^2}{s} ~ \boldsymbol{0.225ms}$ → $0.023s…0.071s…\bold{0.225s}$
     - for 100s trace length we have the following constraints:
       - conservative (3-fold): $0.113\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.035\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.0113\frac{\mu m^2}{s}$
     - for 50s trace length we have the following constraints:
       - conservative (3-fold): $0.225\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.071\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.0225\frac{\mu m^2}{s}$
     - for 20s trace length we have the following constraints:
       - conservative (3-fold): $0.56\frac{\mu m^2}{s}$
       - middle (2.5-fold): $0.18\frac{\mu m^2}{s}$
       - minimum (2-fold): $0.056\frac{\mu m^2}{s}$
***** Coming back to my project
      - Pablo fitted the 400 Hs-PEX5-eGFP samples and got an average transit
        time of 0.225ms
      - which simulations have I got already?

      |   D | sim | where   | max 5000 Intensity                 |
      |-----+-----+---------+------------------------------------|
      | 0.5 |  11 | Sep2019 | 10, 25, 39, 60, 74, 84, 85, 86     |
      |   1 |   8 | Sep2019 | 16, 20, 43, 46, 87, 90, 98         |
      | 1.5 |   7 | Sep2019 | 1, 6, 18                           |
      |   2 |   9 | Sep2019 | 2, 15, 22, 33, 53, 72              |
      | 2.5 |  18 | Sep2019 | 11, 27, 34, 51, 79, 81, 92, 95     |
      |   3 |  13 | Sep2019 | 23, 36, 38, 50, 55, 58, 78, 80, 99 |
      | 3.5 |   7 | Sep2019 | 68                                 |
      |   4 |   6 | Sep2019 | 30, 52, 66, 82                     |
      | 4.5 |  11 | Sep2019 | 5, 12, 41, 76                      |
      |   5 |  10 | Sep2019 | 0, 4, 32, 42, 96                   |
      |     |     |         |                                    |
***** DONE uninstall git lfs (annoying 3 authentications and no benefit...)
      CLOSED: [2020-12-14 Mo 13:33]
      1. =git lfs uninstall=
      2. remove lfs stuff from =.gitattributes=:
         #+begin_example
         *.tf filter=lfs diff=lfs merge=lfs -text
         data/**/*.tf/** filter=lfs diff=lfs merge=lfs -text
         *.h5 filter=lfs diff=lfs merge=lfs -text
         #+end_example
      3. do =git rm --cached= for each of the files stored in git lfs
         #+begin_example
         data/mlruns/1/47b870b8fdcb4445956635c6758caff3/artifacts/model/data/model.h5
         data/mlruns/1/e54a6138a1c94873b2fb0c399bf42edc/artifacts/model/data/model.h5
         #+end_example
      4. since I don't need these runs, I don't add them manually, but leave
         them where they are (at the =/beegfs= at the hpc)
      5. commit everything
      6. remove junk with =rm -rf .git/lfs=
***** DONE Changes in Simulation
      CLOSED: [2020-12-30 Mi 14:51]
      - took nmol_arr out of =produce_training_data=:
        #+begin_example
        nmol_arr : list or tuple
          Number of fast molecules used for simulation. For each set, one will
          be drawn using random.choice()
        #+end_example
        and fixed it to the following:
        #+begin_src python
        nmol = random.choice([500, 1000, 1500, 2000, 2500, 3000, 3500])
        #+end_src
      - fixed printing: if you want to print out to the same line (e.g. in a
        for-loop), just use the string marker =\r=, e.g.:
        #+begin_src python
          import sys
          num_of_mol = 500
          for b in range(0, num_of_mol):
              per = int((float(b) / float(num_of_mol)) * 100)
              sys.stdout.write("\rProcessing tracks: [{:20}] {}% complete".format('=' * int(per / 5), per))
        #+end_src
***** DONE do scaling in =integrate_over_psf=
      CLOSED: [2020-12-30 Mi 14:54]
      - I chose now to ditch the random offset augmentation on the traces, since
        the offset is only determined by the number of molecules.
      - instead, I chose the number of molecules to be a random integer between
        500 and 3500, that gives enough random trace heights while keeping the
        fake intensity levels kind of realistic.
      - it has to be stressed, that in this case, the number of molecules should
        not matter really for the physical calculation, but is meant to make the
        trained model more robust to different data it might get presented
***** DONE Idea: save out trace + label 1 = brightclust + label 2 = trace without artifacts
      CLOSED: [2020-12-30 Mi 14:53]
      - like this there would always be an inbuilt control
      - downside: bigger files, revamp almost all functions
***** DONE fork nanosimpy functions into my own package
     CLOSED: [2020-11-30 Mo 10:21]
     - always dealing with the unmaintained nanosimpy package is tedious
**** now do the simulation from the emacs notebook
     :PROPERTIES:
     :header-args:jupyter-python: :session /jpy:localhost#9999:a37e524a-8134-4d8f-b24a-367acaf1bdd3
     :END:
     #+BEGIN_SRC  emacs-lisp
       (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
     #+END_SRC

     #+BEGIN_SRC jupyter-python
       %cd /beegfs/ye53nis/drmed-git/
       !git log -1
     #+END_SRC

     #+RESULTS:
     : /beegfs/ye53nis/drmed-git
     : commit 387c3e9309caa203938d397218e27d4f01bdad84
     : Author: Apoplex <oligolex@vivaldi.net>
     : Date:   Tue Dec 29 19:11:34 2020 +0100
     :
     :     Add module docs; now use sys.exit instead exit

     #+BEGIN_SRC jupyter-python
       %conda list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       absl-py                   0.11.0                   pypi_0    pypi
       alembic                   1.4.1                      py_0    conda-forge
       appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
       argon2-cffi               20.1.0           py38h7b6447c_1
       asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
       asteval                   0.9.16             pyh5ca1d4c_0    conda-forge
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10                       py_0
       attrs                     20.2.0                     py_0
       azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
       azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
       backcall                  0.2.0                      py_0
       blas                      1.0                         mkl
       bleach                    3.2.1                      py_0
       blinker                   1.4                        py_1    conda-forge
       brotlipy                  0.7.0           py38h7b6447c_1000
       ca-certificates           2020.12.5            ha878542_0    conda-forge
       cachetools                4.1.1                    pypi_0    pypi
       certifi                   2020.12.5        py38h578d9bd_0    conda-forge
       cffi                      1.14.3           py38he30daa8_0
       chardet                   3.0.4                 py38_1003
       click                     7.1.2              pyh9f0ad1d_0    conda-forge
       cloudpickle               1.6.0                      py_0    conda-forge
       configparser              5.0.1                      py_0    conda-forge
       cryptography              3.1.1            py38h1ba5d50_0
       cycler                    0.10.0                   py38_0
       databricks-cli            0.9.1                      py_0    conda-forge
       dbus                      1.13.18              hb2f20db_0
       decorator                 4.4.2                      py_0
       defusedxml                0.6.0                      py_0
       docker-py                 4.3.1            py38h32f6830_1    conda-forge
       docker-pycreds            0.4.0                      py_0    conda-forge
       entrypoints               0.3                      py38_0
       expat                     2.2.10               he6710b0_2
       fcsfiles                  2020.9.18                pypi_0    pypi
       flask                     1.1.2              pyh9f0ad1d_0    conda-forge
       flatbuffers               1.12                     pypi_0    pypi
       fontconfig                2.13.0               h9420a91_0
       freetype                  2.10.4               h5ab3b9f_0
       future                    0.18.2           py38h578d9bd_2    conda-forge
       gast                      0.3.3                    pypi_0    pypi
       gitdb                     4.0.5                      py_0    conda-forge
       gitpython                 3.1.11                     py_0    conda-forge
       glib                      2.66.1               h92f7085_0
       google-auth               1.23.0                   pypi_0    pypi
       google-auth-oauthlib      0.4.2                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       gorilla                   0.3.0                      py_0    conda-forge
       grpcio                    1.32.0                   pypi_0    pypi
       gst-plugins-base          1.14.0               hbbd80ab_1
       gstreamer                 1.14.0               hb31296c_0
       gunicorn                  20.0.4           py38h32f6830_2    conda-forge
       h5py                      2.10.0                   pypi_0    pypi
       icu                       58.2                 he6710b0_3
       idna                      2.10                       py_0
       importlib-metadata        2.0.0                      py_1
       importlib_metadata        2.0.0                         1
       intel-openmp              2020.2                      254
       ipykernel                 5.3.4            py38h5ca1d4c_0
       ipython                   7.18.1           py38h5ca1d4c_0
       ipython_genutils          0.2.0                    py38_0
       isodate                   0.6.0                      py_1    conda-forge
       itsdangerous              1.1.0                      py_0    conda-forge
       jedi                      0.17.2                   py38_0
       jinja2                    2.11.2                     py_0
       jpeg                      9b                   h024ee3a_2
       json5                     0.9.5                      py_0
       jsonschema                3.2.0                      py_2
       jupyter_client            6.1.7                      py_0
       jupyter_core              4.6.3                    py38_0
       jupyterlab                2.2.6                      py_0
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         1.2.0                      py_0
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.0            py38h2531618_0
       lcms2                     2.11                 h396b838_0
       ld_impl_linux-64          2.33.1               h53a641e_7
       libedit                   3.1.20191231         h14c3975_1
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.1.0                hdf63c60_0
       libgfortran-ng            7.3.0                hdf63c60_0
       libpng                    1.6.37               hbc83047_0
       libprotobuf               3.13.0.1             h8b12597_0    conda-forge
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.1.0                hdf63c60_0
       libtiff                   4.1.0                h2733197_1
       libuuid                   1.0.3                h1bed415_2
       libxcb                    1.14                 h7b6447c_0
       libxml2                   2.9.10               hb55368b_3
       lmfit                     1.0.1                      py_1    conda-forge
       lz4-c                     1.9.2                heb0550a_3
       mako                      1.1.3              pyh9f0ad1d_0    conda-forge
       markdown                  3.3.3                    pypi_0    pypi
       markupsafe                1.1.1            py38h7b6447c_0
       matplotlib                3.3.2                         0
       matplotlib-base           3.3.2            py38h817c723_0
       mistune                   0.8.4           py38h7b6447c_1000
       mkl                       2020.2                      256
       mkl-service               2.3.0            py38he904b0f_0
       mkl_fft                   1.2.0            py38h23d657b_0
       mkl_random                1.1.1            py38h0573a6f_0
       mlflow                    1.11.0           py38h32f6830_1    conda-forge
       msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
       multipletau               0.3.3                    pypi_0    pypi
       nbclient                  0.5.1                      py_0
       nbconvert                 6.0.7                    py38_0
       nbformat                  5.0.8                      py_0
       ncurses                   6.2                  he6710b0_1
       nest-asyncio              1.4.1                      py_0
       notebook                  6.1.4                    py38_0
       numpy                     1.19.2           py38h54aff64_0
       numpy-base                1.19.2           py38hfa32c7d_0
       oauthlib                  3.0.1                      py_0    conda-forge
       olefile                   0.46                       py_0
       openssl                   1.1.1h               h516909a_0    conda-forge
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 20.4                       py_0
       pandas                    1.1.3            py38he6710b0_0
       pandoc                    2.11                 hb0f4dca_0
       pandocfilters             1.4.2                    py38_1
       parso                     0.7.0                      py_0
       pcre                      8.44                 he6710b0_0
       pexpect                   4.8.0                    py38_0
       pickleshare               0.7.5                 py38_1000
       pillow                    8.0.1            py38he98fc37_0
       pip                       20.2.4                   py38_0
       prometheus_client         0.8.0                      py_0
       prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
       prompt-toolkit            3.0.8                      py_0
       protobuf                  3.13.0.1         py38h950e882_1    conda-forge
       ptyprocess                0.6.0                    py38_0
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.20                       py_2
       pygments                  2.7.2              pyhd3eb1b0_0
       pyjwt                     1.7.1                      py_0    conda-forge
       pyopenssl                 19.1.0                     py_1
       pyparsing                 2.4.7                      py_0
       pyqt                      5.9.2            py38h05f1152_4
       pyrsistent                0.17.3           py38h7b6447c_0
       pysocks                   1.7.1                    py38_0
       python                    3.8.5                h7579374_1
       python-dateutil           2.8.1                      py_0
       python-editor             1.0.4                      py_0    conda-forge
       python_abi                3.8                      1_cp38    conda-forge
       pytz                      2020.1                     py_0
       pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
       pyzmq                     19.0.2           py38he6710b0_1
       qt                        5.9.7                h5867ecd_1
       querystring_parser        1.2.4                      py_0    conda-forge
       readline                  8.0                  h7b6447c_0
       requests                  2.24.0                     py_0
       requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
       rsa                       4.6                      pypi_0    pypi
       scipy                     1.5.2            py38h0b6359f_0
       seaborn                   0.11.0                     py_0
       send2trash                1.5.0                    py38_0
       setuptools                50.3.0           py38hb0f4dca_1
       sip                       4.19.13          py38he6710b0_0
       six                       1.15.0                     py_0
       smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
       sqlalchemy                1.3.13           py38h516909a_0    conda-forge
       sqlite                    3.33.0               h62c20be_0
       sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
       tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
       tb-nightly                2.4.0a20201102           pypi_0    pypi
       tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.1                    py38_0
       testpath                  0.4.4                      py_0
       tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
       tf-nightly                2.5.0.dev20201029          pypi_0    pypi
       tifffile                  2020.10.1        py38hdd07704_2
       tk                        8.6.10               hbc83047_0
       tornado                   6.0.4            py38h7b6447c_1
       traitlets                 5.0.5                      py_0
       typing-extensions         3.7.4.3                  pypi_0    pypi
       uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge
       urllib3                   1.25.11                    py_0
       wcwidth                   0.2.5                      py_0
       webencodings              0.5.1                    py38_1
       websocket-client          0.57.0           py38h32f6830_3    conda-forge
       werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
       wheel                     0.35.1                     py_0
       wrapt                     1.12.1                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       yaml                      0.2.5                h516909a_0    conda-forge
       zeromq                    4.3.3                he6710b0_3
       zipp                      3.4.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7b6447c_3
       zstd                      1.4.5                h9ceee32_0
       Note: you may need to restart the kernel to use updated packages.
       # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       absl-py                   0.11.0                   pypi_0    pypi
       alembic                   1.4.1                      py_0    conda-forge
       appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
       argon2-cffi               20.1.0           py38h7b6447c_1
       asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
       asteval                   0.9.16             pyh5ca1d4c_0    conda-forge
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10                       py_0
       attrs                     20.2.0                     py_0
       azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
       azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
       backcall                  0.2.0                      py_0
       blas                      1.0                         mkl
       bleach                    3.2.1                      py_0
       blinker                   1.4                        py_1    conda-forge
       brotlipy                  0.7.0           py38h7b6447c_1000
       ca-certificates           2020.12.5            ha878542_0    conda-forge
       cachetools                4.1.1                    pypi_0    pypi
       certifi                   2020.12.5        py38h578d9bd_0    conda-forge
       cffi                      1.14.3           py38he30daa8_0
       chardet                   3.0.4                 py38_1003
       click                     7.1.2              pyh9f0ad1d_0    conda-forge
       cloudpickle               1.6.0                      py_0    conda-forge
       configparser              5.0.1                      py_0    conda-forge
       cryptography              3.1.1            py38h1ba5d50_0
       cycler                    0.10.0                   py38_0
       databricks-cli            0.9.1                      py_0    conda-forge
       dbus                      1.13.18              hb2f20db_0
       decorator                 4.4.2                      py_0
       defusedxml                0.6.0                      py_0
       docker-py                 4.3.1            py38h32f6830_1    conda-forge
       docker-pycreds            0.4.0                      py_0    conda-forge
       entrypoints               0.3                      py38_0
       expat                     2.2.10               he6710b0_2
       fcsfiles                  2020.9.18                pypi_0    pypi
       flask                     1.1.2              pyh9f0ad1d_0    conda-forge
       flatbuffers               1.12                     pypi_0    pypi
       fontconfig                2.13.0               h9420a91_0
       freetype                  2.10.4               h5ab3b9f_0
       future                    0.18.2           py38h578d9bd_2    conda-forge
       gast                      0.3.3                    pypi_0    pypi
       gitdb                     4.0.5                      py_0    conda-forge
       gitpython                 3.1.11                     py_0    conda-forge
       glib                      2.66.1               h92f7085_0
       google-auth               1.23.0                   pypi_0    pypi
       google-auth-oauthlib      0.4.2                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       gorilla                   0.3.0                      py_0    conda-forge
       grpcio                    1.32.0                   pypi_0    pypi
       gst-plugins-base          1.14.0               hbbd80ab_1
       gstreamer                 1.14.0               hb31296c_0
       gunicorn                  20.0.4           py38h32f6830_2    conda-forge
       h5py                      2.10.0                   pypi_0    pypi
       icu                       58.2                 he6710b0_3
       idna                      2.10                       py_0
       importlib-metadata        2.0.0                      py_1
       importlib_metadata        2.0.0                         1
       intel-openmp              2020.2                      254
       ipykernel                 5.3.4            py38h5ca1d4c_0
       ipython                   7.18.1           py38h5ca1d4c_0
       ipython_genutils          0.2.0                    py38_0
       isodate                   0.6.0                      py_1    conda-forge
       itsdangerous              1.1.0                      py_0    conda-forge
       jedi                      0.17.2                   py38_0
       jinja2                    2.11.2                     py_0
       jpeg                      9b                   h024ee3a_2
       json5                     0.9.5                      py_0
       jsonschema                3.2.0                      py_2
       jupyter_client            6.1.7                      py_0
       jupyter_core              4.6.3                    py38_0
       jupyterlab                2.2.6                      py_0
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         1.2.0                      py_0
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.0            py38h2531618_0
       lcms2                     2.11                 h396b838_0
       ld_impl_linux-64          2.33.1               h53a641e_7
       libedit                   3.1.20191231         h14c3975_1
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.1.0                hdf63c60_0
       libgfortran-ng            7.3.0                hdf63c60_0
       libpng                    1.6.37               hbc83047_0
       libprotobuf               3.13.0.1             h8b12597_0    conda-forge
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.1.0                hdf63c60_0
       libtiff                   4.1.0                h2733197_1
       libuuid                   1.0.3                h1bed415_2
       libxcb                    1.14                 h7b6447c_0
       libxml2                   2.9.10               hb55368b_3
       lmfit                     1.0.1                      py_1    conda-forge
       lz4-c                     1.9.2                heb0550a_3
       mako                      1.1.3              pyh9f0ad1d_0    conda-forge
       markdown                  3.3.3                    pypi_0    pypi
       markupsafe                1.1.1            py38h7b6447c_0
       matplotlib                3.3.2                         0
       matplotlib-base           3.3.2            py38h817c723_0
       mistune                   0.8.4           py38h7b6447c_1000
       mkl                       2020.2                      256
       mkl-service               2.3.0            py38he904b0f_0
       mkl_fft                   1.2.0            py38h23d657b_0
       mkl_random                1.1.1            py38h0573a6f_0
       mlflow                    1.11.0           py38h32f6830_1    conda-forge
       msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
       multipletau               0.3.3                    pypi_0    pypi
       nbclient                  0.5.1                      py_0
       nbconvert                 6.0.7                    py38_0
       nbformat                  5.0.8                      py_0
       ncurses                   6.2                  he6710b0_1
       nest-asyncio              1.4.1                      py_0
       notebook                  6.1.4                    py38_0
       numpy                     1.19.2           py38h54aff64_0
       numpy-base                1.19.2           py38hfa32c7d_0
       oauthlib                  3.0.1                      py_0    conda-forge
       olefile                   0.46                       py_0
       openssl                   1.1.1h               h516909a_0    conda-forge
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 20.4                       py_0
       pandas                    1.1.3            py38he6710b0_0
       pandoc                    2.11                 hb0f4dca_0
       pandocfilters             1.4.2                    py38_1
       parso                     0.7.0                      py_0
       pcre                      8.44                 he6710b0_0
       pexpect                   4.8.0                    py38_0
       pickleshare               0.7.5                 py38_1000
       pillow                    8.0.1            py38he98fc37_0
       pip                       20.2.4                   py38_0
       prometheus_client         0.8.0                      py_0
       prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
       prompt-toolkit            3.0.8                      py_0
       protobuf                  3.13.0.1         py38h950e882_1    conda-forge
       ptyprocess                0.6.0                    py38_0
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.20                       py_2
       pygments                  2.7.2              pyhd3eb1b0_0
       pyjwt                     1.7.1                      py_0    conda-forge
       pyopenssl                 19.1.0                     py_1
       pyparsing                 2.4.7                      py_0
       pyqt                      5.9.2            py38h05f1152_4
       pyrsistent                0.17.3           py38h7b6447c_0
       pysocks                   1.7.1                    py38_0
       python                    3.8.5                h7579374_1
       python-dateutil           2.8.1                      py_0
       python-editor             1.0.4                      py_0    conda-forge
       python_abi                3.8                      1_cp38    conda-forge
       pytz                      2020.1                     py_0
       pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
       pyzmq                     19.0.2           py38he6710b0_1
       qt                        5.9.7                h5867ecd_1
       querystring_parser        1.2.4                      py_0    conda-forge
       readline                  8.0                  h7b6447c_0
       requests                  2.24.0                     py_0
       requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
       rsa                       4.6                      pypi_0    pypi
       scipy                     1.5.2            py38h0b6359f_0
       seaborn                   0.11.0                     py_0
       send2trash                1.5.0                    py38_0
       setuptools                50.3.0           py38hb0f4dca_1
       sip                       4.19.13          py38he6710b0_0
       six                       1.15.0                     py_0
       smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
       sqlalchemy                1.3.13           py38h516909a_0    conda-forge
       sqlite                    3.33.0               h62c20be_0
       sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
       tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
       tb-nightly                2.4.0a20201102           pypi_0    pypi
       tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.1                    py38_0
       testpath                  0.4.4                      py_0
       tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
       tf-nightly                2.5.0.dev20201029          pypi_0    pypi
       tifffile                  2020.10.1        py38hdd07704_2
       tk                        8.6.10               hbc83047_0
       tornado                   6.0.4            py38h7b6447c_1
       traitlets                 5.0.5                      py_0
       typing-extensions         3.7.4.3                  pypi_0    pypi
       uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge
       urllib3                   1.25.11                    py_0
       wcwidth                   0.2.5                      py_0
       webencodings              0.5.1                    py38_1
       websocket-client          0.57.0           py38h32f6830_3    conda-forge
       werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
       wheel                     0.35.1                     py_0
       wrapt                     1.12.1                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       yaml                      0.2.5                h516909a_0    conda-forge
       zeromq                    4.3.3                he6710b0_3
       zipp                      3.4.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7b6447c_3
       zstd                      1.4.5                h9ceee32_0

       Note: you may need to restart the kernel to use updated packages.
     #+end_example

     #+BEGIN_SRC jupyter-python
       import sys
       sys.path.append('/beegfs/ye53nis/drmed-git/src/')
       from fluotracify.simulations import simulate_trace_with_artifact as stwa
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       folder = '/beegfs/ye53nis/saves/firstartifact_Nov2020/'
       file_name = 'traces_brightclust_Nov2020'
       total_sim_time = 16384
       d_mol_arr = [100]
       col_per_example = 3
       label_for = 'both'
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       sys.stdout = open('/dev/stdout', 'w')
     #+END_SRC

     #+RESULTS:



     #+BEGIN_SRC jupyter-python :results drawer
       stwa.produce_training_data(folder=folder,
                                  file_name=file_name,
                                  col_per_example=col_per_example,
                                  number_of_sets=2,
                                  traces_per_set=2,
                                  total_sim_time=total_sim_time,
                                  artifact=1,
                                  d_mol_arr=d_mol_arr,
                                  label_for=label_for)
     #+END_SRC

     #+RESULTS:
     :results:
     : 188c4766-8d0a-4c1d-97ef-ab2d2e218d33
     :end:

*** Reading End-to-End Lung cancer screening (Ardila, Kiraly, Bharadwaj, Choi et al, 2019)
    - link: [[docview:~/Dokumente/Forschung/Literatur/ML-applications/Ardila, D.
      End-to-end lung cancer screening 3D DL on low-dose chest CT_PRINTED.pdf]]


    - try Focal Loss [[docview:~/Dokumente/Forschung/Literatur/maths/Lin, T-Y et
      al (Facebook). Focal Loss for Dense Object Detection.pdf]]
      - they used it for a CNN that took whole-CT volumes instead of the regular
        (balanced) Cross entropy to mitigate the sparsity of positive examples
    - use localization metrics! such as their self-defined Hit@N (although this
      is compared with a manual labelling - not sure, maybe in some subset of
      self-taken FCS curves? Maybe ask 5 FCS researchers to check?? :D)
    - In the end it was an ensemble of 10? networks or so working together. And
      I think *All* of them were pretrained!! Important! Probably because there
      were only 398 cancer-positives for training this was even more important.
      - e.g. for Cancer ROI detection first a general dataset for *nodule
        detection* then the specific dataset to only detect *malignant nodules*
      - e.g. full volume model was pretained on imagenet.
    - interesting: the end-score for prediction was combined from the two most
      malignous ROIs using the *noisy-or* equation $1 - (1 -
      p_1)(1 - p_2)$
    - also interesting: statistical evaluation
      - confidence intervals computed bassed on the percentiles of 1000 random
        resamplings (bootstraps) of the data
      - for comparison reader-model differences the metrics were computed after
        these 1000 resamplings as well
      - P values for sensitivity and specifity based on
        - standard permutation test using 10,000 random resamplings
        - for each resampling, randomly swapped reader and model results for
          each case
        - then performed a two-sided hypothesis test comparing model-reader
          difference with distribution of 10,000 model-reader differences across
          the resampled data
        - result: empirical p-value

** doing mlflow runs with training on the new simulations<2021-01-18 Mo>
*** upate tensorflow and mlflow in tensorflow_nightly environment on ara

    - we need:
    - numpy
    - pandas
    - matplotlib
    - seaborn
    - mlflow
    - jupyterlab
    - pip
    - pip:
      - tf-nightly
      - fcsfiles
      - multipletau

    #+begin_example
      conda env remove tf-nightly
      conda create -n tf-nightly numpy pandas matplotlib seaborn tifffile jupyterlab pip
      conda install -n tf-nightly -c conda-forge/label/main mlflow
      conda activate tf-nightly
      (tf-nightly) pip install fcsfiles multipletau tf-nightly
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
      conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (base) [ye53nis@login01 ~]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      absl-py                   0.11.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge/label/m
      ain
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge/label/m
      ain
      argon2-cffi               20.1.0           py38h7b6447c_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge/label/m
      ain
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10                       py_0
      attrs                     20.3.0             pyhd3eb1b0_0
      azure-core                1.10.0             pyhd8ed1ab_0    conda-forge/label/m
      ain
      azure-storage-blob        12.7.0             pyh44b312d_0    conda-forge/label/m
      ain
      backcall                  0.2.0                      py_0
      blas                      1.0                         mkl
      bleach                    3.2.1                      py_0
      blinker                   1.4                        py_1    conda-forge/label/m
      ain
      blosc                     1.20.1               hd408876_0
      brotli                    1.0.9                he6710b0_2
      brotlipy                  0.7.0           py38h27cfd23_1003
      bzip2                     1.0.8                h7b6447c_0
      ca-certificates           2020.12.5            ha878542_0    conda-forge/label/m
      ain
      cachetools                4.2.0                    pypi_0    pypi
      certifi                   2020.12.5        py38h578d9bd_1    conda-forge/label/m
      ain
      cffi                      1.14.4           py38h261ae71_0
      chardet                   4.0.0           py38h06a4308_1003
      charls                    2.1.0                he6710b0_2
      click                     7.1.2              pyh9f0ad1d_0    conda-forge/label/m
      ain
      cloudpickle               1.6.0                      py_0    conda-forge/label/m
      ain
      configparser              5.0.1                      py_0    conda-forge/label/m
      ain
      cryptography              3.3.1            py38h3c74f83_0
      cycler                    0.10.0                   py38_0
      databricks-cli            0.9.1                      py_0    conda-forge/label/m
      ain
      dbus                      1.13.18              hb2f20db_0
      decorator                 4.4.2                      py_0
      defusedxml                0.6.0                      py_0
      docker-py                 4.4.1            py38h578d9bd_0    conda-forge/label/m
      ain
      docker-pycreds            0.4.0                      py_0    conda-forge/label/m
      ain
      entrypoints               0.3                      py38_0
      expat                     2.2.10               he6710b0_2
      fcsfiles                  2020.9.18                pypi_0    pypi
      flask                     1.1.2              pyh9f0ad1d_0    conda-forge/label/m
      ain
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.0               h9420a91_0
      freetype                  2.10.4               h5ab3b9f_0
      gast                      0.4.0                    pypi_0    pypi
      giflib                    5.1.4                h14c3975_1
      gitdb                     4.0.5                      py_0    conda-forge/label/m
      ain
      gitpython                 3.1.12             pyhd8ed1ab_0    conda-forge/label/m
      ain
      glib                      2.66.1               h92f7085_0
      google-auth               1.24.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.2                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      gorilla                   0.3.0                      py_0    conda-forge/label/m
      ain
      grpcio                    1.34.1                   pypi_0    pypi
      gst-plugins-base          1.14.0               h8213a91_2
      gstreamer                 1.14.0               h28cd5cc_2
      gunicorn                  20.0.4           py38h578d9bd_3    conda-forge/label/m
      ain
      h5py                      3.1.0                    pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10                       py_0
      imagecodecs               2020.5.30        py38hfa7d478_2
      importlib-metadata        2.0.0                      py_1
      importlib_metadata        2.0.0                         1
      intel-openmp              2020.2                      254
      ipykernel                 5.3.4            py38h5ca1d4c_0
      ipython                   7.19.0           py38hb070fc8_0
      ipython_genutils          0.2.0              pyhd3eb1b0_1
      isodate                   0.6.0                      py_1    conda-forge/label/m
      ain
      itsdangerous              1.1.0                      py_0    conda-forge/label/m
      ain
      jedi                      0.18.0           py38h06a4308_0
      jinja2                    2.11.2                     py_0
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.5                      py_0
      jsonschema                3.2.0                      py_2
      jupyter_client            6.1.7                      py_0
      jupyter_core              4.7.0            py38h06a4308_0
      jupyterlab                2.2.6                      py_0
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         1.2.0                      py_0
      jxrlib                    1.1                  h7b6447c_2
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.0            py38h2531618_0
      lcms2                     2.11                 h396b838_0
      ld_impl_linux-64          2.33.1               h53a641e_7
      libaec                    1.0.4                he6710b0_1
      libedit                   3.1.20191231         h14c3975_1
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.1.0                hdf63c60_0
      libgfortran-ng            7.3.0                hdf63c60_0
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.13.0.1             h8b12597_0    conda-forge/label/m
      ain
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.1.0                hdf63c60_0
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libwebp                   1.0.1                h8e7db2f_0
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.10               hb55368b_3
      libzopfli                 1.0.3                he6710b0_0
      lz4-c                     1.9.2                heb0550a_3
      mako                      1.1.4              pyh44b312d_0    conda-forge/label/m
      ain
      markdown                  3.3.3                    pypi_0    pypi
      markupsafe                1.1.1            py38h7b6447c_0
      matplotlib                3.3.2                h06a4308_0
      matplotlib-base           3.3.2            py38h817c723_0
      mistune                   0.8.4           py38h7b6447c_1000
      mkl                       2020.2                      256
      mkl-service               2.3.0            py38he904b0f_0
      mkl_fft                   1.2.0            py38h23d657b_0
      mkl_random                1.1.1            py38h0573a6f_0
      mlflow                    1.13.1           py38h578d9bd_0    conda-forge/label/m
      ain
      msrest                    0.6.19             pyh9f0ad1d_0    conda-forge/label/m
      ain
      multipletau               0.3.3                    pypi_0    pypi
      nbclient                  0.5.1                      py_0
      nbconvert                 6.0.7                    py38_0
      nbformat                  5.1.2              pyhd3eb1b0_1
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.4.3              pyhd3eb1b0_0
      notebook                  6.1.6            py38h06a4308_0
      numpy                     1.19.2           py38h54aff64_0
      numpy-base                1.19.2           py38hfa32c7d_0
      oauthlib                  3.0.1                      py_0    conda-forge/label/m
      ain
      olefile                   0.46                       py_0
      openjpeg                  2.3.0                h05c96fa_1
      openssl                   1.1.1i               h27cfd23_0
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 20.8               pyhd3eb1b0_0
      pandas                    1.2.0            py38ha9443f7_0
      pandoc                    2.11                 hb0f4dca_0
      pandocfilters             1.4.3            py38h06a4308_1
      parso                     0.7.0                      py_0
      pcre                      8.44                 he6710b0_0
      pexpect                   4.8.0              pyhd3eb1b0_3
      pickleshare               0.7.5           pyhd3eb1b0_1003
      pillow                    8.1.0            py38he98fc37_0
      pip                       20.3.3           py38h06a4308_0
      prometheus_client         0.9.0              pyhd3eb1b0_0
      prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge/label/m
      ain
      prompt-toolkit            3.0.8                      py_0
      protobuf                  3.13.0.1         py38hadf7658_1    conda-forge/label/m
      ain
      ptyprocess                0.7.0              pyhd3eb1b0_2
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.7.4              pyhd3eb1b0_0
      pyjwt                     2.0.1              pyhd8ed1ab_0    conda-forge/label/m
      ain
      pyopenssl                 20.0.1             pyhd3eb1b0_1
      pyparsing                 2.4.7                      py_0
      pyqt                      5.9.2            py38h05f1152_4
      pyrsistent                0.17.3           py38h7b6447c_0
      pysocks                   1.7.1            py38h06a4308_0
      python                    3.8.5                h7579374_1
      python-dateutil           2.8.1                      py_0
      python-editor             1.0.4                      py_0    conda-forge/label/m
      ain
      python_abi                3.8                      1_cp38    conda-forge/label/m
      ain
      pytz                      2020.5             pyhd3eb1b0_0
      pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge/label/m
      ain
      pyzmq                     20.0.0           py38h2531618_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge/label/m
      ain
      readline                  8.0                  h7b6447c_0
      requests                  2.25.1             pyhd3eb1b0_0
      requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge/label/m
      ain
      rsa                       4.7                      pypi_0    pypi
      scipy                     1.5.2            py38h0b6359f_0
      seaborn                   0.11.1             pyhd3eb1b0_0
      send2trash                1.5.0              pyhd3eb1b0_1
      setuptools                51.1.2           py38h06a4308_4
      sip                       4.19.13          py38he6710b0_0
      six                       1.15.0           py38h06a4308_0
      smmap                     3.0.4              pyh9f0ad1d_0    conda-forge/label/m
      ain
      snappy                    1.1.8                he6710b0_0
      sqlalchemy                1.3.20           py38h1e0a361_0    conda-forge/label/m
      ain
      sqlite                    3.33.0               h62c20be_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge/label/m
      ain
      tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge/label/m
      ain
      tb-nightly                2.5.0a20210118           pypi_0    pypi
      tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.2            py38h06a4308_0
      testpath                  0.4.4                      py_0
      tf-estimator-nightly      2.5.0.dev2021011801          pypi_0    pypi
      tf-nightly                2.5.0.dev20210114          pypi_0    pypi
      tifffile                  2021.1.14          pyhd3eb1b0_1
      tk                        8.6.10               hbc83047_0
      tornado                   6.1              py38h27cfd23_0
      traitlets                 5.0.5                      py_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      urllib3                   1.26.2             pyhd3eb1b0_0
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1                    py38_1
      websocket-client          0.57.0           py38h578d9bd_4    conda-forge/label/m
      ain
      werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge/label/m
      ain
      wheel                     0.36.2             pyhd3eb1b0_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge/label/m
      ain
      zeromq                    4.3.3                he6710b0_3
      zipp                      3.4.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.5                h9ceee32_0
      (base) [ye53nis@login01 ~]$
    #+end_example

*** update =train.py=
    :LOGBOOK:
    CLOCK: [2021-01-24 So 23:40]--[2021-01-24 So 23:40] =>  0:00
    CLOCK: [2021-01-24 So 16:59]--[2021-01-24 So 17:33] =>  0:34
    CLOCK: [2021-01-24 So 15:20]--[2021-01-24 So 16:37] =>  1:17
    CLOCK: [2021-01-24 So 13:20]--[2021-01-24 So 15:02] =>  1:42
    :END:
    - note: I thought about incorporating a =MODEL_TYPE= variable to either
      train a unet or a vae, but probably it is wiser to make to training files
      =train_unet.py= and =train_vae.py=, since they are pretty different.
*** mlflow test
**** connection
    - using =ob-tmux= for script execution
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        cd /beegfs/ye53nis/drmed-git/
        git status
      #+END_SRC

      #+RESULTS:
      #+begin_example
(base) [ye53nis@login01 drmed-git]$ git status
        # On branch develop
        # Changes not staged for commit:
        #   (use "git add <file>..." to update what will be committed)
        #   (use "git checkout -- <file>..." to discard changes in working directory)
        #   (commit or discard the untracked or modified content in submodules)
        #
        #       modified:   src/nanosimpy (new commits, untracked content)
        #
        # Untracked files:
        #   (use "git add <file>..." to include in what will be committed)
        #
        #       .data/
        #       2021-03-20_correlations.csv
        #       data/0.069.svg
        #       data/exp-210204-unet/
        #       data/exp-devtest/
        #       data/exp-test/
        #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
        #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
        #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
        #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
        #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
        #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
        #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
        #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
        #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
        #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
        #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
        #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
        #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
        #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
        #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
        #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
        #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
        #       data/mlruns/2/
        #       data/mlruns/3/
        #       data/tb/
        #       experiment_params.csv
        #       mlruns/
        #       tramp.YDPCnB
        no changes added to commit (use "git add" and/or "git commit -a")
        (base) [ye53nis@login01 drmed-git]$
      #+end_example

**** mlflow environment variables
  #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    conda activate tf-nightly
    cd /beegfs/ye53nis/drmed-git
    export MLFLOW_EXPERIMENT_NAME=exp-210124-test
    export MLFLOW_TRACKING_URI=file:./data/mlruns
    mkdir data/exp-210124-test
  #+END_SRC

**** test run 1
  #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_per_epoch=400 -P validation_steps=200
  #+END_SRC

  #+RESULTS:
  #+begin_example
    (tf-nightly) [ye53nis@node144 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_
    Nov2020 -P steps_per_epoch=400 -P validation_steps=200

    WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file './data/mlruns/mlruns/meta.yaml' does not exist.
    Traceback (most recent call last):
      File "/home/ye53nis/.conda/envs/tf-nightly/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 237, in list_experiments
        experiment = self._get_experiment(exp_id, view_type)
      File "/home/ye53nis/.conda/envs/tf-nightly/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 311, in _get_experiment
        meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
      File "/home/ye53nis/.conda/envs/tf-nightly/lib/python3.8/site-packages/mlflow/utils/file_utils.py", line 170, in read_yaml
        raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
    mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/mlruns/meta.yaml' does not exist.

    2021/01/24 14:09:00 INFO mlflow.projects.utils: === Created directory /tmp/tmptk14etsx for downloading remote URIs passed to arguments of type 'path' ===

    2021/01/24 14:09:00 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d
    54a736a4e4b 1>&2 && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Nov2020 3 --steps_per_epoch 400 --validati
    on_steps 200' in run with ID 'f5b912f975064cd89906212dc8cdc223' ===

    2021-01-24 14:09:02.201110: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shar
    ed object file: No such file or directory

    2021-01-24 14:09:02.201155: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is
    deprecated in favour of importlib; see the module's documentation for alternative uses
      import imp
    2.3.0-dev20200527

    2021-01-24 14:09:04.694755: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object
    file: No such file or directory
    2021-01-24 14:09:04.694795: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
    2021-01-24 14:09:04.694823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node144): /proc/driver/nvidia/version does not exist
    GPUs:  []

    train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set007.csv
    train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set007.csv
    train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set003.csv
    train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set006.csv
    train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set006.csv
    train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set004.csv
    train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set007.csv
    train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set004.csv
    train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set005.csv
    train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set006.csv
    train 10 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set004.csv
    train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set003.csv
    train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set009.csv
    train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set004.csv
    train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set008.csv
    train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set001.csv
    train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set003.csv
    train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
    train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set004.csv
    train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set009.csv
    train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set004.csv
    train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set003.csv
    train 22 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set004.csv
    train 23 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set002.csv
    train 24 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set006.csv
    train 25 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set009.csv
    train 26 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set007.csv
    train 27 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set010.csv
    train 28 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set003.csv
    train 29 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set007.csv
    train 30 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
    train 31 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set001.csv
    train 32 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set001.csv
    train 33 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set009.csv
    train 34 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set002.csv
    train 35 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set008.csv
    train 36 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set009.csv
    train 37 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set007.csv
    train 38 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set004.csv
    train 39 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set005.csv
    train 40 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set002.csv
    train 41 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
    train 42 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set003.csv
    train 43 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set002.csv
    train 44 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set005.csv
    train 45 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set006.csv
    train 46 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set008.csv
    train 47 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set001.csv
    train 48 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set009.csv
    train 49 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set006.csv
    train 50 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set002.csv
    train 51 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set010.csv
    train 52 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set001.csv
    train 53 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set005.csv
    train 54 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set009.csv
    train 55 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set001.csv
    train 56 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set002.csv
    train 57 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set006.csv
    train 58 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set004.csv
    train 59 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set003.csv
    train 60 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set001.csv
    train 61 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set002.csv
    train 62 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set007.csv
    train 63 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set008.csv
    train 64 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set010.csv
    train 65 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set006.csv
    train 66 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set003.csv
    train 67 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set005.csv
    train 68 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set005.csv
    train 69 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set010.csv
    train 70 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set010.csv
    train 71 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set010.csv
    train 72 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set010.csv
    train 73 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set008.csv
    train 74 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set009.csv
    train 75 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set010.csv
    train 76 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set001.csv
    train 77 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set005.csv
    train 78 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set003.csv
    train 79 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set008.csv
    test 80 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set006.csv
    test 81 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set008.csv
    test 82 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set002.csv
    test 83 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set007.csv
    test 84 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set010.csv
    test 85 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set006.csv
    test 86 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set009.csv
    test 87 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set003.csv
    test 88 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set009.csv
    test 89 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set001.csv
    test 90 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set008.csv
    test 91 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set007.csv
    test 92 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set002.csv
    test 93 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set004.csv
    test 94 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set010.csv
    test 95 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set007.csv
    test 96 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
    test 97 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
    test 98 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set008.csv
    test 99 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set005.csv
    The given DataFrame was split into 3 parts with shapes: [(16384, 8000), (16384, 8000), (16384, 8000)]
    The given DataFrame was split into 3 parts with shapes: [(16384, 2000), (16384, 2000), (16384, 2000)]

    for each 16384 timestap trace there are the following numbers of corrupted timesteps:
    label001_1    5916
    label002_1    7367
    label003_1     954
    label004_1    2965
    label005_1       0
    dtype: int64

    2021-01-24 14:16:01.823791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2021-01-24 14:16:01.837231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
    2021-01-24 14:16:01.838675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5629bfa11e70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
    2021-01-24 14:16:01.838706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

    number of training examples: 6400, number of validation examples: 1600

    ------------------------
    number of test examples: 2000

    input - shape:   (None, 16384, 1)
    output - shape:  (None, 16384, 1)

    2021-01-24 14:16:08.935544: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using
    or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(wrapped_dict, collections.Mapping):

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is depr
    ecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()
      all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:82: UserWarning: Logging to MLflow failed: Changing
    param values is not allowed. Param with key='steps_per_epoch' was already logged with value='400' for run ID='f5b912f975064cd89906212dc8cdc223'. Attempted logging new value '1280'.
      try_mlflow_log(mlflow.log_param, param_name, kwargs[param_name])
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:82: UserWarning: Logging to MLflow failed: Changing
    param values is not allowed. Param with key='validation_steps' was already logged with value='200' for run ID='f5b912f975064cd89906212dc8cdc223'. Attempted logging new value '320'.
      try_mlflow_log(mlflow.log_param, param_name, kwargs[param_name])

    Epoch 1/2
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or import
    ing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(values, collections.Sequence):
       1/1280 [..............................] - ETA: 0s - loss: 1.6349 - tp: 7634.0000 - fp: 34786.0000 - tn: 37126.0000 - fn: 2374.0000 - precision: 0.1800 - recall: 0.7628 - accuracy: 0.546
    4 - auc: 0.75242021-01-24 14:16:21.837468: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tenso
    rflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
    Instructions for updating:
    use `tf.profiler.experimental.stop` instead.
    2021-01-24 14:16:23.801416: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_14_16_23
    2021-01-24 14:16:23.815974: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node1
    44.trace.json.gz
    2021-01-24 14:16:23.841986: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_14_16_23
    2021-01-24 14:16:23.842080: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_14_16
    _23/node144.memory_profile.json.gz
    2021-01-24 14:16:23.844155: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_14_16_23Dumped tool data for xplane.
    pb to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node144.xplane.pb
    Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node144.overview_page.pb
    Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node144.input_pipeline.pb
    Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node144.tensorflow_stats.pb
    Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_14_16_23/node144.kernel_stats.pb

    1280/1280 [==============================] - 2372s 2s/step - loss: 0.8691 - tp: 7587311.0000 - fp: 3861041.0000 - tn: 84008352.0000 - fn: 9400853.0000 - precision: 0.6627 - recall: 0.4466
    - accuracy: 0.8735 - auc: 0.8641 - val_loss: 4.9131 - val_tp: 4314509.0000 - val_fp: 21883082.0000 - val_tn: 16088.0000 - val_fn: 729.0000 - val_precision: 0.1647 - val_recall: 0.9998 - va
    l_accuracy: 0.1652 - val_auc: 0.6917
    Epoch 2/2
    1280/1280 [==============================] - 2362s 2s/step - loss: 0.6596 - tp: 10710472.0000 - fp: 4248825.0000 - tn: 83756520.0000 - fn: 6141762.0000 - precision: 0.7160 - recall: 0.6356
     - accuracy: 0.9009 - auc: 0.9111 - val_loss: 1.7651 - val_tp: 4185983.0000 - val_fp: 17996990.0000 - val_tn: 4019617.0000 - val_fn: 11809.0000 - val_precision: 0.1887 - val_recall: 0.9972
     - val_accuracy: 0.3130 - val_auc: 0.8461
    400/400 [==============================] - 147s 366ms/step - loss: 1.7403 - tp: 4666119.0000 - fp: 21836326.0000 - tn: 6252103.0000 - fn: 13450.0000 - precision: 0.1761 - recall: 0.9971 -
    accuracy: 0.3332 - auc: 0.8519^[[B
    WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file './data/mlruns/mlruns/meta.yaml' does not exist.
    Traceback (most recent call last):
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 197, in list_experiments
        experiment = self._get_experiment(exp_id, view_type)
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/store/tracking/file_store.py", line 260, in _get_experiment
        meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/file_utils.py", line 167, in read_yaml
        raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
    mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/mlruns/meta.yaml' does not exist.
    2021/01/24 15:37:50 INFO mlflow.projects: === Run (ID 'f5b912f975064cd89906212dc8cdc223') succeeded ===
    (tf-nightly) [ye53nis@node144 drmed-git]$ conda activate tf-nightly
  #+end_example

**** handling the mlflow run errors
     - =WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file
       './data/mlruns/mlruns/meta.yaml' does not exist.=
       - i deleted the directory =/beegfs/ye53nis/drmed-git/data/mlruns/mlruns=
     - ~mlflow/utils/autologging_utils.py:82: UserWarning: Logging to MLflow
       failed: Changing param values is not allowed. Param with
       key='steps_per_epoch' was already logged with value='400' for run
       ID='f5b912f975064cd89906212dc8cdc223'. Attempted logging new value
       '1280'. try_mlflow_log(mlflow.log_param, param_name, kwargs[param_name])~
       - noticed that =train.py= and MLproject in =develop= is older than
         =exp-310520=, so I updated the files, the errors should be less now.
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        cd /beegfs/ye53nis/drmed-git/
        git log -5
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@node144 drmed-git]$ git log -5
        commit c0dde2ec15648b3b1164af6cc365b2c1884e946c
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 16:32:33 2021 +0100

            Update train.py and MLproject to exp-3105.. state

        commit 3a2ba43088a740b8657d31483fddd6e8ff754eb6
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 15:38:07 2021 +0100

            fix mlproject parameter type

        commit 41b6a8f8ea443563f91da48798e12ef32ec91d05
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 14:07:57 2021 +0100

            update MLproject file for exp-210124-test

        commit a5bfb292560d8a4a6c7530fda32aad06fb4424e0
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 14:02:48 2021 +0100

            update train.py for exp-210124-test

        commit 3130a58bbdfcd7c56c931c8dbe99e97e8eda6a2c
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Mon Jan 18 12:13:21 2021 +0100

            Remove link to Reconnect, causes problems
        (tf-nightly) [ye53nis@node144 drmed-git]$
      #+end_example

**** test run 2
  #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_per_epoch=400 -P validation_steps=200
  #+END_SRC

  #+RESULTS:
  #+begin_example
    (tf-nightly) [ye53nis@node144 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_
    Nov2020 -P steps_per_epoch=400 -P validation_steps=200
    2021/01/24 16:37:53 INFO mlflow.projects.utils: === Created directory /tmp/tmp6tjut7ba for downloading remote URIs passed to arguments of type 'path' ===
    2021/01/24 16:37:53 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d
    54a736a4e4b 1>&2 && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Nov2020 3 400 200' in run with ID '1e41386
    11c01425ca20218eb04f3cfbe' ===
    2021-01-24 16:38:11.462411: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shar
    ed object file: No such file or directory
    2021-01-24 16:38:11.462457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is
    deprecated in favour of importlib; see the module's documentation for alternative uses
      import imp
    2.3.0-dev20200527
    2021-01-24 16:38:26.216174: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object
    file: No such file or directory
    2021-01-24 16:38:26.216212: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
    2021-01-24 16:38:26.216236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node144): /proc/driver/nvidia/version does
    not exist
    GPUs:  []
    train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set007.csv
    train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set007.csv
    train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set003.csv
    train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set006.csv
    train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set006.csv
    train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set004.csv
    train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set007.csv
    train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set004.csv
    train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set005.csv
    train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set006.csv
    train 10 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set004.csv
    train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set003.csv
    train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set009.csv
    train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set004.csv
    train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set008.csv
    train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set001.csv
    train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set003.csv
    train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
    train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set004.csv
    train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set009.csv
    train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set004.csv
    train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set003.csv
    train 22 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set004.csv
    train 23 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set002.csv
    train 24 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set006.csv
    train 25 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set009.csv
    train 26 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set007.csv
    train 27 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set010.csv
    train 28 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set003.csv
    train 29 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set007.csv
    train 30 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
    train 31 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set001.csv
    train 32 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set001.csv
    train 33 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set009.csv
    train 34 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set002.csv
    train 35 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set008.csv
    train 36 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set009.csv
    train 37 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set007.csv
    train 38 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set004.csv
    train 39 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set005.csv
    train 40 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set002.csv
    train 41 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
    train 42 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set003.csv
    train 43 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set002.csv
    train 44 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set005.csv
    train 45 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set006.csv
    train 46 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set008.csv
    train 47 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set001.csv
    train 48 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set009.csv
    train 49 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set006.csv
    train 50 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set002.csv
    train 51 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set010.csv
    train 52 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set001.csv
    train 53 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set005.csv
    train 54 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set009.csv
    train 55 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set001.csv
    train 56 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set002.csv
    train 57 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set006.csv
    train 58 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set004.csv
    train 59 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set003.csv
    train 60 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set001.csv
    train 61 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set002.csv
    train 62 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set007.csv
    train 63 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set008.csv
    train 64 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set010.csv
    train 65 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set006.csv
    train 66 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set003.csv
    train 67 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set005.csv
    train 68 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set005.csv
    train 69 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set010.csv
    train 70 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set010.csv
    train 71 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set010.csv
    train 72 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set010.csv
    train 73 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set008.csv
    train 74 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set009.csv
    train 75 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set010.csv
    train 76 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set001.csv
    train 77 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set005.csv
    train 78 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set003.csv
    train 79 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set008.csv
    test 80 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set006.csv
    test 81 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set008.csv
    test 82 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set002.csv
    test 83 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set007.csv
    test 84 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set010.csv
    test 85 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set006.csv
    test 86 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set009.csv
    test 87 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set003.csv
    test 88 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set009.csv
    test 89 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set001.csv
    test 90 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set008.csv
    test 91 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set007.csv
    test 92 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set002.csv
    test 93 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set004.csv
    test 94 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set010.csv
    test 95 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set007.csv
    test 96 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
    test 97 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
    test 98 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set008.csv
    test 99 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set005.csv
    The given DataFrame was split into 3 parts with shapes: [(16384, 8000), (16384, 8000), (16384, 8000)]
    The given DataFrame was split into 3 parts with shapes: [(16384, 2000), (16384, 2000), (16384, 2000)]

    for each 16384 timestap trace there are the following numbers of corrupted timesteps:
    label001_1    5916
    label002_1    7367
    label003_1     954
    label004_1    2965
    label005_1       0
    dtype: int64
    2021-01-24 16:44:08.463884: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performa
    nce-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2021-01-24 16:44:08.487375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
    2021-01-24 16:44:08.489752: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ede43a3150 initialized for platform Host (this does not guarantee that XLA will be used). Devi
    ces:
    2021-01-24 16:44:08.489814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
    number of training examples: 6400, number of validation examples: 1600

    ------------------------
    number of test examples: 2000

    input - shape:   (None, 16384, 1)
    output - shape:  (None, 16384, 1)
    2021-01-24 16:44:15.606199: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using
    or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(wrapped_dict, collections.Mapping):
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is depr
    ecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()
      all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
    Epoch 1/2
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or import
    ing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(values, collections.Sequence):
      1/400 [..............................] - ETA: 0s - loss: 1.6712 - tp: 5516.0000 - fp: 30470.0000 - tn: 34108.0000 - fn: 11826.0000 - precision: 0.1533 - recall: 0.3181 - accuracy: 0.4837
     - auc: 0.36132021-01-24 16:44:27.774036: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tenso
    rflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
    Instructions for updating:
    use `tf.profiler.experimental.stop` instead.
    2021-01-24 16:44:29.647304: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_16_44_29
    2021-01-24 16:44:29.661793: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node1
    44.trace.json.gz
    2021-01-24 16:44:29.687770: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_16_44_29
    2021-01-24 16:44:29.687890: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_16_44
    _29/node144.memory_profile.json.gz
    2021-01-24 16:44:29.689921: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_16_44_29Dumped tool data for xplane.
    pb to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node144.xplane.pb
    Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node144.overview_page.pb
    Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node144.input_pipeline.pb
    Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node144.tensorflow_stats.pb
    Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_16_44_29/node144.kernel_stats.pb

    400/400 [==============================] - 788s 2s/step - loss: 0.9524 - tp: 1873337.0000 - fp: 1211462.0000 - tn: 26397164.0000 - fn: 3286044.0000 - precision: 0.6073 - recall: 0.3631 - a
    ccuracy: 0.8627 - auc: 0.8330 - val_loss: 2.2494 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13826395.0000 - val_fn: 2557605.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+
    00 - val_accuracy: 0.8439 - val_auc: 0.5519
    Epoch 2/2
    400/400 [==============================] - 775s 2s/step - loss: 0.8417 - tp: 2587744.0000 - fp: 1830158.0000 - tn: 25712094.0000 - fn: 2637997.0000 - precision: 0.5857 - recall: 0.4952 - a
    ccuracy: 0.8636 - auc: 0.8632 - val_loss: 2.3885 - val_tp: 2729037.0000 - val_fp: 13653618.0000 - val_tn: 1228.0000 - val_fn: 117.0000 - val_precision: 0.1666 - val_recall: 1.0000 - val_ac
    curacy: 0.1666 - val_auc: 0.5000
    400/400 [==============================] - 146s 366ms/step - loss: 2.4490 - tp: 4679373.0000 - fp: 28085716.0000 - tn: 2715.0000 - fn: 196.0000 - precision: 0.1428 - recall: 1.0000 - accur
    acy: 0.1429 - auc: 0.5000
    2021/01/24 17:13:06 INFO mlflow.projects: === Run (ID '1e4138611c01425ca20218eb04f3cfbe') succeeded ===
  #+end_example

  - it worked

**** test run 3
     - now, I added different metrics thresholds
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@node144 drmed-git]$ git log -3
        commit 6d52eb9df66b689db47b0301a441eae3481b380a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 17:30:22 2021 +0100

            Add thresholds to metrics

        commit c0dde2ec15648b3b1164af6cc365b2c1884e946c
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 16:32:33 2021 +0100

            Update train.py and MLproject to exp-3105.. state

        commit 3a2ba43088a740b8657d31483fddd6e8ff754eb6
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 15:38:07 2021 +0100

            fix mlproject parameter type
        (tf-nightly) [ye53nis@node144 drmed-git]$
      #+end_example

  #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_per_epoch=400 -P validation_steps=200
  #+END_SRC

  #+RESULTS:
  #+begin_example
    (tf-nightly) [ye53nis@node144 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_
    per_epoch=400 -P validation_steps=200
    2021/01/24 17:33:39 INFO mlflow.projects.utils: === Created directory /tmp/tmphi3w8uva for downloading remote URIs passed to arguments of type 'path' ===

    2021/01/24 17:33:39 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2
    && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Nov2020 3 400 200' in run with ID 'd6553c4225df4f2a91a7698955ad879e' ===

    2021-01-24 17:33:56.911698: W tensorflow/stream_executor/platform/default/dso_loader.cc:55]
    Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory

    2021-01-24 17:33:56.911743: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23:
    DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
      import imp
    2.3.0-dev20200527

    2021-01-24 17:34:13.490720: W tensorflow/stream_executor/platform/default/dso_loader.cc:55]
    Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory

    2021-01-24 17:34:13.490761: E tensorflow/stream_executor/cuda/cuda_driver.cc:313]
    failed call to cuInit: UNKNOWN ERROR (303)

    2021-01-24 17:34:13.490789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156]
    kernel driver does not appear to be running on this host (node144): /proc/driver/nvidia/version does not exist
    GPUs:  []
    train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set007.csv
    train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set007.csv
    train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set003.csv
    train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set006.csv
    train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set006.csv
    train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set004.csv
    train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set007.csv
    train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set004.csv
    train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set005.csv
    train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set006.csv
    train 10 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set004.csv
    train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set003.csv
    train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set009.csv
    train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set004.csv
    train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set008.csv
    train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set001.csv
    train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set003.csv
    train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
    train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set004.csv
    train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set009.csv
    train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set004.csv
    train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set003.csv
    train 22 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set004.csv
    train 23 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set002.csv
    train 24 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set006.csv
    train 25 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set009.csv
    train 26 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set007.csv
    train 27 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set010.csv
    train 28 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set003.csv
    train 29 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set007.csv
    train 30 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
    train 31 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set001.csv
    train 32 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set001.csv
    train 33 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set009.csv
    train 34 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set002.csv
    train 35 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set008.csv
    train 36 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set009.csv
    train 37 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set007.csv
    train 38 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set004.csv
    train 39 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set005.csv
    train 40 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set002.csv
    train 41 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
    train 42 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set003.csv
    train 43 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set002.csv
    train 44 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set005.csv
    train 45 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set006.csv
    train 46 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set008.csv
    train 47 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set001.csv
    train 48 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set009.csv
    train 49 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set006.csv
    train 50 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set002.csv
    train 51 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set010.csv
    train 52 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set001.csv
    train 53 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set005.csv
    train 54 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set009.csv
    train 55 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set001.csv
    train 56 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set002.csv
    train 57 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set006.csv
    train 58 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set004.csv
    train 59 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set003.csv
    train 60 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set001.csv
    train 61 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set002.csv
    train 62 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set007.csv
    train 63 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set008.csv
    train 64 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set010.csv
    train 65 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set006.csv
    train 66 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set003.csv
    train 67 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set005.csv
    train 68 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set005.csv
    train 69 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set010.csv
    train 70 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set010.csv
    train 71 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set010.csv
    train 72 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set010.csv
    train 73 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set008.csv
    train 74 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set009.csv
    train 75 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set010.csv
    train 76 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set001.csv
    train 77 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set005.csv
    train 78 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set003.csv
    train 79 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set008.csv
    test 80 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set006.csv
    test 81 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set008.csv
    test 82 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set002.csv
    test 83 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set007.csv
    test 84 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set010.csv
    test 85 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set006.csv
    test 86 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set009.csv
    test 87 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set003.csv
    test 88 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set009.csv
    test 89 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set001.csv
    test 90 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set008.csv
    test 91 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set007.csv
    test 92 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set002.csv
    test 93 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set004.csv
    test 94 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set010.csv
    test 95 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set007.csv
    test 96 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
    test 97 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
    test 98 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set008.csv
    test 99 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set005.csv
    The given DataFrame was split into 3 parts with shapes: [(16384, 8000), (16384, 8000), (16384, 8000)]
    The given DataFrame was split into 3 parts with shapes: [(16384, 2000), (16384, 2000), (16384, 2000)]

    for each 16384 timestap trace there are the following numbers of corrupted timesteps:
    label001_1    5916
    label002_1    7367
    label003_1     954
    label004_1    2965
    label005_1       0
    dtype: int64

    2021-01-24 17:39:46.169724: I tensorflow/core/platform/cpu_feature_guard.cc:142]
    This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

    2021-01-24 17:39:46.193704: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
    2021-01-24 17:39:46.195281: I tensorflow/compiler/xla/service/service.cc:168]
    XLA service 0x557dbec99910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
    2021-01-24 17:39:46.195324: I tensorflow/compiler/xla/service/service.cc:176]
    StreamExecutor device (0): Host, Default Version

    number of training examples: 6400, number of validation examples: 1600

    ------------------------
    number of test examples: 2000

    input - shape:   (None, 16384, 1)
    output - shape:  (None, 16384, 1)

    2021-01-24 17:39:53.134766: I tensorflow/core/profiler/lib/profiler_session.cc:163]
    Profiler session started.

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739:
    DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(wrapped_dict, collections.Mapping):

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60:
    DeprecationWarning: inspect.getargspec() is deprecated since Pyth on 3.0, use inspect.signature() or inspect.getfullargspec()
      all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505

    Epoch 1/2
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347:
    DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(values, collections.Sequence):

    1/400 [..............................] - ETA: 0s - loss: 1.7399 - tp0.1: 18220.0000 - fp0.1: 60980.0000 - tn0.1: 356.0000 - fn0.1: 2364.0000 - precision0.1: 0.2301 - recall0.1: 0.8852 - tp0.3: 14954.0000
     - fp0.3: 58473.0000 - tn0.3: 2863.0000 - fn0.3: 5630.0000 - precision0.3: 0.2037 - recall0.3: 0.7265 - tp0.5: 10538.0000 - fp0.5: 40621.0000 - tn0.5: 20715.0000 - fn0.5: 10046.0000 - precision0.5: 0.2060
    - recall0.5: 0.5120 - tp0.7: 3030.0000 - fp0.7: 5693.0000 - tn0.7: 55643.0000 - fn0.7: 17554.0000 - precision0.7: 0.3474 - recall0.7: 0.1472 - tp0.9: 239.0000 - fp0.9: 40.0000 - tn0.9: 61296.0000 - fn0.9:
    20345.0000 - precision0.9: 0.8566 - recall0.9: 0.0116 - accuracy: 0.3815 - auc: 0.41952021-01-24 17:40:08.260612: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.

    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277:
    stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
    Instructions for updating:
    use `tf.profiler.experimental.stop` instead.

    2021-01-24 17:40:10.197977: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_17_40_10
    2021-01-24 17:40:10.213131: I tensorflow/core/profiler/rpc/client/save_profile.cc:182]
    Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.trace.json.gz

    2021-01-24 17:40:10.241238: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_17_40_10
    2021-01-24 17:40:10.241346: I tensorflow/core/profiler/rpc/client/save_profile.cc:182]
    Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.memory_profile.json.gz

    2021-01-24 17:40:10.243564: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2021_01_24_17_40_10
    Dumped tool data for xplane.pb to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.xplane.pb
    Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.overview_page.pb
    Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.input_pipeline.pb
    Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.tensorflow_stats.pb
    Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_01_24_17_40_10/node144.kernel_stats.pb

    400/400 [==============================] - 792s 2s/step - loss: 0.9683 - tp0.1: 4671384.0000 - fp0.1: 9937972.0000 - tn0.1: 17502688.0000 - fn0.1: 655955.0000 - precision0.1: 0.3198 - recall0.1: 0.8769 - t
    p0.3: 3404591.0000 - fp0.3: 4285173.0000 - tn0.3: 23155480.0000 - fn0.3: 1922748.0000 - precision0.3: 0.4427 - recall0.3: 0.6391 - tp0.5: 2027859.0000 - fp0.5: 1223185.0000 - tn0.5: 26217472.0000 - fn0.5:
    3299480.0000 - precision0.5: 0.6238 - recall0.5: 0.3807 - tp0.7: 1313035.0000 - fp0.7: 459862.0000 - tn0.7: 26980796.0000 - fn0.7: 4014304.0000 - precision0.7: 0.7406 - recall0.7: 0.2465 - tp0.9: 736340.00
    00 - fp0.9: 108655.0000 - tn0.9: 27332008.0000 - fn0.9: 4590999.0000 - precision0.9: 0.8714 - recall0.9: 0.1382 - accuracy: 0.8620 - auc: 0.8371 - val_loss: 2.0578 - val_tp0.1: 2786779.0000 - val_fp0.1: 13
    596213.0000 - val_tn0.1: 975.0000 - val_fn0.1: 33.0000 - val_precision0.1: 0.1701 - val_recall0.1: 1.0000 - val_tp0.3: 2786330.0000 - val_fp0.3: 13593902.0000 - val_tn0.3: 3286.0000 - val_fn0.3: 482.0000 -
     val_precision0.3: 0.1701 - val_recall0.3: 0.9998 - val_tp0.5: 2408678.0000 - val_fp0.5: 5401328.0000 - val_tn0.5: 8195860.0000 - val_fn0.5: 378134.0000 - val_precision0.5: 0.3084 - val_recall0.5: 0.8643 -
     val_tp0.7: 1879361.0000 - val_fp0.7: 2374034.0000 - val_tn0.7: 11223154.0000 - val_fn0.7: 907451.0000 - val_precision0.7: 0.4418 - val_recall0.7: 0.6744 - val_tp0.9: 1471625.0000 - val_fp0.9: 1406943.0000
     - val_tn0.9: 12190245.0000 - val_fn0.9: 1315187.0000 - val_precision0.9: 0.5112 - val_recall0.9: 0.5281 - val_accuracy: 0.6472 - val_auc: 0.8207
    Epoch 2/2
    400/400 [==============================] - 776s 2s/step - loss: 0.8824 - tp0.1: 4726115.0000 - fp0.1: 9077375.0000 - tn0.1: 18390350.0000 - fn0.1: 574156.0000 - precision0.1: 0.3424 - recall0.1: 0.8917 - t
    p0.3: 3909726.0000 - fp0.3: 5346504.0000 - tn0.3: 22121232.0000 - fn0.3: 1390545.0000 - precision0.3: 0.4224 - recall0.3: 0.7376 - tp0.5: 2022515.0000 - fp0.5: 1073844.0000 - tn0.5: 26393872.0000 - fn0.5:
    3277756.0000 - precision0.5: 0.6532 - recall0.5: 0.3816 - tp0.7: 1323051.0000 - fp0.7: 346151.0000 - tn0.7: 27121556.0000 - fn0.7: 3977220.0000 - precision0.7: 0.7926 - recall0.7: 0.2496 - tp0.9: 672639.00
    00 - fp0.9: 41376.0000 - tn0.9: 27426336.0000 - fn0.9: 4627632.0000 - precision0.9: 0.9421 - recall0.9: 0.1269 - accuracy: 0.8672 - auc: 0.8494 - val_loss: 1.1392 - val_tp0.1: 2121043.0000 - val_fp0.1: 295
    4319.0000 - val_tn0.1: 10807475.0000 - val_fn0.1: 501163.0000 - val_precision0.1: 0.4179 - val_recall0.1: 0.8089 - val_tp0.3: 1335232.0000 - val_fp0.3: 1482150.0000 - val_tn0.3: 12279644.0000 - val_fn0.3:
    1286974.0000 - val_precision0.3: 0.4739 - val_recall0.3: 0.5092 - val_tp0.5: 861583.0000 - val_fp0.5: 875078.0000 - val_tn0.5: 12886716.0000 - val_fn0.5: 1760623.0000 - val_precision0.5: 0.4961 - val_recal
    l0.5: 0.3286 - val_tp0.7: 639908.0000 - val_fp0.7: 477371.0000 - val_tn0.7: 13284423.0000 - val_fn0.7: 1982298.0000 - val_precision0.7: 0.5727 - val_recall0.7: 0.2440 - val_tp0.9: 379220.0000 - val_fp0.9:
    140139.0000 - val_tn0.9: 13621655.0000 - val_fn0.9: 2242986.0000 - val_precision0.9: 0.7302 - val_recall0.9: 0.1446 - val_accuracy: 0.8391 - val_auc: 0.8195
    400/400 [==============================] - 149s 372ms/step - loss: 1.0925 - tp0.1: 3741465.0000 - fp0.1: 6254385.0000 - tn0.1: 21834046.0000 - fn0.1: 938104.0000 - precision0.1: 0.3743 - recall0.1: 0.7995
    - tp0.3: 2384684.0000 - fp0.3: 2773741.0000 - tn0.3: 25314694.0000 - fn0.3: 2294885.0000 - precision0.3: 0.4623 - recall0.3: 0.5096 - tp0.5: 1550871.0000 - fp0.5: 1694065.0000 - tn0.5: 26394368.0000 - fn0.
    5: 3128698.0000 - precision0.5: 0.4779 - recall0.5: 0.3314 - tp0.7: 1148960.0000 - fp0.7: 978743.0000 - tn0.7: 27109692.0000 - fn0.7: 3530609.0000 - precision0.7: 0.5400 - recall0.7: 0.2455 - tp0.9: 685197
    .0000 - fp0.9: 312582.0000 - tn0.9: 27775860.0000 - fn0.9: 3994372.0000 - precision0.9: 0.6867 - recall0.9: 0.1464 - accuracy: 0.8528 - auc: 0.8171

    2021/01/24 18:08:52 INFO mlflow.projects: === Run (ID 'd6553c4225df4f2a91a7698955ad879e') succeeded ===
    (tf-nightly) [ye53nis@node144 drmed-git]$
  #+end_example

**** test run 4
    - now, I changed mlflow logging
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@node144 drmed-git]$ git log -3
        commit 03312de53a90d73c7cacea735890c566aae5dada
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 31 13:23:48 2021 +0100

            Modify mlflow

        commit 6d52eb9df66b689db47b0301a441eae3481b380a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 17:30:22 2021 +0100

            Add thresholds to metrics

        commit c0dde2ec15648b3b1164af6cc365b2c1884e946c
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 16:32:33 2021 +0100

            Update train.py and MLproject to exp-3105.. state
        (tf-nightly) [ye53nis@node144 drmed-git]$
      #+end_example

  #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
    mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_per_epoch=100 -P validation_steps=100
  #+END_SRC

  #+RESULTS:
  #+begin_example
    (tf-nightly) [ye53nis@node144 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_
    per_epoch=100 -P validation_steps=100
    2021/01/31 13:27:51 INFO mlflow.projects.utils: === Created directory /tmp/tmpc9pfwpoh for downloading remote URIs passed to arguments of type 'path' ===
    2021/01/31 13:27:51 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b 1>&2
    && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Nov2020 3 100 100' in run with ID '8d797ea35f0547b0aa24b7a9a8c9b5a9' ===

    2021-01-31 13:28:10.276412: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: N
    o such file or directory

    2021-01-31 13:28:10.276466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:23: DeprecationWarning: the imp module is deprecated in fav
    our of importlib; see the module's documentation for alternative uses
      import imp
    2.3.0-dev20200527

    2021-01-31 13:28:23.599897: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such fil
    e or directory

    2021-01-31 13:28:23.599937: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)

    2021-01-31 13:28:23.599966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node144): /proc/driver/nvidia/version does not exist
    GPUs:  []

    train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set007.csv
    train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set007.csv
    train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set003.csv
    train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set006.csv
    train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set006.csv
    train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set004.csv
    train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set007.csv
    train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set004.csv
    train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set005.csv
    train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set006.csv
    train 10 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set004.csv
    train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set003.csv
    train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set009.csv
    train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set004.csv
    train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set008.csv
    train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set001.csv
    train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set003.csv
    train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
    train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set004.csv
    train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set009.csv
    train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set004.csv
    train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set003.csv
    train 22 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set004.csv
    train 23 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set002.csv
    train 24 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set006.csv
    train 25 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set009.csv
    train 26 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set007.csv
    train 27 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set010.csv
    train 28 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set003.csv
    train 29 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set007.csv
    train 30 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
    train 31 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set001.csv
    train 32 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set001.csv
    train 33 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set009.csv
    train 34 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set002.csv
    train 35 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set008.csv
    train 36 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set009.csv
    train 37 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set007.csv
    train 38 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set004.csv
    train 39 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set005.csv
    train 40 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set002.csv
    train 41 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
    train 42 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set003.csv
    train 43 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set002.csv
    train 44 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set005.csv
    train 45 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set006.csv
    train 46 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set008.csv
    train 47 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set001.csv
    train 48 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set009.csv
    train 49 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set006.csv
    train 50 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set002.csv
    train 51 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set010.csv
    train 52 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set001.csv
    train 53 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set005.csv
    train 54 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set009.csv
    train 55 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set001.csv
    train 56 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set002.csv
    train 57 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set006.csv
    train 58 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set004.csv
    train 59 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set003.csv
    train 60 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set001.csv
    train 61 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set002.csv
    train 62 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set007.csv
    train 63 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set008.csv
    train 64 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set010.csv
    train 65 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set006.csv
    train 66 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set003.csv
    train 67 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set005.csv
    train 68 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set005.csv
    train 69 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set010.csv
    train 70 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set010.csv
    train 71 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set010.csv
    train 72 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set010.csv
    train 73 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set008.csv
    train 74 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set009.csv
    train 75 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set010.csv
    train 76 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set001.csv
    train 77 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set005.csv
    train 78 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set003.csv
    train 79 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set008.csv
    test 80 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set006.csv
    test 81 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set008.csv
    test 82 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set002.csv
    test 83 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set007.csv
    test 84 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set010.csv
    test 85 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set006.csv
    test 86 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set009.csv
    test 87 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set003.csv
    test 88 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set009.csv
    test 89 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set001.csv
    test 90 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set008.csv
    test 91 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set007.csv
    test 92 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set002.csv
    test 93 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set004.csv
    test 94 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set010.csv
    test 95 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set007.csv
    test 96 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
    test 97 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
    test 98 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set008.csv
    test 99 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set005.csv
    The given DataFrame was split into 3 parts with shapes: [(16384, 8000), (16384, 8000), (16384, 8000)]
    The given DataFrame was split into 3 parts with shapes: [(16384, 2000), (16384, 2000), (16384, 2000)]

    for each 16384 timestap trace there are the following numbers of corrupted timesteps:
    label001_1    5916
    label002_1    7367
    label003_1     954
    label004_1    2965
    label005_1       0
    dtype: int64

    2021-01-31 13:36:14.764579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical oper
    ations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

    2021-01-31 13:36:14.775626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz

    2021-01-31 13:36:14.777680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561cb660a760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:

    2021-01-31 13:36:14.777727: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

    number of training examples: 6400, number of validation examples: 1600

    ------------------------
    number of test examples: 2000

    input - shape:   (None, 16384, 1)
    output - shape:  (None, 16384, 1)

    2021-01-31 13:36:22.960149: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/training/tracking/data_structures.py:739: DeprecationWarning: Using or importing the
    ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(wrapped_dict, collections.Mapping):

      /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/utils/autologging_utils.py:60: DeprecationWarning: inspect.getargspec() is deprecated since Pyth
    on 3.0, use inspect.signature() or inspect.getfullargspec()
      all_param_names, _, _, all_default_values = inspect.getargspec(fn)  # pylint: disable=W1505
    Epoch 1/2

    /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:347: DeprecationWarning: Using or importing the ABCs from
     'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
      if not isinstance(values, collections.Sequence):

      1/100 [..............................] - ETA: 0s - loss: 1.6702 - tp0.1: 5491.0000 - fp0.1: 74812.0000 - tn0.1: 672.0000 - fn0.1: 945.0000 - precision0.1: 0.0684 - recall0.1: 0.8532 - tp0.3: 4049.0000 -
    fp0.3: 63267.0000 - tn0.3: 12217.0000 - fn0.3: 2387.0000 - precision0.3: 0.0601 - recall0.3: 0.6291 - tp0.5: 2421.0000 - fp0.5: 32134.0000 - tn0.5: 43350.0000 - fn0.5: 4015.0000 - precision0.5: 0.0701 - re
    call0.5: 0.3762 - tp0.7: 760.0000 - fp0.7: 3691.0000 - tn0.7: 71793.0000 - fn0.7: 5676.0000 - precision0.7: 0.1707 - recall0.7: 0.1181 - tp0.9: 90.0000 - fp0.9: 17.0000 - tn0.9: 75467.0000 - fn0.9: 6346.00
    00 - precision0.9: 0.8411 - recall0.9: 0.0140 - accuracy: 0.5587 - auc: 0.4262

    2021-01-31 13:36:41.474423: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.
    WARNING:tensorflow:From /home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eage
    r.profiler) is deprecated and will be removed after 2020-07-01.
    Instructions for updating:
    use `tf.profiler.experimental.stop` instead.

    2021-01-31 13:36:43.418255: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_13_36_43
    2021-01-31 13:36:43.436068: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.trace.json.gz
    2021-01-31 13:36:43.477032: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_13_36_43
    2021-01-31 13:36:43.477197: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.memor y_profile.json.gz
    2021-01-31 13:36:43.479950: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_13_36_43Dumped tool data for xplane.pb to /tmp/tb/tra in/plugins/profile/2021_01_31_13_36_43/node144.xplane.pb
    Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.overview_page.pb
    Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.input_pipeline.pb
    Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.tensorflow_stats.pb
    Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_01_31_13_36_43/node144.kernel_stats.pb

    100/100 [==============================] - ETA: 0s - loss: 1.2287 - tp0.1: 1067775.0000 - fp0.1: 2602073.0000 - tn0.1: 4355671.0000 - fn0.1: 166481.0000 - precision0.1: 0.2910 - recall0.1: 0.8651 - tp0.3:
    757473.0000 - fp0.3: 860916.0000 - tn0.3: 6096828.0000 - fn0.3: 476783.0000 - precision0.3: 0.4680 - recall0.3: 0.6137 - tp0.5: 495064.0000 - fp0.5: 354737.0000 - tn0.5: 6603007.0000 - fn0.5: 739192.0000 -
     precision0.5: 0.5826 - recall0.5: 0.4011 - tp0.7: 320707.0000 - fp0.7: 115892.0000 - tn0.7: 6841852.0000 - fn0.7: 913549.0000 - precision0.7: 0.7346 - recall0.7: 0.2598 - tp0.9: 166012.0000 - fp0.9: 21459
    .0000 - tn0.9: 6936285.0000 - fn0.9: 1068244.0000 - precision0.9: 0.8855 - recall0.9: 0.1345 - accuracy: 0.8665 - auc: 0.8384

    Traceback (most recent call last):
      File "src/fluotracify/training/train.py", line 200, in <module>
        model.fit(x=dataset_train,
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/mlflow/tensorflow.py", line 831, in fit
        history = original(self, *args, **kwargs)
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 108, in _method_wrapper
        return method(self, *args, **kwargs)
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1116, in fit
        callbacks.on_epoch_end(epoch, epoch_logs)
      File "/home/ye53nis/.conda/envs/mlflow-c61a56dd06e99e6740b7159c7af9d54a736a4e4b/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 411, in on_epoch_end
        callback.on_epoch_end(epoch, numpy_logs)
      File "src/fluotracify/training/train.py", line 147, in log_plots
        mlflow.log_figure(figure=figure,
    AttributeError: module 'mlflow' has no attribute 'log_figure'

    2021/01/31 13:40:43 ERROR mlflow.cli: === Run (ID '8d797ea35f0547b0aa24b7a9a8c9b5a9') failed ===

    (tf-nightly) [ye53nis@node144 drmed-git]$
  #+end_example
  looks like mlflow is not installed the right way
**** test run 5
     I updated conda.yaml to install mlflow with pip rather than conda-forge,
     which installed an old version.
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@node144 drmed-git]$ git log -3
        commit 04e80c35264936d6804396af54ae2a68ca521a0a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 31 14:22:47 2021 +0100

            update conda.yaml

        commit 03312de53a90d73c7cacea735890c566aae5dada
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 31 13:23:48 2021 +0100

            Modify mlflow

        commit 6d52eb9df66b689db47b0301a441eae3481b380a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Sun Jan 24 17:30:22 2021 +0100

            Add thresholds to metrics
        (tf-nightly) [ye53nis@node144 drmed-git]$
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
      mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_per_epoch=100 -P validation_steps=100
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (tf-nightly) [ye53nis@node144 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=None -P csv_path=/beegfs/ye53nis/saves/firstartifact_Nov2020 -P steps_
      per_epoch=100 -P validation_steps=100
      2021/01/31 14:28:26 INFO mlflow.utils.conda: === Creating conda environment mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c ===
      Collecting package metadata (repodata.json): done
      Solving environment: done

      Downloading and Extracting Packages
      ca-certificates-2021 | 121 KB    | ################################################################################################################################################################## | 100%
      pyparsing-2.4.7      | 59 KB     | ################################################################################################################################################################## | 100%
      pandas-1.2.1         | 8.9 MB    | ################################################################################################################################################################## | 100%
      lz4-c-1.9.3          | 186 KB    | ################################################################################################################################################################## | 100%
      python-dateutil-2.8. | 221 KB    | ################################################################################################################################################################## | 100%
      readline-8.1         | 362 KB    | ################################################################################################################################################################## | 100%
      setuptools-52.0.0    | 714 KB    | ################################################################################################################################################################## | 100%
      Preparing transaction: done
      Verifying transaction: done
      Executing transaction: done
      Installing pip dependencies: \ Ran pip subprocess with arguments:
      ['/home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.uitxoel_.requirements.txt']
      Pip subprocess output:
      Collecting mlflow
        Downloading mlflow-1.13.1-py3-none-any.whl (14.1 MB)
      Requirement already satisfied: python-dateutil in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.u
      itxoel_.requirements.txt (line 2)) (2.8.1)
      Requirement already satisfied: pandas in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.uitxoel_.r
      equirements.txt (line 2)) (1.2.1)
      Requirement already satisfied: six>=1.10.0 in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.uitxo
      el_.requirements.txt (line 2)) (1.15.0)
      Requirement already satisfied: numpy in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.uitxoel_.re
      quirements.txt (line 2)) (1.19.2)
      Collecting alembic<=1.4.1
        Downloading alembic-1.4.1.tar.gz (1.1 MB)
      Collecting azure-storage-blob>=12.0.0
        Downloading azure_storage_blob-12.7.1-py2.py3-none-any.whl (339 kB)
      Collecting azure-core<2.0.0,>=1.10.0
        Downloading azure_core-1.10.0-py2.py3-none-any.whl (125 kB)
      Collecting click>=7.0
        Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
      Collecting cryptography>=2.1.4
        Downloading cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)
      Collecting cffi>=1.12
        Downloading cffi-1.14.4-cp38-cp38-manylinux1_x86_64.whl (411 kB)
      Collecting databricks-cli>=0.8.7
        Downloading databricks-cli-0.14.1.tar.gz (54 kB)
      Collecting docker>=4.0.0
        Downloading docker-4.4.1-py2.py3-none-any.whl (146 kB)
      Collecting gitpython>=2.1.0
        Downloading GitPython-3.1.12-py3-none-any.whl (159 kB)
      Collecting gitdb<5,>=4.0.1
        Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)
      Collecting msrest>=0.6.18
        Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)
      Requirement already satisfied: certifi>=2017.4.17 in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->
      mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.uitxoel_.requirements.txt (line 2)) (2020.12.5)
      Collecting isodate>=0.6.0
        Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)
      Collecting protobuf>=3.6.0
        Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)
      Collecting python-editor>=0.3
        Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)
      Collecting requests>=2.17.3
        Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
      Collecting chardet<5,>=3.0.2
        Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)
      Collecting idna<3,>=2.5
        Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
      Collecting requests-oauthlib>=0.5.0
        Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
      Collecting oauthlib>=3.0.0
        Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)
      Collecting smmap<4,>=3.0.1
        Downloading smmap-3.0.5-py2.py3-none-any.whl (25 kB)
      Collecting sqlalchemy
        Downloading SQLAlchemy-1.3.22-cp38-cp38-manylinux2010_x86_64.whl (1.3 MB)
      Collecting sqlparse>=0.3.1
        Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)
      Collecting tabulate>=0.7.7
        Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)
      Collecting urllib3<1.27,>=1.21.1
        Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)
      Collecting websocket-client>=0.32.0
        Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)
      Collecting tf-nightly
        Downloading tf_nightly-2.5.0.dev20210130-cp38-cp38-manylinux2010_x86_64.whl (403.3 MB)
      Requirement already satisfied: wheel~=0.35 in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from tf-nightly->-r /beegfs/ye53nis/drmed-git/condaenv.u
      itxoel_.requirements.txt (line 1)) (0.36.2)
      Collecting gast==0.4.0
        Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)
      Collecting absl-py~=0.10
        Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)
      Collecting astunparse~=1.6.3
        Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
      Collecting flatbuffers~=1.12.0
        Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
      Collecting google-pasta~=0.2
        Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
      Collecting grpcio~=1.34.0
        Using cached grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)
      Collecting h5py~=3.1.0
        Using cached h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)
      Collecting keras-preprocessing~=1.1.2
        Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
      Collecting opt-einsum~=3.3.0
        Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)
      Collecting tb-nightly~=2.5.0.a
        Downloading tb_nightly-2.5.0a20210130-py3-none-any.whl (12.3 MB)
      Requirement already satisfied: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from tb-nightly~=2.5.0.a->tf-nightly->-r /beegfs/
      ye53nis/drmed-git/condaenv.uitxoel_.requirements.txt (line 1)) (52.0.0.post20210125)
      Collecting google-auth<2,>=1.6.3
        Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)
      Collecting cachetools<5.0,>=2.0.0
        Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)
      Collecting google-auth-oauthlib<0.5,>=0.4.1
        Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)
      Collecting markdown>=2.6.8
        Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)
      Collecting pyasn1-modules>=0.2.1
        Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
      Collecting pyasn1<0.5.0,>=0.4.6
        Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
      Collecting rsa<5,>=3.1.4
        Using cached rsa-4.7-py3-none-any.whl (34 kB)
      Collecting tensorboard-plugin-wit>=1.6.0
        Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)
      Collecting termcolor~=1.1.0
        Using cached termcolor-1.1.0-py3-none-any.whl
      Collecting tf-estimator-nightly~=2.5.0.dev
        Downloading tf_estimator_nightly-2.5.0.dev2021013101-py2.py3-none-any.whl (462 kB)
      Collecting typing-extensions~=3.7.4
        Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
      Collecting werkzeug>=0.11.15
        Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
      Collecting wrapt~=1.12.1
        Using cached wrapt-1.12.1-cp38-cp38-linux_x86_64.whl
      Collecting cloudpickle
        Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)
      Collecting entrypoints
        Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)
      Collecting Flask
        Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)
      Collecting itsdangerous>=0.24
        Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
      Collecting Jinja2>=2.10.1
        Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)
      Collecting MarkupSafe>=0.23
        Downloading MarkupSafe-1.1.1-cp38-cp38-manylinux2010_x86_64.whl (32 kB)
      Collecting gunicorn
        Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)
      Collecting Mako
        Downloading Mako-1.1.4.tar.gz (479 kB)
      Requirement already satisfied: pytz>=2017.3 in /home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/site-packages (from pandas->mlflow->-r /beegfs/ye53nis/drmed-git/conda
      env.uitxoel_.requirements.txt (line 2)) (2020.5)
      Collecting prometheus-flask-exporter
        Downloading prometheus_flask_exporter-0.18.1.tar.gz (21 kB)
      Collecting prometheus_client
        Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)
      Collecting pycparser
        Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)
      Collecting pyyaml
        Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)
      Collecting querystring-parser
        Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)
      Building wheels for collected packages: alembic, databricks-cli, Mako, prometheus-flask-exporter
        Building wheel for alembic (setup.py): started
        Building wheel for alembic (setup.py): finished with status 'done'
        Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=04e9a03272dc193ae4beba21b23955b84993725bbcbb76f81f5ce18bf778b29a
        Stored in directory: /home/ye53nis/.cache/pip/wheels/9d/de/6d/ca8d461ec29e010b1267d7353d0b058819770f7680bb9360e4
        Building wheel for databricks-cli (setup.py): started
        Building wheel for databricks-cli (setup.py): finished with status 'done'
        Created wheel for databricks-cli: filename=databricks_cli-0.14.1-py3-none-any.whl size=100577 sha256=372cd434bffaf63c38e34c4b6e34370bfacfd5e56e49699f100b42355386f4a6
        Stored in directory: /home/ye53nis/.cache/pip/wheels/f8/a7/7c/74d614edb0dea04c3bb450951ec35c8f62aa197302ad2c3baa
        Building wheel for Mako (setup.py): started
        Building wheel for Mako (setup.py): finished with status 'done'
        Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=f5300062dbcbc5518fd139004bc95be880779d80c8c75aa5b537a2abfe433434
        Stored in directory: /home/ye53nis/.cache/pip/wheels/17/bc/50/621fe4100d907a7296cc00c21371402b068b648820f6ff5812
        Building wheel for prometheus-flask-exporter (setup.py): started
        Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'
        Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-py3-none-any.whl size=17158 sha256=6d4619160207171ac7eff7b607655b9b1ad67b85d1a85a7cc61f1f6937ebaf35
        Stored in directory: /home/ye53nis/.cache/pip/wheels/12/1a/8d/0c016e06370d07f82def661b6cb7d91d4e6b4ff7f2982e9f2c
      Successfully built alembic databricks-cli Mako prometheus-flask-exporter
      Installing collected packages: urllib3, pyasn1, idna, chardet, rsa, requests, pycparser, pyasn1-modules, oauthlib, MarkupSafe, cachetools, werkzeug, smmap, requests-oauthlib, Jinja2, itsdangerous, isodate,
       google-auth, click, cffi, websocket-client, tensorboard-plugin-wit, tabulate, sqlalchemy, python-editor, protobuf, prometheus-client, msrest, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, Flask, cr
      yptography, azure-core, absl-py, wrapt, typing-extensions, tf-estimator-nightly, termcolor, tb-nightly, sqlparse, querystring-parser, pyyaml, prometheus-flask-exporter, opt-einsum, keras-preprocessing, h5p
      y, gunicorn, google-pasta, gitpython, gast, flatbuffers, entrypoints, docker, databricks-cli, cloudpickle, azure-storage-blob, astunparse, alembic, tf-nightly, mlflow
      Successfully installed Flask-1.1.2 Jinja2-2.11.2 Mako-1.1.4 MarkupSafe-1.1.1 absl-py-0.11.0 alembic-1.4.1 astunparse-1.6.3 azure-core-1.10.0 azure-storage-blob-12.7.1 cachetools-4.2.1 cffi-1.14.4 chardet-4
      .0.0 click-7.1.2 cloudpickle-1.6.0 cryptography-3.3.1 databricks-cli-0.14.1 docker-4.4.1 entrypoints-0.3 flatbuffers-1.12 gast-0.4.0 gitdb-4.0.5 gitpython-3.1.12 google-auth-1.24.0 google-auth-oauthlib-0.4
      .2 google-pasta-0.2.0 grpcio-1.34.1 gunicorn-20.0.4 h5py-3.1.0 idna-2.10 isodate-0.6.0 itsdangerous-1.1.0 keras-preprocessing-1.1.2 markdown-3.3.3 mlflow-1.13.1 msrest-0.6.21 oauthlib-3.1.0 opt-einsum-3.3.
      0 prometheus-client-0.9.0 prometheus-flask-exporter-0.18.1 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.25.1 request
      s-oauthlib-1.3.0 rsa-4.7 smmap-3.0.5 sqlalchemy-1.3.22 sqlparse-0.4.1 tabulate-0.8.7 tb-nightly-2.5.0a20210130 tensorboard-plugin-wit-1.8.0 termcolor-1.1.0 tf-estimator-nightly-2.5.0.dev2021013101 tf-night
      ly-2.5.0.dev20210130 typing-extensions-3.7.4.3 urllib3-1.26.3 websocket-client-0.57.0 werkzeug-1.0.1 wrapt-1.12.1

      done
      #
      # To activate this environment, use
      #
      #     $ conda activate mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c
      #
      # To deactivate an active environment, use
      #
      #     $ conda deactivate

      2021/01/31 14:35:51 INFO mlflow.projects.utils: === Created directory /tmp/tmp6qpfe4x0 for downloading remote URIs passed to arguments of type 'path' ===
      2021/01/31 14:35:51 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c 1>&2
      && python src/fluotracify/training/train.py /beegfs/ye53nis/drmed-git/src 5 0.2 16384 None 2 /beegfs/ye53nis/saves/firstartifact_Nov2020 3 100 100' in run with ID 'b8312cc3b85c40fcbdee0a66662e6485' ===
      2021-01-31 14:36:00.461387: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: N
      o such file or directory
      2021-01-31 14:36:00.461468: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
      2.5.0-dev20210130
      2021-01-31 14:36:08.294105: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such fil
      e or directory
      2021-01-31 14:36:08.294206: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
      2021-01-31 14:36:08.294258: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node144): /proc/driver/nvidia/version does not exist
      GPUs:  []
      train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set007.csv
      train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set007.csv
      train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set003.csv
      train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set006.csv
      train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set006.csv
      train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set004.csv
      train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set007.csv
      train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set004.csv
      train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set005.csv
      train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set006.csv
      train 10 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set004.csv
      train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set003.csv
      train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set009.csv
      train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set004.csv
      train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set008.csv
      train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set001.csv
      train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set003.csv
      train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
      train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set004.csv
      train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set009.csv
      train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set004.csv
      train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set003.csv
      train 22 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set004.csv
      train 23 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set002.csv
      train 24 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set006.csv
      train 25 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set009.csv
      train 26 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set007.csv
      train 27 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set010.csv
      train 28 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set003.csv
      train 29 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set007.csv
      train 30 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
      train 31 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set001.csv
      train 32 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set001.csv
      train 33 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set009.csv
      train 34 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set002.csv
      train 35 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set008.csv
      train 36 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set009.csv
      train 37 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set007.csv
      train 38 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set004.csv
      train 39 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set005.csv
      train 40 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set002.csv
      train 41 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
      train 42 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set003.csv
      train 43 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set002.csv
      train 44 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set005.csv
      train 45 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set006.csv
      train 46 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set008.csv
      train 47 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set001.csv
      train 48 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set009.csv
      train 49 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set006.csv
      train 50 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set002.csv
      train 51 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set010.csv
      train 52 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set001.csv
      train 53 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set005.csv
      train 54 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set009.csv
      train 55 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set001.csv
      train 56 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set002.csv
      train 57 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set006.csv
      train 58 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set004.csv
      train 59 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set003.csv
      train 60 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set001.csv
      train 61 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set002.csv
      train 62 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set007.csv
      train 63 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set008.csv
      train 64 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set010.csv
      train 65 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set006.csv
      train 66 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set003.csv
      train 67 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set005.csv
      train 68 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set005.csv
      train 69 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set010.csv
      train 70 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set010.csv
      train 71 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set010.csv
      train 72 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set010.csv
      train 73 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set008.csv
      train 74 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set009.csv
      train 75 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set010.csv
      train 76 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set001.csv
      train 77 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set005.csv
      train 78 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set003.csv
      train 79 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set008.csv
      test 80 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set006.csv
      test 81 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set008.csv
      test 82 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set002.csv
      test 83 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set007.csv
      test 84 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set010.csv
      test 85 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set006.csv
      test 86 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.6/traces_brightclust_Nov2020_D0.6_set009.csv
      test 87 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.08/traces_brightclust_Nov2020_D0.08_set003.csv
      test 88 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set009.csv
      test 89 /beegfs/ye53nis/saves/firstartifact_Nov2020/10/traces_brightclust_Nov2020_D10_set001.csv
      test 90 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set008.csv
      test 91 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.2/traces_brightclust_Nov2020_D0.2_set007.csv
      test 92 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.1/traces_brightclust_Nov2020_D0.1_set002.csv
      test 93 /beegfs/ye53nis/saves/firstartifact_Nov2020/3.0/traces_brightclust_Nov2020_D3.0_set004.csv
      test 94 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.069/traces_brightclust_Nov2020_D0.069_set010.csv
      test 95 /beegfs/ye53nis/saves/firstartifact_Nov2020/50/traces_brightclust_Nov2020_D50_set007.csv
      test 96 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
      test 97 /beegfs/ye53nis/saves/firstartifact_Nov2020/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
      test 98 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set008.csv
      test 99 /beegfs/ye53nis/saves/firstartifact_Nov2020/0.4/traces_brightclust_Nov2020_D0.4_set005.csv
      The given DataFrame was split into 3 parts with shapes: [(16384, 8000), (16384, 8000), (16384, 8000)]
      The given DataFrame was split into 3 parts with shapes: [(16384, 2000), (16384, 2000), (16384, 2000)]

      for each 16384 timestap trace there are the following numbers of corrupted timesteps:
      label001_1    5916
      label002_1    7367
      label003_1     954
      label004_1    2965
      label005_1       0
      dtype: int64
      2021-01-31 14:43:05.348089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions i
      n performance-critical operations:  AVX2 AVX512F FMA
      To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
      number of training examples: 6400, number of validation examples: 1600

      ------------------------
      number of test examples: 2000

      input - shape:   (None, 16384, 1)
      output - shape:  (None, 16384, 1)
      2021-01-31 14:43:12.062974: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.
      2021-01-31 14:43:12.063027: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.
      2021-01-31 14:43:12.063091: I tensorflow/core/profiler/lib/profiler_session.cc:158] Profiler session tear down.
      2021/01/31 14:43:12 INFO mlflow.utils.autologging_utils: tensorflow autologging will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow
       to the MLflow run with ID 'b8312cc3b85c40fcbdee0a66662e6485'
      2021/01/31 14:43:12 WARNING mlflow.utils.autologging_utils: MLflow issued a warning during tensorflow autologging: "/home/ye53nis/.conda/envs/mlflow-fd9a200e5a24d4c79a0ff13be73ccb5141ed072c/lib/python3.8/s
      ite-packages/mlflow/utils/autologging_utils.py:86: UserWarning: Logging to MLflow failed: Changing param values is not allowed. Param with key='batch_size' was already logged with value='5' for run ID='b83
      12cc3b85c40fcbdee0a66662e6485'. Attempted logging new value 'None'."
      Epoch 1/2
      2021-01-31 14:43:22.942539: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:145] None of the MLIR Optimization Passes are enabled (registered 2)
      2021-01-31 14:43:23.148047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2300000000 Hz
        1/100 [..............................] - ETA: 27:41 - loss: 1.7655 - tp0.1: 6179.0000 - fp0.1: 74969.0000 - tn0.1: 583.0000 - fn0.1: 189.0000 - precision0.1: 0.0761 - recall0.1: 0.9703 - tp0.3: 5260.0000
       - fp0.3: 66819.0000 - tn0.3: 8733.0000 - fn0.3: 1108.0000 - precision0.3: 0.0730 - recall0.3: 0.8260 - tp0.5: 3016.0000 - fp0.5: 46719.0000 - tn0.5: 28833.0000 - fn0.5: 3352.0000 - precision0.5: 0.0606 -
      recall0.5: 0.4736 - tp0.7: 758.0000 - fp0.7: 10118.0000 - tn0.7: 65434.0000 - fn0.7: 5610.0000 - precision0.7: 0.0697 - recall0.7: 0.1190 - tp0.9: 61.0000 - fp0.9: 112.0000 - tn0.9: 75440.0000 - fn0.9: 630
      7.0000 - precision0.9: 0.3526 - recall0.9: 0.0096 - accuracy: 0.3888 - auc: 0.41752021-01-31 14:43:29.924205: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.
      2021-01-31 14:43:29.924303: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.
        2/100 [..............................] - ETA: 3:10 - loss: 1.6614 - tp0.1: 6758.0000 - fp0.1: 77065.5000 - tn0.1: 36666.5000 - fn0.1: 2390.0000 - precision0.1: 0.0805 - recall0.1: 0.7927 - tp0.3: 5466.00
      00 - fp0.3: 67437.0000 - tn0.3: 46295.0000 - fn0.3: 3682.0000 - precision0.3: 0.0750 - recall0.3: 0.6508 - tp0.5: 3016.0000 - fp0.5: 46719.0000 - tn0.5: 67013.0000 - fn0.5: 6132.0000 - precision0.5: 0.0606
       - recall0.5: 0.3632 - tp0.7: 758.0000 - fp0.7: 10118.0000 - tn0.7: 103614.0000 - fn0.7: 8390.0000 - precision0.7: 0.0697 - recall0.7: 0.0913 - tp0.9: 61.0000 - fp0.9: 112.0000 - tn0.9: 113620.0000 - fn0.9
      : 9087.0000 - precision0.9: 0.3526 - recall0.9: 0.0073 - accuracy: 0.5246 - auc: 0.47642021-01-31 14:43:31.866515: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
      2021-01-31 14:43:31.914813: I tensorflow/core/profiler/lib/profiler_session.cc:158] Profiler session tear down.
      2021-01-31 14:43:31.943892: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_14_43_31
      2021-01-31 14:43:31.959090: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.trace.json.gz
      2021-01-31 14:43:31.986567: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_14_43_31
      2021-01-31 14:43:31.986925: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.memor
      y_profile.json.gz
      2021-01-31 14:43:31.992443: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tb/train/plugins/profile/2021_01_31_14_43_31Dumped tool data for xplane.pb to /tmp/tb/trai
      n/plugins/profile/2021_01_31_14_43_31/node144.xplane.pb
      Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.overview_page.pb
      Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.input_pipeline.pb
      Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.tensorflow_stats.pb
      Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_01_31_14_43_31/node144.kernel_stats.pb

      100/100 [==============================] - 259s 2s/step - loss: 1.1121 - tp0.1: 594667.6634 - fp0.1: 1262900.4257 - tn0.1: 2220267.4653 - fn0.1: 99273.3564 - precision0.1: 0.3034 - recall0.1: 0.8327 - tp0.
      3: 454623.3762 - fp0.3: 625205.3762 - tn0.3: 2857962.5149 - fn0.3: 239317.6436 - precision0.3: 0.3888 - recall0.3: 0.6241 - tp0.5: 255692.1683 - fp0.5: 199128.0000 - tn0.5: 3284039.8911 - fn0.5: 438248.851
      5 - precision0.5: 0.5176 - recall0.5: 0.3466 - tp0.7: 146031.6634 - fp0.7: 59820.5347 - tn0.7: 3423347.3564 - fn0.7: 547909.3564 - precision0.7: 0.6680 - recall0.7: 0.1989 - tp0.9: 86541.7129 - fp0.9: 1387
      2.6337 - tn0.9: 3469295.2574 - fn0.9: 607399.3069 - precision0.9: 0.8457 - recall0.9: 0.1191 - accuracy: 0.8344 - auc: 0.7971 - val_loss: 457233.2500 - val_tp0.1: 1229162.0000 - val_fp0.1: 6962838.0000 - v
      al_tn0.1: 0.0000e+00 - val_fn0.1: 0.0000e+00 - val_precision0.1: 0.1500 - val_recall0.1: 1.0000 - val_tp0.3: 1229162.0000 - val_fp0.3: 6962838.0000 - val_tn0.3: 0.0000e+00 - val_fn0.3: 0.0000e+00 - val_pre
      cision0.3: 0.1500 - val_recall0.3: 1.0000 - val_tp0.5: 1229162.0000 - val_fp0.5: 6962838.0000 - val_tn0.5: 0.0000e+00 - val_fn0.5: 0.0000e+00 - val_precision0.5: 0.1500 - val_recall0.5: 1.0000 - val_tp0.7:
       1229162.0000 - val_fp0.7: 6962838.0000 - val_tn0.7: 0.0000e+00 - val_fn0.7: 0.0000e+00 - val_precision0.7: 0.1500 - val_recall0.7: 1.0000 - val_tp0.9: 1229162.0000 - val_fp0.9: 6962838.0000 - val_tn0.9: 0
      .0000e+00 - val_fn0.9: 0.0000e+00 - val_precision0.9: 0.1500 - val_recall0.9: 1.0000 - val_accuracy: 0.1500 - val_auc: 0.5000
      Epoch 2/2
      100/100 [==============================] - 229s 2s/step - loss: 0.9542 - tp0.1: 519521.3762 - fp0.1: 1185311.1188 - tn0.1: 2378417.4257 - fn0.1: 93858.9901 - precision0.1: 0.3034 - recall0.1: 0.8277 - tp0.
      3: 403204.6733 - fp0.3: 663726.0693 - tn0.3: 2900002.4752 - fn0.3: 210175.6931 - precision0.3: 0.3862 - recall0.3: 0.6496 - tp0.5: 185345.9406 - fp0.5: 99511.1089 - tn0.5: 3464217.4356 - fn0.5: 428034.4257
       - precision0.5: 0.6745 - recall0.5: 0.2955 - tp0.7: 107323.0693 - fp0.7: 27653.8218 - tn0.7: 3536074.7228 - fn0.7: 506057.2970 - precision0.7: 0.8370 - recall0.7: 0.1703 - tp0.9: 51201.7426 - fp0.9: 6938.
      3465 - tn0.9: 3556790.1980 - fn0.9: 562178.6238 - precision0.9: 0.9170 - recall0.9: 0.0791 - accuracy: 0.8825 - auc: 0.8284 - val_loss: 1.2666 - val_tp0.1: 1040555.0000 - val_fp0.1: 1748377.0000 - val_tn0.
      1: 5136502.0000 - val_fn0.1: 266566.0000 - val_precision0.1: 0.3731 - val_recall0.1: 0.7961 - val_tp0.3: 913529.0000 - val_fp0.3: 1294318.0000 - val_tn0.3: 5590561.0000 - val_fn0.3: 393592.0000 - val_preci
      sion0.3: 0.4138 - val_recall0.3: 0.6989 - val_tp0.5: 785575.0000 - val_fp0.5: 1050462.0000 - val_tn0.5: 5834417.0000 - val_fn0.5: 521546.0000 - val_precision0.5: 0.4279 - val_recall0.5: 0.6010 - val_tp0.7:
       687372.0000 - val_fp0.7: 910608.0000 - val_tn0.7: 5974271.0000 - val_fn0.7: 619749.0000 - val_precision0.7: 0.4302 - val_recall0.7: 0.5259 - val_tp0.9: 565560.0000 - val_fp0.9: 734195.0000 - val_tn0.9: 61
      50684.0000 - val_fn0.9: 741561.0000 - val_precision0.9: 0.4351 - val_recall0.9: 0.4327 - val_accuracy: 0.8081 - val_auc: 0.8022
      400/400 [==============================] - 151s 376ms/step - loss: 1.0873 - tp0.1: 3701509.0000 - fp0.1: 5630769.0000 - tn0.1: 22457664.0000 - fn0.1: 978060.0000 - precision0.1: 0.3966 - recall0.1: 0.7910
      - tp0.3: 3254446.0000 - fp0.3: 4174340.0000 - tn0.3: 23914076.0000 - fn0.3: 1425123.0000 - precision0.3: 0.4381 - recall0.3: 0.6955 - tp0.5: 2807705.0000 - fp0.5: 3397379.0000 - tn0.5: 24691048.0000 - fn0.
      5: 1871864.0000 - precision0.5: 0.4525 - recall0.5: 0.6000 - tp0.7: 2464880.0000 - fp0.7: 2961952.0000 - tn0.7: 25126486.0000 - fn0.7: 2214689.0000 - precision0.7: 0.4542 - recall0.7: 0.5267 - tp0.9: 20250
      78.0000 - fp0.9: 2431750.0000 - tn0.9: 25656692.0000 - fn0.9: 2654491.0000 - precision0.9: 0.4544 - recall0.9: 0.4327 - accuracy: 0.8392 - auc: 0.8225
      2021/01/31 14:54:05 INFO mlflow.projects: === Run (ID 'b8312cc3b85c40fcbdee0a66662e6485') succeeded ===
      (base) [ye53nis@node144 ~]$
    #+end_example

*** checking if the trained model works with my workflow before
**** update tf-nightly to include =lmfit=
    - we need:
    - numpy
    - pandas
    - matplotlib
    - seaborn
    - mlflow
    - lmfit (needed by =fluotracify.applications.correlate=)
    - jupyterlab
    - pip
    - pip:
      - tf-nightly
      - fcsfiles
      - multipletau

    #+begin_example
      conda env remove -n tf-nightly
      conda create -n tf-nightly numpy pandas matplotlib seaborn tifffile jupyterlab pip
      conda install -n tf-nightly -c conda-forge/label/main mlflow lmfit
      conda activate tf-nightly
      (tf-nightly) pip install fcsfiles multipletau tf-nightly
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
      conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (tf-nightly) [ye53nis@node160 /]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      absl-py                   0.11.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge/label/main
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge/label/main
      argon2-cffi               20.1.0           py38h7b6447c_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge/label/main
      asteval                   0.9.16             pyh5ca1d4c_0    conda-forge/label/main
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10               pyhd3eb1b0_0
      attrs                     20.3.0             pyhd3eb1b0_0
      azure-core                1.10.0             pyhd8ed1ab_0    conda-forge/label/main
      azure-storage-blob        12.7.1             pyh44b312d_0    conda-forge/label/main
      backcall                  0.2.0              pyhd3eb1b0_0
      blas                      1.0                         mkl
      bleach                    3.2.3              pyhd3eb1b0_0
      blinker                   1.4                        py_1    conda-forge/label/main
      blosc                     1.20.1               hd408876_0
      brotli                    1.0.9                he6710b0_2
      brotlipy                  0.7.0           py38h27cfd23_1003
      brunsli                   0.1                  h2531618_0
      bzip2                     1.0.8                h7b6447c_0
      ca-certificates           2020.12.5            ha878542_0    conda-forge/label/main
      cachetools                4.2.1                    pypi_0    pypi
      certifi                   2020.12.5        py38h578d9bd_1    conda-forge/label/main
      cffi                      1.14.4           py38h261ae71_0
      chardet                   4.0.0           py38h06a4308_1003
      charls                    2.1.0                he6710b0_2
      click                     7.1.2              pyh9f0ad1d_0    conda-forge/label/main
      cloudpickle               1.6.0                      py_0    conda-forge/label/main
      configparser              5.0.1                      py_0    conda-forge/label/main
      cryptography              3.3.1            py38h3c74f83_0
      cycler                    0.10.0                   py38_0
      databricks-cli            0.9.1                      py_0    conda-forge/label/main
      dbus                      1.13.18              hb2f20db_0
      decorator                 4.4.2              pyhd3eb1b0_0
      defusedxml                0.6.0                      py_0
      docker-py                 4.4.1            py38h578d9bd_1    conda-forge/label/main
      docker-pycreds            0.4.0                      py_0    conda-forge/label/main
      entrypoints               0.3                      py38_0
      expat                     2.2.10               he6710b0_2
      fcsfiles                  2020.9.18                pypi_0    pypi
      flask                     1.1.2              pyh9f0ad1d_0    conda-forge/label/main
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.0               h9420a91_0
      freetype                  2.10.4               h5ab3b9f_0
      future                    0.18.2           py38h578d9bd_3    conda-forge/label/main
      gast                      0.4.0                    pypi_0    pypi
      giflib                    5.1.4                h14c3975_1
      gitdb                     4.0.5                      py_0    conda-forge/label/main
      gitpython                 3.1.12             pyhd8ed1ab_0    conda-forge/label/main
      glib                      2.66.1               h92f7085_0
      google-auth               1.24.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.2                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      gorilla                   0.3.0                      py_0    conda-forge/label/main
      grpcio                    1.34.1                   pypi_0    pypi
      gst-plugins-base          1.14.0               h8213a91_2
      gstreamer                 1.14.0               h28cd5cc_2
      gunicorn                  20.0.4           py38h578d9bd_3    conda-forge/label/main
      h5py                      3.1.0                    pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10               pyhd3eb1b0_0
      imagecodecs               2021.1.11        py38h581e88b_1
      importlib-metadata        2.0.0                      py_1
      importlib_metadata        2.0.0                         1
      intel-openmp              2020.2                      254
      ipykernel                 5.3.4            py38h5ca1d4c_0
      ipython                   7.19.0           py38hb070fc8_1
      ipython_genutils          0.2.0              pyhd3eb1b0_1
      isodate                   0.6.0                      py_1    conda-forge/label/main
      itsdangerous              1.1.0                      py_0    conda-forge/label/main
      jedi                      0.17.0                   py38_0
      jinja2                    2.11.2             pyhd3eb1b0_0
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.5                      py_0
      jsonschema                3.2.0                      py_2
      jupyter_client            6.1.7                      py_0
      jupyter_core              4.7.0            py38h06a4308_0
      jupyterlab                2.2.6                      py_0
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         1.2.0                      py_0
      jxrlib                    1.1                  h7b6447c_2
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.0            py38h2531618_0
      lcms2                     2.11                 h396b838_0
      ld_impl_linux-64          2.33.1               h53a641e_7
      lerc                      2.2.1                h2531618_0
      libaec                    1.0.4                he6710b0_1
      libdeflate                1.7                  h27cfd23_5
      libedit                   3.1.20191231         h14c3975_1
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.1.0                hdf63c60_0
      libgfortran-ng            7.3.0                hdf63c60_0
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.13.0.1             h8b12597_0    conda-forge/label/main
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.1.0                hdf63c60_0
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libwebp                   1.0.1                h8e7db2f_0
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.10               hb55368b_3
      libzopfli                 1.0.3                he6710b0_0
      lmfit                     1.0.1                      py_1    conda-forge/label/main
      lz4-c                     1.9.3                h2531618_0
      mako                      1.1.4              pyh44b312d_0    conda-forge/label/main
      markdown                  3.3.3                    pypi_0    pypi
      markupsafe                1.1.1            py38h7b6447c_0
      matplotlib                3.3.2                h06a4308_0
      matplotlib-base           3.3.2            py38h817c723_0
      mistune                   0.8.4           py38h7b6447c_1000
      mkl                       2020.2                      256
      mkl-service               2.3.0            py38he904b0f_0
      mkl_fft                   1.2.0            py38h23d657b_0
      mkl_random                1.1.1            py38h0573a6f_0
      mlflow                    1.13.1           py38h578d9bd_2    conda-forge/label/main
      msrest                    0.6.21             pyh44b312d_0    conda-forge/label/main
      multipletau               0.3.3                    pypi_0    pypi
      nbclient                  0.5.1                      py_0
      nbconvert                 6.0.7                    py38_0
      nbformat                  5.1.2              pyhd3eb1b0_1
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.4.3              pyhd3eb1b0_0
      notebook                  6.2.0            py38h06a4308_0
      numpy                     1.19.2           py38h54aff64_0
      numpy-base                1.19.2           py38hfa32c7d_0
      oauthlib                  3.0.1                      py_0    conda-forge/label/main
      olefile                   0.46                       py_0
      openjpeg                  2.3.0                h05c96fa_1
      openssl                   1.1.1i               h27cfd23_0
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 20.9               pyhd3eb1b0_0
      pandas                    1.2.1            py38ha9443f7_0
      pandoc                    2.11                 hb0f4dca_0
      pandocfilters             1.4.3            py38h06a4308_1
      parso                     0.8.1              pyhd3eb1b0_0
      pcre                      8.44                 he6710b0_0
      pexpect                   4.8.0              pyhd3eb1b0_3
      pickleshare               0.7.5           pyhd3eb1b0_1003
      pillow                    8.1.0            py38he98fc37_0
      pip                       20.3.3           py38h06a4308_0
      prometheus_client         0.9.0              pyhd3eb1b0_0
      prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge/label/main
      prompt-toolkit            3.0.8                      py_0
      protobuf                  3.13.0.1         py38hadf7658_1    conda-forge/label/main
      ptyprocess                0.7.0              pyhd3eb1b0_2
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.7.4              pyhd3eb1b0_0
      pyjwt                     2.0.1              pyhd8ed1ab_0    conda-forge/label/main
      pyopenssl                 20.0.1             pyhd3eb1b0_1
      pyparsing                 2.4.7              pyhd3eb1b0_0
      pyqt                      5.9.2            py38h05f1152_4
      pyrsistent                0.17.3           py38h7b6447c_0
      pysocks                   1.7.1            py38h06a4308_0
      python                    3.8.5                h7579374_1
      python-dateutil           2.8.1              pyhd3eb1b0_0
      python-editor             1.0.4                      py_0    conda-forge/label/main
      python_abi                3.8                      1_cp38    conda-forge/label/main
      pytz                      2020.5             pyhd3eb1b0_0
      pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge/label/main
      pyzmq                     20.0.0           py38h2531618_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge/label/main
      readline                  8.1                  h27cfd23_0
      requests                  2.25.1             pyhd3eb1b0_0
      requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge/label/main
      rsa                       4.7                      pypi_0    pypi
      scipy                     1.5.2            py38h0b6359f_0
      seaborn                   0.11.1             pyhd3eb1b0_0
      send2trash                1.5.0              pyhd3eb1b0_1
      setuptools                52.0.0           py38h06a4308_0
      sip                       4.19.13          py38he6710b0_0
      six                       1.15.0           py38h06a4308_0
      smmap                     4.0.0              pyh44b312d_0    conda-forge/label/main
      snappy                    1.1.8                he6710b0_0
      sqlalchemy                1.3.20           py38h1e0a361_0    conda-forge/label/main
      sqlite                    3.33.0               h62c20be_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge/label/main
      tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge/label/main
      tb-nightly                2.5.0a20210130           pypi_0    pypi
      tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.2            py38h06a4308_0
      testpath                  0.4.4              pyhd3eb1b0_0
      tf-estimator-nightly      2.5.0.dev2021020101          pypi_0    pypi
      tf-nightly                2.5.0.dev20210130          pypi_0    pypi
      tifffile                  2021.1.14          pyhd3eb1b0_1
      tk                        8.6.10               hbc83047_0
      tornado                   6.1              py38h27cfd23_0
      traitlets                 5.0.5              pyhd3eb1b0_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge/label/main
      urllib3                   1.26.3             pyhd3eb1b0_0
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1                    py38_1
      websocket-client          0.57.0           py38h578d9bd_4    conda-forge/label/main
      werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge/label/main
      wheel                     0.36.2             pyhd3eb1b0_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge/label/main
      zeromq                    4.3.3                he6710b0_3
      zfp                       0.5.5                h2531618_4
      zipp                      3.4.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.5                h9ceee32_0
      (tf-nightly) [ye53nis@node160 /]$
    #+end_example

*** DONE use =mlflow.keras.log_model()= instead of tf =model.save=
    CLOSED: [2021-07-20 Di 13:44]
#+BEGIN_SRC python
  mlflow.keras.log_model(keras_model,
                         artifact_path,
                         conda_env=None,
                         custom_objects=None,
                         keras_module=None,
                         registered_model_name=None,
                         **kwargs)
#+END_SRC
- keras_model=model
- artifact_path='model'
- conda_env=None (loads mlflow.keras.get_default_conda_env())
- custom_objects={'binary_ce_dice': bm.binary_ce_dice_loss()}
*** DONE Choosing some additional metrics
    CLOSED: [2021-07-20 Di 13:49]
Which measures make sense for Artifact classification / segmentation:
- Recall! - I want all the artifacts
- Precision - slightly less important
- Combining the two, but giving recall a higher weight is possible with the
  *F-Measure*
  \[F_{\beta} = (1 + \beta^2) \cdot
  \frac{\text{precision}\cdot\text{recall}}{\beta^2\cdot\text{precision} +
  \text{recall}}\]
  - To get an evenly weighted version, we could use the \[F_{1} = 2 \cdot \frac{\text{precision}\cdot\text{recall}}{\text{precision} + \text{recall}}\], but even
    better is probably the measure \[F_{2} = 5
    \cdot\frac{\text{precision}\cdot\text{recall}}{4\cdot\text{precision} + \text{recall}}\]
  - just note that if using $F_2$ the outcome depends even stronger on the used
    threshold for deciding if a predicted probability is 1 or 0 → *there is a
    =threshold= argument for the =tf.keras.metrics= :)*
  - PROBLEM: no tf.keras.metrics.Fmeasure (or similar) - mmmh...
- AUC = Area Under the ROC Curve
  - is scale-invariante → measures how well predictions are ranked, rather than
    their absolute values
    - Cave: not always desirable, e.g. if we do need well calibrated probability outputs
  - is classification-threshold-invariant
    - Cave: not always desirable, e.g. when there are wide disparities in the
      cost of false negatives vs false positives, it may be critical to minimize
      one type of classification error → this is actually a thing in artifact
      classification, since we want to minimize the false negatives

This is the list I came up with:

#+BEGIN_SRC python
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
metrics = [tf.keras.metrics.TruePositives(name='tp', thresholds=thresholds),
           tf.keras.metrics.FalsePositives(name='fp', thresholds=thresholds),
           tf.keras.metrics.TrueNegatives(name='tn', thresholds=thresholds),
           tf.keras.metrics.FalseNegatives(name='fn', thresholds=thresholds),
           tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5),
           tf.keras.metrics.Precision(name='precision', thresholds=thresholds),
           tf.keras.metrics.Recall(name='recall', thresholds=thresholds),
           tf.keras.metrics.AUC(num_thresholds=100, name='auc')]
#+END_SRC
*** DONE compute metrics vs threshold → there is a =thresholds= argument for) =tf.keras.metrics= :
    CLOSED: [2021-07-20 Di 14:05]
** Improving unet features, incorporate absolute brightness<2021-04-12 Mo>
   - two ideas:
     1. concatenate some numerical limited version of the absolute trace
        1. normalize not from min to max, but from 0 to max
        2. normalize from 0.05 to 0.95
     2. different normalization? e.g. fit a
        =sklearn.preprocessing.StandardScaler=? This would learn a mean of 0 and
        a variance.
        1. Do this directly on unpreprocessed traces with absolute brightness
           values
        2. Do this on min-max-normalized values
        3. do this on 0 to max normalized values
*** install =sklearn=
    - we need:
      - numpy
      - pandas
      - matplotlib
      - seaborn
      - mlflow
      - lmfit (needed by =fluotracify.applications.correlate=)
      - jupyterlab
      - scikit-learn
      - pip
      - pip:
        - tf-nightly
        - fcsfiles
        - multipletau

    #+begin_example
      conda env remove -n tf-nightly
      conda create -n tf-nightly numpy pandas matplotlib seaborn tifffile jupyterlab pip
      conda install -n tf-nightly -c conda-forge/label/main mlflow lmfit scikit-learn
      conda activate tf-nightly
      (tf-nightly) pip install fcsfiles multipletau tf-nightly
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
      conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (base) [ye53nis@login01 /]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      absl-py                   0.12.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge/label/main
      anyio                     2.2.0            py39h06a4308_1
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge/label/main
      argon2-cffi               20.1.0           py39h27cfd23_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge/label/main
      asteval                   0.9.23             pyhd8ed1ab_0    conda-forge/label/main
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10               pyhd3eb1b0_0
      attrs                     20.3.0             pyhd3eb1b0_0
      babel                     2.9.0              pyhd3eb1b0_0
      backcall                  0.2.0              pyhd3eb1b0_0
      blas                      1.0                         mkl
      bleach                    3.3.0              pyhd3eb1b0_0
      blosc                     1.21.0               h8c45485_0
      brotli                    1.0.9                he6710b0_2
      brotlipy                  0.7.0           py39h27cfd23_1003
      brunsli                   0.1                  h2531618_0
      bzip2                     1.0.8                h7b6447c_0
      ca-certificates           2020.12.5            ha878542_0    conda-forge/label/main
      cachetools                4.2.1                    pypi_0    pypi
      certifi                   2020.12.5        py39hf3d152e_1    conda-forge/label/main
      cffi                      1.14.5           py39h261ae71_0
      chardet                   4.0.0           py39h06a4308_1003
      charls                    2.2.0                h2531618_0
      click                     7.1.2              pyh9f0ad1d_0    conda-forge/label/main
      cloudpickle               1.6.0                      py_0    conda-forge/label/main
      configparser              5.0.2              pyhd8ed1ab_0    conda-forge/label/main
      cryptography              3.4.7            py39hd23ed53_0
      cycler                    0.10.0           py39h06a4308_0
      databricks-cli            0.9.1                      py_0    conda-forge/label/main
      dbus                      1.13.18              hb2f20db_0
      decorator                 5.0.6              pyhd3eb1b0_0
      defusedxml                0.7.1              pyhd3eb1b0_0
      docker-py                 5.0.0            py39hf3d152e_0    conda-forge/label/main
      docker-pycreds            0.4.0                      py_0    conda-forge/label/main
      entrypoints               0.3              py39h06a4308_0
      expat                     2.3.0                h2531618_2
      fcsfiles                  2020.9.18                pypi_0    pypi
      flask                     1.1.2              pyh9f0ad1d_0    conda-forge/label/main
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.1               h6c09931_0
      freetype                  2.10.4               h5ab3b9f_0
      future                    0.18.2           py39hf3d152e_3    conda-forge/label/main
      gast                      0.4.0                    pypi_0    pypi
      giflib                    5.1.4                h14c3975_1
      gitdb                     4.0.7              pyhd8ed1ab_0    conda-forge/label/main
      gitpython                 3.1.14             pyhd8ed1ab_0    conda-forge/label/main
      glib                      2.68.0               h36276a3_0
      google-auth               1.28.1                   pypi_0    pypi
      google-auth-oauthlib      0.4.4                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      grpcio                    1.34.1                   pypi_0    pypi
      gst-plugins-base          1.14.0               h8213a91_2
      gstreamer                 1.14.0               h28cd5cc_2
      gunicorn                  20.1.0           py39hf3d152e_0    conda-forge/label/main
      h5py                      3.1.0                    pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10               pyhd3eb1b0_0
      imagecodecs               2021.3.31        py39h581e88b_0
      importlib-metadata        3.10.0           py39h06a4308_0
      importlib_metadata        3.10.0               hd3eb1b0_0
      intel-openmp              2020.2                      254
      ipykernel                 5.3.4            py39hb070fc8_0
      ipython                   7.22.0           py39hb070fc8_0
      ipython_genutils          0.2.0              pyhd3eb1b0_1
      itsdangerous              1.1.0                      py_0    conda-forge/label/main
      jedi                      0.17.2           py39h06a4308_1
      jinja2                    2.11.3             pyhd3eb1b0_0
      joblib                    1.0.1              pyhd8ed1ab_0    conda-forge/label/main
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.5                      py_0
      jsonschema                3.2.0                      py_2
      jupyter-packaging         0.7.12             pyhd3eb1b0_0
      jupyter_client            6.1.12             pyhd3eb1b0_0
      jupyter_core              4.7.1            py39h06a4308_0
      jupyter_server            1.4.1            py39h06a4308_0
      jupyterlab                3.0.11             pyhd3eb1b0_1
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         2.4.0              pyhd3eb1b0_0
      jxrlib                    1.1                  h7b6447c_2
      keras-nightly             2.6.0.dev2021041200          pypi_0    pypi
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.1            py39h2531618_0
      lcms2                     2.12                 h3be6417_0
      ld_impl_linux-64          2.33.1               h53a641e_7
      lerc                      2.2.1                h2531618_0
      libaec                    1.0.4                he6710b0_1
      libblas                   3.8.0                    21_mkl    conda-forge/label/main
      libcblas                  3.8.0                    21_mkl    conda-forge/label/main
      libdeflate                1.7                  h27cfd23_5
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.1.0                hdf63c60_0
      libgfortran-ng            7.3.0                hdf63c60_0
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.13.0.1             h8b12597_0    conda-forge/label/main
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.1.0                hdf63c60_0
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libwebp                   1.0.1                h8e7db2f_0
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.10               hb55368b_3
      libzopfli                 1.0.3                he6710b0_0
      lmfit                     1.0.2              pyhd8ed1ab_0    conda-forge/label/main
      lz4-c                     1.9.3                h2531618_0
      mako                      1.1.4              pyh44b312d_0    conda-forge/label/main
      markdown                  3.3.4                    pypi_0    pypi
      markupsafe                1.1.1            py39h27cfd23_0
      matplotlib                3.3.4            py39h06a4308_0
      matplotlib-base           3.3.4            py39h62a2d02_0
      mistune                   0.8.4           py39h27cfd23_1000
      mkl                       2020.2                      256
      mkl-service               2.3.0            py39he8ac12f_0
      mkl_fft                   1.3.0            py39h54f3939_0
      mkl_random                1.0.2            py39h63df603_0
      mlflow                    1.15.0           py39ha39b057_0    conda-forge/label/main
      multipletau               0.3.3                    pypi_0    pypi
      nbclassic                 0.2.6              pyhd3eb1b0_0
      nbclient                  0.5.3              pyhd3eb1b0_0
      nbconvert                 6.0.7            py39h06a4308_0
      nbformat                  5.1.3              pyhd3eb1b0_0
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.5.1              pyhd3eb1b0_0
      notebook                  6.3.0            py39h06a4308_0
      numpy                     1.19.5                   pypi_0    pypi
      oauthlib                  3.1.0                    pypi_0    pypi
      olefile                   0.46                       py_0
      openjpeg                  2.3.0                h05c96fa_1
      openssl                   1.1.1k               h27cfd23_0
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 20.9               pyhd3eb1b0_0
      pandas                    1.2.3            py39ha9443f7_0
      pandoc                    2.12                 h06a4308_0
      pandocfilters             1.4.3            py39h06a4308_1
      parso                     0.7.0                      py_0
      pcre                      8.44                 he6710b0_0
      pexpect                   4.8.0              pyhd3eb1b0_3
      pickleshare               0.7.5           pyhd3eb1b0_1003
      pillow                    8.2.0            py39he98fc37_0
      pip                       21.0.1           py39h06a4308_0
      prometheus_client         0.10.0             pyhd3eb1b0_0
      prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge/label/main
      prompt-toolkit            3.0.17             pyh06a4308_0
      protobuf                  3.13.0.1         py39h41458e0_1    conda-forge/label/main
      ptyprocess                0.7.0              pyhd3eb1b0_2
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.8.1              pyhd3eb1b0_0
      pyopenssl                 20.0.1             pyhd3eb1b0_1
      pyparsing                 2.4.7              pyhd3eb1b0_0
      pyqt                      5.9.2            py39h2531618_6
      pyrsistent                0.17.3           py39h27cfd23_0
      pysocks                   1.7.1            py39h06a4308_0
      python                    3.9.2                hdb3f193_0
      python-dateutil           2.8.1              pyhd3eb1b0_0
      python-editor             1.0.4                      py_0    conda-forge/label/main
      python_abi                3.9                      1_cp39    conda-forge/label/main
      pytz                      2021.1             pyhd3eb1b0_0
      pyyaml                    5.3.1            py39h38d8fee_1    conda-forge/label/main
      pyzmq                     20.0.0           py39h2531618_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge/label/main
      readline                  8.1                  h27cfd23_0
      requests                  2.25.1             pyhd3eb1b0_0
      requests-oauthlib         1.3.0                    pypi_0    pypi
      rsa                       4.7.2                    pypi_0    pypi
      scikit-learn              0.23.2           py39hf3c863f_2    conda-forge/label/main
      scipy                     1.6.2            py39h91f5cce_0
      seaborn                   0.11.1             pyhd3eb1b0_0
      send2trash                1.5.0              pyhd3eb1b0_1
      setuptools                52.0.0           py39h06a4308_0
      sip                       4.19.13          py39h2531618_0
      six                       1.15.0           py39h06a4308_0
      smmap                     3.0.5              pyh44b312d_0    conda-forge/label/main
      snappy                    1.1.8                he6710b0_0
      sniffio                   1.2.0            py39h06a4308_1
      sqlalchemy                1.3.20           py39h07f9747_0    conda-forge/label/main
      sqlite                    3.35.4               hdfb4753_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge/label/main
      tabulate                  0.8.9              pyhd8ed1ab_0    conda-forge/label/main
      tb-nightly                2.5.0a20210412           pypi_0    pypi
      tensorboard-data-server   0.6.0                    pypi_0    pypi
      tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.4            py39h06a4308_0
      testpath                  0.4.4              pyhd3eb1b0_0
      tf-estimator-nightly      2.5.0.dev2021032601          pypi_0    pypi
      tf-nightly                2.6.0.dev20210412          pypi_0    pypi
      threadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge/label/main
      tifffile                  2021.3.31          pyhd3eb1b0_1
      tk                        8.6.10               hbc83047_0
      tornado                   6.1              py39h27cfd23_0
      traitlets                 5.0.5              pyhd3eb1b0_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      tzdata                    2020f                h52ac0ba_0
      uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge/label/main
      urllib3                   1.26.4             pyhd3eb1b0_0
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1            py39h06a4308_1
      websocket-client          0.57.0           py39hf3d152e_4    conda-forge/label/main
      werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge/label/main
      wheel                     0.36.2             pyhd3eb1b0_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge/label/main
      zeromq                    4.3.4                h2531618_0
      zfp                       0.5.5                h2531618_6
      zipp                      3.4.1              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.5                h9ceee32_0
      (base) [ye53nis@login01 /]$
    #+end_example

*** new normalizations <2021-07-11 So>
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#9999:fe84eb77-f87c-4174-9d8c-3dab336c6ba5
    :END:
    https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py
    1. Load modules
       #+BEGIN_SRC jupyter-python
         !pwd
       #+END_SRC

       #+RESULTS:
       : ead137fb-459a-457c-9ecf-61a822b690aa

       #+BEGIN_SRC jupyter-python
         !cd '/beegfs/ye53nis/drmed-git'
       #+END_SRC

       #+RESULTS:

       #+BEGIN_SRC jupyter-python
         import sys
         import matplotlib

         import matplotlib.pyplot as plt
         import numpy as np
         import pandas as pd
         import tensorflow as tf

         from sklearn.preprocessing import (MinMaxScaler, MaxAbsScaler, StandardScaler,
                                            RobustScaler, Normalizer,
                                            QuantileTransformer, PowerTransformer)

         FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
         sys.path.append(FLUOTRACIFY_PATH)

         if True:  # isort workaround
             from fluotracify.simulations import import_simulation_from_csv as isfc

         print(tf.version.VERSION)
         print('GPUs: ', tf.config.list_physical_devices('GPU'))
       #+END_SRC

       #+RESULTS:
       : INFO:tensorflow:Enabling eager execution
       : INFO:tensorflow:Enabling v2 tensorshape
       : INFO:tensorflow:Enabling resource variables
       : INFO:tensorflow:Enabling tensor equality
       : INFO:tensorflow:Enabling control flow v2
       : 2.6.0-dev20210412
       : GPUs:  []
    2. Load data

       #+BEGIN_SRC jupyter-python
         train, _, nsamples, _ = isfc.import_from_csv(
             folder='/beegfs/ye53nis/saves/firstartifact_Nov2020_subsample/',
             header=12,
             frac_train=1,
             col_per_example=3,
             dropindex=None,
             dropcolumns=None)

         train_sep = isfc.separate_data_and_labels(
             array=train,
             nsamples=nsamples,
             col_per_example=3)

         train_data = train_sep['0']
       #+END_SRC

       #+RESULTS:
       : train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020_subsample/traces_brightclust_Nov2020_D1.0_set003.csv
       : train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020_subsample/traces_brightclust_Nov2020_D3.0_set004.csv
       : train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020_subsample/traces_brightclust_Nov2020_D0.2_set002.csv
       : train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020_subsample/traces_brightclust_Nov2020_D0.069_set001.csv
       : The given DataFrame was split into 3 parts with shapes: [(16384, 400), (16384, 400), (16384, 400)]
    3. how it was done until now
       #+BEGIN_SRC jupyter-python :pandoc t
         # min-max normalization up till now
         X_tensor = tf.convert_to_tensor(value=train_data.values)
         print(X_tensor.shape)
         # X_tensor = tf.transpose(a=X_tensor, perm=[1, 0])
         # print(X_tensor.shape)
         tensor_min = tf.math.reduce_min(input_tensor=X_tensor, axis=0, keepdims=True)
         tensor_max = tf.math.reduce_max(input_tensor=X_tensor, axis=0, keepdims=True)
         tensor_mean = tf.math.reduce_mean(input_tensor=X_tensor, axis=0, keepdims=True)
         print(tensor_min.shape)
         X_tensor_norm = (X_tensor - tensor_min) / (tensor_max - tensor_min)
         print(X_tensor_norm.shape)
         train_data_norm = pd.DataFrame(data=X_tensor_norm.numpy(),
                                        columns=train_data.columns)

         plt.figure(figsize=(12, 6))
         plt.subplot(1, 2, 1)
         [plt.plot(train_data['trace001'].iloc[:, i], alpha=0.75) for i in range(3)]
         plt.subplot(1, 2, 2)
         [plt.plot(train_data_norm['trace001'].iloc[:, i], alpha=0.75) for i in range(3)]
         plt.show()

         # new: mean normalization
         X_tensor_mean = (X_tensor - tensor_mean) / (tensor_max - tensor_min)
         print(X_tensor_mean.shape)
         train_data_mean = pd.DataFrame(data=X_tensor_mean.numpy(),
                                        columns=train_data.columns)
         train_data_mean
       #+END_SRC

       #+RESULTS:
       :RESULTS:
       : (16384, 400)
       : (1, 400)
       : (16384, 400)
       [[file:./.ob-jupyter/0d617c4a5fac10a80cb533facacb3941265b4b42.png]]
       : (16384, 400)
       :END:
    4. define new distributions

       #+BEGIN_SRC jupyter-python
         def make_distributions(X, transpose=False):
           """Given a pandas DataFrame or pandas Series, this function returns many
           preprocessed / normalized versions of the data.

           Parameters
           ----------
               X : pandas DataFrame or pandas Series
                   Your Data. Notice that normalizations are applied along the ____.
               transpose: bool, optional
                   Normalizations are applied along ___. if your data is along ___,
                   you can choose this option to transpose it.

           Returns:
           --------
               distributions : list of tuples
                   each tuple includes first, a string describing the normalization,
                   second, the transformed Data in form of a pandas DataFrame with Data
                   ordered row-wise. The first tuple is the unscaled data (ordered row-wise).
                   third, the scaler (if there is any)"""
           if isinstance(X, pd.Series):
               X_ind = [X.name]
               X = np.array(X).reshape(1, -1)
               X_col = X.columns
           elif transpose:
               X_ind = X.columns
               X_col = X.index
               X = X.T
           else:
               X_ind = X.index
               X_col = X.columns

           scaler_stand = StandardScaler().fit(X)
           scaler_minmax = MinMaxScaler().fit(X)
           scaler_maxabs = MaxAbsScaler().fit(X)
           scaler_robust = RobustScaler(quantile_range=(25, 75)).fit(X)
           scaler_powerb = PowerTransformer(method='box-cox').fit(X)
           scaler_powery = PowerTransformer(method='yeo-johnson').fit(X)
           scaler_powery.lambdas_ = scaler_powerb.lambdas_
           scaler_quantu = QuantileTransformer(output_distribution='uniform').fit(X)
           scaler_quantn = QuantileTransformer(output_distribution='normal').fit(X)

           distributions = [
               ('Unscaled data',
                pd.DataFrame(X,
                            columns=X_col,
                            index=X_ind),
                np.nan),
               ('Data after standard scaling (z-score)',
                pd.DataFrame(scaler_stand.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_stand),
               ('Data after min-max scaling',
                pd.DataFrame(scaler_minmax.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_minmax),
               ('Data after max-abs scaling',
                pd.DataFrame(scaler_maxabs.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_maxabs),
               ('Data after robust scaling',
                pd.DataFrame(scaler_robust.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_robust),
               ('Data after standard scaling + power transformation (Yeo-Johnson)',
                pd.DataFrame(scaler_powery.transform(scaler_stand.transform(X)),
                             columns=X_col,
                             index=X_ind),
                scaler_powery),
               ('Data after power transformation (Box-Cox)',
                pd.DataFrame(scaler_powerb.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_powerb),
               ('Data after quantile transformation (uniform pdf)',
                pd.DataFrame(scaler_quantu.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_quantu),
               ('Data after quantile transformation (gaussian pdf)',
                pd.DataFrame(scaler_quantn.transform(X),
                             columns=X_col,
                             index=X_ind),
                scaler_quantn),
               ('Data after sample-wise L2 normalizing',
                pd.DataFrame(Normalizer(norm='l2').transform(X.T),
                             columns=X_ind,
                             index=X_col).T,
                np.nan),
               ('Data after sample-wise L1 normalizing',
                pd.DataFrame(Normalizer(norm='l1').transform(X.T),
                             columns=X_ind,
                             index=X_col).T,
                np.nan),
               ('Data after maximum rescaling',
                pd.DataFrame(Normalizer(norm='max').transform(X.T),
                             columns=X_ind,
                             index=X_col).T,
                np.nan)
           ]
           return distributions
       #+END_SRC

       #+RESULTS:

       #+BEGIN_SRC jupyter-python
         dist = make_distributions(train_data, transpose=False)
         dist
       #+END_SRC

       #+RESULTS:
       : /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy/core/_methods.py:205: RuntimeWarning: overflow encountered in multiply
       :   x = um.multiply(x, x, out=x)
       : /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/scipy/stats/morestats.py:908: RuntimeWarning: divide by zero encountered in log
       :   return (lmb - 1) * np.sum(logdata, axis=0) - N/2 * np.log(variance)
       : /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2995: RuntimeWarning: divide by zero encountered in log
       :   loglike = -n_samples / 2 * np.log(x_trans.var())
       : /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy/core/_methods.py:205: RuntimeWarning: overflow encountered in multiply
       :   x = um.multiply(x, x, out=x)

       #+BEGIN_SRC jupyter-python
         print(dist)
       #+END_SRC

       #+RESULTS:
       #+begin_example
         [('Unscaled data',          trace001    trace002    trace003     trace004    trace005  \
         0      754.018494  676.901794  498.305908   720.309937  323.721313
         1      666.794556  555.267578  492.654816   697.321289  364.112946
         2      715.957275  499.356018  466.321655   622.633545  375.809692
         3      657.154114  459.034149  535.105835   635.545837  522.477295
         4      616.482727  539.307068  492.210052   590.638428  534.843201
         ...           ...         ...         ...          ...         ...
         16379  521.752808  646.284119  779.564148  2332.558838  199.963242
         16380  618.194763  559.607727  695.014343  1993.306885  229.738525
         16381  609.652466  589.472290  719.822449  1485.164062  280.392151
         16382  620.979553  588.772766  586.755554  1193.868408  304.137177
         16383  751.637268  555.135864  598.331665  1065.078491  336.629456

                  trace006    trace007    trace008    trace009    trace010  ...  \
         0      543.129822  311.419556  516.338379  337.161224  557.263733  ...
         1      544.123535  434.556030  470.062531  308.559875  569.688965  ...
         2      553.744873  365.927246  376.058258  380.894592  475.625732  ...
         3      487.534668  388.165894  491.942230  370.221954  512.013733  ...
         4      620.908081  328.356659  425.973114  325.750824  556.580261  ...
         ...           ...         ...         ...         ...         ...  ...
         16379  304.133392  255.286819  765.595520  509.118073  431.508850  ...
         16380  280.601410  214.003250  672.589905  545.155762  409.707184  ...
         16381  262.619507  273.560059  656.789673  522.227356  446.445190  ...
         16382  340.902557  254.671768  744.407959  506.209717  436.126099  ...
         16383  324.043365  325.289307  681.677490  406.633392  342.627808  ...

                  trace091    trace092    trace093    trace094    trace095  \
         0      977.848755  545.781677  788.683960  887.465332  401.768097
         1      947.500610  508.677002  764.407227  853.524048  398.673309
         2      939.926697  507.675568  783.334351  853.687439  396.849365
         3      960.987854  492.313416  769.736938  937.796936  377.197906
         4      974.095764  476.890717  781.333984  912.626282  378.945038
         ...           ...         ...         ...         ...         ...
         16379  921.034729  526.733643  601.366577  712.702454  711.295532
         16380  889.003418  540.101318  602.672729  715.226196  742.092407
         16381  858.980225  557.671753  585.629517  711.965027  740.574707
         16382  834.091797  561.952698  589.424438  682.825134  739.458679
         16383  809.784668  566.328003  620.593933  677.919495  729.933167

                   trace096    trace097     trace098    trace099    trace100
         0      3640.799072  734.495300   506.971680  696.570068  581.336304
         1      3494.905273  733.863281   506.944855  724.331848  584.186218
         2      4072.614014  717.392273   527.786133  674.392456  569.638916
         3      4134.416992  723.996033   527.335266  694.907043  567.278137
         4      4467.120605  721.176208   524.716980  706.516907  583.473877
         ...            ...         ...          ...         ...         ...
         16379   610.135559  705.280396  1480.517212  470.642426  721.780823
         16380   621.402039  703.816406  1280.718872  479.142883  706.676697
         16381   663.161377  715.013611  1261.820923  466.791870  709.978333
         16382   679.829163  692.574280  1425.392944  476.635254  725.428711
         16383   714.244324  658.971741  1382.962646  477.999146  714.848267

         [16384 rows x 400 columns], nan), ('Data after standard scaling (z-score)',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.087520 -0.256349 -0.297772 -0.118538 -0.452831 -0.176719 -0.440661
         1     -0.036369 -0.347284 -0.305417 -0.142016 -0.386599 -0.175422 -0.298664
         2      0.033460 -0.389084 -0.341045 -0.218291 -0.367419 -0.162863 -0.377805
         3     -0.050062 -0.419229 -0.247983 -0.205104 -0.126920 -0.249289 -0.352160
         4     -0.107830 -0.359216 -0.306019 -0.250966 -0.106643 -0.075194 -0.421130
         ...         ...       ...       ...       ...       ...       ...       ...
         16379 -0.242380 -0.279239  0.082755  1.527985 -0.655765 -0.488686 -0.505391
         16380 -0.105398 -0.344039 -0.031636  1.181521 -0.606941 -0.519403 -0.552998
         16381 -0.117531 -0.321712  0.001928  0.662576 -0.523881 -0.542875 -0.484319
         16382 -0.101443 -0.322235 -0.178104  0.365087 -0.484945 -0.440691 -0.506100
         16383  0.084138 -0.347383 -0.162443  0.233560 -0.431665 -0.462697 -0.424667

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0     -0.313669 -0.525821 -0.308043  ... -0.283800 -0.242792 -0.308142
         1     -0.358366 -0.540973 -0.294412  ... -0.306577 -0.329245 -0.328034
         2     -0.449162 -0.502652 -0.397603  ... -0.312261 -0.331578 -0.312525
         3     -0.337233 -0.508306 -0.357684  ... -0.296455 -0.367372 -0.323667
         4     -0.400951 -0.531866 -0.308793  ... -0.286617 -0.403306 -0.314164
         ...         ...       ...       ...  ...       ...       ...       ...
         16379 -0.072917 -0.434723 -0.446001  ... -0.326439 -0.287174 -0.461628
         16380 -0.162749 -0.415632 -0.469919  ... -0.350479 -0.256027 -0.460558
         16381 -0.178010 -0.427778 -0.429615  ... -0.373011 -0.215088 -0.474523
         16382 -0.093382 -0.436264 -0.440936  ... -0.391690 -0.205114 -0.471414
         16383 -0.153972 -0.489017 -0.543508  ... -0.409932 -0.194920 -0.445874

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0     -0.098213 -0.666161  1.028767 -0.290217 -0.560149 -0.258146 -0.299515
         1     -0.126558 -0.669834  0.941904 -0.290999 -0.560170 -0.226095 -0.294687
         2     -0.126422 -0.671999  1.285865 -0.311379 -0.543698 -0.283750 -0.319331
         3     -0.056180 -0.695325  1.322662 -0.303208 -0.544055 -0.260066 -0.323330
         4     -0.077201 -0.693251  1.520750 -0.306697 -0.546124 -0.246662 -0.295894
         ...         ...       ...       ...       ...       ...       ...       ...
         16379 -0.244160 -0.298759 -0.775656 -0.326366  0.209304 -0.518977 -0.061598
         16380 -0.242053 -0.262203 -0.768948 -0.328178  0.051391 -0.509163 -0.087185
         16381 -0.244776 -0.264005 -0.744085 -0.314323  0.036455 -0.523423 -0.081592
         16382 -0.269111 -0.265330 -0.734161 -0.342088  0.165736 -0.512059 -0.055418
         16383 -0.273208 -0.276636 -0.713671 -0.383667  0.132201 -0.510484 -0.073342

         [16384 rows x 400 columns], StandardScaler()), ('Data after min-max scaling',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.106722  0.060669  0.075113  0.083603  0.035017  0.049127  0.028303
         1      0.093398  0.048492  0.074132  0.080550  0.040523  0.049236  0.042719
         2      0.100908  0.042894  0.069561  0.070635  0.042117  0.050285  0.034685
         3      0.091926  0.038857  0.081500  0.072349  0.062109  0.043064  0.037288
         4      0.085713  0.046894  0.074055  0.066387  0.063795  0.057610  0.030286
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.071244  0.057604  0.123933  0.297651  0.018147  0.023063  0.021731
         16380  0.085975  0.048926  0.109257  0.252610  0.022206  0.020497  0.016898
         16381  0.084670  0.051916  0.113563  0.185147  0.029111  0.018536  0.023871
         16382  0.086400  0.051846  0.090466  0.146474  0.032347  0.027073  0.021659
         16383  0.106358  0.048478  0.092475  0.129375  0.036776  0.025234  0.029927

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.068211  0.023062  0.073623  ...  0.079135  0.070493  0.063209
         1      0.061148  0.020290  0.075506  ...  0.075781  0.063833  0.060420
         2      0.046802  0.027301  0.061248  ...  0.074944  0.063653  0.062594
         3      0.064487  0.026267  0.066764  ...  0.077272  0.060895  0.061032
         4      0.054419  0.021956  0.073519  ...  0.078720  0.058127  0.062364
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.106251  0.039730  0.054561  ...  0.072857  0.067074  0.041691
         16380  0.092057  0.043223  0.051256  ...  0.069317  0.069473  0.041841
         16381  0.089645  0.041000  0.056825  ...  0.065999  0.072627  0.039883
         16382  0.103017  0.039448  0.055261  ...  0.063248  0.073395  0.040319
         16383  0.093444  0.029796  0.041088  ...  0.060562  0.074181  0.043900

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.068484  0.021370  0.336066  0.058658  0.034924  0.052797  0.041955
         1      0.064889  0.020882  0.321734  0.058571  0.034920  0.056085  0.042295
         2      0.064907  0.020595  0.378486  0.056326  0.038004  0.050169  0.040560
         3      0.073814  0.017498  0.384557  0.057226  0.037937  0.052600  0.040279
         4      0.071149  0.017773  0.417241  0.056842  0.037550  0.053975  0.042210
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.049976  0.070147  0.038343  0.054674  0.178996  0.026033  0.058703
         16380  0.050243  0.075000  0.039450  0.054475  0.149428  0.027040  0.056902
         16381  0.049898  0.074761  0.043552  0.056001  0.146632  0.025576  0.057296
         16382  0.046812  0.074585  0.045190  0.052942  0.170838  0.026743  0.059138
         16383  0.046292  0.073084  0.048571  0.048361  0.164559  0.026904  0.057876

         [16384 rows x 400 columns], MinMaxScaler()), ('Data after max-abs scaling',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.114208  0.067290  0.085521  0.094494  0.043728  0.058640  0.036165
         1      0.100997  0.055198  0.084552  0.091479  0.049184  0.058747  0.050464
         2      0.108443  0.049640  0.080032  0.081681  0.050764  0.059786  0.042494
         3      0.099537  0.045632  0.091837  0.083375  0.070576  0.052638  0.045077
         4      0.093376  0.053612  0.084475  0.077483  0.072247  0.067038  0.038131
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.079028  0.064246  0.133792  0.305998  0.027011  0.032836  0.029646
         16380  0.093636  0.055630  0.119281  0.261493  0.031033  0.030296  0.024852
         16381  0.092342  0.058599  0.123539  0.194832  0.037875  0.028354  0.031768
         16382  0.094057  0.058529  0.100702  0.156619  0.041083  0.036806  0.029575
         16383  0.113848  0.055185  0.102688  0.139723  0.045472  0.034986  0.037775

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.077975  0.032370  0.083564  ...  0.105026  0.095347  0.088183
         1      0.070986  0.029624  0.085427  ...  0.101767  0.088865  0.085469
         2      0.056790  0.036568  0.071322  ...  0.100953  0.088690  0.087585
         3      0.074291  0.035544  0.076779  ...  0.103216  0.086006  0.086065
         4      0.064328  0.031274  0.083462  ...  0.104623  0.083312  0.087362
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.115616  0.048878  0.064707  ...  0.098924  0.092019  0.067239
         16380  0.101571  0.052338  0.061437  ...  0.095484  0.094355  0.067385
         16381  0.099185  0.050137  0.066946  ...  0.092259  0.097424  0.065480
         16382  0.112417  0.048599  0.065399  ...  0.089586  0.098172  0.065904
         16383  0.102943  0.039039  0.051379  ...  0.086975  0.098936  0.069389

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.091648  0.060764  0.350100  0.096151  0.072133  0.080136  0.067477
         1      0.088143  0.060296  0.336071  0.096068  0.072129  0.083330  0.067808
         2      0.088160  0.060020  0.391623  0.093912  0.075094  0.077584  0.066119
         3      0.096846  0.057048  0.397566  0.094776  0.075030  0.079945  0.065845
         4      0.094247  0.057312  0.429559  0.094407  0.074658  0.081280  0.067725
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.073601  0.107578  0.058671  0.092326  0.210651  0.054144  0.083778
         16380  0.073861  0.112236  0.059754  0.092135  0.182223  0.055122  0.082025
         16381  0.073525  0.112006  0.063770  0.093600  0.179534  0.053701  0.082408
         16382  0.070515  0.111837  0.065373  0.090663  0.202807  0.054834  0.084202
         16383  0.070009  0.110397  0.068682  0.086264  0.196770  0.054991  0.082974

         [16384 rows x 400 columns], MaxAbsScaler()), ('Data after robust scaling',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.938560  0.331588 -0.120243  0.559385 -0.780975  0.063121 -0.776111
         1      0.594466 -0.015093 -0.141606  0.481084 -0.598064  0.067061 -0.293932
         2      0.788410 -0.174452 -0.241157  0.226693 -0.545096  0.105209 -0.562669
         3      0.556435 -0.289377  0.018876  0.270673  0.119080 -0.157309 -0.475587
         4      0.395989 -0.060584 -0.143288  0.117716  0.175078  0.371506 -0.709788
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.022284  0.244321  0.943031  6.050807 -1.341406 -0.884481 -0.995916
         16380  0.402742 -0.002723  0.623398  4.895293 -1.206570 -0.977784 -1.157575
         16381  0.369044  0.082397  0.717183  3.164526 -0.977188 -1.049081 -0.924362
         16382  0.413728  0.080403  0.214134  2.172355 -0.869660 -0.738694 -0.998325
         16383  0.929166 -0.015469  0.257896  1.733689 -0.722521 -0.805540 -0.721800

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0     -0.034617 -0.509870  0.031576  ...  0.229219 -0.151340  0.017449
         1     -0.186915 -0.569829  0.067237  ...  0.162655 -0.303809 -0.046206
         2     -0.496292 -0.418190 -0.202726  ...  0.146043 -0.307924  0.003422
         3     -0.114907 -0.440563 -0.098292  ...  0.192237 -0.371049 -0.032231
         4     -0.332017 -0.533790  0.029615  ...  0.220987 -0.434423 -0.001823
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.785712 -0.149389 -0.329342  ...  0.104606 -0.229611 -0.473704
         16380  0.479622 -0.073841 -0.391913  ...  0.034351 -0.174682 -0.470280
         16381  0.427622 -0.121907 -0.286474  ... -0.031500 -0.102483 -0.514968
         16382  0.715982 -0.155486 -0.316090  ... -0.086089 -0.084892 -0.505017
         16383  0.509530 -0.364232 -0.584432  ... -0.139403 -0.066913 -0.423290

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.547968 -0.801234  1.447266 -0.189498 -0.686699 -0.007200 -0.362439
         1      0.456699 -0.809107  1.365107 -0.191379 -0.686769  0.086344 -0.352776
         2      0.457139 -0.813746  1.690441 -0.240413 -0.632215 -0.081928 -0.402103
         3      0.683311 -0.863737  1.725245 -0.220754 -0.633395 -0.012803 -0.410107
         4      0.615627 -0.859293  1.912606 -0.229148 -0.640249  0.026316 -0.355191
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.078026 -0.013837 -0.259440 -0.276469  1.861633 -0.768466  0.113777
         16380  0.084813  0.064506 -0.253096 -0.280827  1.338645 -0.739824  0.062562
         16381  0.076043  0.060645 -0.229579 -0.247494  1.289178 -0.781441  0.073757
         16382 -0.002314  0.057806 -0.220193 -0.314294  1.717341 -0.748273  0.126146
         16383 -0.015506  0.033575 -0.200812 -0.414327  1.606276 -0.743678  0.090270

         [16384 rows x 400 columns], RobustScaler(quantile_range=(25, 75))), ('Data after standard scaling + power transformation (Yeo-Johnson)',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.022772 -0.372874 -0.429758 -0.189818 -0.676076 -0.260921 -0.664154
         1     -0.096675 -0.513496 -0.441282 -0.218601 -0.564283 -0.259254 -0.431639
         2     -0.026661 -0.583657 -0.496377 -0.319098 -0.533354 -0.243261 -0.556568
         3     -0.111284 -0.636470 -0.357273 -0.300947 -0.198484 -0.358761 -0.514816
         4     -0.176185 -0.533164 -0.442194 -0.365498 -0.174570 -0.138913 -0.629918
         ...         ...       ...       ...       ...       ...       ...       ...
         16379 -0.348514 -0.406750  0.018488  0.633265 -1.068398 -0.748305 -0.782905
         16380 -0.173345 -0.508198 -0.091707  0.549590 -0.966985 -0.806055 -0.875511
         16381 -0.187609 -0.472307 -0.057363  0.372203 -0.804763 -0.851420 -0.743349
         16382 -0.168746 -0.473136 -0.262878  0.221893 -0.733105 -0.661693 -0.784252
         16383  0.019790 -0.513657 -0.242874  0.136652 -0.639502 -0.700861 -0.636064

                trace008  trace009  trace010  ...   trace091  trace092    trace093  \
         0     -0.456124 -0.839466 -0.443478  ...  -8.951520 -0.347433  -13.260606
         1     -0.527063 -0.870231 -0.423109  ... -12.932536 -0.472981  -18.186014
         2     -0.683014 -0.793393 -0.585507  ... -14.162353 -0.476543  -14.222190
         3     -0.493050 -0.804529 -0.520429  ... -10.990324 -0.532364  -16.974485
         4     -0.598205 -0.851679 -0.444608  ...  -9.371428 -0.590626  -14.598546
         ...         ...       ...       ...  ...        ...       ...         ...
         16379 -0.136504 -0.664964 -0.668300  ... -17.734339 -0.410321 -135.320084
         16380 -0.243823 -0.630626 -0.710810  ... -25.828493 -0.365845 -133.260040
         16381 -0.263435 -0.652385 -0.639787  ... -36.521942 -0.309825 -162.648666
         16382 -0.159748 -0.667768 -0.659433  ... -48.465191 -0.296592 -155.614273
         16383 -0.232727 -0.766821 -0.848347  ... -63.659214 -0.283233 -107.843590

                trace094     trace095     trace096   trace097    trace098    trace099  \
         0     -0.166364 -2102.018066    -0.006501  -9.935444 -530.478699   -5.869256
         1     -0.200670 -2201.248291    -0.006501 -10.062207 -530.629822   -3.423544
         2     -0.200501 -2261.800537    -0.006501 -13.964580 -424.862579   -8.944134
         3     -0.118337 -3023.245361    -0.006501 -12.252473 -426.921204   -6.059354
         4     -0.141936 -2946.729248    -0.006501 -12.957499 -439.066620   -4.845741
         ...         ...          ...          ...        ...         ...         ...
         16379 -0.360253   -11.406303 -7972.151855 -17.713902   -0.007943 -302.977112
         16380 -0.357140    -6.277905 -7364.589355 -18.227232   -0.026928 -264.517883
         16381 -0.361164    -6.467901 -5475.143555 -14.635371   -0.033288 -322.100128
         16382 -0.397824    -6.611117 -4858.377441 -22.669250   -0.009390 -275.350739
         16383 -0.404121    -7.962756 -3787.701660 -42.939243   -0.011524 -269.407715

                 trace100
         0     -11.546082
         1     -10.681055
         2     -15.847840
         3     -16.884233
         4     -10.891292
         ...          ...
         16379  -0.178515
         16380  -0.286508
         16381  -0.258353
         16382  -0.159297
         16383  -0.221784

         [16384 rows x 400 columns], PowerTransformer()), ('Data after power transformation (Box-Cox)',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.703590  0.229841 -0.144297  0.456233 -1.050543  0.100749 -1.161746
         1      0.492430 -0.106323 -0.169125  0.401313 -0.720897  0.104707 -0.320671
         2      0.616297 -0.305117 -0.290929  0.199921 -0.635466  0.142461 -0.734760
         3      0.466493 -0.472907  0.007270  0.237546  0.179789 -0.140273 -0.588064
         4      0.350292 -0.159598 -0.171093  0.100846  0.232780  0.380374 -1.017226
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.027605  0.155117  0.715256  1.823111 -2.619899 -1.377670 -1.744491
         16380  0.355421 -0.092281  0.514729  1.695868 -2.128841 -1.622602 -2.319606
         16381  0.329624 -0.000263  0.577357  1.418848 -1.480257 -1.832268 -1.534310
         16382  0.363715 -0.002334  0.194588  1.175362 -1.233419 -1.048515 -1.751977
         16383  0.698328 -0.106761  0.233084  1.033311 -0.938795 -1.192261 -1.042516

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0     -0.076007 -1.215649 -0.023763  ...       0.0 -0.139326       0.0
         1     -0.255994 -1.429899  0.014932  ...       0.0 -0.346047       0.0
         2     -0.726247 -0.940548 -0.315290  ...       0.0 -0.351932       0.0
         3     -0.167530 -1.002704 -0.176598  ...       0.0 -0.444463       0.0
         4     -0.455904 -1.297384 -0.025933  ...       0.0 -0.541770       0.0
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.578567 -0.368183 -0.506855  ...       0.0 -0.242755       0.0
         16380  0.380005 -0.248440 -0.612953  ...       0.0 -0.169600       0.0
         16381  0.341870 -0.323047 -0.438769  ...       0.0 -0.077444       0.0
         16382  0.536826 -0.378472 -0.485425  ...       0.0 -0.055640       0.0
         16383  0.401294 -0.801878 -1.001834  ...       0.0 -0.033606       0.0

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.524411       0.0       0.0       0.0       0.0       0.0       0.0
         1      0.454796       0.0       0.0       0.0       0.0       0.0       0.0
         2      0.455113       0.0       0.0       0.0       0.0       0.0       0.0
         3      0.619310       0.0       0.0       0.0       0.0       0.0       0.0
         4      0.573036       0.0       0.0       0.0       0.0       0.0       0.0
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.103333       0.0       0.0       0.0       0.0       0.0       0.0
         16380  0.110752       0.0       0.0       0.0       0.0       0.0       0.0
         16381  0.101162       0.0       0.0       0.0       0.0       0.0       0.0
         16382  0.012233       0.0       0.0       0.0       0.0       0.0       0.0
         16383 -0.003418       0.0       0.0       0.0       0.0       0.0       0.0

         [16384 rows x 400 columns], PowerTransformer(method='box-cox')), ('Data after quantile transformation (uniform pdf)',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.837211  0.667589  0.429786  0.742273  0.119759  0.535601  0.099305
         1      0.759769  0.489391  0.416309  0.718834  0.188309  0.537443  0.328075
         2      0.807031  0.377116  0.359821  0.619431  0.211272  0.557023  0.186104
         3      0.748373  0.294910  0.509992  0.637499  0.563359  0.409422  0.231715
         4      0.691017  0.456856  0.415428  0.565762  0.592064  0.680094  0.121781
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.512047  0.631746  0.834119  0.936185  0.012251  0.072282  0.040563
         16380  0.694333  0.498836  0.763272  0.923359  0.024754  0.050558  0.017235
         16381  0.681666  0.549771  0.787250  0.900471  0.061263  0.037673  0.056537
         16382  0.698298  0.548562  0.607636  0.882800  0.090711  0.116968  0.039962
         16383  0.835788  0.489184  0.628513  0.871007  0.138169  0.093093  0.117773

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.479824  0.080469  0.518984  ...  0.634226  0.416806  0.510365
         1      0.385152  0.056189  0.539527  ...  0.601175  0.318178  0.470334
         2      0.188430  0.134611  0.361202  ...  0.592529  0.315325  0.502002
         3      0.429035  0.120183  0.432236  ...  0.614998  0.274881  0.479193
         4      0.290549  0.070364  0.517820  ...  0.630375  0.235950  0.498526
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.790125  0.361820  0.276140  ...  0.567951  0.364475  0.222494
         16380  0.714469  0.434650  0.236778  ...  0.522600  0.400401  0.224433
         16381  0.698871  0.388517  0.305517  ...  0.479538  0.444902  0.201774
         16382  0.775717  0.355470  0.284043  ...  0.445437  0.453463  0.206482
         16383  0.723722  0.172305  0.127448  ...  0.409840  0.463326  0.248183

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.738333  0.063061  0.838931  0.401126  0.099222  0.495710  0.311860
         1      0.708936  0.060375  0.829387  0.400220  0.099189  0.549592  0.316430
         2      0.709057  0.058249  0.866481  0.375560  0.122618  0.456250  0.291109
         3      0.775845  0.044137  0.870502  0.385976  0.122141  0.492622  0.287050
         4      0.757619  0.045382  0.887631  0.381396  0.119098  0.515235  0.315331
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.544230  0.492799  0.101954  0.356356  0.838020  0.089154  0.560465
         16380  0.548073  0.532053  0.109651  0.353941  0.822539  0.100051  0.533412
         16381  0.542968  0.529551  0.138136  0.371918  0.820302  0.085080  0.539200
         16382  0.498225  0.528381  0.150871  0.337860  0.834155  0.096639  0.565797
         16383  0.490347  0.517013  0.176682  0.285753  0.830662  0.098323  0.548898

         [16384 rows x 400 columns], QuantileTransformer()), ('Data after quantile transformation (gaussian pdf)',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.983061  0.433266 -0.176920  0.650369 -1.176191  0.089357 -1.285522
         1      0.705560 -0.026595 -0.211346  0.579381 -0.884145  0.093994 -0.445236
         2      0.867008 -0.313063 -0.358937  0.303987 -0.802016  0.143427 -0.892344
         3      0.669377 -0.539098  0.025048  0.351781  0.159492 -0.229032 -0.733211
         4      0.498735 -0.108358 -0.213603  0.165594  0.232857  0.467961 -1.166130
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.030201  0.336482  0.970570  1.523517 -2.249164 -1.459005 -1.744194
         16380  0.508169 -0.002919  0.716866  1.428035 -1.964185 -1.639471 -2.114537
         16381  0.472362  0.125082  0.796917  1.284240 -1.544259 -1.778358 -1.584529
         16382  0.519513  0.122029  0.273164  1.189100 -1.336388 -1.190279 -1.751127
         16383  0.977292 -0.027116  0.327919  1.131165 -1.088582 -1.321947 -1.186193

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0     -0.050594 -1.401922  0.047603  ...  0.343067 -0.210071  0.025984
         1     -0.291977 -1.587598  0.099242  ...  0.256389 -0.472800 -0.074429
         2     -0.883697 -1.104854 -0.355249  ...  0.234055 -0.480812  0.005018
         3     -0.178830 -1.174072 -0.170684  ...  0.292370 -0.598117 -0.052179
         4     -0.551783 -1.473082  0.044682  ...  0.332847 -0.719391 -0.003694
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.806854 -0.353599 -0.594347  ...  0.171161 -0.346522 -0.763798
         16380  0.566488 -0.164548 -0.716706  ...  0.056681 -0.252309 -0.757308
         16381  0.521157 -0.283186 -0.508597  ... -0.051314 -0.138552 -0.835302
         16382  0.757809 -0.370595 -0.570872  ... -0.137199 -0.116916 -0.818689
         16383  0.593936 -0.945096 -1.138536  ... -0.227955 -0.092057 -0.680218

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.638214 -1.529578  0.990073 -0.250435 -1.285997 -0.010754 -0.490585
         1      0.550280 -1.551630  0.951745 -0.252777 -1.286188  0.124630 -0.477704
         2      0.550631 -1.569641  1.109909 -0.317162 -1.161997 -0.109885 -0.550147
         3      0.758236 -1.704574  1.128766 -0.289823 -1.164350 -0.018495 -0.562022
         4      0.698663 -1.691378  1.214025 -0.301816 -1.179506  0.038197 -0.480795
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.111097 -0.018050 -1.270494 -0.368217  0.986351 -1.345983  0.152149
         16380  0.120795  0.080431 -1.228388 -0.374703  0.925084 -1.281260  0.083850
         16381  0.107914  0.074141 -1.088732 -0.326779  0.916516 -1.371693  0.098419
         16382 -0.004449  0.071200 -1.032703 -0.418310  0.970716 -1.300944  0.165683
         16383 -0.024200  0.042658 -0.928082 -0.565835  0.956786 -1.291168  0.122878

         [16384 rows x 400 columns], QuantileTransformer(output_distribution='normal')), ('Data after sample-wise L2 normalizing',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.005965  0.003144  0.003777  0.004370  0.002956  0.004146  0.002191
         1      0.005275  0.002579  0.003734  0.004230  0.003325  0.004154  0.003057
         2      0.005664  0.002319  0.003535  0.003777  0.003432  0.004227  0.002575
         3      0.005199  0.002132  0.004056  0.003856  0.004772  0.003722  0.002731
         4      0.004877  0.002505  0.003731  0.003583  0.004885  0.004740  0.002310
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.004128  0.003002  0.005909  0.014151  0.001826  0.002322  0.001796
         16380  0.004891  0.002599  0.005268  0.012093  0.002098  0.002142  0.001506
         16381  0.004823  0.002738  0.005456  0.009010  0.002561  0.002005  0.001925
         16382  0.004913  0.002735  0.004447  0.007243  0.002778  0.002602  0.001792
         16383  0.005947  0.002578  0.004535  0.006462  0.003074  0.002474  0.002289

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.003024  0.001141  0.003516  ...  0.004018  0.005474  0.003652
         1      0.002753  0.001044  0.003594  ...  0.003894  0.005102  0.003540
         2      0.002203  0.001289  0.003001  ...  0.003863  0.005092  0.003628
         3      0.002881  0.001253  0.003230  ...  0.003949  0.004938  0.003565
         4      0.002495  0.001102  0.003512  ...  0.004003  0.004783  0.003618
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.004484  0.001723  0.002723  ...  0.003785  0.005283  0.002785
         16380  0.003939  0.001845  0.002585  ...  0.003653  0.005417  0.002791
         16381  0.003847  0.001767  0.002817  ...  0.003530  0.005594  0.002712
         16382  0.004360  0.001713  0.002752  ...  0.003428  0.005636  0.002730
         16383  0.003992  0.001376  0.002162  ...  0.003328  0.005680  0.002874

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.004435  0.002453  0.011174  0.004548  0.002257  0.004306  0.004727
         1      0.004265  0.002434  0.010726  0.004544  0.002257  0.004478  0.004750
         2      0.004266  0.002423  0.012499  0.004442  0.002350  0.004169  0.004632
         3      0.004686  0.002303  0.012689  0.004483  0.002348  0.004296  0.004612
         4      0.004561  0.002314  0.013710  0.004465  0.002336  0.004368  0.004744
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.003562  0.004343  0.001873  0.004367  0.006592  0.002910  0.005869
         16380  0.003574  0.004531  0.001907  0.004358  0.005702  0.002962  0.005746
         16381  0.003558  0.004522  0.002035  0.004427  0.005618  0.002886  0.005773
         16382  0.003412  0.004515  0.002086  0.004288  0.006347  0.002947  0.005898
         16383  0.003388  0.004457  0.002192  0.004080  0.006158  0.002955  0.005812

         [16384 rows x 400 columns], nan), ('Data after sample-wise L1 normalizing',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.000066  0.000041  0.000042  0.000053  0.000033  0.000049  0.000027
         1      0.000059  0.000033  0.000042  0.000051  0.000037  0.000049  0.000038
         2      0.000063  0.000030  0.000040  0.000045  0.000038  0.000050  0.000032
         3      0.000058  0.000027  0.000045  0.000046  0.000053  0.000044  0.000034
         4      0.000054  0.000032  0.000042  0.000043  0.000054  0.000056  0.000029
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.000046  0.000039  0.000066  0.000170  0.000020  0.000027  0.000022
         16380  0.000054  0.000033  0.000059  0.000145  0.000023  0.000025  0.000019
         16381  0.000054  0.000035  0.000061  0.000108  0.000029  0.000024  0.000024
         16382  0.000055  0.000035  0.000050  0.000087  0.000031  0.000031  0.000022
         16383  0.000066  0.000033  0.000051  0.000078  0.000034  0.000029  0.000029

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.000037  0.000015  0.000041  ...  0.000044  0.000051  0.000041
         1      0.000034  0.000014  0.000041  ...  0.000043  0.000048  0.000040
         2      0.000027  0.000017  0.000035  ...  0.000042  0.000048  0.000041
         3      0.000036  0.000017  0.000037  ...  0.000043  0.000046  0.000040
         4      0.000031  0.000015  0.000041  ...  0.000044  0.000045  0.000041
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.000056  0.000023  0.000031  ...  0.000041  0.000049  0.000032
         16380  0.000049  0.000025  0.000030  ...  0.000040  0.000051  0.000032
         16381  0.000048  0.000024  0.000033  ...  0.000039  0.000052  0.000031
         16382  0.000054  0.000023  0.000032  ...  0.000038  0.000053  0.000031
         16383  0.000049  0.000019  0.000025  ...  0.000036  0.000053  0.000033

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.000054  0.000025  0.000116  0.000046  0.000025  0.000046  0.000047
         1      0.000052  0.000025  0.000112  0.000046  0.000025  0.000048  0.000047
         2      0.000052  0.000025  0.000130  0.000045  0.000026  0.000045  0.000046
         3      0.000057  0.000024  0.000132  0.000046  0.000026  0.000046  0.000046
         4      0.000055  0.000024  0.000143  0.000045  0.000026  0.000047  0.000047
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.000043  0.000045  0.000019  0.000044  0.000074  0.000031  0.000058
         16380  0.000043  0.000047  0.000020  0.000044  0.000064  0.000032  0.000057
         16381  0.000043  0.000047  0.000021  0.000045  0.000063  0.000031  0.000057
         16382  0.000041  0.000047  0.000022  0.000044  0.000072  0.000032  0.000058
         16383  0.000041  0.000046  0.000023  0.000042  0.000069  0.000032  0.000058

         [16384 rows x 400 columns], nan), ('Data after maximum rescaling',        trace001  trace002  trace003  trace004  trace005  trace006  trace007  \
         0      0.114208  0.067290  0.085521  0.094494  0.043728  0.058640  0.036165
         1      0.100997  0.055198  0.084552  0.091479  0.049184  0.058747  0.050464
         2      0.108443  0.049640  0.080032  0.081681  0.050764  0.059786  0.042494
         3      0.099537  0.045632  0.091837  0.083375  0.070576  0.052638  0.045077
         4      0.093376  0.053612  0.084475  0.077483  0.072247  0.067038  0.038131
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.079028  0.064246  0.133792  0.305998  0.027011  0.032836  0.029646
         16380  0.093636  0.055630  0.119281  0.261493  0.031033  0.030296  0.024852
         16381  0.092342  0.058599  0.123539  0.194832  0.037875  0.028354  0.031768
         16382  0.094057  0.058529  0.100702  0.156619  0.041083  0.036806  0.029575
         16383  0.113848  0.055185  0.102688  0.139723  0.045472  0.034986  0.037775

                trace008  trace009  trace010  ...  trace091  trace092  trace093  \
         0      0.077975  0.032370  0.083564  ...  0.105026  0.095347  0.088183
         1      0.070986  0.029624  0.085427  ...  0.101767  0.088865  0.085469
         2      0.056790  0.036568  0.071322  ...  0.100953  0.088690  0.087585
         3      0.074291  0.035544  0.076779  ...  0.103216  0.086006  0.086065
         4      0.064328  0.031274  0.083462  ...  0.104623  0.083312  0.087362
         ...         ...       ...       ...  ...       ...       ...       ...
         16379  0.115616  0.048878  0.064707  ...  0.098924  0.092019  0.067239
         16380  0.101571  0.052338  0.061437  ...  0.095484  0.094355  0.067385
         16381  0.099185  0.050137  0.066946  ...  0.092259  0.097424  0.065480
         16382  0.112417  0.048599  0.065399  ...  0.089586  0.098172  0.065904
         16383  0.102943  0.039039  0.051379  ...  0.086975  0.098936  0.069389

                trace094  trace095  trace096  trace097  trace098  trace099  trace100
         0      0.091648  0.060764  0.350100  0.096151  0.072133  0.080136  0.067477
         1      0.088143  0.060296  0.336071  0.096068  0.072129  0.083330  0.067808
         2      0.088160  0.060020  0.391623  0.093912  0.075094  0.077584  0.066119
         3      0.096846  0.057048  0.397566  0.094776  0.075030  0.079945  0.065845
         4      0.094247  0.057312  0.429559  0.094407  0.074658  0.081280  0.067725
         ...         ...       ...       ...       ...       ...       ...       ...
         16379  0.073601  0.107578  0.058671  0.092326  0.210651  0.054144  0.083778
         16380  0.073861  0.112236  0.059754  0.092135  0.182223  0.055122  0.082025
         16381  0.073525  0.112006  0.063770  0.093600  0.179534  0.053701  0.082408
         16382  0.070515  0.111837  0.065373  0.090663  0.202807  0.054834  0.084202
         16383  0.070009  0.110397  0.068682  0.086264  0.196770  0.054991  0.082974

         [16384 rows x 400 columns], nan)]
       #+end_example

       #+BEGIN_SRC jupyter-python
         plt.figure(figsize=(16,14), facecolor='white')
         for i, (text, normplot, _) in enumerate(dist):
             plt.subplot(4, 3, i+1, title=text)
             [plt.plot(np.array(normplot.iloc[:, 90+j]).flatten(), alpha=0.75) for j in range(3)]
         plt.tight_layout()
       #+END_SRC

       #+RESULTS:


       [[file:./.ob-jupyter/cb2c6480b24f86a0b9c1713c22ee453ee29e82e2.png]]


       [[file:./.ob-jupyter/dc4e4a696d6fa8138d750e19399f1cfdee9a3629.png]]



       [[file:./.ob-jupyter/f23a9b82cf1e695220d5cc354921dde25cb9c4a2.png]]



       [[file:./.ob-jupyter/f3488771109b95b0c10750b6b5fddc67621a994e.png]]



    [[file:./.ob-jupyter/a03d960f819fe254ee3fea6f73455fa726667158.png]]

*** learnings from normalizations <2021-07-11 So>
    - is the setup correct?
      - pandas Series are processed correctly
      - pandas DataFrames are handled correctly. All Scalers have been checked
        if they returned the right number of parameters per trace (to not
        normalize the wrong dimension of the array)
    - what would probably be a good normalization / scaling?
      - we are interested in peaks within a trace full of peaks → a nice offset
        for our peaks of interest would be important
      - all other parts of the trace shouldn't be too outstanding to not get
        picked up too easily by the ML algorithm
      - it should be easy to implement on new traces.
    - tricks for certain transformations
      - Power Transform with Yeo-Johnson in a pure way does not work, because
        our data has a large offset and low variance:
        https://github.com/scipy/scipy/issues/10821 . Two ways to make it work:
        1. Use the learned lambda parameters from the Power Transform with
           Box-Cox.
        2. only using 1) does not center the transformed traces around zero.
           Here
           (https://machinelearningmastery.com/power-transforms-with-scikit-learn/)
           they suggested to use a StandardScaler on the data first. Together
           with 1), this leads to a nice normalization and scaling.
    - problems with certain trainsformations:
      - the parametric transformations, especially the power transforms, seem to
        be too unstable. Sometimes, lambda estimation does not work → then it
        can happen that a whole trace gets "normalized" to a constant
      - min-max scaling and the quantile transformation to a uniform pdf also
        seems to be unsuited, since a  trace *without* a peak get spanned
        between min and max, with steep gradients
    - most promising transforms (keeping the above points in mind):
      - z-score / standard scaling:
      - robust scaling
      - l2 normalizing (but: low absolute values)
    - maybe still useful:
      - max-abs scaling / maximum rescaling (both MaxAbsScaler() and
        Normalizer(norm='max') seem to be the same)
      - quantile tranform (gaussian pdf)
      - L1 normalizing (very low absolute values)

*** building a tf pipeline using =tf.data.Dataset=
    1. keep csv loading with pandas, bc more flexibility.
    2. =ppd.tfds_from_pddf= will be made simpler: just make a dataset out of the
       dataframe, nothing more (move out normalization, or cropping)
       - test, if creating the dataset works if there are traces with different
         lengths in the DataFrame → problem: Pandas will fill the gaps with nan
         values and TF can't handle nan → function to convert nan to zeros!
    3. build cropping function and scaling function to map on the
       tf.data.Dataset

** More versatile model building <2021-07-14 Mi>
*** update packages
    - we need:
      - jupyterlab
      - pip
      - pip:
        - numpy==1.19.5 (needed <1.20 for tensorflow)
        - pandas
        - matplotlib
        - seaborn
        - mlflow
        - lmfit (needed by =fluotracify.applications.correlate=)
        - tf-nightly
        - fcsfiles
        - multipletau
        - scikit-learn

    #+begin_example
      conda env remove -n tf-nightly
      conda create -n tf-nightly jupyterlab pip
      conda activate tf-nightly
      (tf-nightly) pip install numpy==1.19.5  mlflow lmfit scikit-learn tf-nightly matplotlib pandas seaborn tifffile fcsfiles multipletau
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
      conda list -n tf-nightly
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (base) [ye53nis@login01 /]$ conda list -n tf-nightly
      # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      _openmp_mutex             4.5                       1_gnu
      absl-py                   0.13.0                   pypi_0    pypi
      alembic                   1.4.1                      py_0    conda-forge/label/main
      anyio                     2.2.0            py39h06a4308_1
      appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge/label/main
      argon2-cffi               20.1.0           py39h27cfd23_1
      asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge/label/main
      asteval                   0.9.23             pyhd8ed1ab_0    conda-forge/label/main
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10               pyhd3eb1b0_0
      attrs                     21.2.0             pyhd3eb1b0_0
      babel                     2.9.1              pyhd3eb1b0_0
      backcall                  0.2.0              pyhd3eb1b0_0
      blas                      1.0                         mkl
      bleach                    3.3.0              pyhd3eb1b0_0
      blosc                     1.21.0               h8c45485_0
      bottleneck                1.3.2            py39hdd57654_1
      brotli                    1.0.9                he6710b0_2
      brotlipy                  0.7.0           py39h27cfd23_1003
      brunsli                   0.1                  h2531618_0
      bzip2                     1.0.8                h7b6447c_0
      ca-certificates           2021.5.30            ha878542_0    conda-forge/label/main
      cachetools                4.2.2                    pypi_0    pypi
      certifi                   2021.5.30        py39hf3d152e_0    conda-forge/label/main
      cffi                      1.14.6           py39h400218f_0
      cfitsio                   3.470                hf0d0db6_6
      chardet                   4.0.0           py39h06a4308_1003
      charls                    2.2.0                h2531618_0
      click                     8.0.1            py39hf3d152e_0    conda-forge/label/main
      cloudpickle               1.6.0                      py_0    conda-forge/label/main
      configparser              5.0.2              pyhd8ed1ab_0    conda-forge/label/main
      cryptography              3.4.7            py39hd23ed53_0
      cycler                    0.10.0           py39h06a4308_0
      databricks-cli            0.12.1             pyhd8ed1ab_0    conda-forge/label/main
      dataclasses               0.8                pyhc8e2a94_1    conda-forge/label/main
      dbus                      1.13.18              hb2f20db_0
      decorator                 5.0.9              pyhd3eb1b0_0
      defusedxml                0.7.1              pyhd3eb1b0_0
      docker-py                 5.0.0            py39hf3d152e_0    conda-forge/label/main
      docker-pycreds            0.4.0                      py_0    conda-forge/label/main
      entrypoints               0.3              py39h06a4308_0
      expat                     2.4.1                h2531618_2
      fcsfiles                  2021.6.6                 pypi_0    pypi
      flask                     2.0.1              pyhd8ed1ab_0    conda-forge/label/main
      flatbuffers               1.12                     pypi_0    pypi
      fontconfig                2.13.1               h6c09931_0
      freetype                  2.10.4               h5ab3b9f_0
      future                    0.18.2           py39hf3d152e_3    conda-forge/label/main
      gast                      0.4.0                    pypi_0    pypi
      giflib                    5.1.4                h14c3975_1
      gitdb                     4.0.7              pyhd8ed1ab_0    conda-forge/label/main
      gitpython                 3.1.18             pyhd8ed1ab_0    conda-forge/label/main
      glib                      2.69.0               h5202010_0
      google-auth               1.33.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.4                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      greenlet                  1.1.0            py39he80948d_0    conda-forge/label/main
      grpcio                    1.38.1                   pypi_0    pypi
      gst-plugins-base          1.14.0               h8213a91_2
      gstreamer                 1.14.0               h28cd5cc_2
      gunicorn                  20.1.0           py39hf3d152e_0    conda-forge/label/main
      h5py                      3.1.0                    pypi_0    pypi
      icu                       58.2                 he6710b0_3
      idna                      2.10               pyhd3eb1b0_0
      imagecodecs               2021.6.8         py39h581e88b_0
      importlib-metadata        3.10.0           py39h06a4308_0
      importlib_metadata        3.10.0               hd3eb1b0_0
      intel-openmp              2021.3.0          h06a4308_3350
      ipykernel                 5.3.4            py39hb070fc8_0
      ipython                   7.22.0           py39hb070fc8_0
      ipython_genutils          0.2.0              pyhd3eb1b0_1
      itsdangerous              2.0.1              pyhd8ed1ab_0    conda-forge/label/main
      jedi                      0.17.2           py39h06a4308_1
      jinja2                    3.0.1              pyhd3eb1b0_0
      joblib                    1.0.1              pyhd8ed1ab_0    conda-forge/label/main
      jpeg                      9b                   h024ee3a_2
      json5                     0.9.6              pyhd3eb1b0_0
      jsonschema                3.2.0                      py_2
      jupyter-packaging         0.7.12             pyhd3eb1b0_0
      jupyter_client            6.1.12             pyhd3eb1b0_0
      jupyter_core              4.7.1            py39h06a4308_0
      jupyter_server            1.4.1            py39h06a4308_0
      jupyterlab                3.0.14             pyhd3eb1b0_1
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         2.6.1              pyhd3eb1b0_0
      jxrlib                    1.1                  h7b6447c_2
      keras-nightly             2.7.0.dev2021071300          pypi_0    pypi
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.1            py39h2531618_0
      krb5                      1.18.2               h173b8e3_0
      lcms2                     2.12                 h3be6417_0
      ld_impl_linux-64          2.35.1               h7274673_9
      lerc                      2.2.1                h2531618_0
      libaec                    1.0.4                he6710b0_1
      libblas                   3.9.0                     9_mkl    conda-forge/label/main
      libcblas                  3.9.0                     9_mkl    conda-forge/label/main
      libclang                  11.1.0                   pypi_0    pypi
      libcurl                   7.71.1               h20c2e04_1
      libdeflate                1.7                  h27cfd23_5
      libedit                   3.1.20210216         h27cfd23_1
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.3.0               h5101ec6_17
      libgfortran-ng            7.5.0               ha8ba4b0_17
      libgfortran4              7.5.0               ha8ba4b0_17
      libgomp                   9.3.0               h5101ec6_17
      libpng                    1.6.37               hbc83047_0
      libprotobuf               3.17.2               h780b84a_0    conda-forge/label/main
      libsodium                 1.0.18               h7b6447c_0
      libssh2                   1.9.0                h1ba5d50_1
      libstdcxx-ng              9.3.0               hd4cf53a_17
      libtiff                   4.1.0                h2733197_1
      libuuid                   1.0.3                h1bed415_2
      libwebp                   1.0.1                h8e7db2f_0
      libxcb                    1.14                 h7b6447c_0
      libxml2                   2.9.12               h03d6c58_0
      libzopfli                 1.0.3                he6710b0_0
      lmfit                     1.0.2              pyhd8ed1ab_0    conda-forge/label/main
      lz4-c                     1.9.3                h2531618_0
      mako                      1.1.4              pyh44b312d_0    conda-forge/label/main
      markdown                  3.3.4                    pypi_0    pypi
      markupsafe                2.0.1            py39h27cfd23_0
      matplotlib                3.3.4            py39h06a4308_0
      matplotlib-base           3.3.4            py39h62a2d02_0
      mistune                   0.8.4           py39h27cfd23_1000
      mkl                       2021.3.0           h06a4308_520
      mkl-service               2.4.0            py39h7f8727e_0
      mkl_fft                   1.3.0            py39h42c9631_2
      mkl_random                1.2.2            py39h51133e4_0
      mlflow                    1.19.0           py39ha39b057_0    conda-forge/label/main
      multipletau               0.3.3                    pypi_0    pypi
      nbclassic                 0.2.6              pyhd3eb1b0_0
      nbclient                  0.5.3              pyhd3eb1b0_0
      nbconvert                 6.1.0            py39h06a4308_0
      nbformat                  5.1.3              pyhd3eb1b0_0
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.5.1              pyhd3eb1b0_0
      notebook                  6.4.0            py39h06a4308_0
      numexpr                   2.7.3            py39h22e1b3c_1
      numpy                     1.19.5                   pypi_0    pypi
      oauthlib                  3.1.1                    pypi_0    pypi
      olefile                   0.46                       py_0
      openjpeg                  2.3.0                h05c96fa_1
      openssl                   1.1.1k               h7f98852_0    conda-forge/label/main
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 21.0               pyhd3eb1b0_0
      pandas                    1.2.5            py39h295c915_0
      pandocfilters             1.4.3            py39h06a4308_1
      parso                     0.7.0                      py_0
      pcre                      8.45                 h295c915_0
      pexpect                   4.8.0              pyhd3eb1b0_3
      pickleshare               0.7.5           pyhd3eb1b0_1003
      pillow                    8.3.1            py39h2c7a002_0
      pip                       21.1.3           py39h06a4308_0
      prometheus_client         0.11.0             pyhd3eb1b0_0
      prometheus_flask_exporter 0.18.2             pyhd8ed1ab_0    conda-forge/label/main
      prompt-toolkit            3.0.17             pyh06a4308_0
      protobuf                  3.17.2           py39he80948d_0    conda-forge/label/main
      ptyprocess                0.7.0              pyhd3eb1b0_2
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.9.0              pyhd3eb1b0_0
      pyopenssl                 20.0.1             pyhd3eb1b0_1
      pyparsing                 2.4.7              pyhd3eb1b0_0
      pyqt                      5.9.2            py39h2531618_6
      pyrsistent                0.18.0           py39h7f8727e_0
      pysocks                   1.7.1            py39h06a4308_0
      python                    3.9.5                h12debd9_4
      python-dateutil           2.8.1              pyhd3eb1b0_0
      python-editor             1.0.4                      py_0    conda-forge/label/main
      python_abi                3.9                      2_cp39    conda-forge/label/main
      pytz                      2021.1             pyhd3eb1b0_0
      pyyaml                    5.4.1            py39h3811e60_0    conda-forge/label/main
      pyzmq                     20.0.0           py39h2531618_1
      qt                        5.9.7                h5867ecd_1
      querystring_parser        1.2.4                      py_0    conda-forge/label/main
      readline                  8.1                  h27cfd23_0
      requests                  2.25.1             pyhd3eb1b0_0
      requests-oauthlib         1.3.0                    pypi_0    pypi
      rsa                       4.7.2                    pypi_0    pypi
      scikit-learn              0.24.2           py39h4dfa638_0    conda-forge/label/main
      scipy                     1.6.2            py39had2a1c9_1
      seaborn                   0.11.1             pyhd3eb1b0_0
      send2trash                1.5.0              pyhd3eb1b0_1
      setuptools                52.0.0           py39h06a4308_0
      sip                       4.19.13          py39h2531618_0
      six                       1.15.0                   pypi_0    pypi
      smmap                     3.0.5              pyh44b312d_0    conda-forge/label/main
      snappy                    1.1.8                he6710b0_0
      sniffio                   1.2.0            py39h06a4308_1
      sqlalchemy                1.4.21           py39h3811e60_0    conda-forge/label/main
      sqlite                    3.36.0               hc218d9a_0
      sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge/label/main
      tabulate                  0.8.9              pyhd8ed1ab_0    conda-forge/label/main
      tb-nightly                2.6.0a20210714           pypi_0    pypi
      tenacity                  8.0.1              pyhd8ed1ab_0    conda-forge/label/main
      tensorboard-data-server   0.6.1                    pypi_0    pypi
      tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.4            py39h06a4308_0
      testpath                  0.5.0              pyhd3eb1b0_0
      tf-estimator-nightly      2.7.0.dev2021071501          pypi_0    pypi
      tf-nightly                2.7.0.dev20210713          pypi_0    pypi
      threadpoolctl             2.2.0              pyh8a188c0_0    conda-forge/label/main
      tifffile                  2021.4.8           pyhd3eb1b0_2
      tk                        8.6.10               hbc83047_0
      tornado                   6.1              py39h27cfd23_0
      traitlets                 5.0.5              pyhd3eb1b0_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      tzdata                    2021a                h52ac0ba_0
      uncertainties             3.1.6              pyhd8ed1ab_0    conda-forge/label/main
      urllib3                   1.26.6             pyhd3eb1b0_1
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1            py39h06a4308_1
      websocket-client          0.57.0           py39hf3d152e_4    conda-forge/label/main
      werkzeug                  2.0.1              pyhd8ed1ab_0    conda-forge/label/main
      wheel                     0.36.2             pyhd3eb1b0_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      yaml                      0.2.5                h516909a_0    conda-forge/label/main
      zeromq                    4.3.4                h2531618_0
      zfp                       0.5.5                h2531618_6
      zipp                      3.5.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      zstd                      1.4.9                haebb681_0
      (base) [ye53nis@login01 /]$
    #+end_example

    After an error I reinstalled numpy to a newer version. This is nominally not
    compatible with tf-nightly, but we'll see if we run into problems.

    #+begin_example
      (tf-nightly) [ye53nis@login01 ~]$ pip uninstall numpy
      Found existing installation: numpy 1.19.5
      Uninstalling numpy-1.19.5:
        Would remove:
          /home/ye53nis/.conda/envs/tf-nightly/bin/f2py
          /home/ye53nis/.conda/envs/tf-nightly/bin/f2py3
          /home/ye53nis/.conda/envs/tf-nightly/bin/f2py3.9
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy-1.19.5.dist-info/*
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy.libs/libgfortran-2e0d59d6.so.5.0.0
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy.libs/libopenblasp-r0-09e95953.3.13.so
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy.libs/libquadmath-2d0c479f.so.0.0.0
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy.libs/libz-eb09ad1d.so.1.2.3
          /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/numpy/*
      Proceed (y/n)? y
        Successfully uninstalled numpy-1.19.5
      (tf-nightly) [ye53nis@login01 ~]$ pip install numpy
      Collecting numpy
        Downloading numpy-1.21.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)
           |████████████████████████████████| 15.8 MB 6.8 MB/s
      Installing collected packages: numpy
      ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
      tf-nightly 2.7.0.dev20210713 requires numpy~=1.19.2, but you have numpy 1.21.1 which is incompatible.
      Successfully installed numpy-1.21.1
      (     tf-nightly) [ye53nis@login01 ~]$

    #+end_example

*** DONE [#B] check out python module =argparser= as used [[https://github.com/mlflow/mlflow/blob/master/examples/tensorflow/tf2/train_predict_2.py][here]] or better =click= as used [[https://github.com/mlflow/mlflow/blob/master/examples/multistep_workflow/train_keras.py][here]]!
    CLOSED: [2021-07-25 So 16:24]
*** DONE update =train.py= with =click= and new model setup and normalizations
    CLOSED: [2021-07-20 Di 15:54]
*** mlflow test
**** metadata & connection
    - using =ob-tmux= for script execution
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
        cd /beegfs/ye53nis/drmed-git/
        git status
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@login01 drmed-git]$ git status
        # On branch develop
        # Changes not staged for commit:
        #   (use "git add <file>..." to update what will be committed)
        #   (use "git checkout -- <file>..." to discard changes in working directory)
        #   (commit or discard the untracked or modified content in submodules)
        #
        #       modified:   src/nanosimpy (new commits, untracked content)
        #
        # Untracked files:
        #   (use "git add <file>..." to include in what will be committed)
        #
        #       .data/
        #       2021-03-20_correlations.csv
        #       data/0.069.svg
        #       data/exp-210204-unet/
        #       data/exp-devtest/
        #       data/exp-test/
        #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
        #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
        #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
        #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
        #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
        #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
        #       data/mlruns/0/52faa01e685f44ef97be4e64ddc88eb1/
        #       data/mlruns/0/5dc9fe4b91094df58e3d2f1426aa4d96/
        #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
        #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
        #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
        #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
        #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
        #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
        #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
        #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
        #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
        #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
        #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
        #       data/mlruns/2/
        #       data/mlruns/3/
        #       data/mlruns/4/
        #       data/tb/
        #       experiment_params.csv
        #       mlruns/
        #       tramp.YDPCnB
        no changes added to commit (use "git add" and/or "git commit -a")
        (tf-nightly) [ye53nis@login01 drmed-git]$ git log -3
        commit eab86a5b3ce4599bc2f22eee6bfb95c1605d9c51
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 23:25:56 2021 +0200

            fix model saving, adding another numpy()

        commit 3d914ad3b2cf66e71a8ec4789c86b89cbfcc38f9
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 22:16:08 2021 +0200

            Fix model saving by making tensor to numpy array

        commit ae070532902a6b18b3be446936ff3a634b92e06a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 19:03:21 2021 +0200

            Fix error with frac_val=None

            TypeError: '<' not supported between instances of 'int' and 'NoneType'
        (tf-nightly) [ye53nis@login01 drmed-git]$
      #+end_example

**** mlflow environment variables

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
       conda activate tf-nightly
       cd /beegfs/ye53nis/drmed-git
       export MLFLOW_EXPERIMENT_NAME=exp-210720-test
       export MLFLOW_TRACKING_URI=file:./data/mlruns
       mkdir data/exp-210720-test
     #+END_SRC

**** test run 1 - replicating old experiment (minmax, n_levels=9, first_filters=64)

       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
         mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/beegfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='minmax' -P n_levels=9
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (tf-nightly) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/be
         egfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='minmax' -P n_levels=9
         2021/07/20 19:05:40 INFO mlflow.projects.utils: === Created directory /tmp/tmpkurhzmp5 for downloading remote URIs passed to arguments of type 'path' ===
         2021/07/20 19:05:40 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef 1>&2 && python src/fluotracify/trai
         ning/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 5 --frac_val 0.2 --length_delimiter 16384 --learning_rate 0 --epochs 2 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_
         test /beegfs/ye53nis/saves/firstartifact_Nov2020_test --col_per_example 3 --steps_per_epoch 10 --validation_steps 10 --scaler minmax --n_levels 9 --first_filters 64 --pool_size 2' in run with ID 'c0018f9b7b1c4bcfa58cf8df985e45da' ===
         2.7.0-dev20210720
         2021-07-20 19:05:47.322868: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
         2021-07-20 19:05:47.322997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
         GPUs:  []
         2021/07/20 19:05:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading
          MLflow.
         0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
         1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
         2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
         3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
         4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
         5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
         6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
         7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
         8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
         9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
         10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
         11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
         12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
         13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
         14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
         15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
         16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
         17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
         18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
         19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
         20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
         21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
         22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
         23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
         24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
         25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
         26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
         27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
         0 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set010.csv
         1 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set002.csv
         2 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set005.csv
         3 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set005.csv
         4 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set007.csv
         5 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set002.csv
         6 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set001.csv
         7 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set007.csv
         8 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set009.csv
         9 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set002.csv
         10 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set005.csv
         11 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set008.csv
         12 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set005.csv
         13 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set008.csv
         14 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set005.csv
         15 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set006.csv
         16 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set005.csv
         17 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set003.csv
         18 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set001.csv
         19 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set003.csv
         20 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set003.csv
         21 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set005.csv
         22 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set002.csv
         23 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set002.csv
         24 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set004.csv
         25 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set001.csv
         26 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set001.csv
         27 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set001.csv
         28 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set003.csv
         29 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set001.csv
         The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
         The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]

         for each 16384 timestap trace there are the following numbers of corrupted timesteps:
         label001_1    1916
         label002_1    1004
         label003_1    1476
         label004_1    1154
         label005_1    1454
         dtype: int64
         2021-07-20 19:09:06.480357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
         ons:  AVX2 FMA
         To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
         number of training examples: 2240, number of validation examples: 560

         ------------------------
         number of test examples: 3000

         input - shape:   (None, 16384, 1)
         output - shape:  (None, 16384, 1)
         2021-07-20 19:09:10.861204: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
         2021-07-20 19:09:10.861241: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
         2021-07-20 19:09:11.625475: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
         2021/07/20 19:09:11 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='5' for run ID='c00
         18f9b7b1c4bcfa58cf8df985e45da'. Attempted logging new value 'None'.
         Epoch 1/2
          1/10 [==>...........................] - ETA: 3:57 - loss: 1.9391 - tp0.1: 13744.0000 - fp0.1: 67872.0000 - tn0.1: 28.0000 - fn0.1: 276.0000 - precision0.1: 0.1684 - recall0.1: 0.9803 - tp0.3: 13139.0000 - fp0.3: 67765.0000 - tn0.3: 13
         5.0000 - fn0.3: 881.0000 - precision0.3: 0.1624 - recall0.3: 0.9372 - tp0.5: 11940.0000 - fp0.5: 65879.0000 - tn0.5: 2021.0000 - fn0.5: 2080.0000 - precision0.5: 0.1534 - recall0.5: 0.8516 - tp0.7: 6933.0000 - fp0.7: 28863.0000 - tn0.7
         : 39037.0000 - fn0.7: 7087.0000 - precision0.7: 0.1937 - recall0.7: 0.4945 - tp0.9: 1389.0000 - fp0.9: 648.0000 - tn0.9: 67252.0000 - fn0.9: 12631.0000 - precision0.9: 0.6819 - recall0.9: 0.0991 - accuracy: 0.1704 - auc: 0.52862021-07-
         20 19:09:38.374468: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
         2021-07-20 19:09:38.374532: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
          2/10 [=====>........................] - ETA: 25s - loss: 1.8725 - tp0.1: 15231.0000 - fp0.1: 69220.0000 - tn0.1: 69565.0000 - fn0.1: 9824.0000 - precision0.1: 0.1804 - recall0.1: 0.6079 - tp0.3: 13710.0000 - fp0.3: 68172.0000 - tn0.3:
          70613.0000 - fn0.3: 11345.0000 - precision0.3: 0.1674 - recall0.3: 0.5472 - tp0.5: 11941.0000 - fp0.5: 65879.0000 - tn0.5: 72906.0000 - fn0.5: 13114.0000 - precision0.5: 0.1534 - recall0.5: 0.4766 - tp0.7: 6933.0000 - fp0.7: 28863.000
         0 - tn0.7: 109922.0000 - fn0.7: 18122.0000 - precision0.7: 0.1937 - recall0.7: 0.2767 - tp0.9: 1389.0000 - fp0.9: 648.0000 - tn0.9: 138137.0000 - fn0.9: 23666.0000 - precision0.9: 0.6819 - recall0.9: 0.0554 - accuracy: 0.5179 - auc: 0.
         59562021-07-20 19:09:41.585714: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
         2021-07-20 19:09:41.639662: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
         2021-07-20 19:09:41.683925: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_19_09_41

         2021-07-20 19:09:41.703032: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.trace.json.gz
         2021-07-20 19:09:41.733661: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_19_09_41

         2021-07-20 19:09:41.733812: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.memory_profile.json.gz
         2021-07-20 19:09:41.736161: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_19_09_41
         Dumped tool data for xplane.pb to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.xplane.pb
         Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.overview_page.pb
         Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.input_pipeline.pb
         Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.tensorflow_stats.pb
         Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_07_20_19_09_41/login01.kernel_stats.pb

         10/10 [==============================] - 70s 5s/step - loss: 1.5766 - tp0.1: 64086.0000 - fp0.1: 188060.0000 - tn0.1: 512604.0000 - fn0.1: 54450.0000 - precision0.1: 0.2542 - recall0.1: 0.5406 - tp0.3: 51757.0000 - fp0.3: 134773.0000 -
          tn0.3: 565891.0000 - fn0.3: 66779.0000 - precision0.3: 0.2775 - recall0.3: 0.4366 - tp0.5: 42612.0000 - fp0.5: 104088.0000 - tn0.5: 596576.0000 - fn0.5: 75924.0000 - precision0.5: 0.2905 - recall0.5: 0.3595 - tp0.7: 26804.0000 - fp0.7
         : 44269.0000 - tn0.7: 656395.0000 - fn0.7: 91732.0000 - precision0.7: 0.3771 - recall0.7: 0.2261 - tp0.9: 9603.0000 - fp0.9: 2586.0000 - tn0.9: 698078.0000 - fn0.9: 108933.0000 - precision0.9: 0.7878 - recall0.9: 0.0810 - accuracy: 0.7
         803 - auc: 0.6831 - val_loss: inf - val_tp0.1: 116703.0000 - val_fp0.1: 702497.0000 - val_tn0.1: 0.0000e+00 - val_fn0.1: 0.0000e+00 - val_precision0.1: 0.1425 - val_recall0.1: 1.0000 - val_tp0.3: 116703.0000 - val_fp0.3: 702497.0000 -
         val_tn0.3: 0.0000e+00 - val_fn0.3: 0.0000e+00 - val_precision0.3: 0.1425 - val_recall0.3: 1.0000 - val_tp0.5: 116703.0000 - val_fp0.5: 702497.0000 - val_tn0.5: 0.0000e+00 - val_fn0.5: 0.0000e+00 - val_precision0.5: 0.1425 - val_recall0
         .5: 1.0000 - val_tp0.7: 116703.0000 - val_fp0.7: 702497.0000 - val_tn0.7: 0.0000e+00 - val_fn0.7: 0.0000e+00 - val_precision0.7: 0.1425 - val_recall0.7: 1.0000 - val_tp0.9: 116703.0000 - val_fp0.9: 702497.0000 - val_tn0.9: 0.0000e+00 -
          val_fn0.9: 0.0000e+00 - val_precision0.9: 0.1425 - val_recall0.9: 1.0000 - val_accuracy: 0.1425 - val_auc: 0.5000
         Epoch 2/2
         10/10 [==============================] - 42s 4s/step - loss: 1.2112 - tp0.1: 93586.0000 - fp0.1: 274174.0000 - tn0.1: 436544.0000 - fn0.1: 14896.0000 - precision0.1: 0.2545 - recall0.1: 0.8627 - tp0.3: 74034.0000 - fp0.3: 142250.0000 -
          tn0.3: 568468.0000 - fn0.3: 34448.0000 - precision0.3: 0.3423 - recall0.3: 0.6825 - tp0.5: 35018.0000 - fp0.5: 46517.0000 - tn0.5: 664201.0000 - fn0.5: 73464.0000 - precision0.5: 0.4295 - recall0.5: 0.3228 - tp0.7: 14361.0000 - fp0.7:
          2586.0000 - tn0.7: 708132.0000 - fn0.7: 94121.0000 - precision0.7: 0.8474 - recall0.7: 0.1324 - tp0.9: 10396.0000 - fp0.9: 641.0000 - tn0.9: 710077.0000 - fn0.9: 98086.0000 - precision0.9: 0.9419 - recall0.9: 0.0958 - accuracy: 0.8535
          - auc: 0.8143 - val_loss: 1672076149408599059202048.0000 - val_tp0.1: 55748.0000 - val_fp0.1: 354702.0000 - val_tn0.1: 353305.0000 - val_fn0.1: 55445.0000 - val_precision0.1: 0.1358 - val_recall0.1: 0.5014 - val_tp0.3: 55748.0000 - va
         l_fp0.3: 354702.0000 - val_tn0.3: 353305.0000 - val_fn0.3: 55445.0000 - val_precision0.3: 0.1358 - val_recall0.3: 0.5014 - val_tp0.5: 55748.0000 - val_fp0.5: 354702.0000 - val_tn0.5: 353305.0000 - val_fn0.5: 55445.0000 - val_precision0
         .5: 0.1358 - val_recall0.5: 0.5014 - val_tp0.7: 55748.0000 - val_fp0.7: 354702.0000 - val_tn0.7: 353305.0000 - val_fn0.7: 55445.0000 - val_precision0.7: 0.1358 - val_recall0.7: 0.5014 - val_tp0.9: 55748.0000 - val_fp0.9: 354702.0000 -
         val_tn0.9: 353305.0000 - val_fn0.9: 55445.0000 - val_precision0.9: 0.1358 - val_recall0.9: 0.5014 - val_accuracy: 0.4993 - val_auc: 0.5002
         600/600 [==============================] - 379s 630ms/step - loss: 1631392431814784946536448.0000 - tp0.1: 3785515.0000 - fp0.1: 20841488.0000 - tn0.1: 20754294.0000 - fn0.1: 3770718.0000 - precision0.1: 0.1537 - recall0.1: 0.5010 - tp
         0.3: 3785515.0000 - fp0.3: 20841488.0000 - tn0.3: 20754294.0000 - fn0.3: 3770718.0000 - precision0.3: 0.1537 - recall0.3: 0.5010 - tp0.5: 3785515.0000 - fp0.5: 20841488.0000 - tn0.5: 20754294.0000 - fn0.5: 3770718.0000 - precision0.5:
         0.1537 - recall0.5: 0.5010 - tp0.7: 3785515.0000 - fp0.7: 20841488.0000 - tn0.7: 20754294.0000 - fn0.7: 3770718.0000 - precision0.7: 0.1537 - recall0.7: 0.5010 - tp0.9: 3785515.0000 - fp0.9: 20841488.0000 - tn0.9: 20754294.0000 - fn0.9
         : 3770718.0000 - precision0.9: 0.1537 - recall0.9: 0.5010 - accuracy: 0.4993 - auc: 0.5000
         2021-07-20 19:18:05.677332: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
         Traceback (most recent call last):
           File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/train.py", line 263, in <module>
             mlflow_run()
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/click/core.py", line 1137, in __call__
             return self.main(*args, **kwargs)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/click/core.py", line 1062, in main
             rv = self.invoke(ctx)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
             return ctx.invoke(self.callback, **ctx.params)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/click/core.py", line 763, in invoke
             return __callback(*args, **kwargs)
           File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/train.py", line 253, in mlflow_run
             mlflow.keras.log_model(
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/mlflow/keras.py", line 366, in log_model
             Model.log(
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/mlflow/models/model.py", line 187, in log
             flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/mlflow/keras.py", line 246, in save_model
             keras_model.save(model_path, **kwargs)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/engine/training.py", line 2108, in save
             save.save_model(self, filepath, overwrite, include_optimizer, save_format,
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/save.py", line 149, in save_model
             saved_model_save.save(model, filepath, overwrite, include_optimizer,
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/save.py", line 94, in save
             metadata = generate_keras_metadata(saved_nodes, node_paths)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/save.py", line 123, in generate_keras_metadata
             metadata=node._tracking_metadata)  # pylint: disable=protected-access
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/engine/base_layer.py", line 3078, in _tracking_metadata
             return self._trackable_saved_model_saver.tracking_metadata
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/base_serialization.py", line 54, in tracking_metadata
             return json_utils.Encoder().encode(self.python_properties)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/json_utils.py", line 45, in encode
             return super(Encoder, self).encode(_encode_tuple(obj))
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/json/encoder.py", line 199, in encode
             chunks = self.iterencode(o, _one_shot=True)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/json/encoder.py", line 257, in iterencode
             return _iterencode(o, 0)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/json_utils.py", line 42, in default
             return get_json_type(obj)
           File "/home/ye53nis/.conda/envs/mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef/lib/python3.9/site-packages/keras/saving/saved_model/json_utils.py", line 142, in get_json_type
             raise TypeError('Not JSON Serializable:', obj)
         TypeError: ('Not JSON Serializable:', <tf.Tensor: shape=(), dtype=int32, numpy=64>)
         2021/07/20 19:18:32 ERROR mlflow.cli: === Run (ID 'c0018f9b7b1c4bcfa58cf8df985e45da') failed ===
         (tf-nightly) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=2 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/be
         egfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='minmax' -P n_levels=9
         2021/07/20 23:36:54 INFO mlflow.projects.utils: === Created directory /tmp/tmpxgeqhp3z for downloading remote URIs passed to arguments of type 'path' ===
         2021/07/20 23:36:54 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef 1>&2 && python src/fluotracify/trai
         ning/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 5 --frac_val 0.2 --length_delimiter 16384 --learning_rate 0 --epochs 2 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_
         test /beegfs/ye53nis/saves/firstartifact_Nov2020_test --col_per_example 3 --steps_per_epoch 10 --validation_steps 10 --scaler minmax --n_levels 9 --first_filters 64 --pool_size 2' in run with ID '2f5a5c0ca4a7448384a1e1497c3c0269' ===
         2.7.0-dev20210720
         2021-07-20 23:37:00.208781: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
         2021-07-20 23:37:00.208887: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
         GPUs:  []
         2021/07/20 23:37:01 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading
          MLflow.
         0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
         1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
         2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
         3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
         4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
         5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
         6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
         7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
         8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
         9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
         10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
         11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
         12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
         13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
         14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
         15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
         16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
         17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
         18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
         19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
         20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
         21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
         22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
         23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
         24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
         25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
         26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
         27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
         0 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set010.csv
         1 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set002.csv
         2 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set005.csv
         3 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set005.csv
         4 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set007.csv
         5 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set002.csv
         6 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set001.csv
         7 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set007.csv
         8 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set009.csv
         9 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set002.csv
         10 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set005.csv
         11 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set008.csv
         12 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set005.csv
         13 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set008.csv
         14 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set005.csv
         15 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set006.csv
         16 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set005.csv
         17 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set003.csv
         18 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set001.csv
         19 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set003.csv
         20 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set003.csv
         21 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set005.csv
         22 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set002.csv
         23 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set002.csv
         24 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set004.csv
         25 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set001.csv
         26 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set001.csv
         27 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set001.csv
         28 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set003.csv
         29 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set001.csv
         The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
         The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]

         for each 16384 timestap trace there are the following numbers of corrupted timesteps:
         label001_1    1916
         label002_1    1004
         label003_1    1476
         label004_1    1154
         label005_1    1454
         dtype: int64
         2021-07-20 23:40:48.788281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
         ons:  AVX2 FMA
         To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
         number of training examples: 2240, number of validation examples: 560

         ------------------------
         number of test examples: 3000

         input - shape:   (None, 16384, 1)
         output - shape:  (None, 16384, 1)
         2021-07-20 23:40:55.074961: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
         2021-07-20 23:40:55.074999: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
         2021-07-20 23:40:55.830550: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
         2021/07/20 23:40:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='5' for run ID='2f5
         a5c0ca4a7448384a1e1497c3c0269'. Attempted logging new value 'None'.
         Epoch 1/2
          1/10 [==>...........................] - ETA: 4:12 - loss: 1.6922 - tp0.1: 12328.0000 - fp0.1: 69568.0000 - tn0.1: 0.0000e+00 - fn0.1: 24.0000 - precision0.1: 0.1505 - recall0.1: 0.9981 - tp0.3: 12174.0000 - fp0.3: 69440.0000 - tn0.3:
         128.0000 - fn0.3: 178.0000 - precision0.3: 0.1492 - recall0.3: 0.9856 - tp0.5: 10180.0000 - fp0.5: 52540.0000 - tn0.5: 17028.0000 - fn0.5: 2172.0000 - precision0.5: 0.1623 - recall0.5: 0.8242 - tp0.7: 5585.0000 - fp0.7: 5861.0000 - tn0
         .7: 63707.0000 - fn0.7: 6767.0000 - precision0.7: 0.4879 - recall0.7: 0.4522 - tp0.9: 2581.0000 - fp0.9: 716.0000 - tn0.9: 68852.0000 - fn0.9: 9771.0000 - precision0.9: 0.7828 - recall0.9: 0.2090 - accuracy: 0.3321 - auc: 0.69072021-07
         -20 23:41:24.201636: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
         2021-07-20 23:41:24.201682: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
          2/10 [=====>........................] - ETA: 27s - loss: 2.2290 - tp0.1: 12963.0000 - fp0.1: 76656.0000 - tn0.1: 58179.0000 - fn0.1: 16042.0000 - precision0.1: 0.1446 - recall0.1: 0.4469 - tp0.3: 12349.0000 - fp0.3: 71765.0000 - tn0.3
         : 63070.0000 - fn0.3: 16656.0000 - precision0.3: 0.1468 - recall0.3: 0.4258 - tp0.5: 10182.0000 - fp0.5: 53000.0000 - tn0.5: 81835.0000 - fn0.5: 18823.0000 - precision0.5: 0.1612 - recall0.5: 0.3510 - tp0.7: 5585.0000 - fp0.7: 5861.000
         0 - tn0.7: 128974.0000 - fn0.7: 23420.0000 - precision0.7: 0.4879 - recall0.7: 0.1926 - tp0.9: 2581.0000 - fp0.9: 716.0000 - tn0.9: 134119.0000 - fn0.9: 26424.0000 - precision0.9: 0.7828 - recall0.9: 0.0890 - accuracy: 0.5616 - auc: 0.
         46452021-07-20 23:41:27.685706: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
         2021-07-20 23:41:27.727070: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
         2021-07-20 23:41:27.767678: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_23_41_27

         2021-07-20 23:41:27.786406: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.trace.json.gz
         2021-07-20 23:41:27.816611: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_23_41_27

         2021-07-20 23:41:27.816759: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.memory_profile.json.gz
         2021-07-20 23:41:27.819111: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tb/train/plugins/profile/2021_07_20_23_41_27
         Dumped tool data for xplane.pb to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.xplane.pb
         Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.overview_page.pb
         Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.input_pipeline.pb
         Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.tensorflow_stats.pb
         Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_07_20_23_41_27/login01.kernel_stats.pb

         10/10 [==============================] - 72s 5s/step - loss: 1.5070 - tp0.1: 70514.0000 - fp0.1: 299822.0000 - tn0.1: 415093.0000 - fn0.1: 33771.0000 - precision0.1: 0.1904 - recall0.1: 0.6762 - tp0.3: 55203.0000 - fp0.3: 156589.0000 -
          tn0.3: 558326.0000 - fn0.3: 49082.0000 - precision0.3: 0.2606 - recall0.3: 0.5293 - tp0.5: 27663.0000 - fp0.5: 80978.0000 - tn0.5: 633937.0000 - fn0.5: 76622.0000 - precision0.5: 0.2546 - recall0.5: 0.2653 - tp0.7: 15495.0000 - fp0.7:
          12396.0000 - tn0.7: 702519.0000 - fn0.7: 88790.0000 - precision0.7: 0.5556 - recall0.7: 0.1486 - tp0.9: 9828.0000 - fp0.9: 4978.0000 - tn0.9: 709937.0000 - fn0.9: 94457.0000 - precision0.9: 0.6638 - recall0.9: 0.0942 - accuracy: 0.807
         6 - auc: 0.6697 - val_loss: 5470244262657843260044481658880.0000 - val_tp0.1: 0.0000e+00 - val_fp0.1: 0.0000e+00 - val_tn0.1: 687301.0000 - val_fn0.1: 131899.0000 - val_precision0.1: 0.0000e+00 - val_recall0.1: 0.0000e+00 - val_tp0.3:
         0.0000e+00 - val_fp0.3: 0.0000e+00 - val_tn0.3: 687301.0000 - val_fn0.3: 131899.0000 - val_precision0.3: 0.0000e+00 - val_recall0.3: 0.0000e+00 - val_tp0.5: 0.0000e+00 - val_fp0.5: 0.0000e+00 - val_tn0.5: 687301.0000 - val_fn0.5: 13189
         9.0000 - val_precision0.5: 0.0000e+00 - val_recall0.5: 0.0000e+00 - val_tp0.7: 0.0000e+00 - val_fp0.7: 0.0000e+00 - val_tn0.7: 687301.0000 - val_fn0.7: 131899.0000 - val_precision0.7: 0.0000e+00 - val_recall0.7: 0.0000e+00 - val_tp0.9:
          0.0000e+00 - val_fp0.9: 0.0000e+00 - val_tn0.9: 687301.0000 - val_fn0.9: 131899.0000 - val_precision0.9: 0.0000e+00 - val_recall0.9: 0.0000e+00 - val_accuracy: 0.8390 - val_auc: 0.5000
         Epoch 2/2
         10/10 [==============================] - 42s 4s/step - loss: 1.2284 - tp0.1: 108967.0000 - fp0.1: 222931.0000 - tn0.1: 471270.0000 - fn0.1: 16032.0000 - precision0.1: 0.3283 - recall0.1: 0.8717 - tp0.3: 84864.0000 - fp0.3: 100481.0000
         - tn0.3: 593720.0000 - fn0.3: 40135.0000 - precision0.3: 0.4579 - recall0.3: 0.6789 - tp0.5: 30186.0000 - fp0.5: 11380.0000 - tn0.5: 682821.0000 - fn0.5: 94813.0000 - precision0.5: 0.7262 - recall0.5: 0.2415 - tp0.7: 19042.0000 - fp0.7
         : 4363.0000 - tn0.7: 689838.0000 - fn0.7: 105957.0000 - precision0.7: 0.8136 - recall0.7: 0.1523 - tp0.9: 9657.0000 - fp0.9: 925.0000 - tn0.9: 693276.0000 - fn0.9: 115342.0000 - precision0.9: 0.9126 - recall0.9: 0.0773 - accuracy: 0.87
         04 - auc: 0.8590 - val_loss: 322611648340592527671296.0000 - val_tp0.1: 88241.0000 - val_fp0.1: 730959.0000 - val_tn0.1: 0.0000e+00 - val_fn0.1: 0.0000e+00 - val_precision0.1: 0.1077 - val_recall0.1: 1.0000 - val_tp0.3: 88241.0000 - va
         l_fp0.3: 730959.0000 - val_tn0.3: 0.0000e+00 - val_fn0.3: 0.0000e+00 - val_precision0.3: 0.1077 - val_recall0.3: 1.0000 - val_tp0.5: 88241.0000 - val_fp0.5: 730959.0000 - val_tn0.5: 0.0000e+00 - val_fn0.5: 0.0000e+00 - val_precision0.5
         : 0.1077 - val_recall0.5: 1.0000 - val_tp0.7: 88241.0000 - val_fp0.7: 730959.0000 - val_tn0.7: 0.0000e+00 - val_fn0.7: 0.0000e+00 - val_precision0.7: 0.1077 - val_recall0.7: 1.0000 - val_tp0.9: 88241.0000 - val_fp0.9: 730959.0000 - val
         _tn0.9: 0.0000e+00 - val_fn0.9: 0.0000e+00 - val_precision0.9: 0.1077 - val_recall0.9: 1.0000 - val_accuracy: 0.1077 - val_auc: 0.5000
         600/600 [==============================] - 380s 633ms/step - loss: 299875171578617050169344.0000 - tp0.1: 7556233.0000 - fp0.1: 41595756.0000 - tn0.1: 0.0000e+00 - fn0.1: 0.0000e+00 - precision0.1: 0.1537 - recall0.1: 1.0000 - tp0.3: 7
         556233.0000 - fp0.3: 41595756.0000 - tn0.3: 0.0000e+00 - fn0.3: 0.0000e+00 - precision0.3: 0.1537 - recall0.3: 1.0000 - tp0.5: 7556233.0000 - fp0.5: 41595756.0000 - tn0.5: 0.0000e+00 - fn0.5: 0.0000e+00 - precision0.5: 0.1537 - recall0
         .5: 1.0000 - tp0.7: 7556233.0000 - fp0.7: 41595756.0000 - tn0.7: 0.0000e+00 - fn0.7: 0.0000e+00 - precision0.7: 0.1537 - recall0.7: 1.0000 - tp0.9: 7556233.0000 - fp0.9: 41595756.0000 - tn0.9: 0.0000e+00 - fn0.9: 0.0000e+00 - precision
         0.9: 0.1537 - recall0.9: 1.0000 - accuracy: 0.1537 - auc: 0.5000
         2021-07-20 23:49:40.568265: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
         2021/07/20 23:50:06 INFO mlflow.projects: === Run (ID '2f5a5c0ca4a7448384a1e1497c3c0269') succeeded ===
         (tf-nightly) [ye53nis@login01 drmed-git]$
       #+end_example

     - Notes:
       - the first time i forgot to add scikit-learn to =conda.yaml=. I fixed
         that and ran the above command again. also all packages have to be
         installed via pip and numpy needs a version <= 1.19.5, because with
         1.20 there was some change in the C subsystem
       - TypeError: ('Not JSON Serializable:', <tf.Tensor: shape=(),
         dtype=int32, numpy=64>) → at the moment, keras can't serialize tf.
         Variables (https://github.com/tensorflow/tensorflow/issues/28799) →
         added .numpy() to filters

**** test run 2 - trying new setup (robust, n_levels=5, first_filters=32)
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
       mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=10 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/beegfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='robust' -P n_levels=5 -P first_filters=32 -P steps_per_epoch=1120 -P validation_steps=280
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf-nightly) [ye53nis@login01 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=10 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/b
       eegfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='robust' -P n_levels=5 -P first_filters=32 -P steps_per_epoch=1120 -P validation_steps=280
       2021/07/21 20:27:24 INFO mlflow.projects.utils: === Created directory /tmp/tmpzr20eiqm for downloading remote URIs passed to arguments of type 'path' ===
       2021/07/21 20:27:24 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef 1>&2 && python src/fluotracify/trai
       ning/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 5 --frac_val 0.2 --length_delimiter 16384 --learning_rate 0 --epochs 10 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path
       _test /beegfs/ye53nis/saves/firstartifact_Nov2020_test --col_per_example 3 --steps_per_epoch 1120 --validation_steps 280 --scaler robust --n_levels 5 --first_filters 32 --pool_size 2' in run with ID 'fbba032b341f4547b686023edba3c6c2' =
       ==
       2.7.0-dev20210720
       2021-07-21 20:27:37.074774: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
       2021-07-21 20:27:37.074879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
       GPUs:  []
       2021/07/21 20:27:42 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading
        MLflow.
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set010.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set002.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set005.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set005.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set007.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set002.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set001.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set009.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set002.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set005.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set008.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set005.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set008.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set005.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set006.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set005.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set003.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set001.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set003.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set005.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set002.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set002.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set004.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set001.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set001.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set001.csv
       28 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set003.csv
       29 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set001.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]

       for each 16384 timestap trace there are the following numbers of corrupted timesteps:
       label001_1    1916
       label002_1    1004
       label003_1    1476
       label004_1    1154
       label005_1    1454
       dtype: int64
       2021-07-21 20:32:05.730092: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-07-21 20:32:06.289205: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 183500800 exceeds 10% of free system memory.
       2021-07-21 20:32:06.318132: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 183500800 exceeds 10% of free system memory.
       2021-07-21 20:32:06.992378: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 183500800 exceeds 10% of free system memory.
       number of training examples: 2240, number of validation examples: 560

       ------------------------
       2021-07-21 20:32:07.883135: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 196608000 exceeds 10% of free system memory.
       2021-07-21 20:32:07.908783: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 196608000 exceeds 10% of free system memory.
       number of test examples: 3000

       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       2021-07-21 20:32:09.649455: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
       2021-07-21 20:32:09.649492: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
       2021-07-21 20:32:10.468889: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
       2021/07/21 20:32:10 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='5' for run ID='fbb
       a032b341f4547b686023edba3c6c2'. Attempted logging new value 'None'.
       Epoch 1/10
          1/1120 [..............................] - ETA: 6:30:17 - loss: 1.7041 - tp0.1: 13900.0000 - fp0.1: 65126.0000 - tn0.1: 960.0000 - fn0.1: 1934.0000 - precision0.1: 0.1759 - recall0.1: 0.8779 - tp0.3: 12980.0000 - fp0.3: 61707.0000 -
       tn0.3: 4379.0000 - fn0.3: 2854.0000 - precision0.3: 0.1738 - recall0.3: 0.8198 - tp0.5: 7344.0000 - fp0.5: 29351.0000 - tn0.5: 36735.0000 - fn0.5: 8490.0000 - precision0.5: 0.2001 - recall0.5: 0.4638 - tp0.7: 308.0000 - fp0.7: 828.0000
        - tn0.7: 65258.0000 - fn0.7: 15526.0000 - precision0.7: 0.2711 - recall0.7: 0.0195 - tp0.9: 22.0000 - fp0.9: 4.0000 - tn0.9: 66082.0000 - fn0.9: 15812.0000 - precision0.9: 0.8462 - recall0.9: 0.0014 - accuracy: 0.5381 - auc: 0.4875202
       1-07-21 20:32:31.697867: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
       2021-07-21 20:32:31.697915: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
          2/1120 [..............................] - ETA: 30:03 - loss: 1.4947 - tp0.1: 16578.0000 - fp0.1: 117913.0000 - tn0.1: 24320.0000 - fn0.1: 5029.0000 - precision0.1: 0.1233 - recall0.1: 0.7673 - tp0.3: 14924.0000 - fp0.3: 62662.0000 -
        tn0.3: 79571.0000 - fn0.3: 6683.0000 - precision0.3: 0.1924 - recall0.3: 0.6907 - tp0.5: 9217.0000 - fp0.5: 30180.0000 - tn0.5: 112053.0000 - fn0.5: 12390.0000 - precision0.5: 0.2340 - recall0.5: 0.4266 - tp0.7: 2098.0000 - fp0.7: 157
       2.0000 - tn0.7: 140661.0000 - fn0.7: 19509.0000 - precision0.7: 0.5717 - recall0.7: 0.0971 - tp0.9: 1637.0000 - fp0.9: 633.0000 - tn0.9: 141600.0000 - fn0.9: 19970.0000 - precision0.9: 0.7211 - recall0.9: 0.0758 - accuracy: 0.7402 - au
       c: 0.61172021-07-21 20:32:33.312693: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
       2021-07-21 20:32:33.330375: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
       2021-07-21 20:32:33.357644: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_21_20_32_33

       2021-07-21 20:32:33.371486: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.trace.json.gz
       2021-07-21 20:32:33.393579: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_21_20_32_33

       2021-07-21 20:32:33.393708: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.memory_profile.json.gz
       2021-07-21 20:32:33.395393: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tb/train/plugins/profile/2021_07_21_20_32_33
       Dumped tool data for xplane.pb to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.xplane.pb
       Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.overview_page.pb
       Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.input_pipeline.pb
       Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.tensorflow_stats.pb
       Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_07_21_20_32_33/login01.kernel_stats.pb

       1120/1120 [==============================] - 1991s 2s/step - loss: 0.7821 - tp0.1: 13072206.0000 - fp0.1: 21848776.0000 - tn0.1: 55156388.0000 - fn0.1: 1673024.0000 - precision0.1: 0.3743 - recall0.1: 0.8865 - tp0.3: 9804586.0000 - fp0
       .3: 5120145.0000 - tn0.3: 71885016.0000 - fn0.3: 4940644.0000 - precision0.3: 0.6569 - recall0.3: 0.6649 - tp0.5: 8380188.0000 - fp0.5: 2113346.0000 - tn0.5: 74891904.0000 - fn0.5: 6365042.0000 - precision0.5: 0.7986 - recall0.5: 0.568
       3 - tp0.7: 7255264.0000 - fp0.7: 900866.0000 - tn0.7: 76104352.0000 - fn0.7: 7489966.0000 - precision0.7: 0.8895 - recall0.7: 0.4920 - tp0.9: 5875950.0000 - fp0.9: 270278.0000 - tn0.9: 76734880.0000 - fn0.9: 8869280.0000 - precision0.9
       : 0.9560 - recall0.9: 0.3985 - accuracy: 0.9076 - auc: 0.8888 - val_loss: 1.1039 - val_tp0.1: 3033002.0000 - val_fp0.1: 5830794.0000 - val_tn0.1: 13860472.0000 - val_fn0.1: 213332.0000 - val_precision0.1: 0.3422 - val_recall0.1: 0.9343
        - val_tp0.3: 3003362.0000 - val_fp0.3: 5475207.0000 - val_tn0.3: 14216059.0000 - val_fn0.3: 242972.0000 - val_precision0.3: 0.3542 - val_recall0.3: 0.9252 - val_tp0.5: 2965370.0000 - val_fp0.5: 5167320.0000 - val_tn0.5: 14523946.0000
       - val_fn0.5: 280964.0000 - val_precision0.5: 0.3646 - val_recall0.5: 0.9135 - val_tp0.7: 2917193.0000 - val_fp0.7: 4799307.0000 - val_tn0.7: 14891959.0000 - val_fn0.7: 329141.0000 - val_precision0.7: 0.3780 - val_recall0.7: 0.8986 - va
       l_tp0.9: 2708662.0000 - val_fp0.9: 3375111.0000 - val_tn0.9: 16316155.0000 - val_fn0.9: 537672.0000 - val_precision0.9: 0.4452 - val_recall0.9: 0.8344 - val_accuracy: 0.7625 - val_auc: 0.9051
       Epoch 2/10
       1120/1120 [==============================] - 1962s 2s/step - loss: 0.6303 - tp0.1: 13568121.0000 - fp0.1: 16468945.0000 - tn0.1: 60403672.0000 - fn0.1: 1309659.0000 - precision0.1: 0.4517 - recall0.1: 0.9120 - tp0.3: 11384789.0000 - fp
       0.3: 8027374.0000 - tn0.3: 68845200.0000 - fn0.3: 3492991.0000 - precision0.3: 0.5865 - recall0.3: 0.7652 - tp0.5: 8952071.0000 - fp0.5: 2152756.0000 - tn0.5: 74719808.0000 - fn0.5: 5925709.0000 - precision0.5: 0.8061 - recall0.5: 0.60
       17 - tp0.7: 7678013.0000 - fp0.7: 934159.0000 - tn0.7: 75938488.0000 - fn0.7: 7199767.0000 - precision0.7: 0.8915 - recall0.7: 0.5161 - tp0.9: 6070842.0000 - fp0.9: 235727.0000 - tn0.9: 76636928.0000 - fn0.9: 8806938.0000 - precision0.
       9: 0.9626 - recall0.9: 0.4080 - accuracy: 0.9120 - auc: 0.9132 - val_loss: 0.6324 - val_tp0.1: 3123098.0000 - val_fp0.1: 5965675.0000 - val_tn0.1: 13703551.0000 - val_fn0.1: 145276.0000 - val_precision0.1: 0.3436 - val_recall0.1: 0.955
       6 - val_tp0.3: 3029947.0000 - val_fp0.3: 4780823.0000 - val_tn0.3: 14888403.0000 - val_fn0.3: 238427.0000 - val_precision0.3: 0.3879 - val_recall0.3: 0.9271 - val_tp0.5: 2314332.0000 - val_fp0.5: 1205931.0000 - val_tn0.5: 18463292.0000
        - val_fn0.5: 954042.0000 - val_precision0.5: 0.6574 - val_recall0.5: 0.7081 - val_tp0.7: 1853851.0000 - val_fp0.7: 291220.0000 - val_tn0.7: 19378004.0000 - val_fn0.7: 1414523.0000 - val_precision0.7: 0.8642 - val_recall0.7: 0.5672 - v
       al_tp0.9: 1343151.0000 - val_fp0.9: 29856.0000 - val_tn0.9: 19639360.0000 - val_fn0.9: 1925223.0000 - val_precision0.9: 0.9783 - val_recall0.9: 0.4110 - val_accuracy: 0.9058 - val_auc: 0.9281
       Epoch 3/10
       1120/1120 [==============================] - 1974s 2s/step - loss: 0.5171 - tp0.1: 13762400.0000 - fp0.1: 13125375.0000 - tn0.1: 63754936.0000 - fn0.1: 1107725.0000 - precision0.1: 0.5118 - recall0.1: 0.9255 - tp0.3: 12889606.0000 - fp
       0.3: 8592047.0000 - tn0.3: 68288264.0000 - fn0.3: 1980519.0000 - precision0.3: 0.6000 - recall0.3: 0.8668 - tp0.5: 10028195.0000 - fp0.5: 2394137.0000 - tn0.5: 74486088.0000 - fn0.5: 4841930.0000 - precision0.5: 0.8073 - recall0.5: 0.6
       744 - tp0.7: 8414183.0000 - fp0.7: 883107.0000 - tn0.7: 75997152.0000 - fn0.7: 6455942.0000 - precision0.7: 0.9050 - recall0.7: 0.5658 - tp0.9: 6334448.0000 - fp0.9: 168338.0000 - tn0.9: 76711968.0000 - fn0.9: 8535677.0000 - precision0
       .9: 0.9741 - recall0.9: 0.4260 - accuracy: 0.9211 - auc: 0.9343 - val_loss: 0.5210 - val_tp0.1: 3075613.0000 - val_fp0.1: 4846330.0000 - val_tn0.1: 14858724.0000 - val_fn0.1: 156933.0000 - val_precision0.1: 0.3882 - val_recall0.1: 0.95
       15 - val_tp0.3: 2910596.0000 - val_fp0.3: 2738921.0000 - val_tn0.3: 16966132.0000 - val_fn0.3: 321950.0000 - val_precision0.3: 0.5152 - val_recall0.3: 0.9004 - val_tp0.5: 2246773.0000 - val_fp0.5: 758421.0000 - val_tn0.5: 18946632.0000
        - val_fn0.5: 985773.0000 - val_precision0.5: 0.7476 - val_recall0.5: 0.6950 - val_tp0.7: 1942303.0000 - val_fp0.7: 273174.0000 - val_tn0.7: 19431884.0000 - val_fn0.7: 1290243.0000 - val_precision0.7: 0.8767 - val_recall0.7: 0.6009 - v
       al_tp0.9: 1485290.0000 - val_fp0.9: 48760.0000 - val_tn0.9: 19656294.0000 - val_fn0.9: 1747256.0000 - val_precision0.9: 0.9682 - val_recall0.9: 0.4595 - val_accuracy: 0.9240 - val_auc: 0.9410
       Epoch 4/10
        662/1120 [================>.............] - ETA: 12:38 - loss: 0.4663 - tp0.1: 8106158.0000 - fp0.1: 6824216.0000 - tn0.1: 38696464.0000 - fn0.1: 604216.0000 - precision0.1: 0.5429 - recall0.1: 0.9306 - tp0.3: 7576989.0000 - fp0.3: 39
       76801.0000 - tn0.3: 41543852.0000 - fn0.3: 1133385.0000 - precision0.3: 0.6558 - recall0.3: 0.8699 - tp0.5: 6358320.0000 - fp0.5: 1528898.0000 - tn0.5: 43991780.0000 - fn0.5: 2352054.0000 - precision0.5: 0.8062 - recall0.5: 0.7300 - tp
       0.7: 5415428.0000 - fp0.7: 628478.0000 - tn0.7: 44892224.0000 - fn0.7: 3294946.0000 - precision0.7: 0.8960 - recall0.7: 0.6217 - tp0.9: 4001157.0000 - fp0.9: 105884.0000 - tn0.9: 45414772.0000 - fn0.9: 4709217.0000 - precision0.9: 0.97
       42 - recall0.9: 0.4594 - accuracy: 0.9284 - auc: 0.9440srun -p gpu_a100 --time=1-10:00:00 --ntasks-per-node=24 --mem-per-cpu=6000 --gres=gpu:1 --pty bash
       1120/1120 [==============================] - 1976s 2s/step - loss: 0.4626 - tp0.1: 13708478.0000 - fp0.1: 11284665.0000 - tn0.1: 65712932.0000 - fn0.1: 1044407.0000 - precision0.1: 0.5485 - recall0.1: 0.9292 - tp0.3: 12803315.0000 - fp
       0.3: 6361839.0000 - tn0.3: 70635704.0000 - fn0.3: 1949570.0000 - precision0.3: 0.6681 - recall0.3: 0.8679 - tp0.5: 10929751.0000 - fp0.5: 2559137.0000 - tn0.5: 74438360.0000 - fn0.5: 3823134.0000 - precision0.5: 0.8103 - recall0.5: 0.7
       409 - tp0.7: 9390195.0000 - fp0.7: 1115472.0000 - tn0.7: 75882176.0000 - fn0.7: 5362690.0000 - precision0.7: 0.8938 - recall0.7: 0.6365 - tp0.9: 6898553.0000 - fp0.9: 193055.0000 - tn0.9: 76804408.0000 - fn0.9: 7854332.0000 - precision
       0.9: 0.9728 - recall0.9: 0.4676 - accuracy: 0.9304 - auc: 0.9450 - val_loss: 0.4721 - val_tp0.1: 2943120.0000 - val_fp0.1: 3101589.0000 - val_tn0.1: 16632689.0000 - val_fn0.1: 260202.0000 - val_precision0.1: 0.4869 - val_recall0.1: 0.9
       188 - val_tp0.3: 2605314.0000 - val_fp0.3: 1412618.0000 - val_tn0.3: 18321664.0000 - val_fn0.3: 598008.0000 - val_precision0.3: 0.6484 - val_recall0.3: 0.8133 - val_tp0.5: 2170640.0000 - val_fp0.5: 518931.0000 - val_tn0.5: 19215354.000
       0 - val_fn0.5: 1032682.0000 - val_precision0.5: 0.8071 - val_recall0.5: 0.6776 - val_tp0.7: 1905035.0000 - val_fp0.7: 215821.0000 - val_tn0.7: 19518456.0000 - val_fn0.7: 1298287.0000 - val_precision0.7: 0.8982 - val_recall0.7: 0.5947 -
        val_tp0.9: 1554768.0000 - val_fp0.9: 56854.0000 - val_tn0.9: 19677432.0000 - val_fn0.9: 1648554.0000 - val_precision0.9: 0.9647 - val_recall0.9: 0.4854 - val_accuracy: 0.9324 - val_auc: 0.9371
       Epoch 5/10
       1120/1120 [==============================] - 1975s 2s/step - loss: 0.4272 - tp0.1: 13781175.0000 - fp0.1: 10102386.0000 - tn0.1: 66822072.0000 - fn0.1: 1044726.0000 - precision0.1: 0.5770 - recall0.1: 0.9295 - tp0.3: 12705775.0000 - fp
       0.3: 4328689.0000 - tn0.3: 72595784.0000 - fn0.3: 2120126.0000 - precision0.3: 0.7459 - recall0.3: 0.8570 - tp0.5: 11787812.0000 - fp0.5: 2290833.0000 - tn0.5: 74633672.0000 - fn0.5: 3038089.0000 - precision0.5: 0.8373 - recall0.5: 0.7
       951 - tp0.7: 10583272.0000 - fp0.7: 1169837.0000 - tn0.7: 75754696.0000 - fn0.7: 4242629.0000 - precision0.7: 0.9005 - recall0.7: 0.7138 - tp0.9: 7999161.0000 - fp0.9: 253115.0000 - tn0.9: 76671368.0000 - fn0.9: 6826740.0000 - precisio
       n0.9: 0.9693 - recall0.9: 0.5395 - accuracy: 0.9419 - auc: 0.9506 - val_loss: 0.5161 - val_tp0.1: 2778228.0000 - val_fp0.1: 2011519.0000 - val_tn0.1: 17679872.0000 - val_fn0.1: 467977.0000 - val_precision0.1: 0.5800 - val_recall0.1: 0.
       8558 - val_tp0.3: 2348980.0000 - val_fp0.3: 739065.0000 - val_tn0.3: 18952332.0000 - val_fn0.3: 897225.0000 - val_precision0.3: 0.7607 - val_recall0.3: 0.7236 - val_tp0.5: 2192196.0000 - val_fp0.5: 416010.0000 - val_tn0.5: 19275378.000
       0 - val_fn0.5: 1054009.0000 - val_precision0.5: 0.8405 - val_recall0.5: 0.6753 - val_tp0.7: 2031791.0000 - val_fp0.7: 218485.0000 - val_tn0.7: 19472916.0000 - val_fn0.7: 1214414.0000 - val_precision0.7: 0.9029 - val_recall0.7: 0.6259 -
        val_tp0.9: 1687751.0000 - val_fp0.9: 48910.0000 - val_tn0.9: 19642482.0000 - val_fn0.9: 1558454.0000 - val_precision0.9: 0.9718 - val_recall0.9: 0.5199 - val_accuracy: 0.9359 - val_auc: 0.9120
       Epoch 6/10
       1120/1120 [==============================] - 1970s 2s/step - loss: 0.3999 - tp0.1: 13869020.0000 - fp0.1: 9850730.0000 - tn0.1: 67102568.0000 - fn0.1: 928089.0000 - precision0.1: 0.5847 - recall0.1: 0.9373 - tp0.3: 12756373.0000 - fp0.
       3: 3835505.0000 - tn0.3: 73117752.0000 - fn0.3: 2040736.0000 - precision0.3: 0.7688 - recall0.3: 0.8621 - tp0.5: 12004455.0000 - fp0.5: 2125228.0000 - tn0.5: 74828048.0000 - fn0.5: 2792654.0000 - precision0.5: 0.8496 - recall0.5: 0.811
       3 - tp0.7: 11017283.0000 - fp0.7: 1115734.0000 - tn0.7: 75837544.0000 - fn0.7: 3779826.0000 - precision0.7: 0.9080 - recall0.7: 0.7446 - tp0.9: 8476622.0000 - fp0.9: 268056.0000 - tn0.9: 76685192.0000 - fn0.9: 6320487.0000 - precision0
       .9: 0.9693 - recall0.9: 0.5729 - accuracy: 0.9464 - auc: 0.9558 - val_loss: 0.4733 - val_tp0.1: 2953567.0000 - val_fp0.1: 2454471.0000 - val_tn0.1: 17205730.0000 - val_fn0.1: 323834.0000 - val_precision0.1: 0.5461 - val_recall0.1: 0.90
       12 - val_tp0.3: 2256340.0000 - val_fp0.3: 458903.0000 - val_tn0.3: 19201294.0000 - val_fn0.3: 1021061.0000 - val_precision0.3: 0.8310 - val_recall0.3: 0.6885 - val_tp0.5: 2057829.0000 - val_fp0.5: 227793.0000 - val_tn0.5: 19432404.0000
        - val_fn0.5: 1219572.0000 - val_precision0.5: 0.9003 - val_recall0.5: 0.6279 - val_tp0.7: 1881779.0000 - val_fp0.7: 114238.0000 - val_tn0.7: 19545962.0000 - val_fn0.7: 1395622.0000 - val_precision0.7: 0.9428 - val_recall0.7: 0.5742 -
       val_tp0.9: 1565068.0000 - val_fp0.9: 27333.0000 - val_tn0.9: 19632866.0000 - val_fn0.9: 1712333.0000 - val_precision0.9: 0.9828 - val_recall0.9: 0.4775 - val_accuracy: 0.9369 - val_auc: 0.9347
       Epoch 7/10
       1120/1120 [==============================] - 2029s 2s/step - loss: 0.3879 - tp0.1: 13810046.0000 - fp0.1: 9556667.0000 - tn0.1: 67488312.0000 - fn0.1: 895382.0000 - precision0.1: 0.5910 - recall0.1: 0.9391 - tp0.3: 12728987.0000 - fp0.
       3: 3571400.0000 - tn0.3: 73473568.0000 - fn0.3: 1976441.0000 - precision0.3: 0.7809 - recall0.3: 0.8656 - tp0.5: 11980304.0000 - fp0.5: 1957245.0000 - tn0.5: 75087712.0000 - fn0.5: 2725124.0000 - precision0.5: 0.8596 - recall0.5: 0.814
       7 - tp0.7: 11017941.0000 - fp0.7: 1032635.0000 - tn0.7: 76012424.0000 - fn0.7: 3687487.0000 - precision0.7: 0.9143 - recall0.7: 0.7492 - tp0.9: 8554787.0000 - fp0.9: 257613.0000 - tn0.9: 76787328.0000 - fn0.9: 6150641.0000 - precision0
       .9: 0.9708 - recall0.9: 0.5817 - accuracy: 0.9490 - auc: 0.9574 - val_loss: 0.4748 - val_tp0.1: 2863620.0000 - val_fp0.1: 1843777.0000 - val_tn0.1: 17831248.0000 - val_fn0.1: 398952.0000 - val_precision0.1: 0.6083 - val_recall0.1: 0.87
       77 - val_tp0.3: 2275162.0000 - val_fp0.3: 513371.0000 - val_tn0.3: 19161654.0000 - val_fn0.3: 987410.0000 - val_precision0.3: 0.8159 - val_recall0.3: 0.6974 - val_tp0.5: 2103317.0000 - val_fp0.5: 274592.0000 - val_tn0.5: 19400432.0000
       - val_fn0.5: 1159255.0000 - val_precision0.5: 0.8845 - val_recall0.5: 0.6447 - val_tp0.7: 1936403.0000 - val_fp0.7: 142349.0000 - val_tn0.7: 19532676.0000 - val_fn0.7: 1326169.0000 - val_precision0.7: 0.9315 - val_recall0.7: 0.5935 - v
       al_tp0.9: 1646948.0000 - val_fp0.9: 38626.0000 - val_tn0.9: 19636400.0000 - val_fn0.9: 1615624.0000 - val_precision0.9: 0.9771 - val_recall0.9: 0.5048 - val_accuracy: 0.9375 - val_auc: 0.9254
       Epoch 8/10
       1120/1120 [==============================] - 1977s 2s/step - loss: 0.3833 - tp0.1: 14019691.0000 - fp0.1: 9293618.0000 - tn0.1: 67539208.0000 - fn0.1: 897891.0000 - precision0.1: 0.6014 - recall0.1: 0.9398 - tp0.3: 12961161.0000 - fp0.
       3: 3535392.0000 - tn0.3: 73297360.0000 - fn0.3: 1956421.0000 - precision0.3: 0.7857 - recall0.3: 0.8689 - tp0.5: 12240133.0000 - fp0.5: 1974656.0000 - tn0.5: 74858176.0000 - fn0.5: 2677449.0000 - precision0.5: 0.8611 - recall0.5: 0.820
       5 - tp0.7: 11345691.0000 - fp0.7: 1067924.0000 - tn0.7: 75764920.0000 - fn0.7: 3571891.0000 - precision0.7: 0.9140 - recall0.7: 0.7606 - tp0.9: 8900634.0000 - fp0.9: 281391.0000 - tn0.9: 76551472.0000 - fn0.9: 6016948.0000 - precision0
       .9: 0.9694 - recall0.9: 0.5967 - accuracy: 0.9493 - auc: 0.9583 - val_loss: 0.5218 - val_tp0.1: 2794732.0000 - val_fp0.1: 1603257.0000 - val_tn0.1: 18036986.0000 - val_fn0.1: 502625.0000 - val_precision0.1: 0.6355 - val_recall0.1: 0.84
       76 - val_tp0.3: 2275666.0000 - val_fp0.3: 501984.0000 - val_tn0.3: 19138260.0000 - val_fn0.3: 1021691.0000 - val_precision0.3: 0.8193 - val_recall0.3: 0.6901 - val_tp0.5: 2105849.0000 - val_fp0.5: 271619.0000 - val_tn0.5: 19368624.0000
        - val_fn0.5: 1191508.0000 - val_precision0.5: 0.8858 - val_recall0.5: 0.6386 - val_tp0.7: 1943672.0000 - val_fp0.7: 143871.0000 - val_tn0.7: 19496382.0000 - val_fn0.7: 1353685.0000 - val_precision0.7: 0.9311 - val_recall0.7: 0.5895 -
       val_tp0.9: 1655166.0000 - val_fp0.9: 39741.0000 - val_tn0.9: 19600500.0000 - val_fn0.9: 1642191.0000 - val_precision0.9: 0.9766 - val_recall0.9: 0.5020 - val_accuracy: 0.9362 - val_auc: 0.9120
       Epoch 9/10
       1120/1120 [==============================] - 1987s 2s/step - loss: 0.3790 - tp0.1: 13854024.0000 - fp0.1: 9072827.0000 - tn0.1: 67925864.0000 - fn0.1: 897696.0000 - precision0.1: 0.6043 - recall0.1: 0.9391 - tp0.3: 12813930.0000 - fp0.
       3: 3519249.0000 - tn0.3: 73479488.0000 - fn0.3: 1937790.0000 - precision0.3: 0.7845 - recall0.3: 0.8686 - tp0.5: 12075112.0000 - fp0.5: 1944673.0000 - tn0.5: 75053928.0000 - fn0.5: 2676608.0000 - precision0.5: 0.8613 - recall0.5: 0.818
       6 - tp0.7: 11176542.0000 - fp0.7: 1044724.0000 - tn0.7: 75953904.0000 - fn0.7: 3575178.0000 - precision0.7: 0.9145 - recall0.7: 0.7576 - tp0.9: 8801818.0000 - fp0.9: 269755.0000 - tn0.9: 76728920.0000 - fn0.9: 5949902.0000 - precision0
       .9: 0.9703 - recall0.9: 0.5967 - accuracy: 0.9496 - auc: 0.9581 - val_loss: 0.5928 - val_tp0.1: 2564860.0000 - val_fp0.1: 1285695.0000 - val_tn0.1: 18426292.0000 - val_fn0.1: 660754.0000 - val_precision0.1: 0.6661 - val_recall0.1: 0.79
       52 - val_tp0.3: 2217538.0000 - val_fp0.3: 471643.0000 - val_tn0.3: 19240338.0000 - val_fn0.3: 1008076.0000 - val_precision0.3: 0.8246 - val_recall0.3: 0.6875 - val_tp0.5: 2075983.0000 - val_fp0.5: 267283.0000 - val_tn0.5: 19444700.0000
        - val_fn0.5: 1149631.0000 - val_precision0.5: 0.8859 - val_recall0.5: 0.6436 - val_tp0.7: 1928119.0000 - val_fp0.7: 144740.0000 - val_tn0.7: 19567242.0000 - val_fn0.7: 1297495.0000 - val_precision0.7: 0.9302 - val_recall0.7: 0.5978 -
       val_tp0.9: 1656199.0000 - val_fp0.9: 40672.0000 - val_tn0.9: 19671316.0000 - val_fn0.9: 1569415.0000 - val_precision0.9: 0.9760 - val_recall0.9: 0.5135 - val_accuracy: 0.9382 - val_auc: 0.8882
       Epoch 10/10
       1120/1120 [==============================] - 1997s 2s/step - loss: 0.3800 - tp0.1: 13976359.0000 - fp0.1: 9275510.0000 - tn0.1: 67603640.0000 - fn0.1: 894931.0000 - precision0.1: 0.6011 - recall0.1: 0.9398 - tp0.3: 12925544.0000 - fp0.
       3: 3571567.0000 - tn0.3: 73307544.0000 - fn0.3: 1945746.0000 - precision0.3: 0.7835 - recall0.3: 0.8692 - tp0.5: 12186378.0000 - fp0.5: 1967010.0000 - tn0.5: 74912104.0000 - fn0.5: 2684912.0000 - precision0.5: 0.8610 - recall0.5: 0.819
       5 - tp0.7: 11293517.0000 - fp0.7: 1052467.0000 - tn0.7: 75826576.0000 - fn0.7: 3577773.0000 - precision0.7: 0.9148 - recall0.7: 0.7594 - tp0.9: 8883951.0000 - fp0.9: 264328.0000 - tn0.9: 76614824.0000 - fn0.9: 5987339.0000 - precision0
       .9: 0.9711 - recall0.9: 0.5974 - accuracy: 0.9493 - auc: 0.9587 - val_loss: 0.4582 - val_tp0.1: 2836317.0000 - val_fp0.1: 1812512.0000 - val_tn0.1: 17902272.0000 - val_fn0.1: 386500.0000 - val_precision0.1: 0.6101 - val_recall0.1: 0.88
       01 - val_tp0.3: 2359688.0000 - val_fp0.3: 615833.0000 - val_tn0.3: 19098952.0000 - val_fn0.3: 863129.0000 - val_precision0.3: 0.7930 - val_recall0.3: 0.7322 - val_tp0.5: 2162836.0000 - val_fp0.5: 338503.0000 - val_tn0.5: 19376288.0000
       - val_fn0.5: 1059981.0000 - val_precision0.5: 0.8647 - val_recall0.5: 0.6711 - val_tp0.7: 2003919.0000 - val_fp0.7: 183329.0000 - val_tn0.7: 19531448.0000 - val_fn0.7: 1218898.0000 - val_precision0.7: 0.9162 - val_recall0.7: 0.6218 - v
       al_tp0.9: 1720409.0000 - val_fp0.9: 53022.0000 - val_tn0.9: 19661768.0000 - val_fn0.9: 1502408.0000 - val_precision0.9: 0.9701 - val_recall0.9: 0.5338 - val_accuracy: 0.9390 - val_auc: 0.9277
       600/600 [==============================] - 263s 436ms/step - loss: 0.4385 - tp0.1: 6822315.0000 - fp0.1: 4156365.0000 - tn0.1: 37439400.0000 - fn0.1: 733918.0000 - precision0.1: 0.6214 - recall0.1: 0.9029 - tp0.3: 5793366.0000 - fp0.3:
        1249890.0000 - tn0.3: 40345904.0000 - fn0.3: 1762867.0000 - precision0.3: 0.8225 - recall0.3: 0.7667 - tp0.5: 5327038.0000 - fp0.5: 712493.0000 - tn0.5: 40883252.0000 - fn0.5: 2229195.0000 - precision0.5: 0.8820 - recall0.5: 0.7050 -
       tp0.7: 4950945.0000 - fp0.7: 398350.0000 - tn0.7: 41197388.0000 - fn0.7: 2605288.0000 - precision0.7: 0.9255 - recall0.7: 0.6552 - tp0.9: 4264207.0000 - fp0.9: 117300.0000 - tn0.9: 41478476.0000 - fn0.9: 3292026.0000 - precision0.9: 0.
       9732 - recall0.9: 0.5643 - accuracy: 0.9402 - auc: 0.9398
       2021-07-22 02:07:55.612952: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       2021/07/22 02:08:13 INFO mlflow.projects: === Run (ID 'fbba032b341f4547b686023edba3c6c2') succeeded ===
     #+end_example

*** installing tf-nightly-gpu

**** using packages
     - we can use =tf-nightly= with Tensorflow 2.7.0, Python 3.9.X, ...
**** tmux gpu node
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       cd /
       srun -p gpu_a100 --time=1-10:00:00 --ntasks-per-node=24 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (base) [ye53nis@node131 ~]$ module avail

       ----------------------------------------------------------------------------------------------------- /usr/share/Modules/modulefiles ------------------------------------------------------------------------------------------------------
       dot         module-git  module-info modules     null        use.own

       ------------------------------------------------------------------------------------------------------------ /etc/modulefiles -------------------------------------------------------------------------------------------------------------
       mpi/mvapich2-2.2-psm2-x86_64 mpi/openmpi-x86_64

       ---------------------------------------------------------------------------------------------------------- /cluster/modulefiles -----------------------------------------------------------------------------------------------------------
       apps/adf/2019.301                                 compiler/gcc/7.3.0                                libs/lapack/intel-2018                            tools/cmake/3.11.3
       apps/bagel/1.1.2                                  compiler/gcc/8.1.0                                libs/libxc/3.0.0-intel-2018                       tools/cmake/3.15.3
       apps/gromacs/2016.5                               compiler/gcc/9.3.0                                libs/scalapack/intel-2018                         tools/gnuplot/5.2.2
       apps/mathematica/11.3                             compiler/intel/2017-Update7                       libs/szip/2.1.1-intel-2018                        tools/gpaw/20.1
       apps/mathematica/12.0                             compiler/intel/2018-Update1                       libs/zlib/1.2.11-intel-2018                       tools/gpaw/21.1
       apps/matlab/R2018a                                compiler/intel/2018-Update2                       mpi/intel/2017-Update7                            tools/gpaw/21.6
       apps/matlab/R2018b                                compiler/intel/2018-Update3                       mpi/intel/2018-Update1                            tools/jdk/8u172-b11-gcc-8.1.0
       apps/matlab/R2019a                                compiler/intel/2019-Update3                       mpi/intel/2018-Update2                            tools/julia/1.0.5
       apps/matlab/R2020b                                compiler/intel/2019-Update5                       mpi/intel/2018-Update3                            tools/julia/1.4.0
       apps/meep/1.3-openmpi-parallelhdf5                compiler/intel/2020-Update2                       mpi/intel/2019-Update3                            tools/julia/1.5.2
       apps/meep/1.6-intelmpi-serialhdf5                 compiler/pgi/2019                                 mpi/intel/2019-Update5                            tools/miniconda3/py37
       apps/meep/1.6-openmpi-parallelhdf5                compiler/pgi/2020                                 mpi/intel/2020-Update2                            tools/miniconda3/py38
       apps/meep/1.6-openmpi-serialhdf5                  libs/blas/intel-2018                              mpi/openmpi/2.1.3-gcc-7.3.0                       tools/octave/4.4.1-openblas
       apps/metashape/1.5.1                              libs/boost/1.67.0                                 mpi/openmpi/3.0.1-gcc-7.3.0                       tools/octopus/10.1
       apps/molcas/8.2                                   libs/boost/1.67.0-intel-2018                      mpi/openmpi/3.1.0-gcc-4.8.5                       tools/octopus/7.3-gcc-8.1.0
       apps/molpro/2019.2                                libs/boost/1.75.0-gcc-10.2.0                      mpi/openmpi/3.1.0-gcc-7.3.0                       tools/octopus/8.4
       apps/mpb/1.6.2-openmpi-parallelhdf5               libs/fftw/3.3.7-gcc-7.3.0                         mpi/openmpi/3.1.0-gcc-8.1.0                       tools/octopus/9.1
       apps/NWChem/6.8                                   libs/fftw/3.3.7-gcc-7.3.0+mpi                     mpi/openmpi/3.1.2-gcc-7.3.0                       tools/octopus/9.2
       apps/orca/4.2.1                                   libs/fftw/3.3.7-gcc-7.3.0-openmpi-3.0.1-gcc-7.3.0 mpi/openmpi/4.0.5-gcc-10.2.0                      tools/petsc/3.12
       apps/QuantumATK/R-2020.09                         libs/fftw/3.3.7-gcc-8.1.0                         nvidia/cuda/10                                    tools/python/2.7
       apps/salmon/1.2.1                                 libs/fftw/3.3.7-gcc-8.1.0-openmpi-3.1.0-gcc-8.1.0 nvidia/cuda/10.1.168                              tools/python/3.6
       apps/sharc/2.0                                    libs/fftw/3.3.7-intel-2018                        nvidia/cuda/11                                    tools/python/3.7
       apps/sharc/2.1                                    libs/fftw/3.3.7-intel-2019                        nvidia/cuda/11.2                                  tools/python/3.8
       apps/siesta/4.1-b3                                libs/gsl/2.4-intel-2018                           nvidia/cuda/11.3                                  tools/R/3.6.1
       apps/turbomole/7.3                                libs/hdf5/1.10.1-gcc-7.3.0                        nvidia/cuda/9                                     tools/singularity/3.7.0
       apps/turbomole/7.4                                libs/hdf5/1.10.1-gcc-8.1.0                        nvidia/cudnn/7.5.1.10                             tools/swig/3.0.12
       apps/turbomole/7.4.1                              libs/hdf5/1.10.1-intel-2018                       nvidia/cudnn/8                                    tools/swig/4.0.2
       apps/turbomole/7.5                                libs/hdf5/1.10.2-gcc-7.3.0                        tools/ase/3.19                                    tools/tensorflow/1.8.0
       apps/turbomole/7.5.1                              libs/hdf5/1.10.2-intel-2018                       tools/bazel/0.11.1-gcc-4.8.5                      tools/totalview/2018.3
       apps/visit                                        libs/hwlock/1.11.9-gcc-8.1.0                      tools/bazel/0.11.1-gcc-7.3.0
       compiler/gcc/10.2.0                               libs/hwlock/1.11.9-intel-2018                     tools/bazel/0.13.0-gcc-8.1.0
       (base) [ye53nis@node131 ~]$
     #+end_example

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       module load nvidia/cuda/11.2
       module load nvidia/cudnn/8.1
       module list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (base) [ye53nis@node131 /]$ module list
       Currently Loaded Modulefiles:
         1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
       (base) [ye53nis@node131 /]$
     #+end_example

**** start jupyter

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       conda activate tf-nightly
       export PORT=9998
       export XDG_RUNTIME_DIR=''
       export XDG_RUNTIME_DIR=""
       jupyter lab --no-browser --port=$PORT
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf-nightly) [ye53nis@node131 /]$ jupyter lab --no-browser --port=$PORT
       [I 2021-07-22 10:16:38.870 ServerApp] jupyterlab | extension was successfully linked.
       [I 2021-07-22 10:16:41.888 ServerApp] nbclassic | extension was successfully linked.
       [I 2021-07-22 10:16:42.219 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/jupyterlab
       [I 2021-07-22 10:16:42.219 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf-nightly/share/jupyter/lab
       [I 2021-07-22 10:16:42.242 ServerApp] jupyterlab | extension was successfully loaded.
       [I 2021-07-22 10:16:42.344 ServerApp] nbclassic | extension was successfully loaded.
       [I 2021-07-22 10:16:42.344 ServerApp] Serving notebooks from local directory: /
       [I 2021-07-22 10:16:42.344 ServerApp] Jupyter Server 1.4.1 is running at:
       [I 2021-07-22 10:16:42.345 ServerApp] http://localhost:9998/lab?token=b443461269837bdab99581376f62cea97f30e28cfc76c1d5
       [I 2021-07-22 10:16:42.345 ServerApp]  or http://127.0.0.1:9998/lab?token=b443461269837bdab99581376f62cea97f30e28cfc76c1d5
       [I 2021-07-22 10:16:42.345 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
       [C 2021-07-22 10:16:42.368 ServerApp]

           To access the server, open this file in a browser:
               file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-41965-open.html
           Or copy and paste one of these URLs:
               http://localhost:9998/lab?token=b443461269837bdab99581376f62cea97f30e28cfc76c1d5
            or http://127.0.0.1:9998/lab?token=b443461269837bdab99581376f62cea97f30e28cfc76c1d5
       [W 2021-07-22 10:17:29.347 LabApp] Could not determine jupyterlab build status without nodejs
       [I 2021-07-22 10:18:08.766 ServerApp] Kernel started: 41f10cb2-6c0d-4fd5-b3b6-92f0fa588535
       [I 2021-07-22 10:20:08.289 ServerApp] Saving file at /home/ye53nis/DOKTOR/DR-2-Training pipeline for first artefact - slowly diffusing clusters.ipynb
       [I 2021-07-22 10:22:13.518 ServerApp] Saving file at /home/ye53nis/DOKTOR/DR-2-Training pipeline for first artefact - slowly diffusing clusters.ipynb
       2021-07-22 10:22:19.254772: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-07-22 10:22:19.801241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1504] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38434 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:02:00.0, compu
       te capability: 8.0
       2021-07-22 10:22:46.040140: I tensorflow/stream_executor/cuda/cuda_dnn.cc:365] Loaded cuDNN version 8101
       [I 2021-07-22 10:24:18.775 ServerApp] Saving file at /home/ye53nis/DOKTOR/DR-2-Training pipeline for first artefact - slowly diffusing clusters.ipynb
       [I 2021-07-22 11:10:22.878 ServerApp] Saving file at /home/ye53nis/DOKTOR/DR-2-Training pipeline for first artefact - slowly diffusing clusters.ipynb
       [W 2021-07-22 11:39:05.366 ServerApp] Forbidden
       [W 2021-07-22 11:39:05.367 ServerApp] 403 GET /api/kernelspecs (127.0.0.1) 1.76ms referer=None
#+end_example

     #+CALL: ssh-tunnel[:session org-tunnel-gpu](port="9998", node="node131")

     #+RESULTS:
     |                   |           |                                        |           |         |          |            |           |             |           |
     | sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |         |          |            |           |             |           |
     | channel           | 3:        | open                                   | failed:   | connect | failed:  | Connection | refused |             |           |
     | ye53nis@node131's | password: | channel                                | 3:        | open    | failed:  | connect    | failed:   | Connection  | refused |
     |                   |           |                                        |           |         |          |            |           |             |           |
     | Last              | login:    | Thu                                    | Jul       | 22      | 00:11:00 | 2021       | from      | login01.ara |           |

**** testing tensorflow gpu acceleration
     :PROPERTIES:
     :header-args:jupyter-python: :session /jpy:localhost#9998:a37e524a-8134-4d8f-b24a-367acaf1bdd3
     :END:

     #+BEGIN_SRC jupyter-python
       %cd /beegfs/ye53nis/drmed-git
       %conda list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       /beegfs/ye53nis/drmed-git
       # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       _openmp_mutex             4.5                       1_gnu
       absl-py                   0.13.0                   pypi_0    pypi
       alembic                   1.4.1                    pypi_0    pypi
       anyio                     2.2.0            py39h06a4308_1
       argon2-cffi               20.1.0           py39h27cfd23_1
       asteval                   0.9.25                   pypi_0    pypi
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10               pyhd3eb1b0_0
       attrs                     21.2.0             pyhd3eb1b0_0
       babel                     2.9.1              pyhd3eb1b0_0
       backcall                  0.2.0              pyhd3eb1b0_0
       bleach                    3.3.1              pyhd3eb1b0_0
       brotlipy                  0.7.0           py39h27cfd23_1003
       ca-certificates           2021.7.5             h06a4308_1
       cachetools                4.2.2                    pypi_0    pypi
       certifi                   2021.5.30        py39h06a4308_0
       cffi                      1.14.6           py39h400218f_0
       chardet                   4.0.0           py39h06a4308_1003
       click                     8.0.1                    pypi_0    pypi
       cloudpickle               1.6.0                    pypi_0    pypi
       cryptography              3.4.7            py39hd23ed53_0
       cycler                    0.10.0                   pypi_0    pypi
       databricks-cli            0.14.3                   pypi_0    pypi
       decorator                 5.0.9              pyhd3eb1b0_0
       defusedxml                0.7.1              pyhd3eb1b0_0
       docker                    5.0.0                    pypi_0    pypi
       entrypoints               0.3              py39h06a4308_0
       fcsfiles                  2021.6.6                 pypi_0    pypi
       flask                     2.0.1                    pypi_0    pypi
       flatbuffers               1.12                     pypi_0    pypi
       future                    0.18.2                   pypi_0    pypi
       gast                      0.4.0                    pypi_0    pypi
       gitdb                     4.0.7                    pypi_0    pypi
       gitpython                 3.1.18                   pypi_0    pypi
       google-auth               1.33.0                   pypi_0    pypi
       google-auth-oauthlib      0.4.4                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       greenlet                  1.1.0                    pypi_0    pypi
       grpcio                    1.38.1                   pypi_0    pypi
       gunicorn                  20.1.0                   pypi_0    pypi
       h5py                      3.1.0                    pypi_0    pypi
       idna                      2.10               pyhd3eb1b0_0
       importlib-metadata        3.10.0           py39h06a4308_0
       importlib_metadata        3.10.0               hd3eb1b0_0
       ipykernel                 5.3.4            py39hb070fc8_0
       ipython                   7.22.0           py39hb070fc8_0
       ipython_genutils          0.2.0              pyhd3eb1b0_1
       itsdangerous              2.0.1                    pypi_0    pypi
       jedi                      0.17.2           py39h06a4308_1
       jinja2                    3.0.1              pyhd3eb1b0_0
       joblib                    1.0.1                    pypi_0    pypi
       json5                     0.9.6              pyhd3eb1b0_0
       jsonschema                3.2.0                      py_2
       jupyter-packaging         0.7.12             pyhd3eb1b0_0
       jupyter_client            6.1.12             pyhd3eb1b0_0
       jupyter_core              4.7.1            py39h06a4308_0
       jupyter_server            1.4.1            py39h06a4308_0
       jupyterlab                3.0.14             pyhd3eb1b0_1
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         2.6.1              pyhd3eb1b0_0
       keras-nightly             2.7.0.dev2021071300          pypi_0    pypi
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.1                    pypi_0    pypi
       ld_impl_linux-64          2.35.1               h7274673_9
       libclang                  11.1.0                   pypi_0    pypi
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.3.0               h5101ec6_17
       libgomp                   9.3.0               h5101ec6_17
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.3.0               hd4cf53a_17
       lmfit                     1.0.2                    pypi_0    pypi
       mako                      1.1.4                    pypi_0    pypi
       markdown                  3.3.4                    pypi_0    pypi
       markupsafe                2.0.1            py39h27cfd23_0
       matplotlib                3.4.2                    pypi_0    pypi
       mistune                   0.8.4           py39h27cfd23_1000
       mlflow                    1.19.0                   pypi_0    pypi
       multipletau               0.3.3                    pypi_0    pypi
       nbclassic                 0.2.6              pyhd3eb1b0_0
       nbclient                  0.5.3              pyhd3eb1b0_0
       nbconvert                 6.1.0            py39h06a4308_0
       nbformat                  5.1.3              pyhd3eb1b0_0
       ncurses                   6.2                  he6710b0_1
       nest-asyncio              1.5.1              pyhd3eb1b0_0
       notebook                  6.4.0            py39h06a4308_0
       numpy                     1.19.5                   pypi_0    pypi
       oauthlib                  3.1.1                    pypi_0    pypi
       openssl                   1.1.1k               h27cfd23_0
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 21.0               pyhd3eb1b0_0
       pandas                    1.3.0                    pypi_0    pypi
       pandocfilters             1.4.3            py39h06a4308_1
       parso                     0.7.0                      py_0
       pexpect                   4.8.0              pyhd3eb1b0_3
       pickleshare               0.7.5           pyhd3eb1b0_1003
       pillow                    8.3.1                    pypi_0    pypi
       pip                       21.1.3           py39h06a4308_0
       prometheus-flask-exporter 0.18.2                   pypi_0    pypi
       prometheus_client         0.11.0             pyhd3eb1b0_0
       prompt-toolkit            3.0.17             pyh06a4308_0
       protobuf                  3.17.3                   pypi_0    pypi
       ptyprocess                0.7.0              pyhd3eb1b0_2
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.20                       py_2
       pygments                  2.9.0              pyhd3eb1b0_0
       pyopenssl                 20.0.1             pyhd3eb1b0_1
       pyparsing                 2.4.7              pyhd3eb1b0_0
       pyrsistent                0.18.0           py39h7f8727e_0
       pysocks                   1.7.1            py39h06a4308_0
       python                    3.9.5                h12debd9_4
       python-dateutil           2.8.2              pyhd3eb1b0_0
       python-editor             1.0.4                    pypi_0    pypi
       pytz                      2021.1             pyhd3eb1b0_0
       pyyaml                    5.4.1                    pypi_0    pypi
       pyzmq                     20.0.0           py39h2531618_1
       querystring-parser        1.2.4                    pypi_0    pypi
       readline                  8.1                  h27cfd23_0
       requests                  2.25.1             pyhd3eb1b0_0
       requests-oauthlib         1.3.0                    pypi_0    pypi
       rsa                       4.7.2                    pypi_0    pypi
       scikit-learn              0.24.2                   pypi_0    pypi
       scipy                     1.7.0                    pypi_0    pypi
       seaborn                   0.11.1                   pypi_0    pypi
       send2trash                1.5.0              pyhd3eb1b0_1
       setuptools                52.0.0           py39h06a4308_0
       six                       1.15.0                   pypi_0    pypi
       smmap                     4.0.0                    pypi_0    pypi
       sniffio                   1.2.0            py39h06a4308_1
       sqlalchemy                1.4.21                   pypi_0    pypi
       sqlite                    3.36.0               hc218d9a_0
       sqlparse                  0.4.1                    pypi_0    pypi
       tabulate                  0.8.9                    pypi_0    pypi
       tb-nightly                2.6.0a20210720           pypi_0    pypi
       tensorboard-data-server   0.6.1                    pypi_0    pypi
       tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.4            py39h06a4308_0
       testpath                  0.5.0              pyhd3eb1b0_0
       tf-estimator-nightly      2.7.0.dev2021072001          pypi_0    pypi
       tf-nightly                2.7.0.dev20210720          pypi_0    pypi
       threadpoolctl             2.2.0                    pypi_0    pypi
       tifffile                  2021.7.2                 pypi_0    pypi
       tk                        8.6.10               hbc83047_0
       tornado                   6.1              py39h27cfd23_0
       traitlets                 5.0.5              pyhd3eb1b0_0
       typing-extensions         3.7.4.3                  pypi_0    pypi
       tzdata                    2021a                h52ac0ba_0
       uncertainties             3.1.6                    pypi_0    pypi
       urllib3                   1.26.6             pyhd3eb1b0_1
       wcwidth                   0.2.5                      py_0
       webencodings              0.5.1            py39h06a4308_1
       websocket-client          1.1.0                    pypi_0    pypi
       werkzeug                  2.0.1                    pypi_0    pypi
       wheel                     0.36.2             pyhd3eb1b0_0
       wrapt                     1.12.1                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       zeromq                    4.3.4                h2531618_0
       zipp                      3.5.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7b6447c_3
       Note: you may need to restart the kernel to use updated packages.
     #+end_example

     With =nvcc= we can check which *driver* of the NVIDIA graphics card was
     installed. It also tells us which cuda version the driver needs
     #+BEGIN_SRC jupyter-python
       !nvcc -V
     #+END_SRC

     #+RESULTS:
     : nvcc: NVIDIA (R) Cuda compiler driver
     : Copyright (c) 2005-2020 NVIDIA Corporation
     : Built on Mon_Nov_30_19:08:53_PST_2020
     : Cuda compilation tools, release 11.2, V11.2.67
     : Build cuda_11.2.r11.2/compiler.29373293_0

     #+BEGIN_SRC jupyter-python
       import sys

       import numpy as np
       import tensorflow as tf
       import tensorflow.python.platform.build_info as build

       FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
       sys.path.append(FLUOTRACIFY_PATH)

       if True:  # isort workaround
           from fluotracify.simulations import import_simulation_from_csv as isfc
           from fluotracify.training import build_model as bm, preprocess_data as ppd
           from fluotracify.training import evaluate

       print("Python version: ", sys.version)
       print("Tensorflow GPU version: ", tf.__version__)
       print("tf.keras version:", tf.keras.__version__)
       print('GPUs available: ', tf.config.list_physical_devices('GPU'))
       print('Cudnn version: ', build.build_info['cudnn_version'])
       print('Cuda version: ', build.build_info['cuda_version'])
     #+END_SRC

     #+RESULTS:
     : Python version:  3.9.5 (default, Jun  4 2021, 12:28:51)
     : [GCC 7.5.0]
     : Tensorflow GPU version:  2.7.0-dev20210720
     : tf.keras version: 2.7.0
     : GPUs available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
     : Cudnn version:  8
     : Cuda version:  11.2

     #+BEGIN_SRC jupyter-python
       BATCH_SIZE = 5
       FRAC_VAL = 0.2
       LENGTH_DELIMITER = 2**14
       LEARNING_RATE = 1e-5
       EPOCHS = 2
       CSV_PATH = '/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/'
       COL_PER_EXAMPLE = 3
       LOG_DIR_TB = "/tmp/tb"
       METRICS_THRESHOLDS = [0.1, 0.3, 0.5, 0.7, 0.9]
     #+END_SRC

     #+RESULTS:

     #+BEGIN_SRC jupyter-python
       train, test, nsamples, experiment_params = isfc.import_from_csv(
           folder=CSV_PATH,
           header=12,
           frac_train=1-FRAC_VAL,
           col_per_example=COL_PER_EXAMPLE,
           dropindex=None,
           dropcolumns=None)

       train_sep = isfc.separate_data_and_labels(
           array=train,
           nsamples=nsamples,
           col_per_example=COL_PER_EXAMPLE)

       test_sep = isfc.separate_data_and_labels(
           array=test,
           nsamples=nsamples,
           col_per_example=COL_PER_EXAMPLE)

       # '0': trace with artifact
       # '1': just the simulated artifact (label for unet)
       # '2': whole trace without artifact (label for vae)

       train_data = train_sep['0']
       train_labels = train_sep['1']
       train_labels_bool = train_labels > 0.04

       test_data = test_sep['0']
       test_labels = test_sep['1']
       test_labels_bool = test_labels > 0.04
     #+END_SRC

     #+RESULTS:
     #+begin_example
       train 0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       train 1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       train 2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       train 3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       train 4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       train 5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       train 6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       train 7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       train 8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       train 9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csvtrain 10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       train 11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       train 12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       train 13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       train 14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       train 15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       train 16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       train 17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       train 18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       train 19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       train 20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       train 21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       test 22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       test 23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       test 24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       test 25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       test 26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       test 27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2200), (16384, 2200), (16384, 2200)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 600), (16384, 600), (16384, 600)]
     #+end_example


     #+BEGIN_SRC jupyter-python
       dataset_train, dataset_val, num_train_examples, num_val_examples = ppd.tfds_from_pddf(
           features_df=train_data,
           labels_df=train_labels_bool,
           frac_val=FRAC_VAL)

       dataset_test, num_test_examples = ppd.tfds_from_pddf(
           features_df=test_data,
           labels_df=test_labels_bool,
           frac_val=False)
     #+END_SRC

     #+RESULTS:
     : number of training examples: 1760, number of validation examples: 440
     :
     : ------------------------
     : number of test examples: 600
     :


     #+BEGIN_SRC jupyter-python
       scaler = 'robust'
       ds_train_prep = dataset_train.map(lambda trace, label: ppd.tf_crop_trace(trace, label, LENGTH_DELIMITER),
                                         num_parallel_calls=tf.data.AUTOTUNE)
       ds_train_prep = ds_train_prep.map(lambda trace, label: ppd.tf_scale_trace(trace, label, scaler),
                                         num_parallel_calls=tf.data.AUTOTUNE)
       ds_train_prep = ds_train_prep.shuffle(buffer_size=num_train_examples).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

       ds_val_prep = dataset_val.map(lambda trace, label: ppd.tf_crop_trace(trace, label, LENGTH_DELIMITER),
                                     num_parallel_calls=tf.data.AUTOTUNE)
       ds_val_prep = ds_val_prep.map(lambda trace, label: ppd.tf_scale_trace(trace, label, scaler),
                                     num_parallel_calls=tf.data.AUTOTUNE)
       ds_val_prep = ds_val_prep.shuffle(buffer_size=num_val_examples).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

       ds_test_prep = dataset_test.map(lambda trace, label: ppd.tf_crop_trace(trace, label, LENGTH_DELIMITER),
                                       num_parallel_calls=tf.data.AUTOTUNE)
       ds_test_prep = ds_test_prep.map(lambda trace, label: ppd.tf_scale_trace(trace, label, scaler),
                                       num_parallel_calls=tf.data.AUTOTUNE)
       ds_test_prep = ds_test_prep.batch(BATCH_SIZE)
     #+END_SRC

     #+RESULTS:


     #+BEGIN_SRC jupyter-python
       for trace, label in dataset_train.take(1):
           ppd.show_trace(trace, label)

       for trace, label in ds_train_prep.unbatch().take(1):
           ppd.show_trace(trace, label)
     #+END_SRC

     #+RESULTS:
     [[file:./.ob-jupyter/dba191efb2280acf0c801ef384b00f12d301edf4.png]]
     [[file:./.ob-jupyter/85c48986e123108780dcc8a11e0c568c8a3fc633.png]]


     #+BEGIN_SRC jupyter-python
       model = bm.unet_1d_alt2(input_size=LENGTH_DELIMITER,
                               n_levels=9,
                               first_filters=64,
                               pool_size=2)
       optimizer = tf.keras.optimizers.Adam()
       loss = bm.binary_ce_dice_loss()
       metrics = bm.unet_metrics(METRICS_THRESHOLDS)
       model.compile(loss=loss, optimizer=optimizer, metrics=metrics)
       model.summary()
     #+END_SRC

     #+RESULTS:
     #+begin_example
       input - shape:	 (None, 16384, 1)
       output - shape:	 (None, 16384, 1)
       Model: "unet_depth9"
       __________________________________________________________________________________________________
       Layer (type)                    Output Shape         Param #     Connected to
       ==================================================================================================
       input_3 (InputLayer)            [(None, 16384, 1)]   0           []
       __________________________________________________________________________________________________
       encode0 (Sequential)            (None, 16384, 64)    13120       ['input_3[0][0]']
       __________________________________________________________________________________________________
       mp_encode0 (MaxPooling1D)       (None, 8192, 64)     0           ['encode0[0][0]']
       __________________________________________________________________________________________________
       encode1 (Sequential)            (None, 8192, 128)    75008       ['mp_encode0[0][0]']
       __________________________________________________________________________________________________
       mp_encode1 (MaxPooling1D)       (None, 4096, 128)    0           ['encode1[0][0]']
       __________________________________________________________________________________________________
       encode2 (Sequential)            (None, 4096, 256)    297472      ['mp_encode1[0][0]']
       __________________________________________________________________________________________________
       mp_encode2 (MaxPooling1D)       (None, 2048, 256)    0           ['encode2[0][0]']
       __________________________________________________________________________________________________
       encode3 (Sequential)            (None, 2048, 512)    1184768     ['mp_encode2[0][0]']
       __________________________________________________________________________________________________
       mp_encode3 (MaxPooling1D)       (None, 1024, 512)    0           ['encode3[0][0]']
       __________________________________________________________________________________________________
       encode4 (Sequential)            (None, 1024, 512)    1577984     ['mp_encode3[0][0]']
       __________________________________________________________________________________________________
       mp_encode4 (MaxPooling1D)       (None, 512, 512)     0           ['encode4[0][0]']
       __________________________________________________________________________________________________
       encode5 (Sequential)            (None, 512, 512)     1577984     ['mp_encode4[0][0]']
       __________________________________________________________________________________________________
       mp_encode5 (MaxPooling1D)       (None, 256, 512)     0           ['encode5[0][0]']
       __________________________________________________________________________________________________
       encode6 (Sequential)            (None, 256, 512)     1577984     ['mp_encode5[0][0]']
       __________________________________________________________________________________________________
       mp_encode6 (MaxPooling1D)       (None, 128, 512)     0           ['encode6[0][0]']
       __________________________________________________________________________________________________
       encode7 (Sequential)            (None, 128, 512)     1577984     ['mp_encode6[0][0]']
       __________________________________________________________________________________________________
       mp_encode7 (MaxPooling1D)       (None, 64, 512)      0           ['encode7[0][0]']
       __________________________________________________________________________________________________
       encode8 (Sequential)            (None, 64, 512)      1577984     ['mp_encode7[0][0]']
       __________________________________________________________________________________________________
       mp_encode8 (MaxPooling1D)       (None, 32, 512)      0           ['encode8[0][0]']
       __________________________________________________________________________________________________
       two_conv_center (Sequential)    (None, 32, 1024)     4728832     ['mp_encode8[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder8 (Seque  (None, 64, 512)      1051136     ['two_conv_center[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder8 (Concatenate)          (None, 64, 1024)     0           ['encode8[0][0]',
                                                                         'conv_transpose_decoder8[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder8 (Sequential)  (None, 64, 512)      2364416     ['decoder8[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder7 (Seque  (None, 128, 512)     526848      ['two_conv_decoder8[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder7 (Concatenate)          (None, 128, 1024)    0           ['encode7[0][0]',
                                                                         'conv_transpose_decoder7[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder7 (Sequential)  (None, 128, 512)     2364416     ['decoder7[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder6 (Seque  (None, 256, 512)     526848      ['two_conv_decoder7[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder6 (Concatenate)          (None, 256, 1024)    0           ['encode6[0][0]',
                                                                         'conv_transpose_decoder6[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder6 (Sequential)  (None, 256, 512)     2364416     ['decoder6[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder5 (Seque  (None, 512, 512)     526848      ['two_conv_decoder6[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder5 (Concatenate)          (None, 512, 1024)    0           ['encode5[0][0]',
                                                                         'conv_transpose_decoder5[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder5 (Sequential)  (None, 512, 512)     2364416     ['decoder5[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder4 (Seque  (None, 1024, 512)    526848      ['two_conv_decoder5[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder4 (Concatenate)          (None, 1024, 1024)   0           ['encode4[0][0]',
                                                                         'conv_transpose_decoder4[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder4 (Sequential)  (None, 1024, 512)    2364416     ['decoder4[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder3 (Seque  (None, 2048, 512)    526848      ['two_conv_decoder4[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder3 (Concatenate)          (None, 2048, 1024)   0           ['encode3[0][0]',
                                                                         'conv_transpose_decoder3[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder3 (Sequential)  (None, 2048, 512)    2364416     ['decoder3[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder2 (Seque  (None, 4096, 512)    526848      ['two_conv_decoder3[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder2 (Concatenate)          (None, 4096, 768)    0           ['encode2[0][0]',
                                                                         'conv_transpose_decoder2[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder2 (Sequential)  (None, 4096, 512)    1971200     ['decoder2[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder1 (Seque  (None, 8192, 256)    263424      ['two_conv_decoder2[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder1 (Concatenate)          (None, 8192, 384)    0           ['encode1[0][0]',
                                                                         'conv_transpose_decoder1[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder1 (Sequential)  (None, 8192, 256)    494080      ['decoder1[0][0]']
       __________________________________________________________________________________________________
       conv_transpose_decoder0 (Seque  (None, 16384, 128)   66176       ['two_conv_decoder1[0][0]']
       ntial)
       __________________________________________________________________________________________________
       decoder0 (Concatenate)          (None, 16384, 192)   0           ['encode0[0][0]',
                                                                         'conv_transpose_decoder0[0][0]']
       __________________________________________________________________________________________________
       two_conv_decoder0 (Sequential)  (None, 16384, 128)   124160      ['decoder0[0][0]']
       __________________________________________________________________________________________________
       conv1d_116 (Conv1D)             (None, 16384, 1)     129         ['two_conv_decoder0[0][0]']
       ==================================================================================================
       Total params: 35,507,009
       Trainable params: 35,465,025
       Non-trainable params: 41,984
       __________________________________________________________________________________________________
     #+end_example


     #+BEGIN_SRC jupyter-python
       model.fit(
           x=ds_train_prep,
           epochs=EPOCHS,
           steps_per_epoch=1000,
           validation_data=ds_val_prep,
           validation_steps=400)
     #+END_SRC

     #+RESULTS:
     : Epoch 1/2
     : 1000/1000 [==============================] - 167s 147ms/step - loss: 0.7068 - tp0.1: 11117826.0000 - fp0.1: 16085887.0000 - tn0.1: 53414724.0000 - fn0.1: 1301569.0000 - precision0.1: 0.4087 - recall0.1: 0.8952 - tp0.3: 9243915.0000 - fp0.3: 5010995.0000 - tn0.3: 64489564.0000 - fn0.3: 3175480.0000 - precision0.3: 0.6485 - recall0.3: 0.7443 - tp0.5: 7972471.0000 - fp0.5: 1781436.0000 - tn0.5: 67719128.0000 - fn0.5: 4446924.0000 - precision0.5: 0.8174 - recall0.5: 0.6419 - tp0.7: 6956601.0000 - fp0.7: 638981.0000 - tn0.7: 68861648.0000 - fn0.7: 5462794.0000 - precision0.7: 0.9159 - recall0.7: 0.5601 - tp0.9: 5666895.0000 - fp0.9: 138059.0000 - tn0.9: 69362512.0000 - fn0.9: 6752500.0000 - precision0.9: 0.9762 - recall0.9: 0.4563 - accuracy: 0.9240 - auc: 0.9140 - val_loss: 0.7459 - val_tp0.1: 5378957.0000 - val_fp0.1: 4641425.0000 - val_tn0.1: 21921788.0000 - val_fn0.1: 825836.0000 - val_precision0.1: 0.5368 - val_recall0.1: 0.8669 - val_tp0.3: 4521282.0000 - val_fp0.3: 2115636.0000 - val_tn0.3: 24447584.0000 - val_fn0.3: 1683511.0000 - val_precision0.3: 0.6812 - val_recall0.3: 0.7287 - val_tp0.5: 3525960.0000 - val_fp0.5: 641140.0000 - val_tn0.5: 25922062.0000 - val_fn0.5: 2678833.0000 - val_precision0.5: 0.8461 - val_recall0.5: 0.5683 - val_tp0.7: 3026915.0000 - val_fp0.7: 236308.0000 - val_tn0.7: 26326900.0000 - val_fn0.7: 3177878.0000 - val_precision0.7: 0.9276 - val_recall0.7: 0.4878 - val_tp0.9: 2404828.0000 - val_fp0.9: 36983.0000 - val_tn0.9: 26526220.0000 - val_fn0.9: 3799965.0000 - val_precision0.9: 0.9849 - val_recall0.9: 0.3876 - val_accuracy: 0.8987 - val_auc: 0.8972
     : Epoch 2/2


     #+BEGIN_SRC jupyter-python
       print('test')
       model.evaluate(ds_test_prep,
                  steps=tf.math.ceil(num_test_examples / BATCH_SIZE))
     #+END_SRC

     #+RESULTS:
     :RESULTS:
     : test
120/120 [==============================] - 6s 46ms/step - loss: 0.5313 - tp0.1: 1372219.0000 - fp0.1: 1675187.0000 - tn0.1: 6691352.0000 - fn0.1: 91642.0000 - precision0.1: 0.4503 - recall0.1: 0.9374 - tp0.3: 1052791.0000 - fp0.3: 490979.0000 - tn0.3: 7875560.0000 - fn0.3: 411070.0000 - precision0.3: 0.6820 - recall0.3: 0.7192 - tp0.5: 879398.0000 - fp0.5: 208842.0000 - tn0.5: 8157697.0000 - fn0.5: 584463.0000 - precision0.5: 0.8081 - recall0.5: 0.6007 - tp0.7: 792815.0000 - fp0.7: 114806.0000 - tn0.7: 8251733.0000 - fn0.7: 671046.0000 - precision0.7: 0.8735 - recall0.7: 0.5416 - tp0.9: 683896.0000 - fp0.9: 45838.0000 - tn0.9: 8320701.0000 - fn0.9: 779965.0000 - precision0.9: 0.9372 - recall0.9: 0.4672 - accuracy: 0.9193 - auc: 0.9329
     | 0.5313019156455994 | 1372219.0 | 1675187.0 | 6691352.0 | 91642.0 | 0.45029082894325256 | 0.9373970627784729 | 1052791.0 | 490979.0 | 7875560.0 | 411070.0 | 0.6819610595703125 | 0.7191877961158752 | 879398.0 | 208842.0 | 8157697.0 | 584463.0 | 0.808091938495636 | 0.6007387042045593 | 792815.0 | 114806.0 | 8251733.0 | 671046.0 | 0.873508870601654 | 0.5415917038917542 | 683896.0 | 45838.0 | 8320701.0 | 779965.0 | 0.9371853470802307 | 0.46718642115592957 | 0.9193008542060852 | 0.93290776014328 |
     :END:

*** mlflow test with tf-nightly and gpu acceleration
**** metadata & connection
    - using =ob-tmux= for script execution
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        cd /beegfs/ye53nis/drmed-git/
        git status
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf-nightly) [ye53nis@node131 drmed-git]$ git status
        git log -3
        # On branch develop
        # Changes not staged for commit:
        #   (use "git add <file>..." to update what will be committed)
        #   (use "git checkout -- <file>..." to discard changes in working directory)
        #   (commit or discard the untracked or modified content in submodules)
        #
        #       modified:   src/nanosimpy (new commits, untracked content)
        #
        # Untracked files:
        #   (use "git add <file>..." to include in what will be committed)
        #
        #       .data/
        #       2021-03-20_correlations.csv
        #       data/0.069.svg
        #       data/exp-210204-unet/
        #       data/exp-devtest/
        #       data/exp-test/
        #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
        #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
        #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
        #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
        #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
        #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
        #       data/mlruns/0/52faa01e685f44ef97be4e64ddc88eb1/
        #       data/mlruns/0/5dc9fe4b91094df58e3d2f1426aa4d96/
        #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
        #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
        #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
        #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
        #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
        #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
        #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
        #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
        #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
        #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
        #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
        #       data/mlruns/2/
        #       data/mlruns/3/
        #       data/mlruns/4/
        #       data/tb/
        #       experiment_params.csv
        #       mlruns/
        #       tramp.YDPCnB
        no changes added to commit (use "git add" and/or "git commit -a")
        (tf-nightly) [ye53nis@node131 drmed-git]$ git log -3
        commit eab86a5b3ce4599bc2f22eee6bfb95c1605d9c51
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 23:25:56 2021 +0200

            fix model saving, adding another numpy()

        commit 3d914ad3b2cf66e71a8ec4789c86b89cbfcc38f9
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 22:16:08 2021 +0200

            Fix model saving by making tensor to numpy array

        commit ae070532902a6b18b3be446936ff3a634b92e06a
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 20 19:03:21 2021 +0200

            Fix error with frac_val=None

            TypeError: '<' not supported between instances of 'int' and 'NoneType'
        (tf-nightly) [ye53nis@node131 drmed-git]$
      #+end_example

**** mlflow environment variables

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       conda activate tf-nightly
       cd /beegfs/ye53nis/drmed-git
       export MLFLOW_EXPERIMENT_NAME=exp-210720-test
       export MLFLOW_TRACKING_URI=file:./data/mlruns
       mkdir data/exp-210720-test
     #+END_SRC

**** tmux gpu node
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       cd /
       srun -p gpu_a100 --time=1-10:00:00 --ntasks-per-node=24 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
     #+END_SRC

     #+RESULTS:
     #+begin_example
     (base) [ye53nis@node131 ~]$ module avail

       ----------------------------------------------------------------------------------------------------- /usr/share/Modules/modulefiles ------------------------------------------------------------------------------------------------------
       dot         module-git  module-info modules     null        use.own

       ------------------------------------------------------------------------------------------------------------ /etc/modulefiles -------------------------------------------------------------------------------------------------------------
       mpi/mvapich2-2.2-psm2-x86_64 mpi/openmpi-x86_64

       ---------------------------------------------------------------------------------------------------------- /cluster/modulefiles -----------------------------------------------------------------------------------------------------------
       apps/adf/2019.301                                 compiler/gcc/7.3.0                                libs/lapack/intel-2018                            tools/cmake/3.11.3
       apps/bagel/1.1.2                                  compiler/gcc/8.1.0                                libs/libxc/3.0.0-intel-2018                       tools/cmake/3.15.3
       apps/gromacs/2016.5                               compiler/gcc/9.3.0                                libs/scalapack/intel-2018                         tools/gnuplot/5.2.2
       apps/mathematica/11.3                             compiler/intel/2017-Update7                       libs/szip/2.1.1-intel-2018                        tools/gpaw/20.1
       apps/mathematica/12.0                             compiler/intel/2018-Update1                       libs/zlib/1.2.11-intel-2018                       tools/gpaw/21.1
       apps/matlab/R2018a                                compiler/intel/2018-Update2                       mpi/intel/2017-Update7                            tools/gpaw/21.6
       apps/matlab/R2018b                                compiler/intel/2018-Update3                       mpi/intel/2018-Update1                            tools/jdk/8u172-b11-gcc-8.1.0
       apps/matlab/R2019a                                compiler/intel/2019-Update3                       mpi/intel/2018-Update2                            tools/julia/1.0.5
       apps/matlab/R2020b                                compiler/intel/2019-Update5                       mpi/intel/2018-Update3                            tools/julia/1.4.0
       apps/meep/1.3-openmpi-parallelhdf5                compiler/intel/2020-Update2                       mpi/intel/2019-Update3                            tools/julia/1.5.2
       apps/meep/1.6-intelmpi-serialhdf5                 compiler/pgi/2019                                 mpi/intel/2019-Update5                            tools/miniconda3/py37
       apps/meep/1.6-openmpi-parallelhdf5                compiler/pgi/2020                                 mpi/intel/2020-Update2                            tools/miniconda3/py38
       apps/meep/1.6-openmpi-serialhdf5                  libs/blas/intel-2018                              mpi/openmpi/2.1.3-gcc-7.3.0                       tools/octave/4.4.1-openblas
       apps/metashape/1.5.1                              libs/boost/1.67.0                                 mpi/openmpi/3.0.1-gcc-7.3.0                       tools/octopus/10.1
       apps/molcas/8.2                                   libs/boost/1.67.0-intel-2018                      mpi/openmpi/3.1.0-gcc-4.8.5                       tools/octopus/7.3-gcc-8.1.0
       apps/molpro/2019.2                                libs/boost/1.75.0-gcc-10.2.0                      mpi/openmpi/3.1.0-gcc-7.3.0                       tools/octopus/8.4
       apps/mpb/1.6.2-openmpi-parallelhdf5               libs/fftw/3.3.7-gcc-7.3.0                         mpi/openmpi/3.1.0-gcc-8.1.0                       tools/octopus/9.1
       apps/NWChem/6.8                                   libs/fftw/3.3.7-gcc-7.3.0+mpi                     mpi/openmpi/3.1.2-gcc-7.3.0                       tools/octopus/9.2
       apps/orca/4.2.1                                   libs/fftw/3.3.7-gcc-7.3.0-openmpi-3.0.1-gcc-7.3.0 mpi/openmpi/4.0.5-gcc-10.2.0                      tools/petsc/3.12
       apps/QuantumATK/R-2020.09                         libs/fftw/3.3.7-gcc-8.1.0                         nvidia/cuda/10                                    tools/python/2.7
       apps/salmon/1.2.1                                 libs/fftw/3.3.7-gcc-8.1.0-openmpi-3.1.0-gcc-8.1.0 nvidia/cuda/10.1.168                              tools/python/3.6
       apps/sharc/2.0                                    libs/fftw/3.3.7-intel-2018                        nvidia/cuda/11                                    tools/python/3.7
       apps/sharc/2.1                                    libs/fftw/3.3.7-intel-2019                        nvidia/cuda/11.2                                  tools/python/3.8
       apps/siesta/4.1-b3                                libs/gsl/2.4-intel-2018                           nvidia/cuda/11.3                                  tools/R/3.6.1
       apps/turbomole/7.3                                libs/hdf5/1.10.1-gcc-7.3.0                        nvidia/cuda/9                                     tools/singularity/3.7.0
       apps/turbomole/7.4                                libs/hdf5/1.10.1-gcc-8.1.0                        nvidia/cudnn/7.5.1.10                             tools/swig/3.0.12
       apps/turbomole/7.4.1                              libs/hdf5/1.10.1-intel-2018                       nvidia/cudnn/8                                    tools/swig/4.0.2
       apps/turbomole/7.5                                libs/hdf5/1.10.2-gcc-7.3.0                        tools/ase/3.19                                    tools/tensorflow/1.8.0
       apps/turbomole/7.5.1                              libs/hdf5/1.10.2-intel-2018                       tools/bazel/0.11.1-gcc-4.8.5                      tools/totalview/2018.3
       apps/visit                                        libs/hwlock/1.11.9-gcc-8.1.0                      tools/bazel/0.11.1-gcc-7.3.0
       compiler/gcc/10.2.0                               libs/hwlock/1.11.9-intel-2018                     tools/bazel/0.13.0-gcc-8.1.0
       (base) [ye53nis@node131 ~]$
     #+end_example

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       module load nvidia/cuda/11.2
       module load nvidia/cudnn/8.1
       module list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (base) [ye53nis@node131 /]$ module list
       Currently Loaded Modulefiles:
         1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
       (base) [ye53nis@node131 /]$
     #+end_example


**** test run 3- trying new setup (robust, n_levels=5, first_filters=32) with gpu

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=10 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/beegfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='robust' -P n_levels=5 -P first_filters=32 -P steps_per_epoch=1120 -P validation_steps=280
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf-nightly) [ye53nis@node131 drmed-git]$ mlflow run . -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P epochs=10 -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_test=/b
       eegfs/ye53nis/saves/firstartifact_Nov2020_test -P scaler='robust' -P n_levels=5 -P first_filters=32 -P steps_per_epoch=1120 -P validation_steps=280
       2021/07/22 12:32:50 INFO mlflow.projects.utils: === Created directory /tmp/tmphcic88_f for downloading remote URIs passed to arguments of type 'path' ===
       2021/07/22 12:32:50 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef 1>&2 && python src/fluotracify/trai
       ning/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 5 --frac_val 0.2 --length_delimiter 16384 --learning_rate 0 --epochs 10 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path
       _test /beegfs/ye53nis/saves/firstartifact_Nov2020_test --col_per_example 3 --steps_per_epoch 1120 --validation_steps 280 --scaler robust --n_levels 5 --first_filters 32 --pool_size 2' in run with ID 'bbd8c3bbe6f54a2782317f3a062ea7d9' =
       ==
       2.7.0-dev20210720
       GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
       2021/07/22 12:33:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading
        MLflow.
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set010.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set002.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set005.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set005.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set007.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set002.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set001.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set009.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set002.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set005.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set008.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set005.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set008.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set005.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set006.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set005.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D50_set003.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set001.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set003.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D1.0_set005.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.2_set002.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.1_set002.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D3.0_set004.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.08_set001.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.069_set001.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D10_set001.csv
       28 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.6_set003.csv
       29 /beegfs/ye53nis/saves/firstartifact_Nov2020_test/traces_brightclust_Nov2020_D0.4_set001.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]

       for each 16384 timestap trace there are the following numbers of corrupted timesteps:
       label001_1    1916
       label002_1    1004
       label003_1    1476
       label004_1    1154
       label005_1    1454
       dtype: int64
       2021-07-22 12:37:42.824702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-07-22 12:37:43.823639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1504] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38434 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:02:00.0, compu
       te capability: 8.0
       number of training examples: 2240, number of validation examples: 560

       ------------------------
       number of test examples: 3000

       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       2021-07-22 12:37:47.913181: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
       2021-07-22 12:37:47.913219: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
       2021-07-22 12:37:47.913253: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs
       2021-07-22 12:37:48.326045: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
       2021-07-22 12:37:48.328952: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed
       2021/07/22 12:37:48 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='5' for run ID='bbd
       8c3bbe6f54a2782317f3a062ea7d9'. Attempted logging new value 'None'.
       Epoch 1/10
       2021-07-22 12:38:05.569966: I tensorflow/stream_executor/cuda/cuda_dnn.cc:365] Loaded cuDNN version 8101
          1/1120 [..............................] - ETA: 6:06:43 - loss: 1.5906 - tp0.1: 14186.0000 - fp0.1: 66740.0000 - tn0.1: 546.0000 - fn0.1: 448.0000 - precision0.1: 0.1753 - recall0.1: 0.9694 - tp0.3: 13017.0000 - fp0.3: 60642.0000 - t
       n0.3: 6644.0000 - fn0.3: 1617.0000 - precision0.3: 0.1767 - recall0.3: 0.8895 - tp0.5: 5943.0000 - fp0.5: 27598.0000 - tn0.5: 39688.0000 - fn0.5: 8691.0000 - precision0.5: 0.1772 - recall0.5: 0.4061 - tp0.7: 1755.0000 - fp0.7: 2749.000
       0 - tn0.7: 64537.0000 - fn0.7: 12879.0000 - precision0.7: 0.3897 - recall0.7: 0.1199 - tp0.9: 422.0000 - fp0.9: 93.0000 - tn0.9: 67193.0000 - fn0.9: 14212.0000 - precision0.9: 0.8194 - recall0.9: 0.0288 - accuracy: 0.5570 - auc: 0.5073
       2021-07-22 12:38:08.345385: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.
       2021-07-22 12:38:08.345458: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.
          2/1120 [..............................] - ETA: 20:17 - loss: 1.6802 - tp0.1: 16683.0000 - fp0.1: 73439.0000 - tn0.1: 62443.0000 - fn0.1: 11275.0000 - precision0.1: 0.1851 - recall0.1: 0.5967 - tp0.3: 13829.0000 - fp0.3: 62770.0000 -
        tn0.3: 73112.0000 - fn0.3: 14129.0000 - precision0.3: 0.1805 - recall0.3: 0.4946 - tp0.5: 5943.0000 - fp0.5: 27598.0000 - tn0.5: 108284.0000 - fn0.5: 22015.0000 - precision0.5: 0.1772 - recall0.5: 0.2126 - tp0.7: 1755.0000 - fp0.7: 27
       49.0000 - tn0.7: 133133.0000 - fn0.7: 26203.0000 - precision0.7: 0.3897 - recall0.7: 0.0628 - tp0.9: 422.0000 - fp0.9: 93.0000 - tn0.9: 135789.0000 - fn0.9: 27536.0000 - precision0.9: 0.8194 - recall0.9: 0.0151 - accuracy: 0.6972 - auc
       : 0.54302021-07-22 12:38:09.436664: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
       2021-07-22 12:38:09.438267: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed
       2021-07-22 12:38:09.533646: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2348 callback api events and 2309 activity events.
       2021-07-22 12:38:09.606475: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.
       2021-07-22 12:38:09.701231: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_22_12_38_09

       2021-07-22 12:38:09.756119: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.trace.json.gz
       2021-07-22 12:38:09.858008: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: /tmp/tb/train/plugins/profile/2021_07_22_12_38_09

       2021-07-22 12:38:09.867268: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.memory_profile.json.gz
       2021-07-22 12:38:09.870470: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/tb/train/plugins/profile/2021_07_22_12_38_09
       Dumped tool data for xplane.pb to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.xplane.pb
       Dumped tool data for overview_page.pb to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.overview_page.pb
       Dumped tool data for input_pipeline.pb to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.input_pipeline.pb
       Dumped tool data for tensorflow_stats.pb to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.tensorflow_stats.pb
       Dumped tool data for kernel_stats.pb to /tmp/tb/train/plugins/profile/2021_07_22_12_38_09/node131.kernel_stats.pb

       1120/1120 [==============================] - 123s 92ms/step - loss: 0.7528 - tp0.1: 13376810.0000 - fp0.1: 20325288.0000 - tn0.1: 56517316.0000 - fn0.1: 1530977.0000 - precision0.1: 0.3969 - recall0.1: 0.8973 - tp0.3: 10122115.0000 - f
       p0.3: 5701179.0000 - tn0.3: 71141440.0000 - fn0.3: 4785672.0000 - precision0.3: 0.6397 - recall0.3: 0.6790 - tp0.5: 8505022.0000 - fp0.5: 2192948.0000 - tn0.5: 74649648.0000 - fn0.5: 6402765.0000 - precision0.5: 0.7950 - recall0.5: 0.5
       705 - tp0.7: 7354243.0000 - fp0.7: 950792.0000 - tn0.7: 75891768.0000 - fn0.7: 7553544.0000 - precision0.7: 0.8855 - recall0.7: 0.4933 - tp0.9: 5864160.0000 - fp0.9: 258399.0000 - tn0.9: 76584160.0000 - fn0.9: 9043627.0000 - precision0
       .9: 0.9578 - recall0.9: 0.3934 - accuracy: 0.9063 - auc: 0.8950 - val_loss: 0.5754 - val_tp0.1: 2796697.0000 - val_fp0.1: 2629754.0000 - val_tn0.1: 17057760.0000 - val_fn0.1: 453391.0000 - val_precision0.1: 0.5154 - val_recall0.1: 0.86
       05 - val_tp0.3: 2768788.0000 - val_fp0.3: 2504748.0000 - val_tn0.3: 17182764.0000 - val_fn0.3: 481300.0000 - val_precision0.3: 0.5250 - val_recall0.3: 0.8519 - val_tp0.5: 1733100.0000 - val_fp0.5: 190903.0000 - val_tn0.5: 19496608.0000
        - val_fn0.5: 1516988.0000 - val_precision0.5: 0.9008 - val_recall0.5: 0.5332 - val_tp0.7: 1490011.0000 - val_fp0.7: 62595.0000 - val_tn0.7: 19624916.0000 - val_fn0.7: 1760077.0000 - val_precision0.7: 0.9597 - val_recall0.7: 0.4585 - v
       al_tp0.9: 1131005.0000 - val_fp0.9: 10807.0000 - val_tn0.9: 19676704.0000 - val_fn0.9: 2119083.0000 - val_precision0.9: 0.9905 - val_recall0.9: 0.3480 - val_accuracy: 0.9255 - val_auc: 0.9036
       Epoch 2/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.5999 - tp0.1: 13594732.0000 - fp0.1: 16729130.0000 - tn0.1: 60306072.0000 - fn0.1: 1120491.0000 - precision0.1: 0.4483 - recall0.1: 0.9239 - tp0.3: 10726816.0000 - fp
       0.3: 5810474.0000 - tn0.3: 71224728.0000 - fn0.3: 3988407.0000 - precision0.3: 0.6486 - recall0.3: 0.7290 - tp0.5: 9233291.0000 - fp0.5: 2164055.0000 - tn0.5: 74871128.0000 - fn0.5: 5481932.0000 - precision0.5: 0.8101 - recall0.5: 0.62
       75 - tp0.7: 8083895.0000 - fp0.7: 1005421.0000 - tn0.7: 76029800.0000 - fn0.7: 6631328.0000 - precision0.7: 0.8894 - recall0.7: 0.5494 - tp0.9: 6332060.0000 - fp0.9: 250993.0000 - tn0.9: 76784144.0000 - fn0.9: 8383163.0000 - precision0
       .9: 0.9619 - recall0.9: 0.4303 - accuracy: 0.9167 - auc: 0.9195 - val_loss: 0.5863 - val_tp0.1: 2772089.0000 - val_fp0.1: 2133541.0000 - val_tn0.1: 17553856.0000 - val_fn0.1: 478114.0000 - val_precision0.1: 0.5651 - val_recall0.1: 0.85
       29 - val_tp0.3: 2463898.0000 - val_fp0.3: 1368321.0000 - val_tn0.3: 18319080.0000 - val_fn0.3: 786305.0000 - val_precision0.3: 0.6429 - val_recall0.3: 0.7581 - val_tp0.5: 2302394.0000 - val_fp0.5: 1001983.0000 - val_tn0.5: 18685414.000
       0 - val_fn0.5: 947809.0000 - val_precision0.5: 0.6968 - val_recall0.5: 0.7084 - val_tp0.7: 2097249.0000 - val_fp0.7: 567290.0000 - val_tn0.7: 19120108.0000 - val_fn0.7: 1152954.0000 - val_precision0.7: 0.7871 - val_recall0.7: 0.6453 -
       val_tp0.9: 1769349.0000 - val_fp0.9: 158831.0000 - val_tn0.9: 19528568.0000 - val_fn0.9: 1480854.0000 - val_precision0.9: 0.9176 - val_recall0.9: 0.5444 - val_accuracy: 0.9150 - val_auc: 0.9040
       Epoch 3/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.4929 - tp0.1: 13849302.0000 - fp0.1: 13425233.0000 - tn0.1: 63464512.0000 - fn0.1: 1011404.0000 - precision0.1: 0.5078 - recall0.1: 0.9319 - tp0.3: 12152966.0000 - fp
       0.3: 4311523.0000 - tn0.3: 72578168.0000 - fn0.3: 2707740.0000 - precision0.3: 0.7381 - recall0.3: 0.8178 - tp0.5: 11214384.0000 - fp0.5: 2421186.0000 - tn0.5: 74468464.0000 - fn0.5: 3646322.0000 - precision0.5: 0.8224 - recall0.5: 0.7
       546 - tp0.7: 9795003.0000 - fp0.7: 1068420.0000 - tn0.7: 75821216.0000 - fn0.7: 5065703.0000 - precision0.7: 0.9016 - recall0.7: 0.6591 - tp0.9: 7420718.0000 - fp0.9: 184056.0000 - tn0.9: 76705632.0000 - fn0.9: 7439988.0000 - precision
       0.9: 0.9758 - recall0.9: 0.4994 - accuracy: 0.9339 - auc: 0.9426 - val_loss: 0.5206 - val_tp0.1: 3035113.0000 - val_fp0.1: 4182638.0000 - val_tn0.1: 15500679.0000 - val_fn0.1: 219170.0000 - val_precision0.1: 0.4205 - val_recall0.1: 0.9
       327 - val_tp0.3: 2731214.0000 - val_fp0.3: 2278099.0000 - val_tn0.3: 17405218.0000 - val_fn0.3: 523069.0000 - val_precision0.3: 0.5452 - val_recall0.3: 0.8393 - val_tp0.5: 2393529.0000 - val_fp0.5: 1240915.0000 - val_tn0.5: 18442400.00
       00 - val_fn0.5: 860754.0000 - val_precision0.5: 0.6586 - val_recall0.5: 0.7355 - val_tp0.7: 1872359.0000 - val_fp0.7: 197223.0000 - val_tn0.7: 19486092.0000 - val_fn0.7: 1381924.0000 - val_precision0.7: 0.9047 - val_recall0.7: 0.5754 -
        val_tp0.9: 1354824.0000 - val_fp0.9: 18919.0000 - val_tn0.9: 19664396.0000 - val_fn0.9: 1899459.0000 - val_precision0.9: 0.9862 - val_recall0.9: 0.4163 - val_accuracy: 0.9084 - val_auc: 0.9307
       Epoch 4/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.4629 - tp0.1: 13788168.0000 - fp0.1: 12664281.0000 - tn0.1: 64323824.0000 - fn0.1: 974136.0000 - precision0.1: 0.5212 - recall0.1: 0.9340 - tp0.3: 12312722.0000 - fp0
       .3: 4001708.0000 - tn0.3: 72986400.0000 - fn0.3: 2449582.0000 - precision0.3: 0.7547 - recall0.3: 0.8341 - tp0.5: 11585216.0000 - fp0.5: 2435290.0000 - tn0.5: 74552752.0000 - fn0.5: 3177088.0000 - precision0.5: 0.8263 - recall0.5: 0.78
       48 - tp0.7: 10153188.0000 - fp0.7: 1142168.0000 - tn0.7: 75845984.0000 - fn0.7: 4609116.0000 - precision0.7: 0.8989 - recall0.7: 0.6878 - tp0.9: 7683641.0000 - fp0.9: 207058.0000 - tn0.9: 76780960.0000 - fn0.9: 7078663.0000 - precision
       0.9: 0.9738 - recall0.9: 0.5205 - accuracy: 0.9388 - auc: 0.9467 - val_loss: 0.5216 - val_tp0.1: 3013701.0000 - val_fp0.1: 3235021.0000 - val_tn0.1: 16446430.0000 - val_fn0.1: 242448.0000 - val_precision0.1: 0.4823 - val_recall0.1: 0.9
       255 - val_tp0.3: 2842526.0000 - val_fp0.3: 2251160.0000 - val_tn0.3: 17430288.0000 - val_fn0.3: 413623.0000 - val_precision0.3: 0.5580 - val_recall0.3: 0.8730 - val_tp0.5: 2764500.0000 - val_fp0.5: 1842990.0000 - val_tn0.5: 17838462.00
       00 - val_fn0.5: 491649.0000 - val_precision0.5: 0.6000 - val_recall0.5: 0.8490 - val_tp0.7: 2653560.0000 - val_fp0.7: 1417062.0000 - val_tn0.7: 18264392.0000 - val_fn0.7: 602589.0000 - val_precision0.7: 0.6519 - val_recall0.7: 0.8149 -
        val_tp0.9: 1857485.0000 - val_fp0.9: 148850.0000 - val_tn0.9: 19532604.0000 - val_fn0.9: 1398664.0000 - val_precision0.9: 0.9258 - val_recall0.9: 0.5705 - val_accuracy: 0.8982 - val_auc: 0.9367
       Epoch 5/10
       1120/1120 [==============================] - 97s 87ms/step - loss: 0.4326 - tp0.1: 13902226.0000 - fp0.1: 11566118.0000 - tn0.1: 65330508.0000 - fn0.1: 951582.0000 - precision0.1: 0.5459 - recall0.1: 0.9359 - tp0.3: 12553205.0000 - fp0
       .3: 3679244.0000 - tn0.3: 73217296.0000 - fn0.3: 2300603.0000 - precision0.3: 0.7733 - recall0.3: 0.8451 - tp0.5: 11940449.0000 - fp0.5: 2311707.0000 - tn0.5: 74584880.0000 - fn0.5: 2913359.0000 - precision0.5: 0.8378 - recall0.5: 0.80
       39 - tp0.7: 10741299.0000 - fp0.7: 1211991.0000 - tn0.7: 75684600.0000 - fn0.7: 4112509.0000 - precision0.7: 0.8986 - recall0.7: 0.7231 - tp0.9: 8025871.0000 - fp0.9: 222263.0000 - tn0.9: 76674280.0000 - fn0.9: 6827937.0000 - precision
       0.9: 0.9731 - recall0.9: 0.5403 - accuracy: 0.9431 - auc: 0.9505 - val_loss: 0.4909 - val_tp0.1: 3023254.0000 - val_fp0.1: 3064809.0000 - val_tn0.1: 16587139.0000 - val_fn0.1: 262398.0000 - val_precision0.1: 0.4966 - val_recall0.1: 0.9
       201 - val_tp0.3: 2848756.0000 - val_fp0.3: 2028396.0000 - val_tn0.3: 17623548.0000 - val_fn0.3: 436896.0000 - val_precision0.3: 0.5841 - val_recall0.3: 0.8670 - val_tp0.5: 2741626.0000 - val_fp0.5: 1544401.0000 - val_tn0.5: 18107550.00
       00 - val_fn0.5: 544026.0000 - val_precision0.5: 0.6397 - val_recall0.5: 0.8344 - val_tp0.7: 2331416.0000 - val_fp0.7: 736799.0000 - val_tn0.7: 18915144.0000 - val_fn0.7: 954236.0000 - val_precision0.7: 0.7599 - val_recall0.7: 0.7096 -
       val_tp0.9: 1749693.0000 - val_fp0.9: 126440.0000 - val_tn0.9: 19525508.0000 - val_fn0.9: 1535959.0000 - val_precision0.9: 0.9326 - val_recall0.9: 0.5325 - val_accuracy: 0.9090 - val_auc: 0.9344
       Epoch 6/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.4236 - tp0.1: 13849778.0000 - fp0.1: 11517391.0000 - tn0.1: 65463856.0000 - fn0.1: 919424.0000 - precision0.1: 0.5460 - recall0.1: 0.9377 - tp0.3: 12526573.0000 - fp0
       .3: 3702810.0000 - tn0.3: 73278416.0000 - fn0.3: 2242629.0000 - precision0.3: 0.7718 - recall0.3: 0.8482 - tp0.5: 11865574.0000 - fp0.5: 2251609.0000 - tn0.5: 74729560.0000 - fn0.5: 2903628.0000 - precision0.5: 0.8405 - recall0.5: 0.80
       34 - tp0.7: 10742204.0000 - fp0.7: 1154871.0000 - tn0.7: 75826312.0000 - fn0.7: 4026998.0000 - precision0.7: 0.9029 - recall0.7: 0.7273 - tp0.9: 8128745.0000 - fp0.9: 224554.0000 - tn0.9: 76756600.0000 - fn0.9: 6640457.0000 - precision
       0.9: 0.9731 - recall0.9: 0.5504 - accuracy: 0.9438 - auc: 0.9518 - val_loss: 0.4812 - val_tp0.1: 3082711.0000 - val_fp0.1: 3715658.0000 - val_tn0.1: 15959611.0000 - val_fn0.1: 179620.0000 - val_precision0.1: 0.4534 - val_recall0.1: 0.9
       449 - val_tp0.3: 2856309.0000 - val_fp0.3: 2236081.0000 - val_tn0.3: 17439190.0000 - val_fn0.3: 406022.0000 - val_precision0.3: 0.5609 - val_recall0.3: 0.8755 - val_tp0.5: 2618304.0000 - val_fp0.5: 1456358.0000 - val_tn0.5: 18218908.00
       00 - val_fn0.5: 644027.0000 - val_precision0.5: 0.6426 - val_recall0.5: 0.8026 - val_tp0.7: 2287181.0000 - val_fp0.7: 612480.0000 - val_tn0.7: 19062784.0000 - val_fn0.7: 975150.0000 - val_precision0.7: 0.7888 - val_recall0.7: 0.7011 -
       val_tp0.9: 1866916.0000 - val_fp0.9: 130333.0000 - val_tn0.9: 19544936.0000 - val_fn0.9: 1395415.0000 - val_precision0.9: 0.9347 - val_recall0.9: 0.5723 - val_accuracy: 0.9084 - val_auc: 0.9432
       Epoch 7/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.4073 - tp0.1: 13881115.0000 - fp0.1: 11059222.0000 - tn0.1: 65922536.0000 - fn0.1: 887535.0000 - precision0.1: 0.5566 - recall0.1: 0.9399 - tp0.3: 12650980.0000 - fp0
       .3: 3590304.0000 - tn0.3: 73391416.0000 - fn0.3: 2117670.0000 - precision0.3: 0.7789 - recall0.3: 0.8566 - tp0.5: 12046455.0000 - fp0.5: 2255390.0000 - tn0.5: 74726392.0000 - fn0.5: 2722195.0000 - precision0.5: 0.8423 - recall0.5: 0.81
       57 - tp0.7: 10964275.0000 - fp0.7: 1179738.0000 - tn0.7: 75801936.0000 - fn0.7: 3804375.0000 - precision0.7: 0.9029 - recall0.7: 0.7424 - tp0.9: 8192316.0000 - fp0.9: 208856.0000 - tn0.9: 76772912.0000 - fn0.9: 6576334.0000 - precision
       0.9: 0.9751 - recall0.9: 0.5547 - accuracy: 0.9457 - auc: 0.9542 - val_loss: 0.4640 - val_tp0.1: 2943159.0000 - val_fp0.1: 2705104.0000 - val_tn0.1: 17005136.0000 - val_fn0.1: 284200.0000 - val_precision0.1: 0.5211 - val_recall0.1: 0.9
       119 - val_tp0.3: 2601017.0000 - val_fp0.3: 1454127.0000 - val_tn0.3: 18256116.0000 - val_fn0.3: 626342.0000 - val_precision0.3: 0.6414 - val_recall0.3: 0.8059 - val_tp0.5: 2246145.0000 - val_fp0.5: 648141.0000 - val_tn0.5: 19062098.000
       0 - val_fn0.5: 981214.0000 - val_precision0.5: 0.7761 - val_recall0.5: 0.6960 - val_tp0.7: 1990921.0000 - val_fp0.7: 268668.0000 - val_tn0.7: 19441576.0000 - val_fn0.7: 1236438.0000 - val_precision0.7: 0.8811 - val_recall0.7: 0.6169 -
       val_tp0.9: 1686841.0000 - val_fp0.9: 69858.0000 - val_tn0.9: 19640378.0000 - val_fn0.9: 1540518.0000 - val_precision0.9: 0.9602 - val_recall0.9: 0.5227 - val_accuracy: 0.9290 - val_auc: 0.9320
       Epoch 8/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.4069 - tp0.1: 13972691.0000 - fp0.1: 11110207.0000 - tn0.1: 65785804.0000 - fn0.1: 881669.0000 - precision0.1: 0.5571 - recall0.1: 0.9406 - tp0.3: 12698474.0000 - fp0
       .3: 3534131.0000 - tn0.3: 73361872.0000 - fn0.3: 2155886.0000 - precision0.3: 0.7823 - recall0.3: 0.8549 - tp0.5: 12111912.0000 - fp0.5: 2187377.0000 - tn0.5: 74708672.0000 - fn0.5: 2742448.0000 - precision0.5: 0.8470 - recall0.5: 0.81
       54 - tp0.7: 11080940.0000 - fp0.7: 1135717.0000 - tn0.7: 75760312.0000 - fn0.7: 3773420.0000 - precision0.7: 0.9070 - recall0.7: 0.7460 - tp0.9: 8284829.0000 - fp0.9: 207954.0000 - tn0.9: 76688072.0000 - fn0.9: 6569531.0000 - precision
       0.9: 0.9755 - recall0.9: 0.5577 - accuracy: 0.9463 - auc: 0.9545 - val_loss: 0.4694 - val_tp0.1: 2964326.0000 - val_fp0.1: 2518070.0000 - val_tn0.1: 17141924.0000 - val_fn0.1: 313276.0000 - val_precision0.1: 0.5407 - val_recall0.1: 0.9
       044 - val_tp0.3: 2726445.0000 - val_fp0.3: 1481972.0000 - val_tn0.3: 18178028.0000 - val_fn0.3: 551157.0000 - val_precision0.3: 0.6479 - val_recall0.3: 0.8318 - val_tp0.5: 2359419.0000 - val_fp0.5: 760977.0000 - val_tn0.5: 18899028.000
       0 - val_fn0.5: 918183.0000 - val_precision0.5: 0.7561 - val_recall0.5: 0.7199 - val_tp0.7: 2043247.0000 - val_fp0.7: 285032.0000 - val_tn0.7: 19374968.0000 - val_fn0.7: 1234355.0000 - val_precision0.7: 0.8776 - val_recall0.7: 0.6234 -
       val_tp0.9: 1719634.0000 - val_fp0.9: 73103.0000 - val_tn0.9: 19586900.0000 - val_fn0.9: 1557968.0000 - val_precision0.9: 0.9592 - val_recall0.9: 0.5247 - val_accuracy: 0.9268 - val_auc: 0.9302
       Epoch 9/10
       1120/1120 [==============================] - 98s 87ms/step - loss: 0.3986 - tp0.1: 13834028.0000 - fp0.1: 10730599.0000 - tn0.1: 66314680.0000 - fn0.1: 871119.0000 - precision0.1: 0.5632 - recall0.1: 0.9408 - tp0.3: 12610635.0000 - fp0
       .3: 3457758.0000 - tn0.3: 73587520.0000 - fn0.3: 2094512.0000 - precision0.3: 0.7848 - recall0.3: 0.8576 - tp0.5: 12031954.0000 - fp0.5: 2166940.0000 - tn0.5: 74878344.0000 - fn0.5: 2673193.0000 - precision0.5: 0.8474 - recall0.5: 0.81
       82 - tp0.7: 11064598.0000 - fp0.7: 1164665.0000 - tn0.7: 75880648.0000 - fn0.7: 3640549.0000 - precision0.7: 0.9048 - recall0.7: 0.7524 - tp0.9: 8296131.0000 - fp0.9: 225607.0000 - tn0.9: 76819640.0000 - fn0.9: 6409016.0000 - precision
       0.9: 0.9735 - recall0.9: 0.5642 - accuracy: 0.9472 - auc: 0.9553 - val_loss: 0.4743 - val_tp0.1: 2940698.0000 - val_fp0.1: 2570585.0000 - val_tn0.1: 17113848.0000 - val_fn0.1: 312469.0000 - val_precision0.1: 0.5336 - val_recall0.1: 0.9
       039 - val_tp0.3: 2570594.0000 - val_fp0.3: 1257842.0000 - val_tn0.3: 18426590.0000 - val_fn0.3: 682573.0000 - val_precision0.3: 0.6714 - val_recall0.3: 0.7902 - val_tp0.5: 2212770.0000 - val_fp0.5: 552347.0000 - val_tn0.5: 19132084.000
       0 - val_fn0.5: 1040397.0000 - val_precision0.5: 0.8002 - val_recall0.5: 0.6802 - val_tp0.7: 1971406.0000 - val_fp0.7: 244143.0000 - val_tn0.7: 19440280.0000 - val_fn0.7: 1281761.0000 - val_precision0.7: 0.8898 - val_recall0.7: 0.6060 -
        val_tp0.9: 1683339.0000 - val_fp0.9: 66985.0000 - val_tn0.9: 19617446.0000 - val_fn0.9: 1569828.0000 - val_precision0.9: 0.9617 - val_recall0.9: 0.5174 - val_accuracy: 0.9306 - val_auc: 0.9290
       Epoch 10/10
       1120/1120 [==============================] - 97s 87ms/step - loss: 0.4009 - tp0.1: 14043135.0000 - fp0.1: 10803879.0000 - tn0.1: 66028672.0000 - fn0.1: 874728.0000 - precision0.1: 0.5652 - recall0.1: 0.9414 - tp0.3: 12781810.0000 - fp0
       .3: 3470867.0000 - tn0.3: 73361600.0000 - fn0.3: 2136053.0000 - precision0.3: 0.7864 - recall0.3: 0.8568 - tp0.5: 12209273.0000 - fp0.5: 2178880.0000 - tn0.5: 74653744.0000 - fn0.5: 2708590.0000 - precision0.5: 0.8486 - recall0.5: 0.81
       84 - tp0.7: 11240195.0000 - fp0.7: 1167231.0000 - tn0.7: 75665368.0000 - fn0.7: 3677668.0000 - precision0.7: 0.9059 - recall0.7: 0.7535 - tp0.9: 8415261.0000 - fp0.9: 225304.0000 - tn0.9: 76607264.0000 - fn0.9: 6502602.0000 - precision
       0.9: 0.9739 - recall0.9: 0.5641 - accuracy: 0.9467 - auc: 0.9554 - val_loss: 0.4643 - val_tp0.1: 2895355.0000 - val_fp0.1: 2387924.0000 - val_tn0.1: 17332140.0000 - val_fn0.1: 322180.0000 - val_precision0.1: 0.5480 - val_recall0.1: 0.8
       999 - val_tp0.3: 2645722.0000 - val_fp0.3: 1374789.0000 - val_tn0.3: 18345272.0000 - val_fn0.3: 571813.0000 - val_precision0.3: 0.6581 - val_recall0.3: 0.8223 - val_tp0.5: 2297009.0000 - val_fp0.5: 682411.0000 - val_tn0.5: 19037648.000
       0 - val_fn0.5: 920526.0000 - val_precision0.5: 0.7710 - val_recall0.5: 0.7139 - val_tp0.7: 2037277.0000 - val_fp0.7: 284340.0000 - val_tn0.7: 19435724.0000 - val_fn0.7: 1180258.0000 - val_precision0.7: 0.8775 - val_recall0.7: 0.6332 -
       val_tp0.9: 1731057.0000 - val_fp0.9: 75596.0000 - val_tn0.9: 19644468.0000 - val_fn0.9: 1486478.0000 - val_precision0.9: 0.9582 - val_recall0.9: 0.5380 - val_accuracy: 0.9301 - val_auc: 0.9293
       600/600 [==============================] - 13s 21ms/step - loss: 0.4371 - tp0.1: 6966295.0000 - fp0.1: 5223111.0000 - tn0.1: 36372652.0000 - fn0.1: 589938.0000 - precision0.1: 0.5715 - recall0.1: 0.9219 - tp0.3: 6396511.0000 - fp0.3: 2
       670828.0000 - tn0.3: 38924936.0000 - fn0.3: 1159722.0000 - precision0.3: 0.7054 - recall0.3: 0.8465 - tp0.5: 5592839.0000 - fp0.5: 1400352.0000 - tn0.5: 40195440.0000 - fn0.5: 1963394.0000 - precision0.5: 0.7998 - recall0.5: 0.7402 - t
       p0.7: 4985380.0000 - fp0.7: 618073.0000 - tn0.7: 40977728.0000 - fn0.7: 2570853.0000 - precision0.7: 0.8897 - recall0.7: 0.6598 - tp0.9: 4237386.0000 - fp0.9: 157662.0000 - tn0.9: 41438124.0000 - fn0.9: 3318847.0000 - precision0.9: 0.9
       641 - recall0.9: 0.5608 - accuracy: 0.9316 - auc: 0.9421
       2021-07-22 12:55:22.434015: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       2021/07/22 12:55:38 INFO mlflow.projects: === Run (ID 'bbd8c3bbe6f54a2782317f3a062ea7d9') succeeded ===
       (tf-nightly) [ye53nis@node131 drmed-git]$
     #+end_example

** Add hyperparameter tuning <2021-07-22 Do>
*** options for hp tuning
    1. Tensorboard HParams
       https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams
       - https://medium.com/ml-book/neural-networks-hyperparameter-tuning-in-tensorflow-2-0-a7b4e2b574a1
       - https://github.com/tensorflow/tensorboard/issues/2348
       - https://github.com/tensorflow/tensorboard/blob/78db135e980fff6852cd91f3da439b45e7f9fc1e/tensorboard/plugins/hparams/api.py#L15-L111
       - https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/hparams/hparams_demo.py
       -
    2. Keras Tuner https://keras.io/guides/keras_tuner/getting_started/
    3. scikit-learn https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search
       - https://www.pyimagesearch.com/2021/05/31/hyperparameter-tuning-for-deep-learning-with-scikit-learn-keras-and-tensorflow/#download-the-code
       - https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/
       - https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/
    4. using MLFLOW https://github.com/mlflow/mlflow/tree/master/examples/hyperparam
       - https://dzlab.github.io/ml/2020/08/16/mlflow-hyperopt/

*** simple random search and tensorboard HParams logging
**** metadata & connection
    - using =ob-tmux= for script execution
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        cd /beegfs/ye53nis/drmed-git/
        git status
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (base) [ye53nis@node128 drmed-git]$ git status
        git log -3
        # On branch develop
        # Changes not staged for commit:
        #   (use "git add <file>..." to update what will be committed)
        #   (use "git checkout -- <file>..." to discard changes in working directory)
        #   (commit or discard the untracked or modified content in submodules)
        #
        #       modified:   src/nanosimpy (new commits, untracked content)
        #
        # Untracked files:
        #   (use "git add <file>..." to include in what will be committed)
        #
        #       .data/
        #       2021-03-20_correlations.csv
        #       data/0.069.svg
        #       data/exp-210204-unet/
        #       data/exp-devtest/
        #       data/exp-test/
        #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
        #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
        #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
        #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
        #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
        #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
        #       data/mlruns/0/52faa01e685f44ef97be4e64ddc88eb1/
        #       data/mlruns/0/5dc9fe4b91094df58e3d2f1426aa4d96/
        #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
        #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
        #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
        #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
        #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
        #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
        #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
        #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
        #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
        #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
        #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
        #       data/mlruns/2/
        #       data/mlruns/3/
        #       data/mlruns/4/
        #       data/tb/
        #       experiment_params.csv
        #       mlruns/
        #       tramp.YDPCnB
        no changes added to commit (use "git add" and/or "git commit -a")
        (base) [ye53nis@node128 drmed-git]$ git log -3
        commit 0eb664ca4d3c11d7ef63238428a3dfc65fb5529b
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Jul 27 00:32:15 2021 +0200

            Make hparams less versatile because mlflow...

        commit 7eeb0e5d6e5c93af76368c10e29f21ff208ec865
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Mon Jul 26 14:10:54 2021 +0200

            Add parameters to MLproject search_hparams

        commit e336c8b9501bbb6f4fe12a0d9040598bd7336406
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Mon Jul 26 13:16:23 2021 +0200

            Add search_hparams; MLproject entrypoint
        (base) [ye53nis@node128 drmed-git]$
      #+end_example


**** tmux gpu node
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       cd /
       srun -p gpu_p100 --time=1-10:00:00 --ntasks-per-node=12 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
     #+END_SRC

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       module load nvidia/cuda/11.2
       module load nvidia/cudnn/8.1
       module list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (base) [ye53nis@node128 /]$ module list
       Currently Loaded Modulefiles:
         1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
       (base) [ye53nis@node128 /]$
     #+end_example
**** mlflow environment variables

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       conda activate tf
       cd /beegfs/ye53nis/drmed-git
       export MLFLOW_EXPERIMENT_NAME=exp-210804-test
       export MLFLOW_TRACKING_URI=file:./data/mlruns
       mkdir data/exp-210804-test
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node131 drmed-git]$
     #+end_example

**** test run 4 - hyperparameter training

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf-nightly) [ye53nis@node128 drmed-git]$ mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P learning_rate=0 -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample
       2021/07/27 14:07:30 INFO mlflow.projects.utils: === Created directory /tmp/tmpakiwrpjs for downloading remote URIs passed to arguments of type 'path' ===
       2021/07/27 14:07:30 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-119ac947ffa5b6120cc8009a8ede635922e249ef 1>&2 && python src/fluotracify/trai
       ning/search_hparams.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 5 --frac_val 0.2 --length_delimiter 16384 --learning_rate 0 --epochs 10 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -
       -col_per_example 3' in run with ID '052c0bb4a8b148d78818c1af868eefc8' ===
       2.7.0-dev20210720
       GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       2021-07-27 14:09:09.504607: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-07-27 14:09:09.951113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1504] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15411 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:83:00.0,
        compute capability: 6.0
       number of training examples: 2240, number of validation examples: 560

       ------------------------
       2021/07/27 14:09:11 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading
        MLflow.
       --- Running training session 1/4
       {HParam(name='epochs', domain=Discrete([2]), display_name=None, description=None): 2, HParam(name='batch_size', domain=Discrete([5]), display_name=None, description=None): 5, HParam(name='steps_per_epoch', domain=Discrete([650]), displ
       ay_name=None, description=None): 650, HParam(name='validation_steps', domain=Discrete([100]), display_name=None, description=None): 100, HParam(name='scaler', domain=Discrete(['minmax', 'robust']), display_name=None, description=None):
        'robust', HParam(name='n_levels', domain=Discrete([3, 9]), display_name=None, description=None): 9, HParam(name='first_filteres', domain=Discrete([64]), display_name=None, description=None): 64, HParam(name='pool_size', domain=Discret
       e([2]), display_name=None, description=None): 2}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/2
       2021-07-27 14:09:36.980130: I tensorflow/stream_executor/cuda/cuda_dnn.cc:365] Loaded cuDNN version 8101
       650/650 [==============================] - 228s 314ms/step - loss: 0.8511 - tp0.1: 7517754.0000 - fp0.1: 12892360.0000 - tn0.1: 31754188.0000 - fn0.1: 1083699.0000 - precision0.1: 0.3683 - recall0.1: 0.8740 - tp0.3: 5596451.0000 - fp0.
       3: 3081844.0000 - tn0.3: 41564712.0000 - fn0.3: 3005002.0000 - precision0.3: 0.6449 - recall0.3: 0.6506 - tp0.5: 4749639.0000 - fp0.5: 1290844.0000 - tn0.5: 43355656.0000 - fn0.5: 3851814.0000 - precision0.5: 0.7863 - recall0.5: 0.5522
        - tp0.7: 4098295.0000 - fp0.7: 560911.0000 - tn0.7: 44085612.0000 - fn0.7: 4503158.0000 - precision0.7: 0.8796 - recall0.7: 0.4765 - tp0.9: 3378055.0000 - fp0.9: 152105.0000 - tn0.9: 44494448.0000 - fn0.9: 5223398.0000 - precision0.9:
        0.9569 - recall0.9: 0.3927 - accuracy: 0.9034 - auc: 0.8802 - val_loss: 1.1057 - val_tp0.1: 725771.0000 - val_fp0.1: 299309.0000 - val_tn0.1: 6765601.0000 - val_fn0.1: 401319.0000 - val_precision0.1: 0.7080 - val_recall0.1: 0.6439 - v
       al_tp0.3: 714280.0000 - val_fp0.3: 264005.0000 - val_tn0.3: 6800905.0000 - val_fn0.3: 412810.0000 - val_precision0.3: 0.7301 - val_recall0.3: 0.6337 - val_tp0.5: 706868.0000 - val_fp0.5: 243392.0000 - val_tn0.5: 6821518.0000 - val_fn0.
       5: 420222.0000 - val_precision0.5: 0.7439 - val_recall0.5: 0.6272 - val_tp0.7: 644731.0000 - val_fp0.7: 117656.0000 - val_tn0.7: 6947254.0000 - val_fn0.7: 482359.0000 - val_precision0.7: 0.8457 - val_recall0.7: 0.5720 - val_tp0.9: 5450
       87.0000 - val_fp0.9: 31866.0000 - val_tn0.9: 7033044.0000 - val_fn0.9: 582003.0000 - val_precision0.9: 0.9448 - val_recall0.9: 0.4836 - val_accuracy: 0.9190 - val_auc: 0.8182
       Epoch 2/2
       650/650 [==============================] - 200s 307ms/step - loss: 0.6240 - tp0.1: 7661804.0000 - fp0.1: 8855521.0000 - tn0.1: 35912688.0000 - fn0.1: 817978.0000 - precision0.1: 0.4639 - recall0.1: 0.9035 - tp0.3: 6232727.0000 - fp0.3:
        3903637.0000 - tn0.3: 40864584.0000 - fn0.3: 2247055.0000 - precision0.3: 0.6149 - recall0.3: 0.7350 - tp0.5: 5166888.0000 - fp0.5: 1187911.0000 - tn0.5: 43580292.0000 - fn0.5: 3312894.0000 - precision0.5: 0.8131 - recall0.5: 0.6093 -
        tp0.7: 4468449.0000 - fp0.7: 509599.0000 - tn0.7: 44258616.0000 - fn0.7: 4011333.0000 - precision0.7: 0.8976 - recall0.7: 0.5270 - tp0.9: 3578327.0000 - fp0.9: 155610.0000 - tn0.9: 44612620.0000 - fn0.9: 4901455.0000 - precision0.9: 0
       .9583 - recall0.9: 0.4220 - accuracy: 0.9155 - auc: 0.9123 - val_loss: 0.8722 - val_tp0.1: 824424.0000 - val_fp0.1: 693812.0000 - val_tn0.1: 6367364.0000 - val_fn0.1: 306400.0000 - val_precision0.1: 0.5430 - val_recall0.1: 0.7290 - val
       _tp0.3: 781595.0000 - val_fp0.3: 506775.0000 - val_tn0.3: 6554401.0000 - val_fn0.3: 349229.0000 - val_precision0.3: 0.6067 - val_recall0.3: 0.6912 - val_tp0.5: 729901.0000 - val_fp0.5: 313826.0000 - val_tn0.5: 6747350.0000 - val_fn0.5:
        400923.0000 - val_precision0.5: 0.6993 - val_recall0.5: 0.6455 - val_tp0.7: 689642.0000 - val_fp0.7: 205770.0000 - val_tn0.7: 6855406.0000 - val_fn0.7: 441182.0000 - val_precision0.7: 0.7702 - val_recall0.7: 0.6099 - val_tp0.9: 635029
       .0000 - val_fp0.9: 109601.0000 - val_tn0.9: 6951575.0000 - val_fn0.9: 495795.0000 - val_precision0.9: 0.8528 - val_recall0.9: 0.5616 - val_accuracy: 0.9128 - val_auc: 0.8448
       2021-07-27 14:16:54.097808: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       --- Running training session 2/4
       {HParam(name='epochs', domain=Discrete([2]), display_name=None, description=None): 2, HParam(name='batch_size', domain=Discrete([5]), display_name=None, description=None): 5, HParam(name='steps_per_epoch', domain=Discrete([650]), displ
       ay_name=None, description=None): 650, HParam(name='validation_steps', domain=Discrete([100]), display_name=None, description=None): 100, HParam(name='scaler', domain=Discrete(['minmax', 'robust']), display_name=None, description=None):
        'robust', HParam(name='n_levels', domain=Discrete([3, 9]), display_name=None, description=None): 9, HParam(name='first_filteres', domain=Discrete([64]), display_name=None, description=None): 64, HParam(name='pool_size', domain=Discret
       e([2]), display_name=None, description=None): 2}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/2
       650/650 [==============================] - 230s 321ms/step - loss: 0.7854 - tp0.1: 7590732.0000 - fp0.1: 11387884.0000 - tn0.1: 33283700.0000 - fn0.1: 985708.0000 - precision0.1: 0.4000 - recall0.1: 0.8851 - tp0.3: 5932664.0000 - fp0.3
       : 3379486.0000 - tn0.3: 41292088.0000 - fn0.3: 2643776.0000 - precision0.3: 0.6371 - recall0.3: 0.6917 - tp0.5: 4955299.0000 - fp0.5: 1322419.0000 - tn0.5: 43349132.0000 - fn0.5: 3621141.0000 - precision0.5: 0.7893 - recall0.5: 0.5778
       - tp0.7: 4205846.0000 - fp0.7: 539187.0000 - tn0.7: 44132376.0000 - fn0.7: 4370594.0000 - precision0.7: 0.8864 - recall0.7: 0.4904 - tp0.9: 3353898.0000 - fp0.9: 134494.0000 - tn0.9: 44537060.0000 - fn0.9: 5222542.0000 - precision0.9:
       0.9614 - recall0.9: 0.3911 - accuracy: 0.9072 - auc: 0.8961 - val_loss: 0.9377 - val_tp0.1: 1009842.0000 - val_fp0.1: 1535372.0000 - val_tn0.1: 5482043.0000 - val_fn0.1: 164743.0000 - val_precision0.1: 0.3968 - val_recall0.1: 0.8597 -
       val_tp0.3: 1001860.0000 - val_fp0.3: 1476275.0000 - val_tn0.3: 5541140.0000 - val_fn0.3: 172725.0000 - val_precision0.3: 0.4043 - val_recall0.3: 0.8529 - val_tp0.5: 954581.0000 - val_fp0.5: 1205175.0000 - val_tn0.5: 5812240.0000 - val_
       fn0.5: 220004.0000 - val_precision0.5: 0.4420 - val_recall0.5: 0.8127 - val_tp0.7: 883068.0000 - val_fp0.7: 864034.0000 - val_tn0.7: 6153381.0000 - val_fn0.7: 291517.0000 - val_precision0.7: 0.5054 - val_recall0.7: 0.7518 - val_tp0.9:
       780872.0000 - val_fp0.9: 454563.0000 - val_tn0.9: 6562852.0000 - val_fn0.9: 393713.0000 - val_precision0.9: 0.6321 - val_recall0.9: 0.6648 - val_accuracy: 0.8260 - val_auc: 0.8819
       Epoch 2/2
       650/650 [==============================] - 201s 309ms/step - loss: 0.6430 - tp0.1: 7780921.0000 - fp0.1: 8031482.0000 - tn0.1: 36559480.0000 - fn0.1: 876128.0000 - precision0.1: 0.4921 - recall0.1: 0.8988 - tp0.3: 7183486.0000 - fp0.3:
        5761311.0000 - tn0.3: 38829644.0000 - fn0.3: 1473563.0000 - precision0.3: 0.5549 - recall0.3: 0.8298 - tp0.5: 5052472.0000 - fp0.5: 1066772.0000 - tn0.5: 43524200.0000 - fn0.5: 3604577.0000 - precision0.5: 0.8257 - recall0.5: 0.5836 -
        tp0.7: 4430706.0000 - fp0.7: 481093.0000 - tn0.7: 44109848.0000 - fn0.7: 4226343.0000 - precision0.7: 0.9021 - recall0.7: 0.5118 - tp0.9: 3627296.0000 - fp0.9: 175946.0000 - tn0.9: 44415024.0000 - fn0.9: 5029753.0000 - precision0.9: 0
       .9537 - recall0.9: 0.4190 - accuracy: 0.9123 - auc: 0.9130 - val_loss: 0.7147 - val_tp0.1: 994902.0000 - val_fp0.1: 972121.0000 - val_tn0.1: 6086833.0000 - val_fn0.1: 138144.0000 - val_precision0.1: 0.5058 - val_recall0.1: 0.8781 - val
       _tp0.3: 973191.0000 - val_fp0.3: 834166.0000 - val_tn0.3: 6224788.0000 - val_fn0.3: 159855.0000 - val_precision0.3: 0.5385 - val_recall0.3: 0.8589 - val_tp0.5: 916019.0000 - val_fp0.5: 605951.0000 - val_tn0.5: 6453003.0000 - val_fn0.5:
        217027.0000 - val_precision0.5: 0.6019 - val_recall0.5: 0.8085 - val_tp0.7: 886914.0000 - val_fp0.7: 558183.0000 - val_tn0.7: 6500771.0000 - val_fn0.7: 246132.0000 - val_precision0.7: 0.6137 - val_recall0.7: 0.7828 - val_tp0.9: 833460
       .0000 - val_fp0.9: 491709.0000 - val_tn0.9: 6567245.0000 - val_fn0.9: 299586.0000 - val_precision0.9: 0.6289 - val_recall0.9: 0.7356 - val_accuracy: 0.8995 - val_auc: 0.9088
       --- Running training session 3/4
       {HParam(name='epochs', domain=Discrete([2]), display_name=None, description=None): 2, HParam(name='batch_size', domain=Discrete([5]), display_name=None, description=None): 5, HParam(name='steps_per_epoch', domain=Discrete([650]), displ
       ay_name=None, description=None): 650, HParam(name='validation_steps', domain=Discrete([100]), display_name=None, description=None): 100, HParam(name='scaler', domain=Discrete(['minmax', 'robust']), display_name=None, description=None):
        'minmax', HParam(name='n_levels', domain=Discrete([3, 9]), display_name=None, description=None): 3, HParam(name='first_filteres', domain=Discrete([64]), display_name=None, description=None): 64, HParam(name='pool_size', domain=Discret
       e([2]), display_name=None, description=None): 2}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/2
       650/650 [==============================] - 144s 200ms/step - loss: 0.9809 - tp0.1: 7521589.0000 - fp0.1: 16496715.0000 - tn0.1: 28151884.0000 - fn0.1: 1077811.0000 - precision0.1: 0.3132 - recall0.1: 0.8747 - tp0.3: 5024355.0000 - fp0.
       3: 5442979.0000 - tn0.3: 39205600.0000 - fn0.3: 3575045.0000 - precision0.3: 0.4800 - recall0.3: 0.5843 - tp0.5: 3448468.0000 - fp0.5: 2085219.0000 - tn0.5: 42563368.0000 - fn0.5: 5150932.0000 - precision0.5: 0.6232 - recall0.5: 0.4010
        - tp0.7: 2337518.0000 - fp0.7: 776011.0000 - tn0.7: 43872580.0000 - fn0.7: 6261882.0000 - precision0.7: 0.7508 - recall0.7: 0.2718 - tp0.9: 1226045.0000 - fp0.9: 128508.0000 - tn0.9: 44520112.0000 - fn0.9: 7373355.0000 - precision0.9:
        0.9051 - recall0.9: 0.1426 - accuracy: 0.8641 - auc: 0.8296 - val_loss: 1.1492 - val_tp0.1: 1060271.0000 - val_fp0.1: 2219392.0000 - val_tn0.1: 4797436.0000 - val_fn0.1: 114901.0000 - val_precision0.1: 0.3233 - val_recall0.1: 0.9022 -
        val_tp0.3: 914803.0000 - val_fp0.3: 1327297.0000 - val_tn0.3: 5689531.0000 - val_fn0.3: 260369.0000 - val_precision0.3: 0.4080 - val_recall0.3: 0.7784 - val_tp0.5: 880082.0000 - val_fp0.5: 1209811.0000 - val_tn0.5: 5807017.0000 - val_
       fn0.5: 295090.0000 - val_precision0.5: 0.4211 - val_recall0.5: 0.7489 - val_tp0.7: 824421.0000 - val_fp0.7: 1056571.0000 - val_tn0.7: 5960257.0000 - val_fn0.7: 350751.0000 - val_precision0.7: 0.4383 - val_recall0.7: 0.7015 - val_tp0.9:
        666494.0000 - val_fp0.9: 813739.0000 - val_tn0.9: 6203089.0000 - val_fn0.9: 508678.0000 - val_precision0.9: 0.4503 - val_recall0.9: 0.5671 - val_accuracy: 0.8163 - val_auc: 0.8469
       Epoch 2/2
       650/650 [==============================] - 127s 195ms/step - loss: 0.9446 - tp0.1: 7664542.0000 - fp0.1: 16148554.0000 - tn0.1: 28467124.0000 - fn0.1: 967771.0000 - precision0.1: 0.3219 - recall0.1: 0.8879 - tp0.3: 4744338.0000 - fp0.3
       : 5230267.0000 - tn0.3: 39385408.0000 - fn0.3: 3887975.0000 - precision0.3: 0.4756 - recall0.3: 0.5496 - tp0.5: 3348653.0000 - fp0.5: 1361597.0000 - tn0.5: 43254072.0000 - fn0.5: 5283660.0000 - precision0.5: 0.7109 - recall0.5: 0.3879
       - tp0.7: 2633755.0000 - fp0.7: 573598.0000 - tn0.7: 44042092.0000 - fn0.7: 5998558.0000 - precision0.7: 0.8212 - recall0.7: 0.3051 - tp0.9: 1613043.0000 - fp0.9: 86503.0000 - tn0.9: 44529156.0000 - fn0.9: 7019270.0000 - precision0.9: 0
       .9491 - recall0.9: 0.1869 - accuracy: 0.8752 - auc: 0.8352 - val_loss: 0.8730 - val_tp0.1: 1117199.0000 - val_fp0.1: 3156309.0000 - val_tn0.1: 3873918.0000 - val_fn0.1: 44574.0000 - val_precision0.1: 0.2614 - val_recall0.1: 0.9616 - va
       l_tp0.3: 386942.0000 - val_fp0.3: 360315.0000 - val_tn0.3: 6669912.0000 - val_fn0.3: 774831.0000 - val_precision0.3: 0.5178 - val_recall0.3: 0.3331 - val_tp0.5: 245682.0000 - val_fp0.5: 99408.0000 - val_tn0.5: 6930819.0000 - val_fn0.5:
        916091.0000 - val_precision0.5: 0.7119 - val_recall0.5: 0.2115 - val_tp0.7: 140221.0000 - val_fp0.7: 14901.0000 - val_tn0.7: 7015326.0000 - val_fn0.7: 1021552.0000 - val_precision0.7: 0.9039 - val_recall0.7: 0.1207 - val_tp0.9: 30728.
       0000 - val_fp0.9: 228.0000 - val_tn0.9: 7029999.0000 - val_fn0.9: 1131045.0000 - val_precision0.9: 0.9926 - val_recall0.9: 0.0264 - val_accuracy: 0.8760 - val_auc: 0.8239
       --- Running training session 4/4
       {HParam(name='epochs', domain=Discrete([2]), display_name=None, description=None): 2, HParam(name='batch_size', domain=Discrete([5]), display_name=None, description=None): 5, HParam(name='steps_per_epoch', domain=Discrete([650]), displ
       ay_name=None, description=None): 650, HParam(name='validation_steps', domain=Discrete([100]), display_name=None, description=None): 100, HParam(name='scaler', domain=Discrete(['minmax', 'robust']), display_name=None, description=None):
        'minmax', HParam(name='n_levels', domain=Discrete([3, 9]), display_name=None, description=None): 3, HParam(name='first_filteres', domain=Discrete([64]), display_name=None, description=None): 64, HParam(name='pool_size', domain=Discret
       e([2]), display_name=None, description=None): 2}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/2
       650/650 [==============================] - 144s 200ms/step - loss: 0.9729 - tp0.1: 7544296.0000 - fp0.1: 16546602.0000 - tn0.1: 28112428.0000 - fn0.1: 1044678.0000 - precision0.1: 0.3132 - recall0.1: 0.8784 - tp0.3: 5526685.0000 - fp0.
       3: 7631514.0000 - tn0.3: 37027480.0000 - fn0.3: 3062289.0000 - precision0.3: 0.4200 - recall0.3: 0.6435 - tp0.5: 3052031.0000 - fp0.5: 1906925.0000 - tn0.5: 42752096.0000 - fn0.5: 5536943.0000 - precision0.5: 0.6155 - recall0.5: 0.3553
        - tp0.7: 2047837.0000 - fp0.7: 647994.0000 - tn0.7: 44011040.0000 - fn0.7: 6541137.0000 - precision0.7: 0.7596 - recall0.7: 0.2384 - tp0.9: 981957.0000 - fp0.9: 102405.0000 - tn0.9: 44556640.0000 - fn0.9: 7607017.0000 - precision0.9:
       0.9056 - recall0.9: 0.1143 - accuracy: 0.8602 - auc: 0.8301 - val_loss: 0.8734 - val_tp0.1: 1096440.0000 - val_fp0.1: 2818159.0000 - val_tn0.1: 4199639.0000 - val_fn0.1: 77762.0000 - val_precision0.1: 0.2801 - val_recall0.1: 0.9338 - v
       al_tp0.3: 297383.0000 - val_fp0.3: 207636.0000 - val_tn0.3: 6810162.0000 - val_fn0.3: 876819.0000 - val_precision0.3: 0.5889 - val_recall0.3: 0.2533 - val_tp0.5: 156191.0000 - val_fp0.5: 37198.0000 - val_tn0.5: 6980600.0000 - val_fn0.5
       : 1018011.0000 - val_precision0.5: 0.8077 - val_recall0.5: 0.1330 - val_tp0.7: 56323.0000 - val_fp0.7: 2661.0000 - val_tn0.7: 7015137.0000 - val_fn0.7: 1117879.0000 - val_precision0.7: 0.9549 - val_recall0.7: 0.0480 - val_tp0.9: 0.0000
       e+00 - val_fp0.9: 0.0000e+00 - val_tn0.9: 7017798.0000 - val_fn0.9: 1174202.0000 - val_precision0.9: 0.0000e+00 - val_recall0.9: 0.0000e+00 - val_accuracy: 0.8712 - val_auc: 0.8526
       Epoch 2/2
       650/650 [==============================] - 127s 195ms/step - loss: 0.8890 - tp0.1: 7602950.0000 - fp0.1: 15039497.0000 - tn0.1: 29588336.0000 - fn0.1: 1017215.0000 - precision0.1: 0.3358 - recall0.1: 0.8820 - tp0.3: 6088754.0000 - fp0.
       3: 7536945.0000 - tn0.3: 37090880.0000 - fn0.3: 2531411.0000 - precision0.3: 0.4469 - recall0.3: 0.7063 - tp0.5: 3305355.0000 - fp0.5: 1303292.0000 - tn0.5: 43324512.0000 - fn0.5: 5314810.0000 - precision0.5: 0.7172 - recall0.5: 0.3834
        - tp0.7: 2597952.0000 - fp0.7: 482927.0000 - tn0.7: 44144904.0000 - fn0.7: 6022213.0000 - precision0.7: 0.8433 - recall0.7: 0.3014 - tp0.9: 1685352.0000 - fp0.9: 111051.0000 - tn0.9: 44516796.0000 - fn0.9: 6934813.0000 - precision0.9:
        0.9382 - recall0.9: 0.1955 - accuracy: 0.8757 - auc: 0.8519 - val_loss: 1.0253 - val_tp0.1: 1098654.0000 - val_fp0.1: 2347844.0000 - val_tn0.1: 4674583.0000 - val_fn0.1: 70919.0000 - val_precision0.1: 0.3188 - val_recall0.1: 0.9394 -
       val_tp0.3: 917842.0000 - val_fp0.3: 1161244.0000 - val_tn0.3: 5861183.0000 - val_fn0.3: 251731.0000 - val_precision0.3: 0.4415 - val_recall0.3: 0.7848 - val_tp0.5: 669539.0000 - val_fp0.5: 745228.0000 - val_tn0.5: 6277199.0000 - val_fn
       0.5: 500034.0000 - val_precision0.5: 0.4733 - val_recall0.5: 0.5725 - val_tp0.7: 631213.0000 - val_fp0.7: 707518.0000 - val_tn0.7: 6314909.0000 - val_fn0.7: 538360.0000 - val_precision0.7: 0.4715 - val_recall0.7: 0.5397 - val_tp0.9: 54
       1618.0000 - val_fp0.9: 607995.0000 - val_tn0.9: 6414432.0000 - val_fn0.9: 627955.0000 - val_precision0.9: 0.4711 - val_recall0.9: 0.4631 - val_accuracy: 0.8480 - val_auc: 0.8692
       2021/07/27 14:35:58 INFO mlflow.projects: === Run (ID '052c0bb4a8b148d78818c1af868eefc8') succeeded ===
       (base) [ye53nis@login01 /]$
     #+end_example

**** update packages
         - we need:
      - jupyterlab
      - pip
      - pip:
        - numpy==1.19.5 (needed <1.20 for tensorflow)
        - pandas
        - matplotlib
        - seaborn
        - mlflow
        - lmfit (needed by =fluotracify.applications.correlate=)
        - tensorflow (instead of tf-nightly!)
        - fcsfiles
        - multipletau
        - scikit-learn

    #+begin_example
      conda env remove -n tf-nightly
      conda create -n tf jupyterlab pip
      conda activate tf
      (tf) pip install numpy==1.19.5  mlflow lmfit scikit-learn tensorflow matplotlib pandas seaborn tifffile fcsfiles multipletau
      #+end_example

    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
      conda list -n tf
    #+END_SRC

    #+RESULTS:
    #+begin_example
      (base) [ye53nis@login01 ~]$ conda list -n tf
      # packages in environment at /home/ye53nis/.conda/envs/tf:
      #
      # Name                    Version                   Build  Channel
      _libgcc_mutex             0.1                        main
      _openmp_mutex             4.5                       1_gnu
      absl-py                   0.13.0                   pypi_0    pypi
      alembic                   1.4.1                    pypi_0    pypi
      anyio                     2.2.0            py39h06a4308_1
      argon2-cffi               20.1.0           py39h27cfd23_1
      asteval                   0.9.25                   pypi_0    pypi
      astunparse                1.6.3                    pypi_0    pypi
      async_generator           1.10               pyhd3eb1b0_0
      attrs                     21.2.0             pyhd3eb1b0_0
      babel                     2.9.1              pyhd3eb1b0_0
      backcall                  0.2.0              pyhd3eb1b0_0
      bleach                    3.3.1              pyhd3eb1b0_0
      brotlipy                  0.7.0         py39h27cfd23_1003
      ca-certificates           2021.7.5             h06a4308_1
      cachetools                4.2.2                    pypi_0    pypi
      certifi                   2021.5.30        py39h06a4308_0
      cffi                      1.14.6           py39h400218f_0
      chardet                   4.0.0         py39h06a4308_1003
      click                     8.0.1                    pypi_0    pypi
      cloudpickle               1.6.0                    pypi_0    pypi
      cryptography              3.4.7            py39hd23ed53_0
      cycler                    0.10.0                   pypi_0    pypi
      databricks-cli            0.14.3                   pypi_0    pypi
      decorator                 5.0.9              pyhd3eb1b0_0
      defusedxml                0.7.1              pyhd3eb1b0_0
      docker                    5.0.0                    pypi_0    pypi
      entrypoints               0.3              py39h06a4308_0
      fcsfiles                  2021.6.6                 pypi_0    pypi
      flask                     2.0.1                    pypi_0    pypi
      flatbuffers               1.12                     pypi_0    pypi
      future                    0.18.2                   pypi_0    pypi
      gast                      0.4.0                    pypi_0    pypi
      gitdb                     4.0.7                    pypi_0    pypi
      gitpython                 3.1.18                   pypi_0    pypi
      google-auth               1.34.0                   pypi_0    pypi
      google-auth-oauthlib      0.4.5                    pypi_0    pypi
      google-pasta              0.2.0                    pypi_0    pypi
      greenlet                  1.1.0                    pypi_0    pypi
      grpcio                    1.34.1                   pypi_0    pypi
      gunicorn                  20.1.0                   pypi_0    pypi
      h5py                      3.1.0                    pypi_0    pypi
      idna                      2.10               pyhd3eb1b0_0
      importlib-metadata        3.10.0           py39h06a4308_0
      importlib_metadata        3.10.0               hd3eb1b0_0
      ipykernel                 5.3.4            py39hb070fc8_0
      ipython                   7.22.0           py39hb070fc8_0
      ipython_genutils          0.2.0              pyhd3eb1b0_1
      itsdangerous              2.0.1                    pypi_0    pypi
      jedi                      0.17.2           py39h06a4308_1
      jinja2                    3.0.1              pyhd3eb1b0_0
      joblib                    1.0.1                    pypi_0    pypi
      json5                     0.9.6              pyhd3eb1b0_0
      jsonschema                3.2.0                      py_2
      jupyter-packaging         0.7.12             pyhd3eb1b0_0
      jupyter_client            6.1.12             pyhd3eb1b0_0
      jupyter_core              4.7.1            py39h06a4308_0
      jupyter_server            1.4.1            py39h06a4308_0
      jupyterlab                3.0.14             pyhd3eb1b0_1
      jupyterlab_pygments       0.1.2                      py_0
      jupyterlab_server         2.6.1              pyhd3eb1b0_0
      keras-nightly             2.5.0.dev2021032900      pypi_0    pypi
      keras-preprocessing       1.1.2                    pypi_0    pypi
      kiwisolver                1.3.1                    pypi_0    pypi
      ld_impl_linux-64          2.35.1               h7274673_9
      libffi                    3.3                  he6710b0_2
      libgcc-ng                 9.3.0               h5101ec6_17
      libgomp                   9.3.0               h5101ec6_17
      libsodium                 1.0.18               h7b6447c_0
      libstdcxx-ng              9.3.0               hd4cf53a_17
      lmfit                     1.0.2                    pypi_0    pypi
      mako                      1.1.4                    pypi_0    pypi
      markdown                  3.3.4                    pypi_0    pypi
      markupsafe                2.0.1            py39h27cfd23_0
      matplotlib                3.4.2                    pypi_0    pypi
      mistune                   0.8.4           py39h27cfd23_1000
      mlflow                    1.19.0                   pypi_0    pypi
      multipletau               0.3.3                    pypi_0    pypi
      nbclassic                 0.2.6              pyhd3eb1b0_0
      nbclient                  0.5.3              pyhd3eb1b0_0
      nbconvert                 6.1.0            py39h06a4308_0
      nbformat                  5.1.3              pyhd3eb1b0_0
      ncurses                   6.2                  he6710b0_1
      nest-asyncio              1.5.1              pyhd3eb1b0_0
      notebook                  6.4.0            py39h06a4308_0
      numpy                     1.19.5                   pypi_0    pypi
      oauthlib                  3.1.1                    pypi_0    pypi
      openssl                   1.1.1k               h27cfd23_0
      opt-einsum                3.3.0                    pypi_0    pypi
      packaging                 21.0               pyhd3eb1b0_0
      pandas                    1.3.1                    pypi_0    pypi
      pandocfilters             1.4.3            py39h06a4308_1
      parso                     0.7.0                      py_0
      pexpect                   4.8.0              pyhd3eb1b0_3
      pickleshare               0.7.5           pyhd3eb1b0_1003
      pillow                    8.3.1                    pypi_0    pypi
      pip                       21.1.3           py39h06a4308_0
      prometheus-flask-exporter 0.18.2                   pypi_0    pypi
      prometheus_client         0.11.0             pyhd3eb1b0_0
      prompt-toolkit            3.0.17             pyh06a4308_0
      protobuf                  3.17.3                   pypi_0    pypi
      ptyprocess                0.7.0              pyhd3eb1b0_2
      pyasn1                    0.4.8                    pypi_0    pypi
      pyasn1-modules            0.2.8                    pypi_0    pypi
      pycparser                 2.20                       py_2
      pygments                  2.9.0              pyhd3eb1b0_0
      pyopenssl                 20.0.1             pyhd3eb1b0_1
      pyparsing                 2.4.7              pyhd3eb1b0_0
      pyrsistent                0.18.0           py39h7f8727e_0
      pysocks                   1.7.1            py39h06a4308_0
      python                    3.9.5                h12debd9_4
      python-dateutil           2.8.2              pyhd3eb1b0_0
      python-editor             1.0.4                    pypi_0    pypi
      pytz                      2021.1             pyhd3eb1b0_0
      pyyaml                    5.4.1                    pypi_0    pypi
      pyzmq                     20.0.0           py39h2531618_1
      querystring-parser        1.2.4                    pypi_0    pypi
      readline                  8.1                  h27cfd23_0
      requests                  2.25.1             pyhd3eb1b0_0
      requests-oauthlib         1.3.0                    pypi_0    pypi
      rsa                       4.7.2                    pypi_0    pypi
      scikit-learn              0.24.2                   pypi_0    pypi
      scipy                     1.7.0                    pypi_0    pypi
      seaborn                   0.11.1                   pypi_0    pypi
      send2trash                1.5.0              pyhd3eb1b0_1
      setuptools                52.0.0           py39h06a4308_0
      six                       1.15.0                   pypi_0    pypi
      smmap                     4.0.0                    pypi_0    pypi
      sniffio                   1.2.0            py39h06a4308_1
      sqlalchemy                1.4.22                   pypi_0    pypi
      sqlite                    3.36.0               hc218d9a_0
      sqlparse                  0.4.1                    pypi_0    pypi
      tabulate                  0.8.9                    pypi_0    pypi
      tensorboard               2.5.0                    pypi_0    pypi
      tensorboard-data-server   0.6.1                    pypi_0    pypi
      tensorboard-plugin-wit    1.8.0                    pypi_0    pypi
      tensorflow                2.5.0                    pypi_0    pypi
      tensorflow-estimator      2.5.0                    pypi_0    pypi
      termcolor                 1.1.0                    pypi_0    pypi
      terminado                 0.9.4            py39h06a4308_0
      testpath                  0.5.0              pyhd3eb1b0_0
      threadpoolctl             2.2.0                    pypi_0    pypi
      tifffile                  2021.7.30                pypi_0    pypi
      tk                        8.6.10               hbc83047_0
      tornado                   6.1              py39h27cfd23_0
      traitlets                 5.0.5              pyhd3eb1b0_0
      typing-extensions         3.7.4.3                  pypi_0    pypi
      tzdata                    2021a                h52ac0ba_0
      uncertainties             3.1.6                    pypi_0    pypi
      urllib3                   1.26.6             pyhd3eb1b0_1
      wcwidth                   0.2.5                      py_0
      webencodings              0.5.1            py39h06a4308_1
      websocket-client          1.1.0                    pypi_0    pypi
      werkzeug                  2.0.1                    pypi_0    pypi
      wheel                     0.36.2             pyhd3eb1b0_0
      wrapt                     1.12.1                   pypi_0    pypi
      xz                        5.2.5                h7b6447c_0
      zeromq                    4.3.4                h2531618_0
      zipp                      3.5.0              pyhd3eb1b0_0
      zlib                      1.2.11               h7b6447c_3
      (base) [ye53nis@login01 ~]$
    #+end_example

**** problems
     there seem to be no tensorflow logging. The logdir is not created. Maybe it
     is due to tf 2.7? I'll investigate this.
     1. I prepared a new conda environment with tf 2.5 (stable). Let's run
        jupyter and a toy example and see if tf is now creating the logging dir.
        → this did not solve my problems
     2. I investigated tensorflow logging with a toy example and a jupyter
        notebook.
        1. I CAN log under /home/<mydir>
        2. I CAN log under /beegfs/<mydir>
        3. I CAN NOT log under /home → =PermissionDeniedError: ./tmp; Permission
           denied [Op:CreateSummaryFileWriter]=
        5. There is no error under /, BUT the log files are not created → maybe
           a bug? → solution could be: use different log logation, e.g. under
           /beegfs/<mydir>
**** a lot of jupyter exploration - current code
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        cd /beegfs/ye53nis/drmed-git/
        git status
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf) [ye53nis@node131 drmed-git]$ git status
        # On branch develop
        # Changes not staged for commit:
        #   (use "git add <file>..." to update what will be committed)
        #   (use "git checkout -- <file>..." to discard changes in working directory)
        #   (commit or discard the untracked or modified content in submodules)
        #
        #       modified:   src/nanosimpy (new commits, untracked content)
        #
        # Untracked files:
        #   (use "git add <file>..." to include in what will be committed)
        #
        #       .data/
        #       2021-03-20_correlations.csv
        #       data/0.069.svg
        #       data/exp-210204-unet/
        #       data/exp-devtest/
        #       data/exp-test/
        #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
        #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
        #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
        #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
        #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
        #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
        #       data/mlruns/0/52faa01e685f44ef97be4e64ddc88eb1/
        #       data/mlruns/0/5dc9fe4b91094df58e3d2f1426aa4d96/
        #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
        #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
        #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
        #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
        #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
        #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
        #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
        #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
        #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
        #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
        #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
        #       data/mlruns/2/
        #       data/mlruns/3/
        #       data/mlruns/4/
        #       data/mlruns/5/
        #       data/mlruns/6/
        #       data/tb/
        #       experiment_params.csv
        #       mlruns/
        #       tramp.YDPCnB
        no changes added to commit (use "git add" and/or "git commit -a")
        (tf) [ye53nis@node131 drmed-git]$ git log -3
        commit 7c727cb67011a21aff88f1cb803a09e2a524b79f
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 01:16:59 2021 +0200

            conda.yaml to tf; change hparams names for compat

        commit faeaba1172c5f1b6a3381d762518a0ed09ab1688
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 00:47:23 2021 +0200

            Big search_hparams update (see details)

            - remove hparams from click and MLproject, they are not as agile and flexible as
            I wanted. hparam space will have to be edited manually via git.
            - fix minor deprecation notice in F1Score
            - remove a lot of tensorboard logging - it is not needed, as mlflow handles
            everything I need (except distributions / histograms, which are logged anyway).
            Also changed write_images to False, since I am not sure if they are that useful
            for my traces.
            - add input_size (former length_delimiter), lr_start and lr_power as hparams
            - change tmp directory from global /tmp to local tmp folder, bc there was an
            issue with the hpc where no directory was created in /tmp
            - add new learning rate decay as a function giving either a linear (power=1) or
            a polynomial (power>1) decay + new logging of the learning rates as a
            stringified list (thanks mlflow...)
            - add conditional model saving and best run tag for the best validation AUC.
            Remove logging every model
            - load validation data via an own folder (cleaner, better control)

        commit e3a98f974f55e066a679c20003383dd97a7574a3
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Tue Aug 3 22:52:46 2021 +0200

            Add F1Score; Add facecolor; generalize tfds_from_p
        (tf) [ye53nis@node131 drmed-git]$
      #+end_example

**** test run 5 - fixed hyperparameter training
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node131 drmed-git]$ mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/fir
       startifact_Nov2020_val
       2021/08/04 01:19:27 INFO mlflow.utils.conda: === Creating conda environment mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe ===
       Collecting package metadata (repodata.json): done
       Solving environment: done


       ==> WARNING: A newer version of conda exists. <==
         current version: 4.10.0
         latest version: 4.10.3

       Please update conda by running

           $ conda update -n base -c defaults conda



       Downloading and Extracting Packages
       pip-21.2.2           | 1.8 MB    | ################################################################################################################################################################################################ | 100%
       python-3.9.6         | 18.4 MB   | ################################################################################################################################################################################################ | 100%
       _libgcc_mutex-0.1    | 3 KB      | ################################################################################################################################################################################################ | 100%
       Preparing transaction: done
       Verifying transaction: done
       Executing transaction: done
       Installing pip dependencies: \ Ran pip subprocess with arguments:
       ['/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/bin/python', '-m', 'pip', 'install', '-U', '-r', '/beegfs/ye53nis/drmed-git/condaenv.yikj59c7.requirements.txt']
       Pip subprocess output:
       Collecting numpy==1.19.5
         Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)
       Collecting tensorflow
         Using cached tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)
       Collecting mlflow
         Using cached mlflow-1.19.0-py3-none-any.whl (14.4 MB)
       Collecting pandas
         Using cached pandas-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
       Collecting matplotlib
         Using cached matplotlib-3.4.2-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)
       Collecting scikit-learn
         Using cached scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)
       Requirement already satisfied: wheel~=0.35 in /home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages (from tensorflow->-r /beegfs/ye53nis/drmed-git/condaenv.yikj59c7.requirements.txt (line
        2)) (0.36.2)
       Collecting flatbuffers~=1.12.0
         Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
       Collecting termcolor~=1.1.0
         Using cached termcolor-1.1.0-py3-none-any.whl
       Collecting typing-extensions~=3.7.4
         Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)
       Collecting google-pasta~=0.2
         Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)
       Collecting tensorboard~=2.5
         Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)
       Collecting h5py~=3.1.0
         Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)
       Collecting absl-py~=0.10
         Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)
       Collecting opt-einsum~=3.3.0
         Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)
       Collecting keras-nightly~=2.5.0.dev
         Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)
       Collecting astunparse~=1.6.3
         Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
       Collecting wrapt~=1.12.1
         Using cached wrapt-1.12.1-py3-none-any.whl
       Collecting grpcio~=1.34.0
         Using cached grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)
       Collecting gast==0.4.0
         Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)
       Collecting protobuf>=3.9.2
         Using cached protobuf-3.17.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)
       Collecting six~=1.15.0
         Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)
       Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0
         Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)
       Collecting keras-preprocessing~=1.1.2
         Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
       Collecting entrypoints
         Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)
       Collecting alembic<=1.4.1
         Using cached alembic-1.4.1-py2.py3-none-any.whl
       Collecting sqlalchemy
         Using cached SQLAlchemy-1.4.22-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
       Collecting click>=7.0
         Using cached click-8.0.1-py3-none-any.whl (97 kB)
       Collecting requests>=2.17.3
         Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)
       Collecting prometheus-flask-exporter
         Using cached prometheus_flask_exporter-0.18.2-py3-none-any.whl
       Collecting gitpython>=2.1.0
         Using cached GitPython-3.1.18-py3-none-any.whl (170 kB)
       Collecting gunicorn
         Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)
       Collecting querystring-parser
         Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)
       Collecting Flask
         Using cached Flask-2.0.1-py3-none-any.whl (94 kB)
       Collecting pyyaml>=5.1
         Using cached PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)
       Collecting databricks-cli>=0.8.7
         Using cached databricks_cli-0.14.3-py3-none-any.whl
       Collecting docker>=4.0.0
         Using cached docker-5.0.0-py2.py3-none-any.whl (146 kB)
       Collecting pytz
         Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)
       Collecting sqlparse>=0.3.1
         Using cached sqlparse-0.4.1-py3-none-any.whl (42 kB)
       Collecting cloudpickle
         Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)
       Collecting packaging
         Using cached packaging-21.0-py3-none-any.whl (40 kB)
       Collecting python-dateutil>=2.7.3
         Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
       Collecting pyparsing>=2.2.1
         Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)
       Collecting cycler>=0.10
         Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)
       Collecting pillow>=6.2.0
         Using cached Pillow-8.3.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)
       Collecting kiwisolver>=1.0.1
         Using cached kiwisolver-1.3.1-cp39-cp39-manylinux1_x86_64.whl (1.2 MB)
       Collecting threadpoolctl>=2.0.0
         Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)
       Collecting joblib>=0.11
         Using cached joblib-1.0.1-py3-none-any.whl (303 kB)
       Collecting scipy>=0.19.1
         Downloading scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)
       Collecting python-editor>=0.3
         Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)
       Collecting Mako
         Using cached Mako-1.1.4-py2.py3-none-any.whl (75 kB)
       Collecting tabulate>=0.7.7
         Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)
       Collecting websocket-client>=0.32.0
         Using cached websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)
       Collecting gitdb<5,>=4.0.1
         Using cached gitdb-4.0.7-py3-none-any.whl (63 kB)
       Collecting smmap<5,>=3.0.1
         Using cached smmap-4.0.0-py2.py3-none-any.whl (24 kB)
       Requirement already satisfied: certifi>=2017.4.173in /home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages (from requests>=2.17.3->mlflow->-r /beegfs/ye53nis/drmed-git/condaenv.yikj59c7.r
       equirements.txt (line 3)) (2021.5.30)
       Collecting charset-normalizer~=2.0.0
         Downloading charset_normalizer-2.0.4-py3-none-any.whl (36 kB)
       Collecting urllib3<1.27,>=1.21.1
         Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)
       Collecting idna<4,>=2.5
         Using cached idna-3.2-py3-none-any.whl (59 kB)
       Collecting greenlet!=0.4.17
         Using cached greenlet-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)
       Collecting google-auth<2,>=1.6.3
         Using cached google_auth-1.34.0-py2.py3-none-any.whl (152 kB)
       Requirement already satisfied: setuptools>=41.0.0 in /home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow->-r /beegfs/ye53nis/drmed-git/condaenv.yikj59
       c7.requirements.txt (line 2)) (52.0.0.post20210125)
       Collecting werkzeug>=0.11.15
         Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)
       Collecting tensorboard-data-server<0.7.0,>=0.6.0
         Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)
       Collecting markdown>=2.6.8
         Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)
       Collecting tensorboard-plugin-wit>=1.6.0
         Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)
       Collecting google-auth-oauthlib<0.5,>=0.4.1
         Using cached google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)
       Collecting rsa<5,>=3.1.4
         Using cached rsa-4.7.2-py3-none-any.whl (34 kB)
       Collecting cachetools<5.0,>=2.0.0
         Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)
       Collecting pyasn1-modules>=0.2.1
         Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
       Collecting requests-oauthlib>=0.7.0
         Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)
       Collecting pyasn1<0.5.0,>=0.4.6
         Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
       Collecting oauthlib>=3.0.0
         Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)
       Collecting itsdangerous>=2.0
         Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)
       Collecting Jinja2>=3.0
         Using cached Jinja2-3.0.1-py3-none-any.whl (133 kB)
       Collecting MarkupSafe>=2.0
         Using cached MarkupSafe-2.0.1-cp39-cp39-manylinux2010_x86_64.whl (30 kB)
       Collecting prometheus-client
         Using cached prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)
       Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, six, rsa, requests, pyasn1-modules, oauthlib, MarkupSafe, cachetools, werkzeug, smmap, requests-oauthlib, Jinja2, itsdangerous, greenlet, google-auth, click, web
       socket-client, tensorboard-plugin-wit, tensorboard-data-server, tabulate, sqlalchemy, pytz, python-editor, python-dateutil, pyparsing, protobuf, prometheus-client, numpy, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, Flask, absl
       -py, wrapt, typing-extensions, threadpoolctl, termcolor, tensorflow-estimator, tensorboard, sqlparse, scipy, querystring-parser, pyyaml, prometheus-flask-exporter, pillow, pandas, packaging, opt-einsum, kiwisolver, keras-preprocessing,
        keras-nightly, joblib, h5py, gunicorn, google-pasta, gitpython, gast, flatbuffers, entrypoints, docker, databricks-cli, cycler, cloudpickle, astunparse, alembic, tensorflow, scikit-learn, mlflow, matplotlib
       Successfully installed Flask-2.0.1 Jinja2-3.0.1 Mako-1.1.4 MarkupSafe-2.0.1 absl-py-0.13.0 alembic-1.4.1 astunparse-1.6.3 cachetools-4.2.2 charset-normalizer-2.0.4 click-8.0.1 cloudpickle-1.6.0 cycler-0.10.0 databricks-cli-0.14.3 docke
       r-5.0.0 entrypoints-0.3 flatbuffers-1.12 gast-0.4.0 gitdb-4.0.7 gitpython-3.1.18 google-auth-1.34.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 greenlet-1.1.0 grpcio-1.34.1 gunicorn-20.1.0 h5py-3.1.0 idna-3.2 itsdangerous-2.0.1 jobli
       b-1.0.1 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.4 matplotlib-3.4.2 mlflow-1.19.0 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 packaging-21.0 pandas-1.3.1 pillow-8.3.1 prometheus-client-
       0.11.0 prometheus-flask-exporter-0.18.2 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-2.4.7 python-dateutil-2.8.2 python-editor-1.0.4 pytz-2021.1 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.26.0 requests-oauthlib-1.3
       .0 rsa-4.7.2 scikit-learn-0.24.2 scipy-1.7.1 six-1.15.0 smmap-4.0.0 sqlalchemy-1.4.22 sqlparse-0.4.1 tabulate-0.8.9 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.
       0 termcolor-1.1.0 threadpoolctl-2.2.0 typing-extensions-3.7.4.3 urllib3-1.26.6 websocket-client-1.1.0 werkzeug-2.0.1 wrapt-1.12.1

       done
       #
       # To activate this environment, use
       #
       #     $ conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe
       #
       # To deactivate an active environment, use
       #
       #     $ conda deactivate

       2021/08/04 01:23:24 INFO mlflow.projects.utils: === Created directory /tmp/tmpg8g9pu9q for downloading remote URIs passed to arguments of type 'path' ===
       2021/08/04 01:23:24 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/trai
       ning/search_hparams.py --num_session_groups 2 --fluotracify_path /beegfs/ye53nis/drmed-git/src --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val
       --col_per_example 3' in run with ID '0682046ee9914e928574db871c3582b3' ===
       2021-08-04 01:23:28.868769: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2.5.0
       2021-08-04 01:23:34.398402: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
       2021-08-04 01:23:34.444785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 01:23:34.444880: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 01:23:34.454794: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 01:23:34.454878: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       2021-08-04 01:23:34.458819: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
       2021-08-04 01:23:34.461056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
       2021-08-04 01:23:34.468900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
       2021-08-04 01:23:34.471940: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
       2021-08-04 01:23:34.474209: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 01:23:34.480254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D10_set009.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.08_set010.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set008.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set010.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D50_set008.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.6_set007.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set009.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.2_set008.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 900), (16384, 900), (16384, 900)]
       2021-08-04 01:25:52.071574: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-08-04 01:25:52.075481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 01:25:52.079840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       2021-08-04 01:25:52.079941: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 01:25:52.899443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
       2021-08-04 01:25:52.899512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
       2021-08-04 01:25:52.899525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
       2021-08-04 01:25:52.906030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38424 MB memory) -> physical GPU (device: 0, name: A100-PCIE-40GB, pci bu
       s id: 0000:02:00.0, compute capability: 8.0)
       number of examples: 2800

       number of examples: 900

       --- Running training session 1/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       2021-08-04 01:26:10.702478: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
       2021-08-04 01:26:10.916013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199875000 Hz
       2021-08-04 01:26:19.538753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 01:26:20.293389: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
       2021-08-04 01:26:21.255113: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 01:26:22.094488: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       2021-08-04 01:26:23.550612: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.615630: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.640108: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.651879: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.678173: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.712282: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.725071: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.767429: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.826300: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.839775: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.865783: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.908155: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.918556: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.936443: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.963389: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.972320: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:23.985965: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.002807: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.011416: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.022358: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.036415: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.047284: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.058878: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.071229: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.080626: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.083849: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.092979: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.102744: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.111130: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.121192: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.129839: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.132392: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.134990: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.137654: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.140335: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.143011: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.145651: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.148240: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.150924: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.153635: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.156430: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.159214: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.175133: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.189787: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.201556: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.220606: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.232102: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       2021-08-04 01:26:24.234365: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_grad_filter_ops.cc:1171 : Not found: No algorithm worked!
       Traceback (most recent call last):
         File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/search_hparams.py", line 423, in <module>
           hparams_run()
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1137, in __call__
           return self.main(*args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1062, in main
           rv = self.invoke(ctx)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
           return ctx.invoke(self.callback, **ctx.params)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 763, in invoke
           return __callback(*args, **kwargs)
         File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/search_hparams.py", line 391, in hparams_run
           best_auc_val = run_one(
         File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/search_hparams.py", line 292, in run_one
           result = model.fit(
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 490, in safe_patch_function
           patch_function.call(call_original, *args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 156, in call
           return cls().__call__(original, *args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 167, in __call__
           raise e
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 160, in __call__
           return self._patch_implementation(original, *args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 218, in _patch_implementation
           result = super(PatchWithManagedRun, self)._patch_implementation(
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/tensorflow.py", line 1097, in _patch_implementation
           history = original(inst, *args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py", line 448, in call_original
           original_result = original(*og_args, **og_kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py", line 1183, in fit
           tmp_logs = self.train_function(iterator)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py", line 889, in __call__
           result = self._call(*args, **kwds)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py", line 950, in _call
           return self._stateless_fn(*args, **kwds)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/function.py", line 3023, in __call__
           return graph_function._call_flat(
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/function.py", line 1960, in _call_flat
           return self._build_call_outputs(self._inference_function.call(
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/function.py", line 591, in call
           outputs = execute.execute(
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
           tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
       tensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!
                [[node gradient_tape/unet_depth9/conv1d_38/conv1d/Conv2DBackpropFilter (defined at home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:4
       48) ]] [Op:__inference_train_function_29342]

       Function call stack:
       train_function

       2021/08/04 01:26:26 ERROR mlflow.cli: === Run (ID '0682046ee9914e928574db871c3582b3') failed ===
       (tf) [ye53nis@node131 drmed-git]$ cd /beegfs/ye53nis/
     #+end_example

**** trying to fix GPU bug

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        cd /beegfs/ye53nis/drmed-git/
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf) [ye53nis@node131 drmed-git]$ git log -3
        commit cbd622fe1eb765fee68bbfa1422ff377beca252b
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 17:25:43 2021 +0200

            workaround for "no algorithm worked" gpu bug

        commit 7c727cb67011a21aff88f1cb803a09e2a524b79f
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 01:16:59 2021 +0200

            conda.yaml to tf; change hparams names for compat

        commit faeaba1172c5f1b6a3381d762518a0ed09ab1688
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 00:47:23 2021 +0200

            Big search_hparams update (see details)

            - remove hparams from click and MLproject, they are not as agile and flexible as
            I wanted. hparam space will have to be edited manually via git.
            - fix minor deprecation notice in F1Score
            - remove a lot of tensorboard logging - it is not needed, as mlflow handles
            everything I need (except distributions / histograms, which are logged anyway).
            Also changed write_images to False, since I am not sure if they are that useful
            for my traces.
            - add input_size (former length_delimiter), lr_start and lr_power as hparams
            - change tmp directory from global /tmp to local tmp folder, bc there was an
            issue with the hpc where no directory was created in /tmp
            - add new learning rate decay as a function giving either a linear (power=1) or
            a polynomial (power>1) decay + new logging of the learning rates as a
            stringified list (thanks mlflow...)
            - add conditional model saving and best run tag for the best validation AUC.
            Remove logging every model
            - load validation data via an own folder (cleaner, better control)
        (tf) [ye53nis@node131 drmed-git]$
      #+end_example

**** test run 6 - fixed hyperparameter training
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node131 drmed-git]$ mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/fir
       startifact_Nov2020_val
       2021/08/04 17:28:41 INFO mlflow.projects.utils: === Created directory /tmp/tmpugmq18pk for downloading remote URIs passed to arguments of type 'path' ===
       2021/08/04 17:28:41 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/trai
       ning/search_hparams.py --num_session_groups 2 --fluotracify_path /beegfs/ye53nis/drmed-git/src --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val
       --col_per_example 3' in run with ID '9affe15d5d0e4f7088ac2bbb0701c562' ===
       2021-08-04 17:29:02.753931: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2.5.0
       2021-08-04 17:29:28.499128: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
       2021-08-04 17:29:28.596550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 17:29:28.596673: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 17:29:28.749139: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 17:29:28.749232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       2021-08-04 17:29:28.780313: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
       2021-08-04 17:29:28.782233: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
       2021-08-04 17:29:28.872082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
       2021-08-04 17:29:28.906363: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
       2021-08-04 17:29:28.927168: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 17:29:28.936232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D10_set009.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.08_set010.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set008.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set010.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D50_set008.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.6_set007.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set009.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.2_set008.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 900), (16384, 900), (16384, 900)]
       2021-08-04 17:32:18.077242: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-08-04 17:32:18.081598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 17:32:18.085955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       2021-08-04 17:32:18.086050: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 17:32:18.507985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
       2021-08-04 17:32:18.508042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
       2021-08-04 17:32:18.508056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
       2021-08-04 17:32:18.513962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38424 MB memory) -> physical GPU (device: 0, name: A100-PCIE-40GB, pci bu
       s id: 0000:02:00.0, compute capability: 8.0)
       number of examples: 2800

       number of examples: 900

       --- Running training session 1/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       2021-08-04 17:32:39.558117: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
       2021-08-04 17:32:39.772345: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199875000 Hz
       2021-08-04 17:32:48.474116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 17:32:49.168940: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
       2021-08-04 17:32:50.055062: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 17:32:50.939576: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       500/500 [==============================] - 95s 138ms/step - loss: 0.8730 - tp0.1: 5475014.0000 - fp0.1: 9281821.0000 - tn0.1: 25250176.0000 - fn0.1: 952983.0000 - precision0.1: 0.3710 - recall0.1: 0.8517 - tp0.3: 4383357.0000 - fp0.3:
       2951081.0000 - tn0.3: 31580908.0000 - fn0.3: 2044640.0000 - precision0.3: 0.5976 - recall0.3: 0.6819 - tp0.5: 3509588.0000 - fp0.5: 814381.0000 - tn0.5: 33717616.0000 - fn0.5: 2918409.0000 - precision0.5: 0.8117 - recall0.5: 0.5460 - t
       p0.7: 3015750.0000 - fp0.7: 299703.0000 - tn0.7: 34232300.0000 - fn0.7: 3412247.0000 - precision0.7: 0.9096 - recall0.7: 0.4692 - tp0.9: 2477484.0000 - fp0.9: 84243.0000 - tn0.9: 34447792.0000 - fn0.9: 3950513.0000 - precision0.9: 0.96
       71 - recall0.9: 0.3854 - accuracy: 0.9089 - auc: 0.8797 - f1: 0.2713 - val_loss: 183.9564 - val_tp0.1: 1468853.0000 - val_fp0.1: 6563104.0000 - val_tn0.1: 148181.0000 - val_fn0.1: 11862.0000 - val_precision0.1: 0.1829 - val_recall0.1:
       0.9920 - val_tp0.3: 1463700.0000 - val_fp0.3: 6540313.0000 - val_tn0.3: 170972.0000 - val_fn0.3: 17015.0000 - val_precision0.3: 0.1829 - val_recall0.3: 0.9885 - val_tp0.5: 1458202.0000 - val_fp0.5: 6527203.0000 - val_tn0.5: 184082.0000
        - val_fn0.5: 22513.0000 - val_precision0.5: 0.1826 - val_recall0.5: 0.9848 - val_tp0.7: 1454015.0000 - val_fp0.7: 6520494.0000 - val_tn0.7: 190791.0000 - val_fn0.7: 26700.0000 - val_precision0.7: 0.1823 - val_recall0.7: 0.9820 - val_t
       p0.9: 1445230.0000 - val_fp0.9: 6508106.0000 - val_tn0.9: 203179.0000 - val_fn0.9: 35485.0000 - val_precision0.9: 0.1817 - val_recall0.9: 0.9760 - val_accuracy: 0.2005 - val_auc: 0.4986 - val_f1: 0.3062
       Epoch 2/3
       500/500 [==============================] - 64s 128ms/step - loss: 0.6758 - tp0.1: 5665104.0000 - fp0.1: 7823106.0000 - tn0.1: 26763320.0000 - fn0.1: 708475.0000 - precision0.1: 0.4200 - recall0.1: 0.8888 - tp0.3: 4626678.0000 - fp0.3:
       2831353.0000 - tn0.3: 31755090.0000 - fn0.3: 1746901.0000 - precision0.3: 0.6204 - recall0.3: 0.7259 - tp0.5: 3729448.0000 - fp0.5: 895757.0000 - tn0.5: 33690656.0000 - fn0.5: 2644131.0000 - precision0.5: 0.8063 - recall0.5: 0.5851 - t
       p0.7: 3168570.0000 - fp0.7: 317433.0000 - tn0.7: 34268976.0000 - fn0.7: 3205009.0000 - precision0.7: 0.9089 - recall0.7: 0.4971 - tp0.9: 2539527.0000 - fp0.9: 70181.0000 - tn0.9: 34516244.0000 - fn0.9: 3834052.0000 - precision0.9: 0.97
       31 - recall0.9: 0.3984 - accuracy: 0.9136 - auc: 0.9023 - f1: 0.2693 - val_loss: 0.8668 - val_tp0.1: 1378841.0000 - val_fp0.1: 3837148.0000 - val_tn0.1: 2942277.0000 - val_fn0.1: 33734.0000 - val_precision0.1: 0.2643 - val_recall0.1: 0
       .9761 - val_tp0.3: 1330737.0000 - val_fp0.3: 2625598.0000 - val_tn0.3: 4153827.0000 - val_fn0.3: 81838.0000 - val_precision0.3: 0.3364 - val_recall0.3: 0.9421 - val_tp0.5: 1065686.0000 - val_fp0.5: 537444.0000 - val_tn0.5: 6241981.0000
        - val_fn0.5: 346889.0000 - val_precision0.5: 0.6648 - val_recall0.5: 0.7544 - val_tp0.7: 819995.0000 - val_fp0.7: 58147.0000 - val_tn0.7: 6721278.0000 - val_fn0.7: 592580.0000 - val_precision0.7: 0.9338 - val_recall0.7: 0.5805 - val_t
       p0.9: 607957.0000 - val_fp0.9: 3164.0000 - val_tn0.9: 6776261.0000 - val_fn0.9: 804618.0000 - val_precision0.9: 0.9948 - val_recall0.9: 0.4304 - val_accuracy: 0.8920 - val_auc: 0.9215 - val_f1: 0.2941
       Epoch 3/3
       500/500 [==============================] - 64s 128ms/step - loss: 0.5919 - tp0.1: 6007967.0000 - fp0.1: 7406941.0000 - tn0.1: 27024452.0000 - fn0.1: 520637.0000 - precision0.1: 0.4479 - recall0.1: 0.9203 - tp0.3: 5091688.0000 - fp0.3:
       3189258.0000 - tn0.3: 31242148.0000 - fn0.3: 1436916.0000 - precision0.3: 0.6149 - recall0.3: 0.7799 - tp0.5: 4134601.0000 - fp0.5: 1114206.0000 - tn0.5: 33317194.0000 - fn0.5: 2394003.0000 - precision0.5: 0.7877 - recall0.5: 0.6333 -
       tp0.7: 3396170.0000 - fp0.7: 341897.0000 - tn0.7: 34089496.0000 - fn0.7: 3132434.0000 - precision0.7: 0.9085 - recall0.7: 0.5202 - tp0.9: 2669876.0000 - fp0.9: 76253.0000 - tn0.9: 34355144.0000 - fn0.9: 3858728.0000 - precision0.9: 0.9
       722 - recall0.9: 0.4090 - accuracy: 0.9144 - auc: 0.9203 - f1: 0.2750 - val_loss: 1.3201 - val_tp0.1: 861165.0000 - val_fp0.1: 68038.0000 - val_tn0.1: 6649151.0000 - val_fn0.1: 613646.0000 - val_precision0.1: 0.9268 - val_recall0.1: 0.
       5839 - val_tp0.3: 791102.0000 - val_fp0.3: 31498.0000 - val_tn0.3: 6685691.0000 - val_fn0.3: 683709.0000 - val_precision0.3: 0.9617 - val_recall0.3: 0.5364 - val_tp0.5: 711173.0000 - val_fp0.5: 13480.0000 - val_tn0.5: 6703709.0000 - va
       l_fn0.5: 763638.0000 - val_precision0.5: 0.9814 - val_recall0.5: 0.4822 - val_tp0.7: 630577.0000 - val_fp0.7: 5643.0000 - val_tn0.7: 6711546.0000 - val_fn0.7: 844234.0000 - val_precision0.7: 0.9911 - val_recall0.7: 0.4276 - val_tp0.9:
       511455.0000 - val_fp0.9: 1986.0000 - val_tn0.9: 6715203.0000 - val_fn0.9: 963356.0000 - val_precision0.9: 0.9961 - val_recall0.9: 0.3468 - val_accuracy: 0.9051 - val_auc: 0.7910 - val_f1: 0.3051
       2021-08-04 17:36:35.806305: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       --- Running training session 2/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 90s 138ms/step - loss: 0.8913 - tp0.1: 5607505.0000 - fp0.1: 9496502.0000 - tn0.1: 25004216.0000 - fn0.1: 851791.0000 - precision0.1: 0.3713 - recall0.1: 0.8681 - tp0.3: 4400145.0000 - fp0.3:
       3020958.0000 - tn0.3: 31479736.0000 - fn0.3: 2059151.0000 - precision0.3: 0.5929 - recall0.3: 0.6812 - tp0.5: 3485710.0000 - fp0.5: 787535.0000 - tn0.5: 33713180.0000 - fn0.5: 2973586.0000 - precision0.5: 0.8157 - recall0.5: 0.5396 - t
       p0.7: 3009588.0000 - fp0.7: 303653.0000 - tn0.7: 34197048.0000 - fn0.7: 3449708.0000 - precision0.7: 0.9084 - recall0.7: 0.4659 - tp0.9: 2492995.0000 - fp0.9: 86538.0000 - tn0.9: 34414168.0000 - fn0.9: 3966301.0000 - precision0.9: 0.96
       65 - recall0.9: 0.3860 - accuracy: 0.9082 - auc: 0.8834 - f1: 0.2724 - val_loss: 1.1559 - val_tp0.1: 838655.0000 - val_fp0.1: 100610.0000 - val_tn0.1: 6644884.0000 - val_fn0.1: 607851.0000 - val_precision0.1: 0.8929 - val_recall0.1: 0.
       5798 - val_tp0.3: 785579.0000 - val_fp0.3: 59597.0000 - val_tn0.3: 6685897.0000 - val_fn0.3: 660927.0000 - val_precision0.3: 0.9295 - val_recall0.3: 0.5431 - val_tp0.5: 700637.0000 - val_fp0.5: 21193.0000 - val_tn0.5: 6724301.0000 - va
       l_fn0.5: 745869.0000 - val_precision0.5: 0.9706 - val_recall0.5: 0.4844 - val_tp0.7: 618377.0000 - val_fp0.7: 5653.0000 - val_tn0.7: 6739841.0000 - val_fn0.7: 828129.0000 - val_precision0.7: 0.9909 - val_recall0.7: 0.4275 - val_tp0.9:
       513181.0000 - val_fp0.9: 739.0000 - val_tn0.9: 6744755.0000 - val_fn0.9: 933325.0000 - val_precision0.9: 0.9986 - val_recall0.9: 0.3548 - val_accuracy: 0.9064 - val_auc: 0.7981 - val_f1: 0.3002
       Epoch 2/3
       500/500 [==============================] - 64s 129ms/step - loss: 0.6595 - tp0.1: 5765317.0000 - fp0.1: 7727348.0000 - tn0.1: 26819878.0000 - fn0.1: 647455.0000 - precision0.1: 0.4273 - recall0.1: 0.8990 - tp0.3: 4640759.0000 - fp0.3:
       2785369.0000 - tn0.3: 31761876.0000 - fn0.3: 1772013.0000 - precision0.3: 0.6249 - recall0.3: 0.7237 - tp0.5: 3754523.0000 - fp0.5: 892257.0000 - tn0.5: 33654992.0000 - fn0.5: 2658249.0000 - precision0.5: 0.8080 - recall0.5: 0.5855 - t
       p0.7: 3185619.0000 - fp0.7: 349597.0000 - tn0.7: 34197632.0000 - fn0.7: 3227153.0000 - precision0.7: 0.9011 - recall0.7: 0.4968 - tp0.9: 2501811.0000 - fp0.9: 79557.0000 - tn0.9: 34467668.0000 - fn0.9: 3910961.0000 - precision0.9: 0.96
       92 - recall0.9: 0.3901 - accuracy: 0.9133 - auc: 0.9058 - f1: 0.2707 - val_loss: 1.0026 - val_tp0.1: 1061354.0000 - val_fp0.1: 367034.0000 - val_tn0.1: 6339501.0000 - val_fn0.1: 424111.0000 - val_precision0.1: 0.7430 - val_recall0.1: 0
       .7145 - val_tp0.3: 1016237.0000 - val_fp0.3: 260341.0000 - val_tn0.3: 6446194.0000 - val_fn0.3: 469228.0000 - val_precision0.3: 0.7961 - val_recall0.3: 0.6841 - val_tp0.5: 885229.0000 - val_fp0.5: 79214.0000 - val_tn0.5: 6627321.0000 -
        val_fn0.5: 600236.0000 - val_precision0.5: 0.9179 - val_recall0.5: 0.5959 - val_tp0.7: 691320.0000 - val_fp0.7: 7507.0000 - val_tn0.7: 6699028.0000 - val_fn0.7: 794145.0000 - val_precision0.7: 0.9893 - val_recall0.7: 0.4654 - val_tp0.
       9: 507656.0000 - val_fp0.9: 764.0000 - val_tn0.9: 6705771.0000 - val_fn0.9: 977809.0000 - val_precision0.9: 0.9985 - val_recall0.9: 0.3417 - val_accuracy: 0.9171 - val_auc: 0.8501 - val_f1: 0.3070
       Epoch 3/3
       500/500 [==============================] - 64s 129ms/step - loss: 0.5963 - tp0.1: 5795774.0000 - fp0.1: 6529806.0000 - tn0.1: 28012928.0000 - fn0.1: 621493.0000 - precision0.1: 0.4702 - recall0.1: 0.9032 - tp0.3: 5004661.0000 - fp0.3:
       3329830.0000 - tn0.3: 31212892.0000 - fn0.3: 1412606.0000 - precision0.3: 0.6005 - recall0.3: 0.7799 - tp0.5: 4056576.0000 - fp0.5: 878536.0000 - tn0.5: 33664216.0000 - fn0.5: 2360691.0000 - precision0.5: 0.8220 - recall0.5: 0.6321 - t
       p0.7: 3506547.0000 - fp0.7: 336656.0000 - tn0.7: 34206056.0000 - fn0.7: 2910720.0000 - precision0.7: 0.9124 - recall0.7: 0.5464 - tp0.9: 2778171.0000 - fp0.9: 74299.0000 - tn0.9: 34468436.0000 - fn0.9: 3639096.0000 - precision0.9: 0.97
       40 - recall0.9: 0.4329 - accuracy: 0.9209 - auc: 0.9182 - f1: 0.2709 - val_loss: 0.6599 - val_tp0.1: 1394526.0000 - val_fp0.1: 1895831.0000 - val_tn0.1: 4793769.0000 - val_fn0.1: 107874.0000 - val_precision0.1: 0.4238 - val_recall0.1:
       0.9282 - val_tp0.3: 1080605.0000 - val_fp0.3: 309605.0000 - val_tn0.3: 6379995.0000 - val_fn0.3: 421795.0000 - val_precision0.3: 0.7773 - val_recall0.3: 0.7193 - val_tp0.5: 928444.0000 - val_fp0.5: 95728.0000 - val_tn0.5: 6593872.0000
       - val_fn0.5: 573956.0000 - val_precision0.5: 0.9065 - val_recall0.5: 0.6180 - val_tp0.7: 813820.0000 - val_fp0.7: 34852.0000 - val_tn0.7: 6654748.0000 - val_fn0.7: 688580.0000 - val_precision0.7: 0.9589 - val_recall0.7: 0.5417 - val_tp
       0.9: 598360.0000 - val_fp0.9: 1321.0000 - val_tn0.9: 6688279.0000 - val_fn0.9: 904040.0000 - val_precision0.9: 0.9978 - val_recall0.9: 0.3983 - val_accuracy: 0.9183 - val_auc: 0.9256 - val_f1: 0.3100
       --- Running training session 3/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 59s 87ms/step - loss: 0.8351 - tp0.1: 5640072.0000 - fp0.1: 10257778.0000 - tn0.1: 24348344.0000 - fn0.1: 713817.0000 - precision0.1: 0.3548 - recall0.1: 0.8877 - tp0.3: 4365516.0000 - fp0.3:
       2767269.0000 - tn0.3: 31838848.0000 - fn0.3: 1988373.0000 - precision0.3: 0.6120 - recall0.3: 0.6871 - tp0.5: 3670902.0000 - fp0.5: 897197.0000 - tn0.5: 33708932.0000 - fn0.5: 2682987.0000 - precision0.5: 0.8036 - recall0.5: 0.5777 - t
       p0.7: 3125620.0000 - fp0.7: 307705.0000 - tn0.7: 34298420.0000 - fn0.7: 3228269.0000 - precision0.7: 0.9104 - recall0.7: 0.4919 - tp0.9: 2476224.0000 - fp0.9: 74240.0000 - tn0.9: 34531864.0000 - fn0.9: 3877665.0000 - precision0.9: 0.97
       09 - recall0.9: 0.3897 - accuracy: 0.9126 - auc: 0.8927 - f1: 0.2686 - val_loss: 0.9890 - val_tp0.1: 981937.0000 - val_fp0.1: 183309.0000 - val_tn0.1: 6551685.0000 - val_fn0.1: 475069.0000 - val_precision0.1: 0.8427 - val_recall0.1: 0.
       6739 - val_tp0.3: 964991.0000 - val_fp0.3: 157582.0000 - val_tn0.3: 6577412.0000 - val_fn0.3: 492015.0000 - val_precision0.3: 0.8596 - val_recall0.3: 0.6623 - val_tp0.5: 921108.0000 - val_fp0.5: 115535.0000 - val_tn0.5: 6619459.0000 -
       val_fn0.5: 535898.0000 - val_precision0.5: 0.8885 - val_recall0.5: 0.6322 - val_tp0.7: 823784.0000 - val_fp0.7: 56522.0000 - val_tn0.7: 6678472.0000 - val_fn0.7: 633222.0000 - val_precision0.7: 0.9358 - val_recall0.7: 0.5654 - val_tp0.
       9: 620330.0000 - val_fp0.9: 4429.0000 - val_tn0.9: 6730565.0000 - val_fn0.9: 836676.0000 - val_precision0.9: 0.9929 - val_recall0.9: 0.4258 - val_accuracy: 0.9205 - val_auc: 0.8322 - val_f1: 0.3020
       Epoch 2/3
       500/500 [==============================] - 40s 79ms/step - loss: 0.7016 - tp0.1: 5987838.0000 - fp0.1: 9931951.0000 - tn0.1: 24461332.0000 - fn0.1: 578877.0000 - precision0.1: 0.3761 - recall0.1: 0.9118 - tp0.3: 4510204.0000 - fp0.3: 2
       589957.0000 - tn0.3: 31803338.0000 - fn0.3: 2056511.0000 - precision0.3: 0.6352 - recall0.3: 0.6868 - tp0.5: 3830066.0000 - fp0.5: 880283.0000 - tn0.5: 33513006.0000 - fn0.5: 2736649.0000 - precision0.5: 0.8131 - recall0.5: 0.5833 - tp
       0.7: 3285868.0000 - fp0.7: 338547.0000 - tn0.7: 34054724.0000 - fn0.7: 3280847.0000 - precision0.7: 0.9066 - recall0.7: 0.5004 - tp0.9: 2532947.0000 - fp0.9: 65212.0000 - tn0.9: 34328072.0000 - fn0.9: 4033768.0000 - precision0.9: 0.974
       9 - recall0.9: 0.3857 - accuracy: 0.9117 - auc: 0.8984 - f1: 0.2763 - val_loss: 0.7358 - val_tp0.1: 1365510.0000 - val_fp0.1: 2723181.0000 - val_tn0.1: 4032759.0000 - val_fn0.1: 70550.0000 - val_precision0.1: 0.3340 - val_recall0.1: 0.
       9509 - val_tp0.3: 1003845.0000 - val_fp0.3: 232194.0000 - val_tn0.3: 6523746.0000 - val_fn0.3: 432215.0000 - val_precision0.3: 0.8121 - val_recall0.3: 0.6990 - val_tp0.5: 820372.0000 - val_fp0.5: 42683.0000 - val_tn0.5: 6713257.0000 -
       val_fn0.5: 615688.0000 - val_precision0.5: 0.9505 - val_recall0.5: 0.5713 - val_tp0.7: 708868.0000 - val_fp0.7: 10887.0000 - val_tn0.7: 6745053.0000 - val_fn0.7: 727192.0000 - val_precision0.7: 0.9849 - val_recall0.7: 0.4936 - val_tp0.
       9: 545906.0000 - val_fp0.9: 1114.0000 - val_tn0.9: 6754826.0000 - val_fn0.9: 890154.0000 - val_precision0.9: 0.9980 - val_recall0.9: 0.3801 - val_accuracy: 0.9196 - val_auc: 0.9233 - val_f1: 0.2983
       Epoch 3/3
       500/500 [==============================] - 40s 80ms/step - loss: 0.6704 - tp0.1: 5965528.0000 - fp0.1: 9672327.0000 - tn0.1: 24780768.0000 - fn0.1: 541385.0000 - precision0.1: 0.3815 - recall0.1: 0.9168 - tp0.3: 4622629.0000 - fp0.3: 2
       647031.0000 - tn0.3: 31806060.0000 - fn0.3: 1884284.0000 - precision0.3: 0.6359 - recall0.3: 0.7104 - tp0.5: 3932959.0000 - fp0.5: 904070.0000 - tn0.5: 33549024.0000 - fn0.5: 2573954.0000 - precision0.5: 0.8131 - recall0.5: 0.6044 - tp
       0.7: 3392990.0000 - fp0.7: 347744.0000 - tn0.7: 34105372.0000 - fn0.7: 3113923.0000 - precision0.7: 0.9070 - recall0.7: 0.5214 - tp0.9: 2621960.0000 - fp0.9: 65762.0000 - tn0.9: 34387308.0000 - fn0.9: 3884953.0000 - precision0.9: 0.975
       5 - recall0.9: 0.4029 - accuracy: 0.9151 - auc: 0.9059 - f1: 0.2742 - val_loss: 0.6881 - val_tp0.1: 1355413.0000 - val_fp0.1: 2285403.0000 - val_tn0.1: 4454778.0000 - val_fn0.1: 96406.0000 - val_precision0.1: 0.3723 - val_recall0.1: 0.
       9336 - val_tp0.3: 1028628.0000 - val_fp0.3: 283957.0000 - val_tn0.3: 6456224.0000 - val_fn0.3: 423191.0000 - val_precision0.3: 0.7837 - val_recall0.3: 0.7085 - val_tp0.5: 892319.0000 - val_fp0.5: 92137.0000 - val_tn0.5: 6648044.0000 -
       val_fn0.5: 559500.0000 - val_precision0.5: 0.9064 - val_recall0.5: 0.6146 - val_tp0.7: 783009.0000 - val_fp0.7: 30834.0000 - val_tn0.7: 6709347.0000 - val_fn0.7: 668810.0000 - val_precision0.7: 0.9621 - val_recall0.7: 0.5393 - val_tp0.
       9: 604295.0000 - val_fp0.9: 2997.0000 - val_tn0.9: 6737184.0000 - val_fn0.9: 847524.0000 - val_precision0.9: 0.9951 - val_recall0.9: 0.4162 - val_accuracy: 0.9205 - val_auc: 0.9180 - val_f1: 0.3011
       --- Running training session 4/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 58s 87ms/step - loss: 0.7889 - tp0.1: 5669918.0000 - fp0.1: 10256284.0000 - tn0.1: 24321200.0000 - fn0.1: 712606.0000 - precision0.1: 0.3560 - recall0.1: 0.8884 - tp0.3: 4369201.0000 - fp0.3:
       2770010.0000 - tn0.3: 31807464.0000 - fn0.3: 2013323.0000 - precision0.3: 0.6120 - recall0.3: 0.6846 - tp0.5: 3686534.0000 - fp0.5: 960194.0000 - tn0.5: 33617256.0000 - fn0.5: 2695990.0000 - precision0.5: 0.7934 - recall0.5: 0.5776 - t
       p0.7: 3146676.0000 - fp0.7: 359852.0000 - tn0.7: 34217620.0000 - fn0.7: 3235848.0000 - precision0.7: 0.8974 - recall0.7: 0.4930 - tp0.9: 2418580.0000 - fp0.9: 79976.0000 - tn0.9: 34497496.0000 - fn0.9: 3963944.0000 - precision0.9: 0.96
       80 - recall0.9: 0.3789 - accuracy: 0.9107 - auc: 0.8888 - f1: 0.2696 - val_loss: 0.7050 - val_tp0.1: 1373223.0000 - val_fp0.1: 2744071.0000 - val_tn0.1: 4017386.0000 - val_fn0.1: 57320.0000 - val_precision0.1: 0.3335 - val_recall0.1: 0
       .9599 - val_tp0.3: 1177235.0000 - val_fp0.3: 866483.0000 - val_tn0.3: 5894974.0000 - val_fn0.3: 253308.0000 - val_precision0.3: 0.5760 - val_recall0.3: 0.8229 - val_tp0.5: 1045222.0000 - val_fp0.5: 386506.0000 - val_tn0.5: 6374951.0000
        - val_fn0.5: 385321.0000 - val_precision0.5: 0.7300 - val_recall0.5: 0.7306 - val_tp0.7: 926806.0000 - val_fp0.7: 157543.0000 - val_tn0.7: 6603914.0000 - val_fn0.7: 503737.0000 - val_precision0.7: 0.8547 - val_recall0.7: 0.6479 - val_
       tp0.9: 694371.0000 - val_fp0.9: 11446.0000 - val_tn0.9: 6750011.0000 - val_fn0.9: 736172.0000 - val_precision0.9: 0.9838 - val_recall0.9: 0.4854 - val_accuracy: 0.9058 - val_auc: 0.9272 - val_f1: 0.2973
       Epoch 2/3
       500/500 [==============================] - 40s 79ms/step - loss: 0.6470 - tp0.1: 5890598.0000 - fp0.1: 9388637.0000 - tn0.1: 25169516.0000 - fn0.1: 511257.0000 - precision0.1: 0.3855 - recall0.1: 0.9201 - tp0.3: 4577983.0000 - fp0.3: 2
       576307.0000 - tn0.3: 31981856.0000 - fn0.3: 1823872.0000 - precision0.3: 0.6399 - recall0.3: 0.7151 - tp0.5: 3816365.0000 - fp0.5: 746481.0000 - tn0.5: 33811644.0000 - fn0.5: 2585490.0000 - precision0.5: 0.8364 - recall0.5: 0.5961 - tp
       0.7: 3385771.0000 - fp0.7: 308733.0000 - tn0.7: 34249392.0000 - fn0.7: 3016084.0000 - precision0.7: 0.9164 - recall0.7: 0.5289 - tp0.9: 2736434.0000 - fp0.9: 78415.0000 - tn0.9: 34479740.0000 - fn0.9: 3665421.0000 - precision0.9: 0.972
       1 - recall0.9: 0.4274 - accuracy: 0.9187 - auc: 0.9099 - f1: 0.2703 - val_loss: 0.6849 - val_tp0.1: 1377446.0000 - val_fp0.1: 2608788.0000 - val_tn0.1: 4148249.0000 - val_fn0.1: 57517.0000 - val_precision0.1: 0.3456 - val_recall0.1: 0.
       9599 - val_tp0.3: 1166332.0000 - val_fp0.3: 778757.0000 - val_tn0.3: 5978280.0000 - val_fn0.3: 268631.0000 - val_precision0.3: 0.5996 - val_recall0.3: 0.8128 - val_tp0.5: 1065889.0000 - val_fp0.5: 390473.0000 - val_tn0.5: 6366564.0000
       - val_fn0.5: 369074.0000 - val_precision0.5: 0.7319 - val_recall0.5: 0.7428 - val_tp0.7: 981571.0000 - val_fp0.7: 247914.0000 - val_tn0.7: 6509123.0000 - val_fn0.7: 453392.0000 - val_precision0.7: 0.7984 - val_recall0.7: 0.6840 - val_t
       p0.9: 637682.0000 - val_fp0.9: 8835.0000 - val_tn0.9: 6748202.0000 - val_fn0.9: 797281.0000 - val_precision0.9: 0.9863 - val_recall0.9: 0.4444 - val_accuracy: 0.9073 - val_auc: 0.9269 - val_f1: 0.2981
       Epoch 3/3
       500/500 [==============================] - 40s 79ms/step - loss: 0.6399 - tp0.1: 5918008.0000 - fp0.1: 8740990.0000 - tn0.1: 25757746.0000 - fn0.1: 543268.0000 - precision0.1: 0.4037 - recall0.1: 0.9159 - tp0.3: 4563979.0000 - fp0.3: 2
       347884.0000 - tn0.3: 32150828.0000 - fn0.3: 1897297.0000 - precision0.3: 0.6603 - recall0.3: 0.7064 - tp0.5: 3893237.0000 - fp0.5: 706441.0000 - tn0.5: 33792304.0000 - fn0.5: 2568039.0000 - precision0.5: 0.8464 - recall0.5: 0.6025 - tp
       0.7: 3484617.0000 - fp0.7: 302510.0000 - tn0.7: 34196232.0000 - fn0.7: 2976659.0000 - precision0.7: 0.9201 - recall0.7: 0.5393 - tp0.9: 2849563.0000 - fp0.9: 72130.0000 - tn0.9: 34426588.0000 - fn0.9: 3611713.0000 - precision0.9: 0.975
       3 - recall0.9: 0.4410 - accuracy: 0.9201 - auc: 0.9104 - f1: 0.2725 - val_loss: 0.6677 - val_tp0.1: 1418577.0000 - val_fp0.1: 2365481.0000 - val_tn0.1: 4330392.0000 - val_fn0.1: 77550.0000 - val_precision0.1: 0.3749 - val_recall0.1: 0.
       9482 - val_tp0.3: 1104127.0000 - val_fp0.3: 329436.0000 - val_tn0.3: 6366437.0000 - val_fn0.3: 392000.0000 - val_precision0.3: 0.7702 - val_recall0.3: 0.7380 - val_tp0.5: 914154.0000 - val_fp0.5: 53904.0000 - val_tn0.5: 6641969.0000 -
       val_fn0.5: 581973.0000 - val_precision0.5: 0.9443 - val_recall0.5: 0.6110 - val_tp0.7: 826451.0000 - val_fp0.7: 23645.0000 - val_tn0.7: 6672228.0000 - val_fn0.7: 669676.0000 - val_precision0.7: 0.9722 - val_recall0.7: 0.5524 - val_tp0.
       9: 716521.0000 - val_fp0.9: 6940.0000 - val_tn0.9: 6688933.0000 - val_fn0.9: 779606.0000 - val_precision0.9: 0.9904 - val_recall0.9: 0.4789 - val_accuracy: 0.9224 - val_auc: 0.9275 - val_f1: 0.3089
       WARNING:root:Malformed run '1e98b3ed2e1d421da9592058bd5587a8'. Detailed error Yaml file './data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 724, in _list_run_infos
           run_info = self._get_run_info_from_dir(r_dir)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 554, in _get_run_info_from_dir
           meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/file_utils.py", line 175, in read_yaml
           raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
       mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/meta.yaml' does not exist.
       WARNING:root:Malformed run '.trash'. Detailed error Yaml file './data/mlruns/0/.trash/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 724, in _list_run_infos
           run_info = self._get_run_info_from_dir(r_dir)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 554, in _get_run_info_from_dir
           meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/file_utils.py", line 175, in read_yaml
           raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
       mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/0/.trash/meta.yaml' does not exist.
       WARNING:root:Malformed run '037e1d9e4ad74784974f4aaac11138cc'. Detailed error Yaml file './data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 724, in _list_run_infos
           run_info = self._get_run_info_from_dir(r_dir)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 554, in _get_run_info_from_dir
           meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/file_utils.py", line 175, in read_yaml
           raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
       mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/meta.yaml' does not exist.
       WARNING:root:Malformed run '306234c75c9c48058cbd694579eff31b'. Detailed error Yaml file './data/mlruns/0/306234c75c9c48058cbd694579eff31b/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 724, in _list_run_infos
           run_info = self._get_run_info_from_dir(r_dir)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 554, in _get_run_info_from_dir
           meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/file_utils.py", line 175, in read_yaml
           raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
       mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/0/306234c75c9c48058cbd694579eff31b/meta.yaml' does not exist.
       WARNING:root:Malformed run 'd9b44dc2e3d44ea1a71129808b642af6'. Detailed error Yaml file './data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 724, in _list_run_infos
           run_info = self._get_run_info_from_dir(r_dir)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py", line 554, in _get_run_info_from_dir
           meta = read_yaml(run_dir, FileStore.META_DATA_FILE_NAME)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/mlflow/utils/file_utils.py", line 175, in read_yaml
           raise MissingConfigException("Yaml file '%s' does not exist." % file_path)
       mlflow.exceptions.MissingConfigException: Yaml file './data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/meta.yaml' does not exist.
       Traceback (most recent call last):
         File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/search_hparams.py", line 431, in <module>
           hparams_run()
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1137, in __call__
           return self.main(*args, **kwargs)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1062, in main
           rv = self.invoke(ctx)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 1404, in invoke
           return ctx.invoke(self.callback, **ctx.params)
         File "/home/ye53nis/.conda/envs/mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe/lib/python3.9/site-packages/click/core.py", line 763, in invoke
           return __callback(*args, **kwargs)
         File "/beegfs/ye53nis/drmed-git/src/fluotracify/training/search_hparams.py", line 423, in hparams_run
           mlflow.set_tag("best_run", best_run.info.run_id)
       UnboundLocalError: local variable 'best_run' referenced before assignment
       2021/08/04 17:47:21 ERROR mlflow.cli: === Run (ID '9affe15d5d0e4f7088ac2bbb0701c562') failed ===
       (tf) [ye53nis@node131 drmed-git]$
     #+end_example

**** trying to fix best_run bug

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        cd /beegfs/ye53nis/drmed-git/
        git log -3
      #+END_SRC

      #+RESULTS:
      #+begin_example
        (tf) [ye53nis@node131 drmed-git]$ git log -3
        commit 26447bff9b9ed3b9ab691fc4c9ac351519af2436
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 22:36:06 2021 +0200

            Fix mlflow best run logging

        commit c1a6f0285ed991987200e8a6fb09ad24d502c352
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 18:00:14 2021 +0200

            Try fixing "best_run referenced before assignment"

        commit cbd622fe1eb765fee68bbfa1422ff377beca252b
        Author: Apoplex <oligolex@vivaldi.net>
        Date:   Wed Aug 4 17:25:43 2021 +0200

            workaround for "no algorithm worked" gpu bug
        (tf) [ye53nis@node131 drmed-git]$
      #+end_example

**** test run 7 - finally fixed hyperparameter training
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node131 drmed-git]$ mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/fir
       startifact_Nov2020_val
       2021/08/04 22:38:08 INFO mlflow.projects.utils: === Created directory /tmp/tmpew62btq6 for downloading remote URIs passed to arguments of type 'path' ===
       2021/08/04 22:38:08 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/trai
       ning/search_hparams.py --num_session_groups 2 --fluotracify_path /beegfs/ye53nis/drmed-git/src --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val
       --col_per_example 3' in run with ID '35233ce8221741c4983b7d5101cc2faf' ===
       2021-08-04 22:38:11.168487: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2.5.0
       2021-08-04 22:38:16.842134: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
       2021-08-04 22:38:16.896169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 22:38:16.896273: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 22:38:16.905566: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 22:38:16.905657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       2021-08-04 22:38:16.908939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
       2021-08-04 22:38:16.910578: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
       2021-08-04 22:38:16.918753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
       2021-08-04 22:38:16.921298: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
       2021-08-04 22:38:16.923006: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 22:38:16.929597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D10_set009.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.08_set010.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set008.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set010.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D50_set008.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.6_set007.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set009.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.2_set008.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 900), (16384, 900), (16384, 900)]
       2021-08-04 22:40:54.662817: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-08-04 22:40:54.666686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-04 22:40:54.670846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       2021-08-04 22:40:54.670942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-04 22:40:55.069333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
       2021-08-04 22:40:55.069409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
       2021-08-04 22:40:55.069424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
       2021-08-04 22:40:55.075342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38424 MB memory) -> physical GPU (device: 0, name: A100-PCIE-40GB, pci bu
       s id: 0000:02:00.0, compute capability: 8.0)
       number of examples: 2800

       number of examples: 900

       --- Running training session 1/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       2021-08-04 22:41:13.338916: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
       2021-08-04 22:41:13.553226: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199875000 Hz
       2021-08-04 22:41:22.188741: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-04 22:41:22.871530: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
       2021-08-04 22:41:23.798757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-04 22:41:24.475616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       500/500 [==============================] - 93s 136ms/step - loss: 0.8042 - tp0.1: 5641692.0000 - fp0.1: 9604892.0000 - tn0.1: 24902332.0000 - fn0.1: 811087.0000 - precision0.1: 0.3700 - recall0.1: 0.8743 - tp0.3: 4312543.0000 - fp0.3:
       2776336.0000 - tn0.3: 31730892.0000 - fn0.3: 2140236.0000 - precision0.3: 0.6084 - recall0.3: 0.6683 - tp0.5: 3549293.0000 - fp0.5: 830982.0000 - tn0.5: 33676232.0000 - fn0.5: 2903486.0000 - precision0.5: 0.8103 - recall0.5: 0.5500 - t
       p0.7: 3049494.0000 - fp0.7: 331981.0000 - tn0.7: 34175228.0000 - fn0.7: 3403285.0000 - precision0.7: 0.9018 - recall0.7: 0.4726 - tp0.9: 2459662.0000 - fp0.9: 89251.0000 - tn0.9: 34417976.0000 - fn0.9: 3993117.0000 - precision0.9: 0.96
       50 - recall0.9: 0.3812 - accuracy: 0.9088 - auc: 0.8854 - f1: 0.2722 - val_loss: 0.7131 - val_tp0.1: 1447641.0000 - val_fp0.1: 2725381.0000 - val_tn0.1: 3968266.0000 - val_fn0.1: 50712.0000 - val_precision0.1: 0.3469 - val_recall0.1: 0
       .9662 - val_tp0.3: 1225810.0000 - val_fp0.3: 923408.0000 - val_tn0.3: 5770239.0000 - val_fn0.3: 272543.0000 - val_precision0.3: 0.5704 - val_recall0.3: 0.8181 - val_tp0.5: 1060284.0000 - val_fp0.5: 340163.0000 - val_tn0.5: 6353484.0000
        - val_fn0.5: 438069.0000 - val_precision0.5: 0.7571 - val_recall0.5: 0.7076 - val_tp0.7: 947154.0000 - val_fp0.7: 147667.0000 - val_tn0.7: 6545980.0000 - val_fn0.7: 551199.0000 - val_precision0.7: 0.8651 - val_recall0.7: 0.6321 - val_
       tp0.9: 783359.0000 - val_fp0.9: 32228.0000 - val_tn0.9: 6661419.0000 - val_fn0.9: 714994.0000 - val_precision0.9: 0.9605 - val_recall0.9: 0.5228 - val_accuracy: 0.9050 - val_auc: 0.9254 - val_f1: 0.3092
       Epoch 2/3
       500/500 [==============================] - 63s 127ms/step - loss: 0.6541 - tp0.1: 5804435.0000 - fp0.1: 8013033.0000 - tn0.1: 26531728.0000 - fn0.1: 610796.0000 - precision0.1: 0.4201 - recall0.1: 0.9048 - tp0.3: 4462556.0000 - fp0.3:
       2317920.0000 - tn0.3: 32226846.0000 - fn0.3: 1952675.0000 - precision0.3: 0.6581 - recall0.3: 0.6956 - tp0.5: 3851976.0000 - fp0.5: 986325.0000 - tn0.5: 33558448.0000 - fn0.5: 2563255.0000 - precision0.5: 0.7961 - recall0.5: 0.6004 - t
       p0.7: 3264000.0000 - fp0.7: 368345.0000 - tn0.7: 34176440.0000 - fn0.7: 3151231.0000 - precision0.7: 0.8986 - recall0.7: 0.5088 - tp0.9: 2532029.0000 - fp0.9: 74535.0000 - tn0.9: 34470240.0000 - fn0.9: 3883202.0000 - precision0.9: 0.97
       14 - recall0.9: 0.3947 - accuracy: 0.9133 - auc: 0.9047 - f1: 0.2708 - val_loss: 0.6426 - val_tp0.1: 1363586.0000 - val_fp0.1: 1175634.0000 - val_tn0.1: 5489141.0000 - val_fn0.1: 163639.0000 - val_precision0.1: 0.5370 - val_recall0.1:
       0.8929 - val_tp0.3: 1081857.0000 - val_fp0.3: 307670.0000 - val_tn0.3: 6357105.0000 - val_fn0.3: 445368.0000 - val_precision0.3: 0.7786 - val_recall0.3: 0.7084 - val_tp0.5: 933013.0000 - val_fp0.5: 114177.0000 - val_tn0.5: 6550598.0000
        - val_fn0.5: 594212.0000 - val_precision0.5: 0.8910 - val_recall0.5: 0.6109 - val_tp0.7: 797929.0000 - val_fp0.7: 31228.0000 - val_tn0.7: 6633547.0000 - val_fn0.7: 729296.0000 - val_precision0.7: 0.9623 - val_recall0.7: 0.5225 - val_t
       p0.9: 618313.0000 - val_fp0.9: 3186.0000 - val_tn0.9: 6661589.0000 - val_fn0.9: 908912.0000 - val_precision0.9: 0.9949 - val_recall0.9: 0.4049 - val_accuracy: 0.9135 - val_auc: 0.9179 - val_f1: 0.3143
       Epoch 3/3
       500/500 [==============================] - 63s 126ms/step - loss: 0.6043 - tp0.1: 5877391.0000 - fp0.1: 7612817.0000 - tn0.1: 26931248.0000 - fn0.1: 538531.0000 - precision0.1: 0.4357 - recall0.1: 0.9161 - tp0.3: 4709475.0000 - fp0.3:
       2731832.0000 - tn0.3: 31812252.0000 - fn0.3: 1706447.0000 - precision0.3: 0.6329 - recall0.3: 0.7340 - tp0.5: 3946724.0000 - fp0.5: 911022.0000 - tn0.5: 33633056.0000 - fn0.5: 2469198.0000 - precision0.5: 0.8125 - recall0.5: 0.6151 - t
       p0.7: 3358238.0000 - fp0.7: 324193.0000 - tn0.7: 34219880.0000 - fn0.7: 3057684.0000 - precision0.7: 0.9120 - recall0.7: 0.5234 - tp0.9: 2644443.0000 - fp0.9: 77127.0000 - tn0.9: 34466948.0000 - fn0.9: 3771479.0000 - precision0.9: 0.97
       17 - recall0.9: 0.4122 - accuracy: 0.9175 - auc: 0.9156 - f1: 0.2709 - val_loss: 0.9509 - val_tp0.1: 1472593.0000 - val_fp0.1: 4351331.0000 - val_tn0.1: 2351189.0000 - val_fn0.1: 16887.0000 - val_precision0.1: 0.2529 - val_recall0.1: 0
       .9887 - val_tp0.3: 1052817.0000 - val_fp0.3: 300202.0000 - val_tn0.3: 6402318.0000 - val_fn0.3: 436663.0000 - val_precision0.3: 0.7781 - val_recall0.3: 0.7068 - val_tp0.5: 665675.0000 - val_fp0.5: 8549.0000 - val_tn0.5: 6693971.0000 -
       val_fn0.5: 823805.0000 - val_precision0.5: 0.9873 - val_recall0.5: 0.4469 - val_tp0.7: 432515.0000 - val_fp0.7: 1187.0000 - val_tn0.7: 6701333.0000 - val_fn0.7: 1056965.0000 - val_precision0.7: 0.9973 - val_recall0.7: 0.2904 - val_tp0.
       9: 317052.0000 - val_fp0.9: 279.0000 - val_tn0.9: 6702241.0000 - val_fn0.9: 1172428.0000 - val_precision0.9: 0.9991 - val_recall0.9: 0.2129 - val_accuracy: 0.8984 - val_auc: 0.9097 - val_f1: 0.3077
       2021-08-04 22:45:09.756420: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       --- Running training session 2/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 89s 136ms/step - loss: 0.7643 - tp0.1: 5755370.0000 - fp0.1: 8905100.0000 - tn0.1: 25553544.0000 - fn0.1: 745986.0000 - precision0.1: 0.3926 - recall0.1: 0.8853 - tp0.3: 4609840.0000 - fp0.3:
       3553837.0000 - tn0.3: 30904816.0000 - fn0.3: 1891516.0000 - precision0.3: 0.5647 - recall0.3: 0.7091 - tp0.5: 3520194.0000 - fp0.5: 826488.0000 - tn0.5: 33632144.0000 - fn0.5: 2981162.0000 - precision0.5: 0.8099 - recall0.5: 0.5415 - t
       p0.7: 3030989.0000 - fp0.7: 307747.0000 - tn0.7: 34150888.0000 - fn0.7: 3470367.0000 - precision0.7: 0.9078 - recall0.7: 0.4662 - tp0.9: 2489995.0000 - fp0.9: 86976.0000 - tn0.9: 34371680.0000 - fn0.9: 4011361.0000 - precision0.9: 0.96
       62 - recall0.9: 0.3830 - accuracy: 0.9070 - auc: 0.8914 - f1: 0.2740 - val_loss: 0.6980 - val_tp0.1: 1372348.0000 - val_fp0.1: 2594765.0000 - val_tn0.1: 4167074.0000 - val_fn0.1: 57813.0000 - val_precision0.1: 0.3459 - val_recall0.1: 0
       .9596 - val_tp0.3: 1099707.0000 - val_fp0.3: 580645.0000 - val_tn0.3: 6181194.0000 - val_fn0.3: 330454.0000 - val_precision0.3: 0.6545 - val_recall0.3: 0.7689 - val_tp0.5: 922917.0000 - val_fp0.5: 158551.0000 - val_tn0.5: 6603288.0000
       - val_fn0.5: 507244.0000 - val_precision0.5: 0.8534 - val_recall0.5: 0.6453 - val_tp0.7: 837068.0000 - val_fp0.7: 73151.0000 - val_tn0.7: 6688688.0000 - val_fn0.7: 593093.0000 - val_precision0.7: 0.9196 - val_recall0.7: 0.5853 - val_tp
       0.9: 727992.0000 - val_fp0.9: 20951.0000 - val_tn0.9: 6740888.0000 - val_fn0.9: 702169.0000 - val_precision0.9: 0.9720 - val_recall0.9: 0.5090 - val_accuracy: 0.9187 - val_auc: 0.9260 - val_f1: 0.2973
       Epoch 2/3
       500/500 [==============================] - 64s 127ms/step - loss: 0.6189 - tp0.1: 5994392.0000 - fp0.1: 7498394.0000 - tn0.1: 26908276.0000 - fn0.1: 558929.0000 - precision0.1: 0.4443 - recall0.1: 0.9147 - tp0.3: 4992491.0000 - fp0.3:
       3449646.0000 - tn0.3: 30957048.0000 - fn0.3: 1560830.0000 - precision0.3: 0.5914 - recall0.3: 0.7618 - tp0.5: 3889785.0000 - fp0.5: 889921.0000 - tn0.5: 33516764.0000 - fn0.5: 2663536.0000 - precision0.5: 0.8138 - recall0.5: 0.5936 - t
       p0.7: 3319193.0000 - fp0.7: 335719.0000 - tn0.7: 34070960.0000 - fn0.7: 3234128.0000 - precision0.7: 0.9081 - recall0.7: 0.5065 - tp0.9: 2626983.0000 - fp0.9: 78108.0000 - tn0.9: 34328560.0000 - fn0.9: 3926338.0000 - precision0.9: 0.97
       11 - recall0.9: 0.4009 - accuracy: 0.9132 - auc: 0.9137 - f1: 0.2759 - val_loss: 0.7179 - val_tp0.1: 1376553.0000 - val_fp0.1: 2519612.0000 - val_tn0.1: 4212516.0000 - val_fn0.1: 83319.0000 - val_precision0.1: 0.3533 - val_recall0.1: 0
       .9429 - val_tp0.3: 1301250.0000 - val_fp0.3: 1497335.0000 - val_tn0.3: 5234793.0000 - val_fn0.3: 158622.0000 - val_precision0.3: 0.4650 - val_recall0.3: 0.8913 - val_tp0.5: 974071.0000 - val_fp0.5: 222331.0000 - val_tn0.5: 6509797.0000
        - val_fn0.5: 485801.0000 - val_precision0.5: 0.8142 - val_recall0.5: 0.6672 - val_tp0.7: 801763.0000 - val_fp0.7: 51388.0000 - val_tn0.7: 6680740.0000 - val_fn0.7: 658109.0000 - val_precision0.7: 0.9398 - val_recall0.7: 0.5492 - val_t
       p0.9: 644627.0000 - val_fp0.9: 8312.0000 - val_tn0.9: 6723816.0000 - val_fn0.9: 815245.0000 - val_precision0.9: 0.9873 - val_recall0.9: 0.4416 - val_accuracy: 0.9136 - val_auc: 0.9198 - val_f1: 0.3025
       Epoch 3/3
       500/500 [==============================] - 64s 127ms/step - loss: 0.6038 - tp0.1: 5704132.0000 - fp0.1: 7041375.0000 - tn0.1: 27616262.0000 - fn0.1: 598230.0000 - precision0.1: 0.4475 - recall0.1: 0.9051 - tp0.3: 4794860.0000 - fp0.3:
       2888251.0000 - tn0.3: 31769406.0000 - fn0.3: 1507502.0000 - precision0.3: 0.6241 - recall0.3: 0.7608 - tp0.5: 3870922.0000 - fp0.5: 887603.0000 - tn0.5: 33770036.0000 - fn0.5: 2431440.0000 - precision0.5: 0.8135 - recall0.5: 0.6142 - t
       p0.7: 3329963.0000 - fp0.7: 320572.0000 - tn0.7: 34337076.0000 - fn0.7: 2972399.0000 - precision0.7: 0.9122 - recall0.7: 0.5284 - tp0.9: 2652683.0000 - fp0.9: 73533.0000 - tn0.9: 34584096.0000 - fn0.9: 3649679.0000 - precision0.9: 0.97
       30 - recall0.9: 0.4209 - accuracy: 0.9190 - auc: 0.9154 - f1: 0.2667 - val_loss: 0.6428 - val_tp0.1: 1328091.0000 - val_fp0.1: 2080194.0000 - val_tn0.1: 4694199.0000 - val_fn0.1: 89516.0000 - val_precision0.1: 0.3897 - val_recall0.1: 0
       .9369 - val_tp0.3: 1240255.0000 - val_fp0.3: 1322809.0000 - val_tn0.3: 5451584.0000 - val_fn0.3: 177352.0000 - val_precision0.3: 0.4839 - val_recall0.3: 0.8749 - val_tp0.5: 916429.0000 - val_fp0.5: 94120.0000 - val_tn0.5: 6680273.0000
       - val_fn0.5: 501178.0000 - val_precision0.5: 0.9069 - val_recall0.5: 0.6465 - val_tp0.7: 802304.0000 - val_fp0.7: 28326.0000 - val_tn0.7: 6746067.0000 - val_fn0.7: 615303.0000 - val_precision0.7: 0.9659 - val_recall0.7: 0.5660 - val_tp
       0.9: 650972.0000 - val_fp0.9: 2811.0000 - val_tn0.9: 6771582.0000 - val_fn0.9: 766635.0000 - val_precision0.9: 0.9957 - val_recall0.9: 0.4592 - val_accuracy: 0.9273 - val_auc: 0.9250 - val_f1: 0.2950
       --- Running training session 3/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 59s 86ms/step - loss: 0.7778 - tp0.1: 5607708.0000 - fp0.1: 9777951.0000 - tn0.1: 24821988.0000 - fn0.1: 752374.0000 - precision0.1: 0.3645 - recall0.1: 0.8817 - tp0.3: 4412756.0000 - fp0.3: 2
       963524.0000 - tn0.3: 31636396.0000 - fn0.3: 1947326.0000 - precision0.3: 0.5982 - recall0.3: 0.6938 - tp0.5: 3641774.0000 - fp0.5: 892009.0000 - tn0.5: 33707912.0000 - fn0.5: 2718308.0000 - precision0.5: 0.8033 - recall0.5: 0.5726 - tp
       0.7: 3136317.0000 - fp0.7: 323322.0000 - tn0.7: 34276592.0000 - fn0.7: 3223765.0000 - precision0.7: 0.9065 - recall0.7: 0.4931 - tp0.9: 2480579.0000 - fp0.9: 68412.0000 - tn0.9: 34531500.0000 - fn0.9: 3879503.0000 - precision0.9: 0.973
       2 - recall0.9: 0.3900 - accuracy: 0.9119 - auc: 0.8909 - f1: 0.2688 - val_loss: 1.0945 - val_tp0.1: 993536.0000 - val_fp0.1: 202775.0000 - val_tn0.1: 6485224.0000 - val_fn0.1: 510465.0000 - val_precision0.1: 0.8305 - val_recall0.1: 0.6
       606 - val_tp0.3: 929918.0000 - val_fp0.3: 126935.0000 - val_tn0.3: 6561064.0000 - val_fn0.3: 574083.0000 - val_precision0.3: 0.8799 - val_recall0.3: 0.6183 - val_tp0.5: 841780.0000 - val_fp0.5: 57015.0000 - val_tn0.5: 6630984.0000 - va
       l_fn0.5: 662221.0000 - val_precision0.5: 0.9366 - val_recall0.5: 0.5597 - val_tp0.7: 740352.0000 - val_fp0.7: 19660.0000 - val_tn0.7: 6668339.0000 - val_fn0.7: 763649.0000 - val_precision0.7: 0.9741 - val_recall0.7: 0.4923 - val_tp0.9:
        599985.0000 - val_fp0.9: 3877.0000 - val_tn0.9: 6684122.0000 - val_fn0.9: 904016.0000 - val_precision0.9: 0.9936 - val_recall0.9: 0.3989 - val_accuracy: 0.9122 - val_auc: 0.8250 - val_f1: 0.3102
       Epoch 2/3
       500/500 [==============================] - 40s 79ms/step - loss: 0.6627 - tp0.1: 5985933.0000 - fp0.1: 9420216.0000 - tn0.1: 25027872.0000 - fn0.1: 525964.0000 - precision0.1: 0.3885 - recall0.1: 0.9192 - tp0.3: 4627174.0000 - fp0.3: 2
       807965.0000 - tn0.3: 31640130.0000 - fn0.3: 1884723.0000 - precision0.3: 0.6223 - recall0.3: 0.7106 - tp0.5: 3851072.0000 - fp0.5: 860585.0000 - tn0.5: 33587508.0000 - fn0.5: 2660825.0000 - precision0.5: 0.8173 - recall0.5: 0.5914 - tp
       0.7: 3340676.0000 - fp0.7: 326966.0000 - tn0.7: 34121172.0000 - fn0.7: 3171221.0000 - precision0.7: 0.9109 - recall0.7: 0.5130 - tp0.9: 2631962.0000 - fp0.9: 68532.0000 - tn0.9: 34379576.0000 - fn0.9: 3879935.0000 - precision0.9: 0.974
       6 - recall0.9: 0.4042 - accuracy: 0.9140 - auc: 0.9073 - f1: 0.2743 - val_loss: 0.7115 - val_tp0.1: 1395809.0000 - val_fp0.1: 2221965.0000 - val_tn0.1: 4478526.0000 - val_fn0.1: 95700.0000 - val_precision0.1: 0.3858 - val_recall0.1: 0.
       9358 - val_tp0.3: 996063.0000 - val_fp0.3: 217541.0000 - val_tn0.3: 6482950.0000 - val_fn0.3: 495446.0000 - val_precision0.3: 0.8207 - val_recall0.3: 0.6678 - val_tp0.5: 794832.0000 - val_fp0.5: 32772.0000 - val_tn0.5: 6667719.0000 - v
       al_fn0.5: 696677.0000 - val_precision0.5: 0.9604 - val_recall0.5: 0.5329 - val_tp0.7: 644550.0000 - val_fp0.7: 5059.0000 - val_tn0.7: 6695432.0000 - val_fn0.7: 846959.0000 - val_precision0.7: 0.9922 - val_recall0.7: 0.4321 - val_tp0.9:
        462974.0000 - val_fp0.9: 511.0000 - val_tn0.9: 6699980.0000 - val_fn0.9: 1028535.0000 - val_precision0.9: 0.9989 - val_recall0.9: 0.3104 - val_accuracy: 0.9110 - val_auc: 0.9167 - val_f1: 0.3081
       Epoch 3/3
       500/500 [==============================] - 40s 79ms/step - loss: 0.6672 - tp0.1: 5920817.0000 - fp0.1: 9314216.0000 - tn0.1: 25159448.0000 - fn0.1: 565527.0000 - precision0.1: 0.3886 - recall0.1: 0.9128 - tp0.3: 4558789.0000 - fp0.3: 2
       507828.0000 - tn0.3: 31965812.0000 - fn0.3: 1927555.0000 - precision0.3: 0.6451 - recall0.3: 0.7028 - tp0.5: 3829652.0000 - fp0.5: 773133.0000 - tn0.5: 33700552.0000 - fn0.5: 2656692.0000 - precision0.5: 0.8320 - recall0.5: 0.5904 - tp
       0.7: 3348055.0000 - fp0.7: 312985.0000 - tn0.7: 34160684.0000 - fn0.7: 3138289.0000 - precision0.7: 0.9145 - recall0.7: 0.5162 - tp0.9: 2630627.0000 - fp0.9: 69603.0000 - tn0.9: 34404048.0000 - fn0.9: 3855717.0000 - precision0.9: 0.974
       2 - recall0.9: 0.4056 - accuracy: 0.9163 - auc: 0.9062 - f1: 0.2734 - val_loss: 0.6953 - val_tp0.1: 1382121.0000 - val_fp0.1: 2628238.0000 - val_tn0.1: 4114476.0000 - val_fn0.1: 67165.0000 - val_precision0.1: 0.3446 - val_recall0.1: 0.
       9537 - val_tp0.3: 974211.0000 - val_fp0.3: 198600.0000 - val_tn0.3: 6544114.0000 - val_fn0.3: 475075.0000 - val_precision0.3: 0.8307 - val_recall0.3: 0.6722 - val_tp0.5: 848306.0000 - val_fp0.5: 63985.0000 - val_tn0.5: 6678729.0000 - v
       al_fn0.5: 600980.0000 - val_precision0.5: 0.9299 - val_recall0.5: 0.5853 - val_tp0.7: 751966.0000 - val_fp0.7: 21923.0000 - val_tn0.7: 6720791.0000 - val_fn0.7: 697320.0000 - val_precision0.7: 0.9717 - val_recall0.7: 0.5189 - val_tp0.9
       : 595464.0000 - val_fp0.9: 2799.0000 - val_tn0.9: 6739915.0000 - val_fn0.9: 853822.0000 - val_precision0.9: 0.9953 - val_recall0.9: 0.4109 - val_accuracy: 0.9188 - val_auc: 0.9227 - val_f1: 0.3006
       --- Running training session 4/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 58s 86ms/step - loss: 0.8807 - tp0.1: 5739160.0000 - fp0.1: 10436654.0000 - tn0.1: 24008664.0000 - fn0.1: 775526.0000 - precision0.1: 0.3548 - recall0.1: 0.8810 - tp0.3: 4471210.0000 - fp0.3:
       2932399.0000 - tn0.3: 31512928.0000 - fn0.3: 2043476.0000 - precision0.3: 0.6039 - recall0.3: 0.6863 - tp0.5: 3714300.0000 - fp0.5: 918995.0000 - tn0.5: 33526324.0000 - fn0.5: 2800386.0000 - precision0.5: 0.8017 - recall0.5: 0.5701 - t
       p0.7: 3159511.0000 - fp0.7: 329224.0000 - tn0.7: 34116092.0000 - fn0.7: 3355175.0000 - precision0.7: 0.9056 - recall0.7: 0.4850 - tp0.9: 2454177.0000 - fp0.9: 74628.0000 - tn0.9: 34370668.0000 - fn0.9: 4060509.0000 - precision0.9: 0.97
       05 - recall0.9: 0.3767 - accuracy: 0.9092 - auc: 0.8872 - f1: 0.2744 - val_loss: 0.7190 - val_tp0.1: 1360668.0000 - val_fp0.1: 2764841.0000 - val_tn0.1: 4001484.0000 - val_fn0.1: 65007.0000 - val_precision0.1: 0.3298 - val_recall0.1: 0
       .9544 - val_tp0.3: 1200713.0000 - val_fp0.3: 1047749.0000 - val_tn0.3: 5718576.0000 - val_fn0.3: 224962.0000 - val_precision0.3: 0.5340 - val_recall0.3: 0.8422 - val_tp0.5: 1046253.0000 - val_fp0.5: 391003.0000 - val_tn0.5: 6375322.000
       0 - val_fn0.5: 379422.0000 - val_precision0.5: 0.7280 - val_recall0.5: 0.7339 - val_tp0.7: 935055.0000 - val_fp0.7: 169852.0000 - val_tn0.7: 6596473.0000 - val_fn0.7: 490620.0000 - val_precision0.7: 0.8463 - val_recall0.7: 0.6559 - val
       _tp0.9: 768348.0000 - val_fp0.9: 34054.0000 - val_tn0.9: 6732271.0000 - val_fn0.9: 657327.0000 - val_precision0.9: 0.9576 - val_recall0.9: 0.5389 - val_accuracy: 0.9060 - val_auc: 0.9242 - val_f1: 0.2965
       Epoch 2/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6863 - tp0.1: 5883322.0000 - fp0.1: 9694103.0000 - tn0.1: 24821196.0000 - fn0.1: 561369.0000 - precision0.1: 0.3777 - recall0.1: 0.9129 - tp0.3: 4377304.0000 - fp0.3: 2
       281154.0000 - tn0.3: 32234148.0000 - fn0.3: 2067387.0000 - precision0.3: 0.6574 - recall0.3: 0.6792 - tp0.5: 3742603.0000 - fp0.5: 827495.0000 - tn0.5: 33687816.0000 - fn0.5: 2702088.0000 - precision0.5: 0.8189 - recall0.5: 0.5807 - tp
       0.7: 3241393.0000 - fp0.7: 320006.0000 - tn0.7: 34195300.0000 - fn0.7: 3203298.0000 - precision0.7: 0.9101 - recall0.7: 0.5030 - tp0.9: 2540697.0000 - fp0.9: 66971.0000 - tn0.9: 34448344.0000 - fn0.9: 3903994.0000 - precision0.9: 0.974
       3 - recall0.9: 0.3942 - accuracy: 0.9138 - auc: 0.8988 - f1: 0.2719 - val_loss: 0.6747 - val_tp0.1: 1368997.0000 - val_fp0.1: 2264191.0000 - val_tn0.1: 4473748.0000 - val_fn0.1: 85064.0000 - val_precision0.1: 0.3768 - val_recall0.1: 0.
       9415 - val_tp0.3: 1001298.0000 - val_fp0.3: 292205.0000 - val_tn0.3: 6445734.0000 - val_fn0.3: 452763.0000 - val_precision0.3: 0.7741 - val_recall0.3: 0.6886 - val_tp0.5: 888983.0000 - val_fp0.5: 118276.0000 - val_tn0.5: 6619663.0000 -
        val_fn0.5: 565078.0000 - val_precision0.5: 0.8826 - val_recall0.5: 0.6114 - val_tp0.7: 773454.0000 - val_fp0.7: 37594.0000 - val_tn0.7: 6700345.0000 - val_fn0.7: 680607.0000 - val_precision0.7: 0.9536 - val_recall0.7: 0.5319 - val_tp0
       .9: 619198.0000 - val_fp0.9: 4449.0000 - val_tn0.9: 6733490.0000 - val_fn0.9: 834863.0000 - val_precision0.9: 0.9929 - val_recall0.9: 0.4258 - val_accuracy: 0.9166 - val_auc: 0.9198 - val_f1: 0.3015
       Epoch 3/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6401 - tp0.1: 5848922.0000 - fp0.1: 9032319.0000 - tn0.1: 25569392.0000 - fn0.1: 509372.0000 - precision0.1: 0.3930 - recall0.1: 0.9199 - tp0.3: 4431719.0000 - fp0.3: 2
       322183.0000 - tn0.3: 32279500.0000 - fn0.3: 1926575.0000 - precision0.3: 0.6562 - recall0.3: 0.6970 - tp0.5: 3822816.0000 - fp0.5: 890769.0000 - tn0.5: 33710932.0000 - fn0.5: 2535478.0000 - precision0.5: 0.8110 - recall0.5: 0.6012 - tp
       0.7: 3245936.0000 - fp0.7: 314473.0000 - tn0.7: 34287224.0000 - fn0.7: 3112358.0000 - precision0.7: 0.9117 - recall0.7: 0.5105 - tp0.9: 2544889.0000 - fp0.9: 67882.0000 - tn0.9: 34533828.0000 - fn0.9: 3813405.0000 - precision0.9: 0.974
       0 - recall0.9: 0.4002 - accuracy: 0.9164 - auc: 0.9084 - f1: 0.2687 - val_loss: 0.6660 - val_tp0.1: 1332292.0000 - val_fp0.1: 2497327.0000 - val_tn0.1: 4296806.0000 - val_fn0.1: 65575.0000 - val_precision0.1: 0.3479 - val_recall0.1: 0.
       9531 - val_tp0.3: 1020928.0000 - val_fp0.3: 280397.0000 - val_tn0.3: 6513736.0000 - val_fn0.3: 376939.0000 - val_precision0.3: 0.7845 - val_recall0.3: 0.7303 - val_tp0.5: 865746.0000 - val_fp0.5: 72514.0000 - val_tn0.5: 6721619.0000 -
       val_fn0.5: 532121.0000 - val_precision0.5: 0.9227 - val_recall0.5: 0.6193 - val_tp0.7: 737598.0000 - val_fp0.7: 17707.0000 - val_tn0.7: 6776426.0000 - val_fn0.7: 660269.0000 - val_precision0.7: 0.9766 - val_recall0.7: 0.5277 - val_tp0.
       9: 568187.0000 - val_fp0.9: 1799.0000 - val_tn0.9: 6792334.0000 - val_fn0.9: 829680.0000 - val_precision0.9: 0.9968 - val_recall0.9: 0.4065 - val_accuracy: 0.9262 - val_auc: 0.9303 - val_f1: 0.2915
       2021/08/04 22:56:08 INFO mlflow.projects: === Run (ID '35233ce8221741c4983b7d5101cc2faf') succeeded ===
       (tf) [ye53nis@node131 drmed-git]$
     #+end_example

**** test run 8 - it works!!

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       conda activate tf
       cd /beegfs/ye53nis/drmed-git
       export MLFLOW_EXPERIMENT_NAME=exp-210805-test
       export MLFLOW_TRACKING_URI=file:/beegfs/ye53nis/drmed-git/data/mlruns
       mkdir data/exp-210805-test
     #+END_SRC

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node131 drmed-git]$ mlflow run . -e search_hparams -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample -P csv_path_val=/beegfs/ye53nis/saves/fir
       startifact_Nov2020_val
       INFO: 'exp-210805-test' does not exist. Creating a new experiment
       2021/08/05 01:05:05 INFO mlflow.projects.utils: === Created directory /tmp/tmp8y4n_toe for downloading remote URIs passed to arguments of type 'path' ===
       2021/08/05 01:05:05 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/trai
       ning/search_hparams.py --num_session_groups 2 --fluotracify_path /beegfs/ye53nis/drmed-git/src --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample --csv_path_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val
       --col_per_example 3' in run with ID '09f12eb855fb4bd99b5105fb5f3e58b4' ===
       2021-08-05 01:05:08.963892: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2.5.0
       2021-08-05 01:05:14.578650: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
       2021-08-05 01:05:14.631165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-05 01:05:14.631263: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-05 01:05:14.639676: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-05 01:05:14.639764: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       2021-08-05 01:05:14.642677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
       2021-08-05 01:05:14.644044: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
       2021-08-05 01:05:14.651442: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
       2021-08-05 01:05:14.653450: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
       2021-08-05 01:05:14.654640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-05 01:05:14.660689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set002.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set001.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set004.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set004.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set003.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set004.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set010.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set001.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set006.csv
       9 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set004.csv
       10 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set001.csv
       11 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set009.csv
       12 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set002.csv
       13 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set009.csv
       14 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D50_set006.csv
       15 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set003.csv
       16 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.1_set004.csv
       17 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set007.csv
       18 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D1.0_set010.csv
       19 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set003.csv
       20 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set009.csv
       21 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.2_set001.csv
       22 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D3.0_set005.csv
       23 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.08_set004.csv
       24 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.069_set002.csv
       25 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D10_set010.csv
       26 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.6_set010.csv
       27 /beegfs/ye53nis/saves/firstartifact_Nov2020_train_subsample/traces_brightclust_Nov2020_D0.4_set006.csv
       0 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D10_set009.csv
       1 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.08_set010.csv
       2 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set008.csv
       3 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set010.csv
       4 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D50_set008.csv
       5 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.6_set007.csv
       6 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.1_set009.csv
       7 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.069_set007.csv
       8 /beegfs/ye53nis/saves/firstartifact_Nov2020_val/traces_brightclust_Nov2020_D0.2_set008.csv
       The given DataFrame was split into 3 parts with shapes: [(16384, 2800), (16384, 2800), (16384, 2800)]
       The given DataFrame was split into 3 parts with shapes: [(16384, 900), (16384, 900), (16384, 900)]
       2021-08-05 01:08:10.518655: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operati
       ons:  AVX2 FMA
       To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
       2021-08-05 01:08:10.522942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
       pciBusID: 0000:02:00.0 name: A100-PCIE-40GB computeCapability: 8.0
       coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
       2021-08-05 01:08:10.527141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
       2021-08-05 01:08:10.527237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
       2021-08-05 01:08:10.924169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
       2021-08-05 01:08:10.924225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
       2021-08-05 01:08:10.924239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
       2021-08-05 01:08:10.930420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38424 MB memory) -> physical GPU (device: 0, name: A100-PCIE-40GB, pci bu
       s id: 0000:02:00.0, compute capability: 8.0)
       number of examples: 2800

       number of examples: 900

       --- Running training session 1/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       2021-08-05 01:08:30.333411: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
       2021-08-05 01:08:30.548468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199875000 Hz
       2021-08-05 01:08:39.200416: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
       2021-08-05 01:08:39.895179: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
       2021-08-05 01:08:40.782293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
       2021-08-05 01:08:41.449059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
       500/500 [==============================] - 94s 136ms/step - loss: 0.8465 - tp0.1: 5573283.0000 - fp0.1: 9556973.0000 - tn0.1: 24922254.0000 - fn0.1: 907477.0000 - precision0.1: 0.3684 - recall0.1: 0.8600 - tp0.3: 4328544.0000 - fp0.3:
       2914618.0000 - tn0.3: 31564632.0000 - fn0.3: 2152216.0000 - precision0.3: 0.5976 - recall0.3: 0.6679 - tp0.5: 3481008.0000 - fp0.5: 837136.0000 - tn0.5: 33642108.0000 - fn0.5: 2999752.0000 - precision0.5: 0.8061 - recall0.5: 0.5371 - t
       p0.7: 2980707.0000 - fp0.7: 311954.0000 - tn0.7: 34167288.0000 - fn0.7: 3500053.0000 - precision0.7: 0.9053 - recall0.7: 0.4599 - tp0.9: 2452437.0000 - fp0.9: 89341.0000 - tn0.9: 34389892.0000 - fn0.9: 4028323.0000 - precision0.9: 0.96
       49 - recall0.9: 0.3784 - accuracy: 0.9063 - auc: 0.8779 - f1: 0.2732 - val_loss: 1.1080 - val_tp0.1: 875336.0000 - val_fp0.1: 157023.0000 - val_tn0.1: 6538933.0000 - val_fn0.1: 620708.0000 - val_precision0.1: 0.8479 - val_recall0.1: 0.
       5851 - val_tp0.3: 838251.0000 - val_fp0.3: 86533.0000 - val_tn0.3: 6609423.0000 - val_fn0.3: 657793.0000 - val_precision0.3: 0.9064 - val_recall0.3: 0.5603 - val_tp0.5: 813926.0000 - val_fp0.5: 65703.0000 - val_tn0.5: 6630253.0000 - va
       l_fn0.5: 682118.0000 - val_precision0.5: 0.9253 - val_recall0.5: 0.5441 - val_tp0.7: 789134.0000 - val_fp0.7: 49447.0000 - val_tn0.7: 6646509.0000 - val_fn0.7: 706910.0000 - val_precision0.7: 0.9410 - val_recall0.7: 0.5275 - val_tp0.9:
        747501.0000 - val_fp0.9: 31174.0000 - val_tn0.9: 6664782.0000 - val_fn0.9: 748543.0000 - val_precision0.9: 0.9600 - val_recall0.9: 0.4997 - val_accuracy: 0.9087 - val_auc: 0.8039 - val_f1: 0.3088
       Epoch 2/3
       500/500 [==============================] - 63s 126ms/step - loss: 0.7041 - tp0.1: 5758062.0000 - fp0.1: 8869655.0000 - tn0.1: 25659296.0000 - fn0.1: 672994.0000 - precision0.1: 0.3936 - recall0.1: 0.8954 - tp0.3: 4392915.0000 - fp0.3:
       2482074.0000 - tn0.3: 32046862.0000 - fn0.3: 2038141.0000 - precision0.3: 0.6390 - recall0.3: 0.6831 - tp0.5: 3631533.0000 - fp0.5: 799499.0000 - tn0.5: 33729440.0000 - fn0.5: 2799523.0000 - precision0.5: 0.8196 - recall0.5: 0.5647 - t
       p0.7: 3124553.0000 - fp0.7: 316262.0000 - tn0.7: 34212704.0000 - fn0.7: 3306503.0000 - precision0.7: 0.9081 - recall0.7: 0.4859 - tp0.9: 2484625.0000 - fp0.9: 69557.0000 - tn0.9: 34459372.0000 - fn0.9: 3946431.0000 - precision0.9: 0.97
       28 - recall0.9: 0.3863 - accuracy: 0.9121 - auc: 0.8955 - f1: 0.2714 - val_loss: 0.9020 - val_tp0.1: 1432699.0000 - val_fp0.1: 4177679.0000 - val_tn0.1: 2555849.0000 - val_fn0.1: 25773.0000 - val_precision0.1: 0.2554 - val_recall0.1: 0
       .9823 - val_tp0.3: 1314433.0000 - val_fp0.3: 2136861.0000 - val_tn0.3: 4596667.0000 - val_fn0.3: 144039.0000 - val_precision0.3: 0.3809 - val_recall0.3: 0.9012 - val_tp0.5: 1032252.0000 - val_fp0.5: 441253.0000 - val_tn0.5: 6292275.000
       0 - val_fn0.5: 426220.0000 - val_precision0.5: 0.7005 - val_recall0.5: 0.7078 - val_tp0.7: 875757.0000 - val_fp0.7: 132415.0000 - val_tn0.7: 6601113.0000 - val_fn0.7: 582715.0000 - val_precision0.7: 0.8687 - val_recall0.7: 0.6005 - val
       _tp0.9: 700117.0000 - val_fp0.9: 20482.0000 - val_tn0.9: 6713046.0000 - val_fn0.9: 758355.0000 - val_precision0.9: 0.9716 - val_recall0.9: 0.4800 - val_accuracy: 0.8941 - val_auc: 0.9128 - val_f1: 0.3023
       Epoch 3/3
       500/500 [==============================] - 63s 127ms/step - loss: 0.6243 - tp0.1: 5815415.0000 - fp0.1: 7957486.0000 - tn0.1: 26623182.0000 - fn0.1: 563914.0000 - precision0.1: 0.4222 - recall0.1: 0.9116 - tp0.3: 4692528.0000 - fp0.3:
       2856869.0000 - tn0.3: 31723806.0000 - fn0.3: 1686801.0000 - precision0.3: 0.6216 - recall0.3: 0.7356 - tp0.5: 3828444.0000 - fp0.5: 902854.0000 - tn0.5: 33677840.0000 - fn0.5: 2550885.0000 - precision0.5: 0.8092 - recall0.5: 0.6001 - t
       p0.7: 3241887.0000 - fp0.7: 309633.0000 - tn0.7: 34271048.0000 - fn0.7: 3137442.0000 - precision0.7: 0.9128 - recall0.7: 0.5082 - tp0.9: 2578882.0000 - fp0.9: 57882.0000 - tn0.9: 34522784.0000 - fn0.9: 3800447.0000 - precision0.9: 0.97
       80 - recall0.9: 0.4043 - accuracy: 0.9157 - auc: 0.9118 - f1: 0.2695 - val_loss: 0.6520 - val_tp0.1: 1412199.0000 - val_fp0.1: 1863904.0000 - val_tn0.1: 4813013.0000 - val_fn0.1: 102884.0000 - val_precision0.1: 0.4311 - val_recall0.1:
       0.9321 - val_tp0.3: 1206563.0000 - val_fp0.3: 716035.0000 - val_tn0.3: 5960882.0000 - val_fn0.3: 308520.0000 - val_precision0.3: 0.6276 - val_recall0.3: 0.7964 - val_tp0.5: 1029225.0000 - val_fp0.5: 267676.0000 - val_tn0.5: 6409241.000
       0 - val_fn0.5: 485858.0000 - val_precision0.5: 0.7936 - val_recall0.5: 0.6793 - val_tp0.7: 867349.0000 - val_fp0.7: 75135.0000 - val_tn0.7: 6601782.0000 - val_fn0.7: 647734.0000 - val_precision0.7: 0.9203 - val_recall0.7: 0.5725 - val_
       tp0.9: 687914.0000 - val_fp0.9: 10271.0000 - val_tn0.9: 6666646.0000 - val_fn0.9: 827169.0000 - val_precision0.9: 0.9853 - val_recall0.9: 0.4540 - val_accuracy: 0.9080 - val_auc: 0.9221 - val_f1: 0.3122
       2021-08-05 01:12:24.005783: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
       --- Running training session 2/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.08988484041391967,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 90s 137ms/step - loss: 0.8090 - tp0.1: 5574523.0000 - fp0.1: 9680169.0000 - tn0.1: 24876378.0000 - fn0.1: 828938.0000 - precision0.1: 0.3654 - recall0.1: 0.8705 - tp0.3: 4266332.0000 - fp0.3:
       2727943.0000 - tn0.3: 31828584.0000 - fn0.3: 2137129.0000 - precision0.3: 0.6100 - recall0.3: 0.6663 - tp0.5: 3498671.0000 - fp0.5: 787055.0000 - tn0.5: 33769472.0000 - fn0.5: 2904790.0000 - precision0.5: 0.8164 - recall0.5: 0.5464 - t
       p0.7: 3023523.0000 - fp0.7: 306806.0000 - tn0.7: 34249720.0000 - fn0.7: 3379938.0000 - precision0.7: 0.9079 - recall0.7: 0.4722 - tp0.9: 2455908.0000 - fp0.9: 82085.0000 - tn0.9: 34474440.0000 - fn0.9: 3947553.0000 - precision0.9: 0.96
       77 - recall0.9: 0.3835 - accuracy: 0.9099 - auc: 0.8831 - f1: 0.2704 - val_loss: 0.8679 - val_tp0.1: 1065375.0000 - val_fp0.1: 808807.0000 - val_tn0.1: 5985694.0000 - val_fn0.1: 332124.0000 - val_precision0.1: 0.5684 - val_recall0.1: 0
       .7623 - val_tp0.3: 954083.0000 - val_fp0.3: 250744.0000 - val_tn0.3: 6543757.0000 - val_fn0.3: 443416.0000 - val_precision0.3: 0.7919 - val_recall0.3: 0.6827 - val_tp0.5: 896195.0000 - val_fp0.5: 144354.0000 - val_tn0.5: 6650147.0000 -
        val_fn0.5: 501304.0000 - val_precision0.5: 0.8613 - val_recall0.5: 0.6413 - val_tp0.7: 842892.0000 - val_fp0.7: 85926.0000 - val_tn0.7: 6708575.0000 - val_fn0.7: 554607.0000 - val_precision0.7: 0.9075 - val_recall0.7: 0.6031 - val_tp0
       .9: 768531.0000 - val_fp0.9: 38644.0000 - val_tn0.9: 6755857.0000 - val_fn0.9: 628968.0000 - val_precision0.9: 0.9521 - val_recall0.9: 0.5499 - val_accuracy: 0.9212 - val_auc: 0.8603 - val_f1: 0.2915
       Epoch 2/3
       500/500 [==============================] - 64s 128ms/step - loss: 0.6864 - tp0.1: 5947178.0000 - fp0.1: 8670024.0000 - tn0.1: 25709228.0000 - fn0.1: 633552.0000 - precision0.1: 0.4069 - recall0.1: 0.9037 - tp0.3: 4564906.0000 - fp0.3:
       2513070.0000 - tn0.3: 31866188.0000 - fn0.3: 2015824.0000 - precision0.3: 0.6449 - recall0.3: 0.6937 - tp0.5: 3813963.0000 - fp0.5: 922457.0000 - tn0.5: 33456804.0000 - fn0.5: 2766767.0000 - precision0.5: 0.8052 - recall0.5: 0.5796 - t
       p0.7: 3258911.0000 - fp0.7: 368924.0000 - tn0.7: 34010340.0000 - fn0.7: 3321819.0000 - precision0.7: 0.8983 - recall0.7: 0.4952 - tp0.9: 2530598.0000 - fp0.9: 86864.0000 - tn0.9: 34292432.0000 - fn0.9: 4050132.0000 - precision0.9: 0.96
       68 - recall0.9: 0.3845 - accuracy: 0.9099 - auc: 0.9012 - f1: 0.2768 - val_loss: 1.5099 - val_tp0.1: 722773.0000 - val_fp0.1: 17387.0000 - val_tn0.1: 6719289.0000 - val_fn0.1: 732551.0000 - val_precision0.1: 0.9765 - val_recall0.1: 0.4
       966 - val_tp0.3: 702890.0000 - val_fp0.3: 11958.0000 - val_tn0.3: 6724718.0000 - val_fn0.3: 752434.0000 - val_precision0.3: 0.9833 - val_recall0.3: 0.4830 - val_tp0.5: 670136.0000 - val_fp0.5: 7166.0000 - val_tn0.5: 6729510.0000 - val_
       fn0.5: 785188.0000 - val_precision0.5: 0.9894 - val_recall0.5: 0.4605 - val_tp0.7: 627751.0000 - val_fp0.7: 3732.0000 - val_tn0.7: 6732944.0000 - val_fn0.7: 827573.0000 - val_precision0.7: 0.9941 - val_recall0.7: 0.4313 - val_tp0.9: 53
       6740.0000 - val_fp0.9: 788.0000 - val_tn0.9: 6735888.0000 - val_fn0.9: 918584.0000 - val_precision0.9: 0.9985 - val_recall0.9: 0.3688 - val_accuracy: 0.9033 - val_auc: 0.7509 - val_f1: 0.3017
       Epoch 3/3
       500/500 [==============================] - 64s 128ms/step - loss: 0.6016 - tp0.1: 5957421.0000 - fp0.1: 7693797.0000 - tn0.1: 26794472.0000 - fn0.1: 514321.0000 - precision0.1: 0.4364 - recall0.1: 0.9205 - tp0.3: 4746772.0000 - fp0.3:
       2686523.0000 - tn0.3: 31801738.0000 - fn0.3: 1724970.0000 - precision0.3: 0.6386 - recall0.3: 0.7335 - tp0.5: 3928251.0000 - fp0.5: 891625.0000 - tn0.5: 33596632.0000 - fn0.5: 2543491.0000 - precision0.5: 0.8150 - recall0.5: 0.6070 - t
       p0.7: 3376066.0000 - fp0.7: 352702.0000 - tn0.7: 34135552.0000 - fn0.7: 3095676.0000 - precision0.7: 0.9054 - recall0.7: 0.5217 - tp0.9: 2677154.0000 - fp0.9: 82662.0000 - tn0.9: 34405600.0000 - fn0.9: 3794588.0000 - precision0.9: 0.97
       00 - recall0.9: 0.4137 - accuracy: 0.9161 - auc: 0.9168 - f1: 0.2729 - val_loss: 0.6179 - val_tp0.1: 1384238.0000 - val_fp0.1: 2265434.0000 - val_tn0.1: 4483179.0000 - val_fn0.1: 59149.0000 - val_precision0.1: 0.3793 - val_recall0.1: 0
       .9590 - val_tp0.3: 1131758.0000 - val_fp0.3: 489605.0000 - val_tn0.3: 6259008.0000 - val_fn0.3: 311629.0000 - val_precision0.3: 0.6980 - val_recall0.3: 0.7841 - val_tp0.5: 938215.0000 - val_fp0.5: 112348.0000 - val_tn0.5: 6636265.0000
       - val_fn0.5: 505172.0000 - val_precision0.5: 0.8931 - val_recall0.5: 0.6500 - val_tp0.7: 810921.0000 - val_fp0.7: 36179.0000 - val_tn0.7: 6712434.0000 - val_fn0.7: 632466.0000 - val_precision0.7: 0.9573 - val_recall0.7: 0.5618 - val_tp
       0.9: 657088.0000 - val_fp0.9: 5618.0000 - val_tn0.9: 6742995.0000 - val_fn0.9: 786299.0000 - val_precision0.9: 0.9915 - val_recall0.9: 0.4552 - val_accuracy: 0.9246 - val_auc: 0.9380 - val_f1: 0.2996
       --- Running training session 3/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 1
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 59s 86ms/step - loss: 0.8098 - tp0.1: 5657751.0000 - fp0.1: 9653736.0000 - tn0.1: 24862488.0000 - fn0.1: 786024.0000 - precision0.1: 0.3695 - recall0.1: 0.8780 - tp0.3: 4449369.0000 - fp0.3: 3
       110455.0000 - tn0.3: 31405756.0000 - fn0.3: 1994406.0000 - precision0.3: 0.5886 - recall0.3: 0.6905 - tp0.5: 3608880.0000 - fp0.5: 871530.0000 - tn0.5: 33644692.0000 - fn0.5: 2834895.0000 - precision0.5: 0.8055 - recall0.5: 0.5601 - tp
       0.7: 3059317.0000 - fp0.7: 293792.0000 - tn0.7: 34222424.0000 - fn0.7: 3384458.0000 - precision0.7: 0.9124 - recall0.7: 0.4748 - tp0.9: 2446459.0000 - fp0.9: 66866.0000 - tn0.9: 34449352.0000 - fn0.9: 3997316.0000 - precision0.9: 0.973
       4 - recall0.9: 0.3797 - accuracy: 0.9095 - auc: 0.8865 - f1: 0.2719 - val_loss: 0.6960 - val_tp0.1: 1298584.0000 - val_fp0.1: 2735500.0000 - val_tn0.1: 4094349.0000 - val_fn0.1: 63567.0000 - val_precision0.1: 0.3219 - val_recall0.1: 0.
       9533 - val_tp0.3: 1046167.0000 - val_fp0.3: 538814.0000 - val_tn0.3: 6291035.0000 - val_fn0.3: 315984.0000 - val_precision0.3: 0.6601 - val_recall0.3: 0.7680 - val_tp0.5: 905849.0000 - val_fp0.5: 179338.0000 - val_tn0.5: 6650511.0000 -
        val_fn0.5: 456302.0000 - val_precision0.5: 0.8347 - val_recall0.5: 0.6650 - val_tp0.7: 777202.0000 - val_fp0.7: 48686.0000 - val_tn0.7: 6781163.0000 - val_fn0.7: 584949.0000 - val_precision0.7: 0.9411 - val_recall0.7: 0.5706 - val_tp0
       .9: 601927.0000 - val_fp0.9: 3190.0000 - val_tn0.9: 6826659.0000 - val_fn0.9: 760224.0000 - val_precision0.9: 0.9947 - val_recall0.9: 0.4419 - val_accuracy: 0.9224 - val_auc: 0.9235 - val_f1: 0.2851
       Epoch 2/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6657 - tp0.1: 6038595.0000 - fp0.1: 9381109.0000 - tn0.1: 25009172.0000 - fn0.1: 531126.0000 - precision0.1: 0.3916 - recall0.1: 0.9192 - tp0.3: 4590759.0000 - fp0.3: 2
       623413.0000 - tn0.3: 31766868.0000 - fn0.3: 1978962.0000 - precision0.3: 0.6364 - recall0.3: 0.6988 - tp0.5: 3919695.0000 - fp0.5: 877585.0000 - tn0.5: 33512682.0000 - fn0.5: 2650026.0000 - precision0.5: 0.8171 - recall0.5: 0.5966 - tp
       0.7: 3405408.0000 - fp0.7: 357797.0000 - tn0.7: 34032488.0000 - fn0.7: 3164313.0000 - precision0.7: 0.9049 - recall0.7: 0.5183 - tp0.9: 2611090.0000 - fp0.9: 71935.0000 - tn0.9: 34318336.0000 - fn0.9: 3958631.0000 - precision0.9: 0.973
       2 - recall0.9: 0.3974 - accuracy: 0.9139 - auc: 0.9058 - f1: 0.2764 - val_loss: 0.7539 - val_tp0.1: 1425809.0000 - val_fp0.1: 3416596.0000 - val_tn0.1: 3317608.0000 - val_fn0.1: 31987.0000 - val_precision0.1: 0.2944 - val_recall0.1: 0.
       9781 - val_tp0.3: 1153794.0000 - val_fp0.3: 584876.0000 - val_tn0.3: 6149328.0000 - val_fn0.3: 304002.0000 - val_precision0.3: 0.6636 - val_recall0.3: 0.7915 - val_tp0.5: 1023952.0000 - val_fp0.5: 210947.0000 - val_tn0.5: 6523257.0000
       - val_fn0.5: 433844.0000 - val_precision0.5: 0.8292 - val_recall0.5: 0.7024 - val_tp0.7: 892274.0000 - val_fp0.7: 76689.0000 - val_tn0.7: 6657515.0000 - val_fn0.7: 565522.0000 - val_precision0.7: 0.9209 - val_recall0.7: 0.6121 - val_tp
       0.9: 694057.0000 - val_fp0.9: 10486.0000 - val_tn0.9: 6723718.0000 - val_fn0.9: 763739.0000 - val_precision0.9: 0.9851 - val_recall0.9: 0.4761 - val_accuracy: 0.9213 - val_auc: 0.9320 - val_f1: 0.3021
       Epoch 3/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6313 - tp0.1: 5835142.0000 - fp0.1: 9197283.0000 - tn0.1: 25434982.0000 - fn0.1: 492595.0000 - precision0.1: 0.3882 - recall0.1: 0.9222 - tp0.3: 4412807.0000 - fp0.3: 1
       929867.0000 - tn0.3: 32702396.0000 - fn0.3: 1914930.0000 - precision0.3: 0.6957 - recall0.3: 0.6974 - tp0.5: 3916359.0000 - fp0.5: 813841.0000 - tn0.5: 33818420.0000 - fn0.5: 2411378.0000 - precision0.5: 0.8279 - recall0.5: 0.6189 - tp
       0.7: 3427132.0000 - fp0.7: 325708.0000 - tn0.7: 34306584.0000 - fn0.7: 2900605.0000 - precision0.7: 0.9132 - recall0.7: 0.5416 - tp0.9: 2673381.0000 - fp0.9: 64869.0000 - tn0.9: 34567400.0000 - fn0.9: 3654356.0000 - precision0.9: 0.976
       3 - recall0.9: 0.4225 - accuracy: 0.9213 - auc: 0.9124 - f1: 0.2676 - val_loss: 0.6419 - val_tp0.1: 1322642.0000 - val_fp0.1: 2095325.0000 - val_tn0.1: 4683356.0000 - val_fn0.1: 90677.0000 - val_precision0.1: 0.3870 - val_recall0.1: 0.
       9358 - val_tp0.3: 996512.0000 - val_fp0.3: 198904.0000 - val_tn0.3: 6579777.0000 - val_fn0.3: 416807.0000 - val_precision0.3: 0.8336 - val_recall0.3: 0.7051 - val_tp0.5: 905996.0000 - val_fp0.5: 81731.0000 - val_tn0.5: 6696950.0000 - v
       al_fn0.5: 507323.0000 - val_precision0.5: 0.9173 - val_recall0.5: 0.6410 - val_tp0.7: 819186.0000 - val_fp0.7: 33804.0000 - val_tn0.7: 6744877.0000 - val_fn0.7: 594133.0000 - val_precision0.7: 0.9604 - val_recall0.7: 0.5796 - val_tp0.9
       : 653298.0000 - val_fp0.9: 4501.0000 - val_tn0.9: 6774180.0000 - val_fn0.9: 760021.0000 - val_precision0.9: 0.9932 - val_recall0.9: 0.4622 - val_accuracy: 0.9281 - val_auc: 0.9250 - val_f1: 0.2943
       --- Running training session 4/4
       {'hp_epochs': 3, 'hp_batch_size': 5, 'hp_steps_per_epoch': 500, 'hp_validation_steps': 100, 'hp_scaler': 'robust', 'hp_n_levels': 3, 'hp_first_filteres': 64, 'hp_pool_size': 2, 'hp_input_size': 8192, 'hp_lr_start': 0.09170272672180384,
        'hp_lr_power': 1.0}
       --- repeat #: 2
       input - shape:   (None, 16384, 1)
       output - shape:  (None, 16384, 1)
       Epoch 1/3
       500/500 [==============================] - 58s 86ms/step - loss: 0.8227 - tp0.1: 5768282.0000 - fp0.1: 10143748.0000 - tn0.1: 24324484.0000 - fn0.1: 723474.0000 - precision0.1: 0.3625 - recall0.1: 0.8886 - tp0.3: 4575680.0000 - fp0.3:
       3265890.0000 - tn0.3: 31202360.0000 - fn0.3: 1916076.0000 - precision0.3: 0.5835 - recall0.3: 0.7048 - tp0.5: 3680479.0000 - fp0.5: 842388.0000 - tn0.5: 33625848.0000 - fn0.5: 2811277.0000 - precision0.5: 0.8137 - recall0.5: 0.5669 - t
       p0.7: 3187933.0000 - fp0.7: 315804.0000 - tn0.7: 34152452.0000 - fn0.7: 3303823.0000 - precision0.7: 0.9099 - recall0.7: 0.4911 - tp0.9: 2543673.0000 - fp0.9: 80198.0000 - tn0.9: 34388036.0000 - fn0.9: 3948083.0000 - precision0.9: 0.96
       94 - recall0.9: 0.3918 - accuracy: 0.9108 - auc: 0.8920 - f1: 0.2736 - val_loss: 0.6994 - val_tp0.1: 1219562.0000 - val_fp0.1: 1097875.0000 - val_tn0.1: 5682393.0000 - val_fn0.1: 192170.0000 - val_precision0.1: 0.5263 - val_recall0.1:
       0.8639 - val_tp0.3: 1158237.0000 - val_fp0.3: 721434.0000 - val_tn0.3: 6058834.0000 - val_fn0.3: 253495.0000 - val_precision0.3: 0.6162 - val_recall0.3: 0.8204 - val_tp0.5: 1096307.0000 - val_fp0.5: 487008.0000 - val_tn0.5: 6293260.000
       0 - val_fn0.5: 315425.0000 - val_precision0.5: 0.6924 - val_recall0.5: 0.7766 - val_tp0.7: 1033043.0000 - val_fp0.7: 343705.0000 - val_tn0.7: 6436563.0000 - val_fn0.7: 378689.0000 - val_precision0.7: 0.7504 - val_recall0.7: 0.7318 - va
       l_tp0.9: 908105.0000 - val_fp0.9: 156883.0000 - val_tn0.9: 6623385.0000 - val_fn0.9: 503627.0000 - val_precision0.9: 0.8527 - val_recall0.9: 0.6433 - val_accuracy: 0.9020 - val_auc: 0.9058 - val_f1: 0.2940
       Epoch 2/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6734 - tp0.1: 5848450.0000 - fp0.1: 9526208.0000 - tn0.1: 25032716.0000 - fn0.1: 552623.0000 - precision0.1: 0.3804 - recall0.1: 0.9137 - tp0.3: 4429492.0000 - fp0.3: 2
       531581.0000 - tn0.3: 32027336.0000 - fn0.3: 1971581.0000 - precision0.3: 0.6363 - recall0.3: 0.6920 - tp0.5: 3756606.0000 - fp0.5: 861005.0000 - tn0.5: 33697932.0000 - fn0.5: 2644467.0000 - precision0.5: 0.8135 - recall0.5: 0.5869 - tp
       0.7: 3213893.0000 - fp0.7: 347972.0000 - tn0.7: 34210932.0000 - fn0.7: 3187180.0000 - precision0.7: 0.9023 - recall0.7: 0.5021 - tp0.9: 2475219.0000 - fp0.9: 75334.0000 - tn0.9: 34483576.0000 - fn0.9: 3925854.0000 - precision0.9: 0.970
       5 - recall0.9: 0.3867 - accuracy: 0.9144 - auc: 0.9024 - f1: 0.2703 - val_loss: 0.7359 - val_tp0.1: 1419696.0000 - val_fp0.1: 3159715.0000 - val_tn0.1: 3571449.0000 - val_fn0.1: 41140.0000 - val_precision0.1: 0.3100 - val_recall0.1: 0.
       9718 - val_tp0.3: 1143187.0000 - val_fp0.3: 525803.0000 - val_tn0.3: 6205361.0000 - val_fn0.3: 317649.0000 - val_precision0.3: 0.6850 - val_recall0.3: 0.7826 - val_tp0.5: 957808.0000 - val_fp0.5: 121812.0000 - val_tn0.5: 6609352.0000 -
        val_fn0.5: 503028.0000 - val_precision0.5: 0.8872 - val_recall0.5: 0.6557 - val_tp0.7: 779806.0000 - val_fp0.7: 25020.0000 - val_tn0.7: 6706144.0000 - val_fn0.7: 681030.0000 - val_precision0.7: 0.9689 - val_recall0.7: 0.5338 - val_tp0
       .9: 574091.0000 - val_fp0.9: 1829.0000 - val_tn0.9: 6729335.0000 - val_fn0.9: 886745.0000 - val_precision0.9: 0.9968 - val_recall0.9: 0.3930 - val_accuracy: 0.9237 - val_auc: 0.9312 - val_f1: 0.3027
       Epoch 3/3
       500/500 [==============================] - 39s 79ms/step - loss: 0.6529 - tp0.1: 6027563.0000 - fp0.1: 9380879.0000 - tn0.1: 25038634.0000 - fn0.1: 512924.0000 - precision0.1: 0.3912 - recall0.1: 0.9216 - tp0.3: 4646844.0000 - fp0.3: 2
       553894.0000 - tn0.3: 31865608.0000 - fn0.3: 1893643.0000 - precision0.3: 0.6453 - recall0.3: 0.7105 - tp0.5: 3950120.0000 - fp0.5: 818824.0000 - tn0.5: 33600676.0000 - fn0.5: 2590367.0000 - precision0.5: 0.8283 - recall0.5: 0.6039 - tp
       0.7: 3450228.0000 - fp0.7: 324890.0000 - tn0.7: 34094620.0000 - fn0.7: 3090259.0000 - precision0.7: 0.9139 - recall0.7: 0.5275 - tp0.9: 2767414.0000 - fp0.9: 78357.0000 - tn0.9: 34341160.0000 - fn0.9: 3773073.0000 - precision0.9: 0.972
       5 - recall0.9: 0.4231 - accuracy: 0.9168 - auc: 0.9107 - f1: 0.2754 - val_loss: 0.6849 - val_tp0.1: 1409798.0000 - val_fp0.1: 2600499.0000 - val_tn0.1: 4115417.0000 - val_fn0.1: 66286.0000 - val_precision0.1: 0.3515 - val_recall0.1: 0.
       9551 - val_tp0.3: 999421.0000 - val_fp0.3: 171550.0000 - val_tn0.3: 6544366.0000 - val_fn0.3: 476663.0000 - val_precision0.3: 0.8535 - val_recall0.3: 0.6771 - val_tp0.5: 905112.0000 - val_fp0.5: 74074.0000 - val_tn0.5: 6641842.0000 - v
       al_fn0.5: 570972.0000 - val_precision0.5: 0.9244 - val_recall0.5: 0.6132 - val_tp0.7: 812564.0000 - val_fp0.7: 30988.0000 - val_tn0.7: 6684928.0000 - val_fn0.7: 663520.0000 - val_precision0.7: 0.9633 - val_recall0.7: 0.5505 - val_tp0.9
       : 634884.0000 - val_fp0.9: 4048.0000 - val_tn0.9: 6711868.0000 - val_fn0.9: 841200.0000 - val_precision0.9: 0.9937 - val_recall0.9: 0.4301 - val_accuracy: 0.9213 - val_auc: 0.9252 - val_f1: 0.3054
       2021/08/05 01:22:26 INFO mlflow.projects: === Run (ID '09f12eb855fb4bd99b5105fb5f3e58b4') succeeded ===
       (tf) [ye53nis@node131 drmed-git]$
     #+end_example

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session mlflowui
       conda activate tf
       mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
     #+END_SRC
**** one trick to make mlflowui show artifacts


*** DONE Implement talos 1.0 with mlflow, see [[file:~/Dokumente/org/04_Digital-und-Technik/programmieren.org::*Querying runs programmatically][here]] - or other Hyperparameter optimization
    CLOSED: [2021-07-25 So 16:42]
- an implementation of hyperopt + unet training [[https://www.kaggle.com/yassinealouini/mlflow-hyperopt-u-net-workflo][here]]


** TODOs
*** TODO super cool way of presenting work:https://stanfordmlgroup.github.io/projects/ecg/


*** TODO Investigate Error on GPU node
- 2020-04-13 02:45:28.216446: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open
#  shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217069: W
  tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load
  dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6:
  cannot open shared object file: No such file or directory; LD_LIBRARY_PATH:
  /cluster/miniconda3/lib
- 2020-04-13 02:45:28.217123: W
  tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some
  TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please
  make sure the missing libraries mentioned above are installed properly
*** TODO fix pydot and graphviz to make model plotting work

*** PENDING Fix isort and sys.path conflicts
    - State "PENDING"    from "TODO"       [2020-05-02 Sa 13:06] \\
      Waiting for isort 5.0.0 release
    See/ here: https:/github.com/timothycrosley/isort/issues/468#issuecomment-570899233

*** TODO [#C] Set up nice package using cookiecutter, poetry, See [[https://stackoverflow.com/questions/49474575/how-to-install-my-own-python-module-package-via-conda-and-watch-its-changes][here]]
    - actually, I would love to merge the git-org-mode workflow with this data
      science workflow: https://drivendata.github.io/cookiecutter-data-science/
    - I would probably do the following structure:

      #+begin_example t
├── LICENSE
├── Makefile           <- Makefile with commands like `make data` or `make train`
├── README.md          <- The top-level README for developers using this project.
├── data               <- NOT on git
│   ├── external       <- Data from third party sources.
│   ├── interim        <- Intermediate data that has been transformed.
│   ├── processed      <- The final, canonical data sets for modeling.
|   |-- simulated      <- my simulations would have to go here as well, since large files
|   |                     can not be reasonably managed with git
│   └── raw            <- The original, immutable data dump.
│
|-- experiments        <- folder for my exp-<date>-<description> folders.
|-- LabBook.org
|-- index.html         <- on data branch
|-- conda.yaml
|-- MLproject
├── docs               <- A default Sphinx project; see sphinx-doc.org for details
│
├── *mlruns*           <- Trained and serialized models, model predictions, or model summaries
|                         In my case: the mlflow folder.
│
├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
│                         the creator's initials, and a short `-` delimited description, e.g.
│                         `1.0-jqp-initial-data-exploration`.
│
├── (references)       <- (Data dictionaries, manuals, and all other explanatory materials.)
|                         Not really sure if needed, since most explanatory stuff is either in
|                         ./experiments/ or in index.html
│
├── *reports*          <- Generated analysis as HTML, PDF, LaTeX, etc.
│   └── (figures)      <- Generated graphics and figures to be used in reporting
|                         Yes, but more precise: there are figures / the open notebook report in
|                         form of index.html for each experiment. Here, there can be drafts of
|                         publications. Figures should be produced in the scope of an experiment,
|                         so that provenance is ensured.
│
├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
│                         generated with `pip freeze > requirements.txt`
│
├── setup.py           <- Make this project pip installable with `pip install -e`
├── src                <- Source code for use in this project.
|   |                     Yes but: maybe have subfolder for the actual module, so that submodules
|   |                     can go here as well.
│   ├── __init__.py    <- Makes src a Python module
│   │
│   ├── data           <- Scripts to download or generate data
│   │   └── make_dataset.py
│   │
│   ├── features       <- Scripts to turn raw data into features for modeling
│   │   └── build_features.py
│   │
│   ├── models         <- Scripts to train models and then use trained models to make
│   │   │                 predictions
│   │   ├── predict_model.py
│   │   └── train_model.py
│   │
│   └── visualization  <- Scripts to create exploratory and results oriented visualizations
│       └── visualize.py
│
└── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io
|                         Interesting! This is standardized testing!
      #+end_example

    - other packaging resources:

      - https://cjolowicz.github.io/posts/hypermodern-python-01-setup/

      - https://github.com/pypa/sampleproject

      -
*** TODO [#A] Do Calibration plots for training analysis
    - predicted probability on x-axis in bins (0-0.1, 0.1-0.2, ...) and allocate
      the true probability (0 or 1) there, compute confidence intervals
    - also plot a bar plot in each bin of the absolute number of predictions in
      there → shows when e.g. there "never" would be high predictions.
    -

*** TODO There is https://pypi.org/project/multipletau-cor-tttr/ check it out
* Reconnect
  :LOGBOOK:
  CLOCK: [2020-05-04 Mo 14:59]--[2020-05-04 Mo 14:59] =>  0:00
  :END:
** Tmux on Ara, Login node for git pull
#+CALL: setup-tmux[:session local]

#+RESULTS:
|         |                                        |           |
| sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
| >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

Test:

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session local
  cd /beegfs/ye53nis/drmed-git/
  git pull
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@login01 drmed-git]$ git status
  # On branch develop
  # Untracked files:
  #   (use "git add <file>..." to include in what will be committed)
  #
  #       data/exp-devtest/
  #       data/exp-test/
  #       data/mlruns/0/037e1d9e4ad74784974f4aaac11138cc/
  #       data/mlruns/0/19ccbacbf4334e5496aa8aca189b48f6/
  #       data/mlruns/0/1d1a38b21990451582bf9b07a9487820/
  #       data/mlruns/0/1e98b3ed2e1d421da9592058bd5587a8/
  #       data/mlruns/0/265692a2dfa1437f99a847dd7fe0c8e4/
  #       data/mlruns/0/306234c75c9c48058cbd694579eff31b/
  #       data/mlruns/0/67f319f4d8f746ffa6af7c161bdd0a7b/
  #       data/mlruns/0/7f23f6ba7a244914b3cbbebd731d50a1/
  #       data/mlruns/0/83913f83a27245e7b16d9847de14e2ed/
  #       data/mlruns/0/bf2ced34703e42eba1858a9515694a9e/
  #       data/mlruns/0/d57baeff5b994289bf6ce4c842a87509/
  #       data/mlruns/0/d9b44dc2e3d44ea1a71129808b642af6/
  #       data/mlruns/0/e4ad17b5c0e3489f89194eff033a9279/
  #       data/mlruns/0/f9da7fa18bcd4dd79eee13e35f4a5573/
  #       data/mlruns/0/fce85613c2724819a168ba0d34cff11d/
  #       data/mlruns/1/504c8c02948c498fa7485c044b956468/
  #       data/mlruns/1/6444eabd24a7402a92f895804b01163c/
  #       data/mlruns/mlruns/
  #       data/tb/
  #       experiment_params.csv
  #       mlruns/
  #       test.pdf
  #       test.svg
  #       tramp.YDPCnB
  no changes added to commit (use "git add" and/or "git commit -a")
#+end_example

** Compute node for script execution
#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tmux
  srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
#+END_SRC

#+RESULTS:
#+begin_example
  (base) [ye53nis@login01 /]$ srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
  (base) [ye53nis@node142 /]$
#+end_example

** Jupyter on Ara
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#9999:a37e524a-8134-4d8f-b24a-367acaf1bdd3
   :END:

1. Request compute node via tmux
   #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
   cd /
   srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
   #+END_SRC



2.
#+CALL: jpt-tmux[:session jpmux]

   #+RESULTS:
   #+begin_example
     (tf-nightly) [ye53nis@node152 /]$ jupyter lab --no-browser --port=$PORT
     [I 2021-07-30 15:24:30.855 ServerApp] jupyterlab | extension was successfully linked.
     [I 2021-07-30 15:24:37.313 ServerApp] nbclassic | extension was successfully linked.
     [I 2021-07-30 15:24:38.083 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/jupyterlab
     [I 2021-07-30 15:24:38.083 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf-nightly/share/jupyter/lab
     [I 2021-07-30 15:24:38.110 ServerApp] jupyterlab | extension was successfully loaded.
     [I 2021-07-30 15:24:38.262 ServerApp] nbclassic | extension was successfully loaded.
     [I 2021-07-30 15:24:38.263 ServerApp] Serving notebooks from local directory: /
     [I 2021-07-30 15:24:38.263 ServerApp] Jupyter Server 1.4.1 is running at:
     [I 2021-07-30 15:24:38.263 ServerApp] http://localhost:9999/lab?token=c5a6d2b0c17e319f955017078adb80c170e35cde289130d6
     [I 2021-07-30 15:24:38.263 ServerApp]  or http://127.0.0.1:9999/lab?token=c5a6d2b0c17e319f955017078adb80c170e35cde289130d6
     [I 2021-07-30 15:24:38.263 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
     [C 2021-07-30 15:24:38.312 ServerApp]

         To access the server, open this file in a browser:
             file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-197308-open.html
         Or copy and paste one of these URLs:
             http://localhost:9999/lab?token=c5a6d2b0c17e319f955017078adb80c170e35cde289130d6
          or http://127.0.0.1:9999/lab?token=c5a6d2b0c17e319f955017078adb80c170e35cde289130d6
   #+end_example



#+CALL: ssh-tunnel(port="9999", node="node152")

#+RESULTS:
|                   |           |                                        |           |   |          |      |      |             |
| sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |   |          |      |      |             |
| ye53nis@node152's | password: |                                        |           |   |          |      |      |             |
| Last              | login:    | Tue                                    | Aug       | 3 | 11:43:26 | 2021 | from | login01.ara |

I started a Python3 kernel using =jupyter-server-list-kernels=. Then I added the
kernel ID to the =:PROPERTIES:= drawer of this (and following) subtrees.

#+begin_example
python3           03038b73-b2b5-49ce-a1dc-21afb6247d0f   a few seconds ago    starting   0
#+end_example

Test:

#+CALL: jp-metadata(_long='True)

#+RESULTS:
#+begin_example
  No of CPUs in system: 72
  No of CPUs the current process can use: 24
  load average: (2.5, 9.22, 11.88)
  os.uname():  posix.uname_result(sysname='Linux', nodename='node157', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
  PID of process: 323378
  RAM total: 199G, RAM used: 2.6G, RAM free: 169G
  the current directory: /
  My disk usage:
  Filesystem           Size  Used Avail Use% Mounted on
  /dev/sda1             50G  3.2G   47G   7% /
  devtmpfs              94G     0   94G   0% /dev
  tmpfs                 94G  862M   93G   1% /dev/shm
  tmpfs                 94G  195M   94G   1% /run
  tmpfs                 94G     0   94G   0% /sys/fs/cgroup
  nfs01-ib:/home        80T   68T   13T  85% /home
  nfs02-ib:/data01      88T   70T   19T  80% /data01
  nfs01-ib:/cluster    2.0T  407G  1.7T  20% /cluster
  nfs03-ib:/pool/work  100T   78T   23T  78% /nfsdata
  /dev/sda6            169G  9.8G  159G   6% /local
  /dev/sda3            6.0G  426M  5.6G   7% /var
  /dev/sda5            2.0G   58M  2.0G   3% /tmp
  beegfs_nodev         524T  279T  246T  54% /beegfs
  tmpfs                 19G     0   19G   0% /run/user/67339
  # packages in environment at /home/ye53nis/.conda/envs/tf-nightly:
  #
  # Name                    Version                   Build  Channel
  _libgcc_mutex             0.1                        main
  absl-py                   0.11.0                   pypi_0    pypi
  alembic                   1.4.1                      py_0    conda-forge
  appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
  argon2-cffi               20.1.0           py38h7b6447c_1
  asn1crypto                1.4.0              pyh9f0ad1d_0    conda-forge
  asteval                   0.9.16             pyh5ca1d4c_0    conda-forge
  astunparse                1.6.3                    pypi_0    pypi
  async_generator           1.10                       py_0
  attrs                     20.2.0                     py_0
  azure-core                1.8.2              pyh9f0ad1d_0    conda-forge
  azure-storage-blob        12.5.0             pyh9f0ad1d_0    conda-forge
  backcall                  0.2.0                      py_0
  blas                      1.0                         mkl
  bleach                    3.2.1                      py_0
  blinker                   1.4                        py_1    conda-forge
  brotlipy                  0.7.0           py38h7b6447c_1000
  ca-certificates           2020.12.5            ha878542_0    conda-forge
  cachetools                4.1.1                    pypi_0    pypi
  certifi                   2020.12.5        py38h578d9bd_0    conda-forge
  cffi                      1.14.3           py38he30daa8_0
  chardet                   3.0.4                 py38_1003
  click                     7.1.2              pyh9f0ad1d_0    conda-forge
  cloudpickle               1.6.0                      py_0    conda-forge
  configparser              5.0.1                      py_0    conda-forge
  cryptography              3.1.1            py38h1ba5d50_0
  cycler                    0.10.0                   py38_0
  databricks-cli            0.9.1                      py_0    conda-forge
  dbus                      1.13.18              hb2f20db_0
  decorator                 4.4.2                      py_0
  defusedxml                0.6.0                      py_0
  docker-py                 4.3.1            py38h32f6830_1    conda-forge
  docker-pycreds            0.4.0                      py_0    conda-forge
  entrypoints               0.3                      py38_0
  expat                     2.2.10               he6710b0_2
  fcsfiles                  2020.9.18                pypi_0    pypi
  flask                     1.1.2              pyh9f0ad1d_0    conda-forge
  flatbuffers               1.12                     pypi_0    pypi
  fontconfig                2.13.0               h9420a91_0
  freetype                  2.10.4               h5ab3b9f_0
  future                    0.18.2           py38h578d9bd_2    conda-forge
  gast                      0.3.3                    pypi_0    pypi
  gitdb                     4.0.5                      py_0    conda-forge
  gitpython                 3.1.11                     py_0    conda-forge
  glib                      2.66.1               h92f7085_0
  google-auth               1.23.0                   pypi_0    pypi
  google-auth-oauthlib      0.4.2                    pypi_0    pypi
  google-pasta              0.2.0                    pypi_0    pypi
  gorilla                   0.3.0                      py_0    conda-forge
  grpcio                    1.32.0                   pypi_0    pypi
  gst-plugins-base          1.14.0               hbbd80ab_1
  gstreamer                 1.14.0               hb31296c_0
  gunicorn                  20.0.4           py38h32f6830_2    conda-forge
  h5py                      2.10.0                   pypi_0    pypi
  icu                       58.2                 he6710b0_3
  idna                      2.10                       py_0
  importlib-metadata        2.0.0                      py_1
  importlib_metadata        2.0.0                         1
  intel-openmp              2020.2                      254
  ipykernel                 5.3.4            py38h5ca1d4c_0
  ipython                   7.18.1           py38h5ca1d4c_0
  ipython_genutils          0.2.0                    py38_0
  isodate                   0.6.0                      py_1    conda-forge
  itsdangerous              1.1.0                      py_0    conda-forge
  jedi                      0.17.2                   py38_0
  jinja2                    2.11.2                     py_0
  jpeg                      9b                   h024ee3a_2
  json5                     0.9.5                      py_0
  jsonschema                3.2.0                      py_2
  jupyter_client            6.1.7                      py_0
  jupyter_core              4.6.3                    py38_0
  jupyterlab                2.2.6                      py_0
  jupyterlab_pygments       0.1.2                      py_0
  jupyterlab_server         1.2.0                      py_0
  keras-preprocessing       1.1.2                    pypi_0    pypi
  kiwisolver                1.3.0            py38h2531618_0
  lcms2                     2.11                 h396b838_0
  ld_impl_linux-64          2.33.1               h53a641e_7
  libedit                   3.1.20191231         h14c3975_1
  libffi                    3.3                  he6710b0_2
  libgcc-ng                 9.1.0                hdf63c60_0
  libgfortran-ng            7.3.0                hdf63c60_0
  libpng                    1.6.37               hbc83047_0
  libprotobuf               3.13.0.1             h8b12597_0    conda-forge
  libsodium                 1.0.18               h7b6447c_0
  libstdcxx-ng              9.1.0                hdf63c60_0
  libtiff                   4.1.0                h2733197_1
  libuuid                   1.0.3                h1bed415_2
  libxcb                    1.14                 h7b6447c_0
  libxml2                   2.9.10               hb55368b_3
  lmfit                     1.0.1                      py_1    conda-forge
  lz4-c                     1.9.2                heb0550a_3
  mako                      1.1.3              pyh9f0ad1d_0    conda-forge
  markdown                  3.3.3                    pypi_0    pypi
  markupsafe                1.1.1            py38h7b6447c_0
  matplotlib                3.3.2                         0
  matplotlib-base           3.3.2            py38h817c723_0
  mistune                   0.8.4           py38h7b6447c_1000
  mkl                       2020.2                      256
  mkl-service               2.3.0            py38he904b0f_0
  mkl_fft                   1.2.0            py38h23d657b_0
  mkl_random                1.1.1            py38h0573a6f_0
  mlflow                    1.11.0           py38h32f6830_1    conda-forge
  msrest                    0.6.19             pyh9f0ad1d_0    conda-forge
  multipletau               0.3.3                    pypi_0    pypi
  nbclient                  0.5.1                      py_0
  nbconvert                 6.0.7                    py38_0
  nbformat                  5.0.8                      py_0
  ncurses                   6.2                  he6710b0_1
  nest-asyncio              1.4.1                      py_0
  notebook                  6.1.4                    py38_0
  numpy                     1.19.2           py38h54aff64_0
  numpy-base                1.19.2           py38hfa32c7d_0
  oauthlib                  3.0.1                      py_0    conda-forge
  olefile                   0.46                       py_0
  openssl                   1.1.1h               h516909a_0    conda-forge
  opt-einsum                3.3.0                    pypi_0    pypi
  packaging                 20.4                       py_0
  pandas                    1.1.3            py38he6710b0_0
  pandoc                    2.11                 hb0f4dca_0
  pandocfilters             1.4.2                    py38_1
  parso                     0.7.0                      py_0
  pcre                      8.44                 he6710b0_0
  pexpect                   4.8.0                    py38_0
  pickleshare               0.7.5                 py38_1000
  pillow                    8.0.1            py38he98fc37_0
  pip                       20.2.4                   py38_0
  prometheus_client         0.8.0                      py_0
  prometheus_flask_exporter 0.18.1             pyh9f0ad1d_0    conda-forge
  prompt-toolkit            3.0.8                      py_0
  protobuf                  3.13.0.1         py38h950e882_1    conda-forge
  ptyprocess                0.6.0                    py38_0
  pyasn1                    0.4.8                    pypi_0    pypi
  pyasn1-modules            0.2.8                    pypi_0    pypi
  pycparser                 2.20                       py_2
  pygments                  2.7.2              pyhd3eb1b0_0
  pyjwt                     1.7.1                      py_0    conda-forge
  pyopenssl                 19.1.0                     py_1
  pyparsing                 2.4.7                      py_0
  pyqt                      5.9.2            py38h05f1152_4
  pyrsistent                0.17.3           py38h7b6447c_0
  pysocks                   1.7.1                    py38_0
  python                    3.8.5                h7579374_1
  python-dateutil           2.8.1                      py_0
  python-editor             1.0.4                      py_0    conda-forge
  python_abi                3.8                      1_cp38    conda-forge
  pytz                      2020.1                     py_0
  pyyaml                    5.3.1            py38h8df0ef7_1    conda-forge
  pyzmq                     19.0.2           py38he6710b0_1
  qt                        5.9.7                h5867ecd_1
  querystring_parser        1.2.4                      py_0    conda-forge
  readline                  8.0                  h7b6447c_0
  requests                  2.24.0                     py_0
  requests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge
  rsa                       4.6                      pypi_0    pypi
  scipy                     1.5.2            py38h0b6359f_0
  seaborn                   0.11.0                     py_0
  send2trash                1.5.0                    py38_0
  setuptools                50.3.0           py38hb0f4dca_1
  sip                       4.19.13          py38he6710b0_0
  six                       1.15.0                     py_0
  smmap                     3.0.4              pyh9f0ad1d_0    conda-forge
  sqlalchemy                1.3.13           py38h516909a_0    conda-forge
  sqlite                    3.33.0               h62c20be_0
  sqlparse                  0.4.1              pyh9f0ad1d_0    conda-forge
  tabulate                  0.8.7              pyh9f0ad1d_0    conda-forge
  tb-nightly                2.4.0a20201102           pypi_0    pypi
  tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
  termcolor                 1.1.0                    pypi_0    pypi
  terminado                 0.9.1                    py38_0
  testpath                  0.4.4                      py_0
  tf-estimator-nightly      2.4.0.dev2020102301          pypi_0    pypi
  tf-nightly                2.5.0.dev20201029          pypi_0    pypi
  tifffile                  2020.10.1        py38hdd07704_2
  tk                        8.6.10               hbc83047_0
  tornado                   6.0.4            py38h7b6447c_1
  traitlets                 5.0.5                      py_0
  typing-extensions         3.7.4.3                  pypi_0    pypi
  uncertainties             3.1.5              pyhd8ed1ab_0    conda-forge
  urllib3                   1.25.11                    py_0
  wcwidth                   0.2.5                      py_0
  webencodings              0.5.1                    py38_1
  websocket-client          0.57.0           py38h32f6830_3    conda-forge
  werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
  wheel                     0.35.1                     py_0
  wrapt                     1.12.1                   pypi_0    pypi
  xz                        5.2.5                h7b6447c_0
  yaml                      0.2.5                h516909a_0    conda-forge
  zeromq                    4.3.3                he6710b0_3
  zipp                      3.4.0              pyhd3eb1b0_0
  zlib                      1.2.11               h7b6447c_3
  zstd                      1.4.5                h9ceee32_0

  Note: you may need to restart the kernel to use updated packages.
  {'SLURM_CHECKPOINT_IMAGE_DIR': '/var/slurm/checkpoint',
   'SLURM_NODELIST': 'node157',
   'SLURM_JOB_NAME': 'bash',
   'XDG_SESSION_ID': '9639',
   'SLURMD_NODENAME': 'node157',
   'SLURM_TOPOLOGY_ADDR': 'node157',
   'SLURM_NTASKS_PER_NODE': '24',
   'HOSTNAME': 'login01',
   'SLURM_PRIO_PROCESS': '0',
   'SLURM_SRUN_COMM_PORT': '44097',
   'SHELL': '/bin/bash',
   'TERM': 'xterm-color',
   'SLURM_JOB_QOS': 'qstand',
   'SLURM_PTY_WIN_ROW': '33',
   'HISTSIZE': '1000',
   'TMPDIR': '/tmp',
   'SLURM_TOPOLOGY_ADDR_PATTERN': 'node',
   'SSH_CLIENT': '10.231.210.198 43508 22',
   'CONDA_SHLVL': '2',
   'CONDA_PROMPT_MODIFIER': '(tf-nightly) ',
   'WINDOWID': '0',
   'QTDIR': '/usr/lib64/qt-3.3',
   'QTINC': '/usr/lib64/qt-3.3/include',
   'SSH_TTY': '/dev/pts/5',
   'QT_GRAPHICSSYSTEM_CHECKED': '1',
   'SLURM_NNODES': '1',
   'USER': 'ye53nis',
   'http_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
   'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',
   'CONDA_EXE': '/cluster/miniconda3/bin/conda',
   'SLURM_STEP_NUM_NODES': '1',
   'SLURM_JOBID': '564736',
   'SRUN_DEBUG': '3',
   'SLURM_NTASKS': '24',
   'SLURM_LAUNCH_NODE_IPADDR': '192.168.192.5',
   'SLURM_STEP_ID': '0',
   'TMUX': '/tmp/tmux-67339/default,27827,6',
   '_CE_CONDA': '',
   'CONDA_PREFIX_1': '/cluster/miniconda3',
   'SLURM_STEP_LAUNCHER_PORT': '44097',
   'SLURM_TASKS_PER_NODE': '24',
   'MAIL': '/var/spool/mail/ye53nis',
   'PATH': '/home/ye53nis/.conda/envs/tf-nightly/bin:/home/lex/Programme/miniconda3/envs/tf-nightly-lab/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/home/lex/Programme/miniconda3/bin:/usr/sbin:/home/ye53nis/.local/bin:/home/ye53nis/bin',
   'SLURM_WORKING_CLUSTER': 'hpc:192.168.192.1:6817:8448',
   'SLURM_JOB_ID': '564736',
   'CONDA_PREFIX': '/home/ye53nis/.conda/envs/tf-nightly',
   'SLURM_JOB_USER': 'ye53nis',
   'SLURM_STEPID': '0',
   'PWD': '/',
   'SLURM_SRUN_COMM_HOST': '192.168.192.5',
   'LANG': 'en_US.UTF-8',
   'SLURM_PTY_WIN_COL': '205',
   'SLURM_UMASK': '0022',
   'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles',
   'SLURM_JOB_UID': '67339',
   'LOADEDMODULES': '',
   'SLURM_NODEID': '0',
   'TMUX_PANE': '%6',
   'SLURM_SUBMIT_DIR': '/',
   'SLURM_TASK_PID': '318640',
   'SLURM_NPROCS': '24',
   'SLURM_CPUS_ON_NODE': '24',
   'SLURM_DISTRIBUTION': 'block',
   'https_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
   'SLURM_PROCID': '0',
   'HISTCONTROL': 'ignoredups',
   '_CE_M': '',
   'SLURM_JOB_NODELIST': 'node157',
   'SLURM_PTY_PORT': '34941',
   'HOME': '/home/ye53nis',
   'SHLVL': '3',
   'SLURM_LOCALID': '0',
   'SLURM_JOB_GID': '13280',
   'SLURM_JOB_CPUS_PER_NODE': '24',
   'SLURM_CLUSTER_NAME': 'hpc',
   'SLURM_GTIDS': '0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23',
   'SLURM_SUBMIT_HOST': 'login01',
   'SLURM_JOB_PARTITION': 's_standard',
   'MATHEMATICA_HOME': '/cluster/apps/mathematica/11.3',
   'CONDA_PYTHON_EXE': '/cluster/miniconda3/bin/python',
   'LOGNAME': 'ye53nis',
   'SLURM_STEP_NUM_TASKS': '24',
   'QTLIB': '/usr/lib64/qt-3.3/lib',
   'SLURM_JOB_ACCOUNT': 'iaob',
   'SLURM_JOB_NUM_NODES': '1',
   'MODULESHOME': '/usr/share/Modules',
   'CONDA_DEFAULT_ENV': 'tf-nightly',
   'LESSOPEN': '||/usr/bin/lesspipe.sh %s',
   'SLURM_STEP_TASKS_PER_NODE': '24',
   'PORT': '9999',
   'SLURM_STEP_NODELIST': 'node157',
   'DISPLAY': ':0',
   'XDG_RUNTIME_DIR': '',
   'XAUTHORITY': '/home/lex/.Xauthority',
   'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\n}',
   '_': '/home/ye53nis/.conda/envs/tf-nightly/bin/jupyter',
   'JPY_PARENT_PID': '318741',
   'CLICOLOR': '1',
   'PAGER': 'cat',
   'GIT_PAGER': 'cat',
   'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'}
#+end_example

** Tensorboard tunnel, Mlflow ui tunnel


#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session mlflowui
  conda activate tf
  mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns --default-artifact-root file:///beegfs/ye53nis/drmed-git -p 5001
#+END_SRC

#+RESULTS:
#+begin_example
  (tf) [ye53nis@login01 ~]$ mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
  [2021-08-04 23:04:35 +0200] [11795] [INFO] Starting gunicorn 20.1.0
  [2021-08-04 23:04:35 +0200] [11795] [INFO] Listening at: http://127.0.0.1:5001 (11795)
  [2021-08-04 23:04:35 +0200] [11795] [INFO] Using worker: sync
  [2021-08-04 23:04:35 +0200] [11800] [INFO] Booting worker with pid: 11800
#+end_example


#+CALL: ssh-tunnel[:session local3](port="5001", node="login01")

#+RESULTS:
|                   |           |                                        |           |       |          |      |      |                |
| sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |       |          |      |      |                |
| ye53nis@login01's | password: |                                        |           |       |          |      |      |                |
| bind:             | Address   | already                                | in        | use |          |      |      |                |
| Last              | login:    | Thu                                    | Aug       |     5 | 20:32:16 | 2021 | from | 10.231.184.163 |

#+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session tensorboard
  conda activate tf
  tensorboard --logdir /beegfs/ye53nis/tmp
#+END_SRC

#+RESULTS:
#+begin_example
  (tf-nightly) [ye53nis@login01 ~]$ tensorboard --logdir /tmp/tb/hparams
  2021-07-27 14:55:37.034279: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
  2021-07-27 14:55:37.034359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login01): /proc/driver/nvidia/version does not exist
  /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/tensorboard_data_server/bin/server: /lib64/libc.so.6: version `GLIBC_2.18' not found (required by /home/ye53nis/.conda/envs/tf-nightly/lib/python3.9/site-packages/tensorb
  oard_data_server/bin/server)
  Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
  TensorBoard 2.6.0a20210720 at http://localhost:6006/ (Press CTRL+C to quit)
#+end_example

#+CALL: ssh-tunnel[:session local2](port="6006", node="login01")

#+RESULTS:
|                   |           |                                        |           |       |          |      |      |                |
| sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |       |          |      |      |                |
| ye53nis@login01's | password: |                                        |           |       |          |      |      |                |
| bind:             | Address   | already                                | in        | use |          |      |      |                |
| Last              | login:    | Tue                                    | Aug       |     3 | 13:55:10 | 2021 | from | 10.231.184.125 |

** gpu node

   #+CALL: setup-tmux[:session local]

   #+RESULTS:
   |         |                                        |           |
   | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
   | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

   #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
     cd /
     srun -p gpu_p100 --time=7-10:00:00 --ntasks-per-node=12 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
   #+END_SRC

   #+RESULTS:
   #+begin_example
     (tf) [ye53nis@login01 /]$ srun -p gpu_a100 --time=3-10:00:00 --ntasks-per-node=12 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
     (base) [ye53nis@node131 /]$ cd /
     (base) [ye53nis@node131 /]$
   #+end_example

   #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
     module load nvidia/cuda/11.2
     module load nvidia/cudnn/8.1
     module list
   #+END_SRC

   #+RESULTS:
   #+begin_example
     (base) [ye53nis@node131 /]$ module list
     Currently Loaded Modulefiles:
       1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
     (base) [ye53nis@node131 /]$
   #+end_example
