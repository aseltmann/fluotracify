#+TITLE: Lab book Fluotracify
#+AUTHOR: Alexander Seltmann
#+LANGUAGE: en
#+PROPERTY: header-args :eval never-export :exports both
#+OPTIONS: toc:4
#+OPTIONS: H:4
#+HTML_HEAD_EXTRA: <style type="text/css">.example {background-color: #FBFBBF;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-emacs-lisp {background-color: #F7ECFB;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-sh {background-color: #F0FBE9;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-tmux {background-color: #E1EED8;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-python {background-color: #E6EDF4;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">pre.src-jupyter-python {background-color: #FAEAE1;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details {padding: 1em; background-color: #f0f0f0; border-radius: 15px; color: hsl(157 75% 20%); font-size: 0.9em; box-shadow: 0.05em 0.1em 5px 0.01em  #00000057;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">details:hover {background:pink;}</style>
#+HTML_HEAD_EXTRA: <style type="text/css">table {display: block; overflow-x: auto; white-space: nowrap;}</style>


* Technical Notes
** README
*** General:
   - This file corresponds to my lab book for my doctoral thesis tackling
     artifact correction in Fluorescence Correlation Spectroscopy (FCS)
     measurements using Deep Neural Networks. It also contains notes taken
     during the process of setting up this workflow for reproducible research.
   - This file contains explanations of how things are organized, of the
     workflow for doing experiments, changes made to the code, and the observed
     behavior in the "* Data" section.
   - The branching model used is described in [[http://starpu-simgrid.gforge.inria.fr/misc/SIGOPS_paper.pdf][this paper]]. Therefore: if you
     are interested in the "* Data" section, you have to =git clone= the /data/
     branch of the repository. The /main/ branch is clean from any results, it
     contains only source code and the analysis.
   - This project is my take on [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]]. The idea was postulated in
     a blog post in 2006:
     #+BEGIN_QUOTE
     ... there is a URL to a laboratory notebook that is freely available and
     indexed on common search engines. It does not necessarily have to look like
     a paper notebook but it is essential that all of the information available
     to the researchers to make their conclusions is equally available to the
     rest of the world ---Jean-Claude Bradley
     #+END_QUOTE
   - Proposal on how to deal with truly private data (e.g. notes from a
     confidential meeting with a colleague), which might otherwise be noted in a
     normal Lab notebook: do not include them here. Only notes relevant to the
     current project should be taken
*** Code block languages used in this document

   #+BEGIN_SRC sh
     # This is a sh block for shell / bash scripting. In the context of this file,
     # these blocks are mainly used for operations on my local computer.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light green colour (#F0FBE9)
   #+END_SRC

   #+BEGIN_SRC tmux
     # This block can open and access tmux sessions, used for shell scripting on
     # remote computing clusters.
     # In the LabBook.html rendering of this document, these blocks will have a
     # distinct light green colour (#E1EED8)
   #+END_SRC

   #+BEGIN_SRC python
     # This is a python block. In the context of this file, it is seldomly used
     # (only for examplary scripts.)
     # In the LabBook.html rendering of this document, these blocks will have a
     # light blue colour (#E6EDF4)
   #+END_SRC

   #+BEGIN_SRC jupyter-python :session /jpy:localhost#8889:704d35be-572a-4268-a70b-565164b8620f
     # This is a jupyter-python block. The code is sent to a jupyter kernel running
     # on a remote high performance computing cluster. Most of my jupyter code is
     # executed this way.
     # In the LabBook.html rendering of this document, these blocks will have a
     # light orange colour (#FAEAE1)
   #+END_SRC

   #+BEGIN_SRC emacs-lisp
     ;; This is a emacs-lisp block, the language used to customize Emacs, which is
     ;; sometimes necessary, since the reproducible workflow of this LabBook is
     ;; tightly integrated with Emacs and org-mode.
     ;; In the LabBook.html rendering of this document, these blocks will have a
     ;; light violet colour (#F7ECFB)
   #+END_SRC

   #+begin_example
     This is a literal example block. It can be used very flexibly - in the context
     of this document the output of most code blocks is displayed this way.
     In the LabBook.html rendering of this document, these blocks will have a light
     yellow colour (#FBFBBF)
   #+end_example

   #+begin_details
   #+begin_example
     This is a literal example block enclosed in a details block. This is useful to
     make the page more readable by collapsing large amounts of output.
     In the Labbook.html rendering of this document, the details block will have a
     light grey colour (#f0f0f0) and a pink color when hovering above it.
   #+end_example
   #+end_details

*** Experiments workflow:
   1) Create a new branch from =main=
   2) Print out the git log from the latest commit and the metadata
   3) Call the analysis scripts, follow the principles outlined in
      [[* Organization of code]]
   4) All machine learning runs are saved in =data/mlruns=, all other data in
      =data/#experiment-name=
   5) Add a ~** exp-<date>-<name>~" section to this file under [[* Data]]
   6) Commit/push the results of this separate branch
   7) Merge this new branch with the remote =data= branch
*** Example for experimental setup procedure

**** Setting starting a jupyter kernel from a remote jupyter session using =emacs-jupyter= in =org babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-jupyter-setup
    :END:

*** tools used (notes)
**** Emacs =magit=
   - =gitflow-avh= (=magit-flow=) to follow the flow
   - possibly https://github.com/magit/magit-annex for large files. Follow this:
     https://git-annex.branchable.com/walkthrough/
   - maybe check out git-toolbelt at some point
     https://github.com/nvie/git-toolbelt#readme with
     https://nvie.com/posts/git-power-tools/
**** jupyter
   - emacs jupyter for running and connecting to kernel on server:
     https://github.com/dzop/emacs-jupyter
   - if I actually still would use .ipynb files, these might come handy:
     + jupytext: https://github.com/mwouts/jupytext
     + nbstripout: https://github.com/kynan/nbstripout
**** mlflow
   - https://docs.faculty.ai/user-guide/experiments/index.html and
     https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/hls-image-processing/02-image-segmentation-dl.html
**** tensorflow
   - https://www.tensorflow.org/tensorboard/image_summaries

** Template for data entry and setup notes:
*** exp-#date-#title
**** git:

    #+begin_src sh
    git log -1
    #+end_src

**** System Metadata:

    #+NAME: jp-metadata
    #+BEGIN_SRC jupyter-python :var _long="true"
      import os
      import pprint

      ramlist = os.popen('free -th').readlines()[-1].split()[1:]

      print('No of CPUs in system:', os.cpu_count())
      print('No of CPUs the current process can use:',
            len(os.sched_getaffinity(0)))
      print('load average:', os.getloadavg())
      print('os.uname(): ', os.uname())
      print('PID of process:', os.getpid())
      print('RAM total: {}, RAM used: {}, RAM free: {}'.format(
          ramlist[0], ramlist[1], ramlist[2]))

      !echo the current directory: $PWD
      !echo My disk usage:
      !df -h
      if _long:
          %conda list
          pprint.pprint(dict(os.environ), sort_dicts=False)

    #+END_SRC

**** Tmux setup and scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-tmux
    :END:

    #+NAME: setup-tmux
    #+BEGIN_SRC sh :session local
    rm ~/.tmux-local-socket-remote-machine
    REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
    echo $REMOTE_SOCKET
    ssh ara -tfN \
        -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
    #+END_SRC

    #+RESULTS: setup-tmux
    | rm:                                  | cannot                               | remove    | '/home/lex/.tmux-local-socket-remote-machine': | No | such | file | or | directory |
    | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |                                                |    |      |      |    |           |
    | /tmp/tmux-67339/default              |                                      |           |                                                |    |      |      |    |           |
    | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |                                                |    |      |      |    |           |

**** SSH tunneling
    :PROPERTIES:
    :CUSTOM_ID: ssh-tunneling
    :END:

    Different applications can be run on the remote compute node. If I want to
    access them at the local machine, and open them with the browser, I use this
    tunneling script.

    #+NAME: ssh-tunnel
    #+BEGIN_SRC sh :session org-tunnel :var port="8889" :var node="node001"
    ssh -t -t ara -L $port:localhost:$port ssh $node -L $port:Localhost:$port
    #+END_SRC

    Apps I use that way:
    - Jupyter lab for running Python 3-Kernels
    - TensorBoard
    - Mlflow ui

**** jupyter scripts
    :PROPERTIES:
    :CUSTOM_ID: scripts-jp
    :END:

    Starting a jupyter instance on a server where the necessary libraries are
    installed is easy using this script:

    #+NAME: jpt-tmux
    #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine
    conda activate tf
    export PORT=8889
    export XDG_RUNTIME_DIR=''
    export XDG_RUNTIME_DIR=""
    jupyter lab --no-browser --port=$PORT
    #+END_SRC

    On the compute node of the HPC, the users' environment is managed through
    module files using the system [[https://lmod.readthedocs.io][Lmod]]. The =export XDG_RUNTIME_DIR= statements
    are needed because of a jupyter bug which did not let it start. Right now,
    =ob-tmux= does not support a =:var= header like normal =org-babel= does. So
    the =$port= variable has to be set here in the template.

    Now this port has to be tunnelled on our local computer (See
    [[#ssh-tunneling]]). While the tmux session above keeps running, no matter if
    Emacs is running or not, this following ssh tunnel needs to be active
    locally to connect to the notebook. If you close Emacs, it would need to be
    reestablished

*** Setup notes
**** Setting up a tmux connection from using =ob-tmux= in =org-babel=
    :PROPERTIES:
    :CUSTOM_ID: sec-tmux-setup
    :END:
    - prerequisite: tmux versions need to be the same locally and on the server.
      Let's verify that now.
      - the local tmux version:

        #+BEGIN_SRC sh
        tmux -V
        #+END_SRC

        #+RESULTS:
        : tmux 3.0a

      - the remote tmux version:

       #+BEGIN_SRC sh :session local
        ssh ara tmux -V
      #+END_SRC

        #+RESULTS:
        | ye53nis@ara-login01.rz.uni-jena.de's | password: |
        | tmux                                 | 3.0a      |

    - as is described in [[https://github.com/ahendriksen/ob-tmux][the ob-tmux readme]], the following code snippet creates
      a socket on the remote machine and forwards this socket to the local
      machine (note that =socket_path= was introduced in tmux version 2.2)

      #+BEGIN_SRC sh :session local
      REMOTE_SOCKET=$(ssh ara 'tmux ls -F "#{socket_path}"' | head -1)
      echo $REMOTE_SOCKET
      ssh ara -tfN \
          -L ~/.tmux-local-socket-remote-machine:$REMOTE_SOCKET
      #+END_SRC

      #+RESULTS:
      | ye53nis@ara-login01.rz.uni-jena.de's | password:                            |           |
      | /tmp/tmux-67339/default              |                                      |           |
      | >                                    | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    - now a new tmux session with name =ob-NAME= is created when using a code
      block which looks like this: =#+BEGIN_SRC tmux :socket
      ~/.tmux-local-socket-remote-machine :session NAME=
    - Commands can be sent now to the remote tmux session, BUT note that the
      output is not printed yet
    - there is a workaround for getting output back to our LabBook.org: A [[#scripts-tmux][script]]
      which allows to print the output from the tmux session in an
      =#+begin_example=-Block below the tmux block by pressing =C-c C-o= or =C-c
      C-v C-o= when the pointer is inside the tmux block.

**** =emacs-jupyter= Setup

    =Emacs-jupyter= aims to be an API for a lot of functionalities of the
    =jupyter= project. The documentation can be found on [[https://github.com/dzop/emacs-jupyter][GitHub]].

    1. For the *whole document*: connect to a running jupyter instance
       1. =M-x jupyter-server-list-kernels=
          1. set server URL, e.g. =http://localhost:8889=
          2. set websocket URL, e.g. =http://localhost:8889=
       2. two possibilities
          1. kernel already exists $\to$ list of kernels and =kernel-ID= is displayed
          2. kernel does not exist $\to$ prompt asks if you want to start one $\to$
             *yes* $\to$ type kernel you want to start, e.g. =Python 3=
    2. In the *subtree* where you want to use =jupyter-python= blocks with =org
       babel=
       1. set the =:header-args:jupyter-python :session
          /jpy:localhost#kernel:8889-ID=
       2. customize the output folder using the following org-mode variable:
          #+BEGIN_SRC  emacs-lisp
            (setq org-babel-jupyter-resource-directory "./data/exp-test/plots")
          #+END_SRC

          #+RESULTS:
          : ./data/exp-test/plots
    3. For each *individual block*, the following customizations might be useful
       1. jupyter kernels can return multiple kinds of rich output (images,
          html, ...) or scalar data (plain text, numbers, lists, ...). To force
          a plain output, use =:results scalar=. To show the output in the
          minibuffer only, use =:results silent=
       2. to change the priority of different rich outputs, use =:display=
          header argument, e.g. =:display text/plain text/html= prioritizes
          plain text over html. All supported mimetypes in default order:
          1. text/org
          2. image/svg+xml, image/jpeg, image/png
          3. text/html
          4. text/markdown
          5. text/latex
          6. text/plain
       3. We can set jupyter to output pandas DataFrames as org tables
          automatically using the source block header argument =:pandoc t=
       4. useful keybindings
          - =M-i= to open the documentation for wherever your pointer is (like
            pressing =Shift-TAB= in Jupyter notebooks)
          - =C-c C-i= to interrupt the kernel, =C-c C-r= to restart the kernel

*** Notes on archiving
**** Exporting the LabBook.org to html in a twbs style
     - I am partial to the twitter bootstrap theme of html, since I like it's
       simple design, but clear structure with a nice table of contents at the
       side → the following org mode extension supports a seemless export to
       twitter bootstrap html: https://github.com/marsmining/ox-twbs
     - when installed, the export can be triggered via the command
       =(org-twbs-export-as-html)= or via the keyboard shortcut for export =C-c
       C-e= followed by =w= for Twitter bootstrap and =h= for saving the .html
     - _Things to configure:_
       - in general, there are multiple export options:
         https://orgmode.org/manual/Export-Settings.html
       - E.g. I set 2 =#+OPTIONS= keywords at the begin of the file: =toc:4= and
         =H:4= which make sure that in my export my sidebar table of contents
         will show numbered headings till a depth of 4.
       - I configured my code blocks so that they will not be evaluated when
         exporting (I would recommend this especially if you only export for
         archiving) and that both the code block and the output will be exported
         with the keyword: =#+PROPERTY: header-args :eval never-export :exports
         both=
       - To discriminate between code blocks for different languages I gave each
         of them a distinct colour using =#+HTML_HEAD_EXTRA: <style...= (see
         above)
       - I had to configure a style for =table=, so that the
         - =display: block; overflow-x: auto;= gets the table to be restricted
           to the width of the text and if it is larger, activates scrolling
         - =white-space: nowrap;= makes it that there is no wrap in a column, so
           it might be broader, but better readable if you have scrolling anyway
     - _Things to do before exporting / Troubleshooting while exporting:_
       - when using a dark theme for you emacs, the export of the code blocks
         might show some ugly dark backgrounds from the theme. If this becomes
         an issue, change to a light theme for the export with =M-x
         (load-theme)= and choose =solarized-light=
       - only in the =data= branch you set the git tags after merging. If you
         want to show them here, execute the corresponding function in [[Git TAGs]]
       - make sure your file links work properly! I recommend referencing your
         files relatively (e.g. [ [ f ile:./data/exp-XXXXXX-test/test.png]]
         without spaces). Otherwise there will be errors in your /*Messages*/
         buffer
       - There might be errors with your code blocks
         - e.g. the export function expects you to assign a default variable to
           your functions
         - if you call a function via the =#+CALL= mechanism, it wants you to
           include two parentheses for the function, e.g. =#+CALL: test()=
       - check indentation of code blocks inside lists
       - add a =details= block around large output cells. This makes them
         expandable. I added some =#+HTML_HEAD_EXTRA: <style...= inspired by
         [[https://alhassy.github.io/org-special-block-extras/#Folded-Details][alhassy]]. That's how the =details= block looks like:
         #+begin_example
         #+begin_details

         #+end_details
         #+end_example
       - If you reference a parameter with an underscore in the name, use the
         org markdown tricks to style them like code (~==~ or =~~=), otherwise
         the part after the underscore will be rendered like a subscript:
         =under_score= vs under_score
     - _Things to do after exporting:_
       - In my workflow, the exported =LabBook.html= with the overview of all
         experiments is in the =data= folder. If you move the file, you will
         have to fix the file links for the new location, e.g. via "Find and
         replace" =M-%=:
         - if you move the org file → in the org file find =[[file:./data/= and
           replace with =[[file:./= → then export with =C-c C-e w h=
         - if you export first with =C-c C-e w h= and move the html file to
           =data= → in the html file find =./data= and replace with =.=
** Organization of git

*** remote/origin/main branch:
  - contains all the source code in folder **src/** which is used for experiments.
  - contains the **LabBook.org** template
  - contains setup- and metadata files such as **MLproject** or **conda.yaml**
  - the log contains only lasting alterations on the folders and files mentioned
    above, which are e.g. used for conducting experiments or which introduce new
    features. Day-to-day changes in code
*** remote/origin/exp### branches:
  - if an experiment is done, the code and templates will be branched out from
    *main* in an *#experiment-name* branch, ### meaning some meaningful
    descriptor.
  - all data generated during the experiment (e.g. .csv files, plots, images,
    etc), is stored in a folder with the name **data/#experiment-name**, except
    machine learning-specific data and metadata from `mlflow` runs, which are
    saved under **data/mlruns** (this allows easily comparing machine learning
    runs with different experimental settings)
  - The **LabBook.org** file is essential
    - If possible, all code is executed from inside this file (meaning analysis
      scripts or calling the code from the **scr/** directory).
    - All other steps taken during an experiment are noted down, as well as
      conclusions or my thought process while conducting the experiment
    - Provenance data, such as Metadata about the environment the code was
      executed in, the command line output of the code, and some
*** remote/origin/develop branch:
  - this is the branch I use for day to day work on features and exploration.
    All of my current activity can be followed here.
*** remote/origin/data branch:
  - contains a full cronicle of the whole research process
  - all *#experiment-name* branches are merged here. Afterwards the original
    branch is deleted and on the data branch there is a *Git tag* which shows
    the merge commit to make accessing single experiments easy.
  - the *develop* branch is merged here as well.

*** Git TAGs
**** Stable versions:
**** All tags from git:
   #+begin_src sh :results output
    git push origin --tags
    git tag -n1
   #+end_src

   #+RESULTS:
   : exp-200402-test Merge branch 'exp-200402-test' into data
   : exp-200520-unet Merge branch 'exp-310520-unet' into data
   : exp-200531-unet Merge branch 'heads/exp-310520-unet' into data
   : exp-201231-clustsim exp-201231-clustsim
   : exp-210204-unet Add exp-210204-unet LabBook part 3
   : exp-310520-unet move exp-310520-unet to data branch manually
** Organization of code
*** scripts:
*** src/
**** fluotracify/
***** imports/
***** simulations/
***** training/
***** applications/
***** doc/
    - use Sphinx
      - follow this: https://daler.github.io/sphinxdoc-test/includeme.html
      - evtl export org-mode Readme to rst via https://github.com/msnoigrs/ox-rst
      - possibly heavily use
        http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html
    - for examples sphinx-galleries could be useful
      https://sphinx-gallery.github.io/stable/getting_started.html

**** nanosimpy/
    - cloned from dwaithe with refactoring for Python 3-compatibility

** Changes in this repository (without "* Data" in this file)
*** Changes in LabBook.org (without "* Data")
**** 2022-02-19
     - Add =#+HTML_HEAD_EXTRA: <style...= for =table= to enable scrolling if the
       table overflows
**** 2021-12-16
     - Add =details= blocks, corresponding =#+HTML_HEAD_EXTRA: <style...= and
       documentation in  [[Notes on archiving]]
**** 2021-08-05
     - Rename =master= branch to =main= branch
**** 2021-04-04
     - Add =#+OPTIONS: H:4= and =#+OPTIONS: toc:4= to show up to 4 levels of
       depth in the html (twbs) export of this LabBook in the table of contents
       at the side
     - I added [[Notes on archiving]]
**** 2020-11-04
    - update "jupyter scripts" in [[Template for data entry and setup notes:]]
      for new conda environment on server (now =conda activate tf-nightly=)
**** 2020-05-31
    - extend general documentation in README
    - Add code block examples
    - extend documentation on experiment workflow
    - move setup notes from README to "Template for data entry and setup notes"
    - remove emacs-lisp code for custom tmux block functions (not relevant
      enough)
    - change named "jpt-tmux" from starting a jupyter notebook to starting
      jupyter lab. Load a conda environment instead of using Lmod's =module
      load=
**** 2020-05-07
    - extend documentation on git model
    - extend documentation on jupyter setup
**** 2020-04-22
    - added parts of README which describe the experimental process
    - added templates for system metadata, tmux, jupyter setup
    - added organization of code
**** 2020-03-30
    - set up lab book and form git repo accoring to setup by Luka Stanisic et al
*** Changes in src/fluotracify

* Data
** exp-220227-unet
*** Setup: GPU node on HPC

    1. Setup tmux
       #+CALL: setup-tmux[:session local]

       #+RESULTS:
       |         |                                        |           |
       | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
       | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    2. first, connect with the GPU node in the high performance cluster
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         cd /
         srun -p gpu_p100 --time=7-10:00:00 --ntasks-per-node=12 --mem-per-cpu=4000 --gres=gpu:1 --pty bash
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (base) [ye53nis@node128 /]$
       #+end_example

    3. Load CUDA and cuDNN in the version compatible to your tensorflow library
       (see https://www.tensorflow.org/install/source#gpu)
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         module load nvidia/cuda/11.2
         module load nvidia/cudnn/8.1
         module list
       #+END_SRC

       #+RESULTS:
       #+begin_example
         Currently Loaded Modulefiles:
           1) nvidia/cuda/11.2   2) nvidia/cudnn/8.1
         (base) [ye53nis@node128 /]$
       #+end_example

    4. Branch out git branch =exp-210807-hparams= from =main= (done via magit)
       and make sure you are on the correct branch

       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         cd /beegfs/ye53nis/drmed-git
         git checkout exp-220227-unet
       #+END_SRC

       #+RESULTS:
       #+begin_example
         Checking out files: 100% (147/147), done.
         M       src/nanosimpy
         Branch exp-220227-unet set up to track remote branch exp-220227-unet from origin.
         Switched to a new branch 'exp-220227-unet'
         (base) [ye53nis@node128 drmed-git]$
       #+end_example

    7. load conda environment, define MLflow environment variables and create log directory
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
         conda activate tf
         cd /beegfs/ye53nis/drmed-git
         export MLFLOW_EXPERIMENT_NAME=exp-220227-unet
         export MLFLOW_TRACKING_URI=file:./data/mlruns
         mkdir -p data/exp-220227-unet/jupyter
         mkdir ../tmp
       #+END_SRC

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node128 drmed-git]$
       #+end_example

    8. set output directory for matplotlib plots in jupyter
       #+begin_src emacs-lisp
         (setq org-babel-jupyter-resource-directory "./data/exp-220227-unet/jupyter")
       #+end_src

       #+RESULTS:
       : ./data/exp-220227-unet/jupyter

*** Setup: Jupyter node on HPC
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3
    :END:
    1. Set up tmux (if we haven't done that before) (=#+CALL:
       setup-tmux[:session local]=)
       #+CALL: setup-tmux[:session local]

       #+RESULTS:
       |         |                                        |           |
       | sh-5.1$ | ye53nis@ara-login01.rz.uni-jena.de's | password: |
       | >       | ye53nis@ara-login01.rz.uni-jena.de's | password: |

    2. Request compute node
       #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session jpmux
         cd /
         srun -p s_standard --time=7-10:00:00 --ntasks-per-node=24 --mem-per-cpu=2000 --pty bash
       #+END_SRC

    3. Start Jupyter Lab (~#+CALL: jpt-tmux[:session jpmux]~)
       #+CALL: jpt-tmux[:session jpmux]

       #+RESULTS:
       #+begin_example
         (tf) [ye53nis@node160 /]$ jupyter lab --no-browser --port=$PORT
         [I 2022-02-27 21:53:58.608 ServerApp] jupyterlab | extension was successfully linked.
         [I 2022-02-27 21:54:06.305 ServerApp] nbclassic | extension was successfully linked.
         [I 2022-02-27 21:54:06.854 LabApp] JupyterLab extension loaded from /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/jupyterlab
         [I 2022-02-27 21:54:06.855 LabApp] JupyterLab application directory is /home/ye53nis/.conda/envs/tf/share/jupyter/lab
         [I 2022-02-27 21:54:06.864 ServerApp] jupyterlab | extension was successfully loaded.
         [I 2022-02-27 21:54:06.958 ServerApp] nbclassic | extension was successfully loaded.
         [I 2022-02-27 21:54:06.959 ServerApp] Serving notebooks from local directory: /
         [I 2022-02-27 21:54:06.959 ServerApp] Jupyter Server 1.4.1 is running at:
         [I 2022-02-27 21:54:06.959 ServerApp] http://localhost:8889/lab?token=1f5faf05b94506631e22832abcc6da3142d96ebcd4514c77
         [I 2022-02-27 21:54:06.959 ServerApp]  or http://127.0.0.1:8889/lab?token=1f5faf05b94506631e22832abcc6da3142d96ebcd4514c77
         [I 2022-02-27 21:54:06.959 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
         [C 2022-02-27 21:54:07.092 ServerApp]

             To access the server, open this file in a browser:
                 file:///home/ye53nis/.local/share/jupyter/runtime/jpserver-418797-open.html
             Or copy and paste one of these URLs:
                 http://localhost:8889/lab?token=1f5faf05b94506631e22832abcc6da3142d96ebcd4514c77
              or http://127.0.0.1:8889/lab?token=1f5faf05b94506631e22832abcc6da3142d96ebcd4514c77
       #+end_example

    4. Create SSH Tunnel for jupyter lab to the local computer (e.g. ~#+CALL:
       ssh-tunnel(port="8889", node="node160")~)
       #+CALL: ssh-tunnel(port="8889", node="node160")

       #+RESULTS:
       |                   |           |                                        |           |   |          |      |      |             |
       | sh-5.1$           | sh-5.1$   | ye53nis@ara-login01.rz.uni-jena.de's | password: |   |          |      |      |             |
       | ye53nis@node160's | password: |                                        |           |   |          |      |      |             |
       | Last              | login:    | Thu                                    | Mar       | 3 | 14:59:00 | 2022 | from | login01.ara |

    5. I started a Python3 kernel using =jupyter-server-list-kernels=. Then I
       added the kernel ID to the =:PROPERTIES:= drawer of this (and following)
       subtrees.
       #+begin_example
       python3           c4f3acce-60c4-489d-922c-407da110fd6a   a few seconds ago    idle       1
       #+end_example

    6. Test (~#+CALL: jp-metadata(_long='True)~) and record metadata:
       #+CALL: jp-metadata(_long='True)

       #+RESULTS:
       #+begin_example
         No of CPUs in system: 72
         No of CPUs the current process can use: 24
         load average: (18.98, 19.87, 21.27)
         os.uname():  posix.uname_result(sysname='Linux', nodename='node160', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64')
         PID of process: 404234
         RAM total: 199G, RAM used: 32G, RAM free: 76G
         the current directory: /
         My disk usage:
         Filesystem           Size  Used Avail Use% Mounted on
         /dev/sda1             50G  3.8G   47G   8% /
         devtmpfs              94G     0   94G   0% /dev
         tmpfs                 94G  158M   94G   1% /dev/shm
         tmpfs                 94G  163M   94G   1% /run
         tmpfs                 94G     0   94G   0% /sys/fs/cgroup
         nfs01-ib:/cluster    2.0T  469G  1.6T  23% /cluster
         nfs01-ib:/home        80T   68T   13T  85% /home
         nfs03-ib:/pool/work  100T   71T   29T  71% /nfsdata
         nfs02-ib:/data01      88T   73T   15T  84% /data01
         /dev/sda5            2.0G   34M  2.0G   2% /tmp
         /dev/sda6            169G   33M  169G   1% /local
         /dev/sda3            6.0G  411M  5.6G   7% /var
         beegfs_nodev         524T  461T   64T  88% /beegfs
         tmpfs                 19G     0   19G   0% /run/user/67339# packages in environment at /home/ye53nis/.conda/envs/tf:
         #
         # Name                    Version                   Build  Channel
         _libgcc_mutex             0.1                        main
         _openmp_mutex             4.5                       1_gnu
         absl-py                   1.0.0                    pypi_0    pypi
         alembic                   1.7.6                    pypi_0    pypi
         anyio                     2.2.0            py39h06a4308_1
         argon2-cffi               20.1.0           py39h27cfd23_1
         asteval                   0.9.26                   pypi_0    pypi
         astunparse                1.6.3                    pypi_0    pypi
         async_generator           1.10               pyhd3eb1b0_0
         attrs                     21.4.0             pyhd3eb1b0_0
         babel                     2.9.1              pyhd3eb1b0_0
         backcall                  0.2.0              pyhd3eb1b0_0
         bleach                    4.1.0              pyhd3eb1b0_0
         brotlipy                  0.7.0           py39h27cfd23_1003
         ca-certificates           2021.10.26           h06a4308_2
         cachetools                5.0.0                    pypi_0    pypi
         certifi                   2021.10.8        py39h06a4308_2
         cffi                      1.15.0           py39hd667e15_1
         charset-normalizer        2.0.4              pyhd3eb1b0_0
         click                     8.0.3                    pypi_0    pypi
         cloudpickle               2.0.0                    pypi_0    pypi
         cryptography              36.0.0           py39h9ce1e76_0
         cycler                    0.11.0                   pypi_0    pypi
         cython                    0.29.27                  pypi_0    pypi
         databricks-cli            0.16.4                   pypi_0    pypi
         debugpy                   1.5.1            py39h295c915_0
         decorator                 5.1.1              pyhd3eb1b0_0
         defusedxml                0.7.1              pyhd3eb1b0_0
         docker                    5.0.3                    pypi_0    pypi
         entrypoints               0.3              py39h06a4308_0
         fcsfiles                  2022.2.2                 pypi_0    pypi
         flask                     2.0.2                    pypi_0    pypi
         flatbuffers               2.0                      pypi_0    pypi
         fonttools                 4.29.1                   pypi_0    pypi
         future                    0.18.2                   pypi_0    pypi
         gast                      0.5.3                    pypi_0    pypi
         gitdb                     4.0.9                    pypi_0    pypi
         gitpython                 3.1.26                   pypi_0    pypi
         google-auth               2.6.0                    pypi_0    pypi
         google-auth-oauthlib      0.4.6                    pypi_0    pypi
         google-pasta              0.2.0                    pypi_0    pypi
         greenlet                  1.1.2                    pypi_0    pypi
         grpcio                    1.43.0                   pypi_0    pypi
         gunicorn                  20.1.0                   pypi_0    pypi
         h5py                      3.6.0                    pypi_0    pypi
         idna                      3.3                pyhd3eb1b0_0
         importlib-metadata        4.8.2            py39h06a4308_0
         importlib_metadata        4.8.2                hd3eb1b0_0
         ipykernel                 6.4.1            py39h06a4308_1
         ipython                   7.31.1           py39h06a4308_0
         ipython_genutils          0.2.0              pyhd3eb1b0_1
         itsdangerous              2.0.1                    pypi_0    pypi
         jedi                      0.18.1           py39h06a4308_1
         jinja2                    3.0.2              pyhd3eb1b0_0
         joblib                    1.1.0                    pypi_0    pypi
         json5                     0.9.6              pyhd3eb1b0_0
         jsonschema                3.2.0              pyhd3eb1b0_2
         jupyter_client            7.1.2              pyhd3eb1b0_0
         jupyter_core              4.9.1            py39h06a4308_0
         jupyter_server            1.4.1            py39h06a4308_0
         jupyterlab                3.2.1              pyhd3eb1b0_1
         jupyterlab_pygments       0.1.2                      py_0
         jupyterlab_server         2.10.2             pyhd3eb1b0_1
         keras                     2.8.0                    pypi_0    pypi
         keras-preprocessing       1.1.2                    pypi_0    pypi
         kiwisolver                1.3.2                    pypi_0    pypi
         ld_impl_linux-64          2.35.1               h7274673_9
         libclang                  13.0.0                   pypi_0    pypi
         libffi                    3.3                  he6710b0_2
         libgcc-ng                 9.3.0               h5101ec6_17
         libgomp                   9.3.0               h5101ec6_17
         libsodium                 1.0.18               h7b6447c_0
         libstdcxx-ng              9.3.0               hd4cf53a_17
         lmfit                     1.0.3                    pypi_0    pypi
         mako                      1.1.6                    pypi_0    pypi
         markdown                  3.3.6                    pypi_0    pypi
         markupsafe                2.0.1            py39h27cfd23_0
         matplotlib                3.5.1                    pypi_0    pypi
         matplotlib-inline         0.1.2              pyhd3eb1b0_2
         mistune                   0.8.4           py39h27cfd23_1000
         mlflow                    1.23.1                   pypi_0    pypi
         multipletau               0.3.3                    pypi_0    pypi
         nbclassic                 0.2.6              pyhd3eb1b0_0
         nbclient                  0.5.3              pyhd3eb1b0_0
         nbconvert                 6.3.0            py39h06a4308_0
         nbformat                  5.1.3              pyhd3eb1b0_0
         ncurses                   6.3                  h7f8727e_2
         nest-asyncio              1.5.1              pyhd3eb1b0_0
         notebook                  6.4.6            py39h06a4308_0
         numpy                     1.22.2                   pypi_0    pypi
         oauthlib                  3.2.0                    pypi_0    pypi
         openssl                   1.1.1m               h7f8727e_0
         opt-einsum                3.3.0                    pypi_0    pypi
         packaging                 21.3               pyhd3eb1b0_0
         pandas                    1.4.0                    pypi_0    pypi
         pandocfilters             1.5.0              pyhd3eb1b0_0
         parso                     0.8.3              pyhd3eb1b0_0
         pexpect                   4.8.0              pyhd3eb1b0_3
         pickleshare               0.7.5           pyhd3eb1b0_1003
         pillow                    9.0.1                    pypi_0    pypi
         pip                       21.2.4           py39h06a4308_0
         prometheus-flask-exporter 0.18.7                   pypi_0    pypi
         prometheus_client         0.13.1             pyhd3eb1b0_0
         prompt-toolkit            3.0.20             pyhd3eb1b0_0
         protobuf                  3.19.4                   pypi_0    pypi
         ptyprocess                0.7.0              pyhd3eb1b0_2
         pyasn1                    0.4.8                    pypi_0    pypi
         pyasn1-modules            0.2.8                    pypi_0    pypi
         pycparser                 2.21               pyhd3eb1b0_0
         pygments                  2.11.2             pyhd3eb1b0_0
         pyopenssl                 22.0.0             pyhd3eb1b0_0
         pyparsing                 3.0.4              pyhd3eb1b0_0
         pyrsistent                0.18.0           py39heee7806_0
         pysocks                   1.7.1            py39h06a4308_0
         python                    3.9.7                h12debd9_1
         python-dateutil           2.8.2              pyhd3eb1b0_0
         pytz                      2021.3             pyhd3eb1b0_0
         pyyaml                    6.0                      pypi_0    pypi
         pyzmq                     22.3.0           py39h295c915_2
         querystring-parser        1.2.4                    pypi_0    pypi
         readline                  8.1.2                h7f8727e_1
         requests                  2.27.1             pyhd3eb1b0_0
         requests-oauthlib         1.3.1                    pypi_0    pypi
         rsa                       4.8                      pypi_0    pypi
         scikit-learn              1.0.2                    pypi_0    pypi
         scipy                     1.8.0                    pypi_0    pypi
         seaborn                   0.11.2                   pypi_0    pypi
         send2trash                1.8.0              pyhd3eb1b0_1
         setuptools                58.0.4           py39h06a4308_0
         six                       1.16.0             pyhd3eb1b0_0
         smmap                     5.0.0                    pypi_0    pypi
         sniffio                   1.2.0            py39h06a4308_1
         sqlalchemy                1.4.31                   pypi_0    pypi
         sqlite                    3.37.2               hc218d9a_0
         sqlparse                  0.4.2                    pypi_0    pypi
         tabulate                  0.8.9                    pypi_0    pypi
         tensorboard               2.8.0                    pypi_0    pypi
         tensorboard-data-server   0.6.1                    pypi_0    pypi
         tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
         tensorflow                2.8.0                    pypi_0    pypi
         tensorflow-io-gcs-filesystem 0.24.0                   pypi_0    pypi
         termcolor                 1.1.0                    pypi_0    pypi
         terminado                 0.9.4            py39h06a4308_0
         testpath                  0.5.0              pyhd3eb1b0_0
         tf-estimator-nightly      2.8.0.dev2021122109          pypi_0    pypi
         threadpoolctl             3.1.0                    pypi_0    pypi
         tk                        8.6.11               h1ccaba5_0
         tornado                   6.1              py39h27cfd23_0
         traitlets                 5.1.1              pyhd3eb1b0_0
         typing-extensions         4.0.1                    pypi_0    pypi
         tzdata                    2021e                hda174b7_0
         uncertainties             3.1.6                    pypi_0    pypi
         urllib3                   1.26.8             pyhd3eb1b0_0
         wcwidth                   0.2.5              pyhd3eb1b0_0
         webencodings              0.5.1            py39h06a4308_1
         websocket-client          1.2.3                    pypi_0    pypi
         werkzeug                  2.0.3                    pypi_0    pypi
         wheel                     0.37.1             pyhd3eb1b0_0
         wrapt                     1.13.3                   pypi_0    pypi
         xz                        5.2.5                h7b6447c_0
         zeromq                    4.3.4                h2531618_0
         zipp                      3.7.0              pyhd3eb1b0_0
         zlib                      1.2.11               h7f8727e_4

         Note: you may need to restart the kernel to use updated packages.
         {'SLURM_CHECKPOINT_IMAGE_DIR': '/var/slurm/checkpoint',
          'SLURM_NODELIST': 'node160',
          'SLURM_JOB_NAME': 'bash',
          'XDG_SESSION_ID': '115650',
          'SLURMD_NODENAME': 'node160',
          'SLURM_TOPOLOGY_ADDR': 'node160',
          'SLURM_NTASKS_PER_NODE': '24',
          'HOSTNAME': 'login01',
          'SLURM_PRIO_PROCESS': '0',
          'SLURM_SRUN_COMM_PORT': '40528',
          'SHELL': '/bin/bash',
          'TERM': 'xterm-color',
          'SLURM_JOB_QOS': 'qstand',
          'SLURM_PTY_WIN_ROW': '24',
          'HISTSIZE': '1000',
          'TMPDIR': '/tmp',
          'SLURM_TOPOLOGY_ADDR_PATTERN': 'node',
          'SSH_CLIENT': '10.231.181.134 58866 22',
          'CONDA_SHLVL': '2',
          'CONDA_PROMPT_MODIFIER': '(tf) ',
          'QTDIR': '/usr/lib64/qt-3.3',
          'QTINC': '/usr/lib64/qt-3.3/include',
          'SSH_TTY': '/dev/pts/166',
          'NO_PROXY': 'localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001',
          'QT_GRAPHICSSYSTEM_CHECKED': '1',
          'SLURM_NNODES': '1',
          'USER': 'ye53nis',
          'http_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',
          'CONDA_EXE': '/cluster/miniconda3/bin/conda',
          'SLURM_STEP_NUM_NODES': '1',
          'SLURM_JOBID': '1617391',
          'SRUN_DEBUG': '3',
          'FTP_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'ftp_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_NTASKS': '24',
          'SLURM_LAUNCH_NODE_IPADDR': '192.168.192.5',
          'SLURM_STEP_ID': '0',
          'TMUX': '/tmp/tmux-67339/default,12792,2',
          '_CE_CONDA': '',
          'CONDA_PREFIX_1': '/cluster/miniconda3',
          'SLURM_STEP_LAUNCHER_PORT': '40528',
          'SLURM_TASKS_PER_NODE': '24',
          'MAIL': '/var/spool/mail/ye53nis',
          'PATH': '/home/ye53nis/.conda/envs/tf/bin:/home/lex/Programme/miniconda3/envs/tf/bin:/home/lex/Programme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/usr/sbin:/home/ye53nis/.local/bin:/home/ye53nis/bin',
          'SLURM_WORKING_CLUSTER': 'hpc:192.168.192.1:6817:8448',
          'SLURM_JOB_ID': '1617391',
          'CONDA_PREFIX': '/home/ye53nis/.conda/envs/tf',
          'SLURM_JOB_USER': 'ye53nis',
          'SLURM_STEPID': '0',
          'PWD': '/',
          'SLURM_SRUN_COMM_HOST': '192.168.192.5',
          'LANG': 'en_US.UTF-8',
          'SLURM_PTY_WIN_COL': '80',
          'SLURM_UMASK': '0022',
          'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles',
          'SLURM_JOB_UID': '67339',
          'LOADEDMODULES': '',
          'SLURM_NODEID': '0',
          'TMUX_PANE': '%2',
          'SLURM_SUBMIT_DIR': '/',
          'SLURM_TASK_PID': '61062',
          'SLURM_NPROCS': '24',
          'SLURM_CPUS_ON_NODE': '24',
          'SLURM_DISTRIBUTION': 'block',
          'HTTPS_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'https_proxy': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_PROCID': '0',
          'HISTCONTROL': 'ignoredups',
          '_CE_M': '',
          'SLURM_JOB_NODELIST': 'node160',
          'SLURM_PTY_PORT': '41792',
          'HOME': '/home/ye53nis',
          'SHLVL': '3',
          'SLURM_LOCALID': '0',
          'SLURM_JOB_GID': '13280',
          'SLURM_JOB_CPUS_PER_NODE': '24',
          'SLURM_CLUSTER_NAME': 'hpc',
          'no_proxy': 'localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001',
          'SLURM_GTIDS': '0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23',
          'SLURM_SUBMIT_HOST': 'login01',
          'HTTP_PROXY': 'http://internet4nzm.rz.uni-jena.de:3128',
          'SLURM_JOB_PARTITION': 's_standard',
          'MATHEMATICA_HOME': '/cluster/apps/mathematica/12.3',
          'CONDA_PYTHON_EXE': '/cluster/miniconda3/bin/python',
          'LOGNAME': 'ye53nis',
          'SLURM_STEP_NUM_TASKS': '24',
          'QTLIB': '/usr/lib64/qt-3.3/lib',
          'SLURM_JOB_ACCOUNT': 'iaob',
          'SLURM_JOB_NUM_NODES': '1',
          'MODULESHOME': '/usr/share/Modules',
          'CONDA_DEFAULT_ENV': 'tf',
          'LESSOPEN': '||/usr/bin/lesspipe.sh %s',
          'SLURM_STEP_TASKS_PER_NODE': '24',
          'PORT': '8889',
          'SLURM_STEP_NODELIST': 'node160',
          'DISPLAY': ':0',
          'XDG_RUNTIME_DIR': '',
          'XAUTHORITY': '/home/lex/.Xauthority',
          'BASH_FUNC_module()': '() {  eval `/usr/bin/modulecmd bash $*`\n}',
          '_': '/home/ye53nis/.conda/envs/tf/bin/jupyter',
          'PYDEVD_USE_FRAME_EVAL': 'NO',
          'JPY_PARENT_PID': '61845',
          'CLICOLOR': '1',
          'PAGER': 'cat',
          'GIT_PAGER': 'cat',
          'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}
       #+end_example

*** Setup: Node for running Mlflow UI
     1. Create mlflow tmux session and start mlflow ui
        #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session mlflowui
          conda activate tf
          mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
        #+END_SRC

        #+RESULTS:
        #+begin_example
          (tf) [ye53nis@login01 ~]$ mlflow ui --backend-store-uri file:///beegfs/ye53nis/drmed-git/data/mlruns -p 5001
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Starting gunicorn 20.1.0
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Listening at: http://127.0.0.1:5001 (5106)
          [2021-08-08 14:47:33 +0200] [5106] [INFO] Using worker: sync
          [2021-08-08 14:47:33 +0200] [5115] [INFO] Booting worker with pid: 5115
        #+end_example

     2. SHH tunnel the mflow session to the local computer (#+CALL:
        ssh-tunnel[:session local3](port="5001", node="login01"))
        #+CALL: ssh-tunnel[:session local3](port="5001", node="login01")

        #+RESULTS:
        |                   |           |                                        |           |       |          |      |      |               |
        | sh-5.1$           | sh-5.1$   |
ye53nis@ara-login01.rz.uni-jena.de's | password: |       |          |      |      |               |
        | ye53nis@login01's | password: |                                        |           |       |          |      |      |               |
        | bind:             | Address   | already                                | in        | use
 |          |      |      |               |
        | Last              | login:    | Tue                                    | Aug       |    17 | 18:03:52 | 2021 | from | 10.231.188.20 |

*** Setup: Record GPU metadata & git
     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       pwd
       git log -10
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node128 drmed-git]$ pwd
       /beegfs/ye53nis/drmed-git
       (tf) [ye53nis@node128 drmed-git]$ git log -10
       commit 4c2dc79f0483090d3af2591891c2349b0a48115f
       Author: Apoplex <oligolex@vivaldi.net>
       Date:   Thu Mar 3 14:10:45 2022 +0100

           Fix normalize() for l1 and l2 in preprocessing

       commit 39baf02076ba8fbcf444bfa11108d302bcb4c45f
       Author: Alex Seltmann <seltmann@posteo.de>
       Date:   Sun Feb 27 22:20:22 2022 +0100

           Add comparison file from exp-210807-hparams

       commit d51b11eda090b9301e783ec35bdfd26c7bf0709c
       Author: Apoplex <oligolex@vivaldi.net>
       Date:   Sun Feb 27 18:40:00 2022 +0100

           fix model input_size to None; else to crop_size

       commit c637444d8b798603629f6f0bd72ee55af7f81a5f
       Author: Apoplex <oligolex@vivaldi.net>
       Date:   Sun Feb 27 18:39:29 2022 +0100

           Fix function call correlate_and_fit

       commit 291c6619c12bc39d526137a43d976b3cb4881e50
       Author: Apoplex <oligolex@vivaldi.net>
       Date:   Sat Feb 26 20:04:07 2022 +0100

           Fix scale_trace; simplify tf_pad_trace call

       commit dcca8b9e17909a95b824c8a7b1fec52eeed198c3
       Author: Apoplex <oligolex@vivaldi.net>
       Date:   Thu Feb 24 16:11:39 2022 +0100

           test tf_pad_trace

       commit 6cf2da85748ef13f2e752bea8989a6d31549ced3
       (tf) [ye53nis@node128 drmed-git]$
     #+end_example


     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       nvcc -V
       echo --------------------
       lscpu
       echo --------------------
       nproc
       echo --------------------
       free -h
       echo --------------------
       df -h
       echo --------------------
       printenv
       echo --------------------
       top -bcn1 -w512 | head -n 15
     #+END_SRC

     #+RESULTS:
     #+begin_example
       (tf) [ye53nis@node128 drmed-git]$ nvcc -V
       nvcc: NVIDIA (R) Cuda compiler driver
       Copyright (c) 2005-2020 NVIDIA Corporation
       Built on Mon_Nov_30_19:08:53_PST_2020
       Cuda compilation tools, release 11.2, V11.2.67
       Build cuda_11.2.r11.2/compiler.29373293_0
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ lscpu
       Architecture:          x86_64
       CPU op-mode(s):        32-bit, 64-bit
       Byte Order:            Little Endian
       CPU(s):                48
       On-line CPU(s) list:   0-47
       Thread(s) per core:    2
       Core(s) per socket:    12
       Socket(s):             2
       NUMA node(s):          4
       Vendor ID:             GenuineIntel
       CPU family:            6
       Model:                 79
       Model name:            Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
       Stepping:              1
       CPU MHz:               1203.527
       CPU max MHz:           2900.0000
       CPU min MHz:           1200.0000
       BogoMIPS:              4399.79
       Virtualization:        VT-x
       L1d cache:             32K
       L1i cache:             32K
       L2 cache:              256K
       L3 cache:              15360K
       NUMA node0 CPU(s):     0-5,24-29
       NUMA node1 CPU(s):     6-11,30-35
       NUMA node2 CPU(s):     12-17,36-41
       NUMA node3 CPU(s):     18-23,42-47
       Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonst
       op_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cd
       p_l3 intel_ppin intel_pt ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida
       arat pln pts spec_ctrl intel_stibp
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ nproc
       12
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ free -h
                     total        used        free      shared  buff/cache   available
       Mem:           125G        1.1G        116G        230M        8.6G        123G
       Swap:           11G          0B         11G
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ df -h
       Filesystem           Size  Used Avail Use% Mounted on
       /dev/sda1             50G  7.0G   44G  14% /
       devtmpfs              63G     0   63G   0% /dev
       tmpfs                 63G  188M   63G   1% /dev/shm
       tmpfs                 63G   43M   63G   1% /run
       tmpfs                 63G     0   63G   0% /sys/fs/cgroup
       nfs01-ib:/cluster    2.0T  469G  1.6T  23% /cluster
       nfs01-ib:/home        80T   68T   13T  85% /home
       nfs03-ib:/pool/work  100T   71T   29T  71% /nfsdata
       /dev/sda3            6.0G  635M  5.4G  11% /var
       /dev/sda6            169G  354M  169G   1% /local
       /dev/sda5            2.0G   35M  2.0G   2% /tmp
       beegfs_nodev         524T  508T   17T  97% /beegfs
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ printenv
       SLURM_CHECKPOINT_IMAGE_DIR=/var/slurm/checkpoint
       SLURM_NODELIST=node128
       CUDA_PATH=/cluster/nvidia/cuda/11.2
       SLURM_JOB_NAME=bash
       CUDA_INC_PATH=/cluster/nvidia/cuda/11.2/include
       XDG_SESSION_ID=44301
       SLURMD_NODENAME=node128
       SLURM_TOPOLOGY_ADDR=node128
       SLURM_NTASKS_PER_NODE=12
       HOSTNAME=login01
       SLURM_PRIO_PROCESS=0
       SLURM_SRUN_COMM_PORT=38740
       SHELL=/bin/bash
       TERM=screen
       MLFLOW_EXPERIMENT_NAME=exp-220227-unet
       SLURM_JOB_QOS=qstand
       SLURM_PTY_WIN_ROW=53
       HISTSIZE=1000
       TMPDIR=/tmp
       SLURM_TOPOLOGY_ADDR_PATTERN=node
       SSH_CLIENT=10.231.181.128 49370 22
       INCLUDEDIR=/cluster/nvidia/cuda/11.2/include
       CONDA_SHLVL=2
       CONDA_PROMPT_MODIFIER=(tf)
       OLDPWD=/beegfs/ye53nis/drmed-git
       QTDIR=/usr/lib64/qt-3.3
       QTINC=/usr/lib64/qt-3.3/include
       SSH_TTY=/dev/pts/79
       NO_PROXY=localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001
       QT_GRAPHICSSYSTEM_CHECKED=1
       SLURM_NNODES=1
       USER=ye53nis
       http_proxy=http://internet4nzm.rz.uni-jena.de:3128
       LD_LIBRARY_PATH=/cluster/nvidia/cuda/11.2/lib64:/cluster/nvidia/cuda/11.2/nvvm/lib64:/cluster/nvidia/cudnn/8.1//lib64
       LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01
       ;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:
       ,*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01
       ;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:
       ,*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;3
       5:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=
       01;36:*.xspf=01;36:
       CONDA_EXE=/cluster/miniconda3/bin/conda
       SLURM_STEP_NUM_NODES=1
       SLURM_JOBID=1615665
       SRUN_DEBUG=3
       FTP_PROXY=http://internet4nzm.rz.uni-jena.de:3128
       ftp_proxy=http://internet4nzm.rz.uni-jena.de:3128
       SLURM_NTASKS=12
       SLURM_LAUNCH_NODE_IPADDR=192.168.192.5
       SLURM_STEP_ID=0
       TMUX=/tmp/tmux-67339/default,20557,7
       _CE_CONDA=
       CONDA_PREFIX_1=/cluster/miniconda3
       MODCUDA=YES
       SLURM_STEP_LAUNCHER_PORT=38740
       SLURM_TASKS_PER_NODE=12
       MAIL=/var/spool/mail/ye53nis
       PATH=/cluster/nvidia/cuda/11.2/bin:/cluster/nvidia/cuda/11.2/nvvm:/cluster/nvidia/cuda/11.2/open64/bin:/cluster/nvidia/cuda/11.2/libnvvp:/home/ye53nis/.conda/envs/tf/bin:/home/lex/Programme/miniconda3/envs/tf-nightly-lab/bin:/home/lex/P
       rogramme/miniconda3/condabin:/home/lex/.local/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/var/lib/snapd/snap/bin:/usr/sbin:/home/ye53nis/.local/bi
       n:/home/ye53nis/bin
       SLURM_WORKING_CLUSTER=hpc:192.168.192.1:6817:8448
       SLURM_JOB_ID=1615665
       LD_RUN_PATH=/cluster/nvidia/cuda/11.2/lib64
       SLURM_STEP_GPUS=0
       CONDA_PREFIX=/home/ye53nis/.conda/envs/tf
       CUDA_LIB_PATH=/cluster/nvidia/cuda/11.2/lib64
       SLURM_JOB_USER=ye53nis
       SLURM_STEPID=0
       PWD=/beegfs/ye53nis/drmed-git
       _LMFILES_=/cluster/modulefiles/nvidia/cuda/11.2:/cluster/modulefiles/nvidia/cudnn/8.1
       CUDA_VISIBLE_DEVICES=0
       SLURM_SRUN_COMM_HOST=192.168.192.5
       LANG=en_US.UTF-8
       SLURM_PTY_WIN_COL=236
       SLURM_UMASK=0022
       MODULEPATH=/usr/share/Modules/modulefiles:/etc/modulefiles:/cluster/modulefiles
       SLURM_JOB_UID=67339
       LOADEDMODULES=nvidia/cuda/11.2:nvidia/cudnn/8.1
       SLURM_NODEID=0
       TMUX_PANE=%7
       SLURM_SUBMIT_DIR=/
       SLURM_TASK_PID=4042
       SLURM_NPROCS=12
       SLURM_CPUS_ON_NODE=12
       SLURM_DISTRIBUTION=block
       HTTPS_PROXY=http://internet4nzm.rz.uni-jena.de:3128
       https_proxy=http://internet4nzm.rz.uni-jena.de:3128
       SLURM_PROCID=0
       HISTCONTROL=ignoredups
       _CE_M=
       SLURM_JOB_NODELIST=node128
       SLURM_PTY_PORT=37529
       HOME=/home/ye53nis
       SHLVL=3
       SLURM_LOCALID=0
       SLURM_JOB_GID=13280
       SLURM_JOB_CPUS_PER_NODE=12
       SLURM_CLUSTER_NAME=hpc
       no_proxy=localhost,127.0.0.0/8,.uni-jena.de,141.35.0.0/16,10.0.0.0/8,192.168.0.0/16,172.0.0.0/8,fe80::/7,2001:638:1558::/24,vmaster,node001
       SLURM_GTIDS=0,1,2,3,4,5,6,7,8,9,10,11
       SLURM_SUBMIT_HOST=login01
       HTTP_PROXY=http://internet4nzm.rz.uni-jena.de:3128
       SLURM_JOB_PARTITION=gpu_p100
       MATHEMATICA_HOME=/cluster/apps/mathematica/11.3
       CONDA_PYTHON_EXE=/cluster/miniconda3/bin/python
       LOGNAME=ye53nis
       SLURM_STEP_NUM_TASKS=12
       QTLIB=/usr/lib64/qt-3.3/lib
       GPU_DEVICE_ORDINAL=0
       SLURM_JOB_ACCOUNT=iaob
       MLFLOW_TRACKING_URI=file:./data/mlruns
       SLURM_JOB_NUM_NODES=1
       MODULESHOME=/usr/share/Modules
       CONDA_DEFAULT_ENV=tf
       LESSOPEN=||/usr/bin/lesspipe.sh %s
       SLURM_STEP_TASKS_PER_NODE=12
       SLURM_STEP_NODELIST=node128
       DISPLAY=:0
       XDG_RUNTIME_DIR=/run/user/67339
       INCLUDE=/cluster/nvidia/cudnn/8.1//include
       XAUTHORITY=/home/lex/.Xauthority
       BASH_FUNC_module()=() {  eval `/usr/bin/modulecmd bash $*`
       }
       _=/bin/printenv
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ top -bcn1 -w512 | head -n 15
       top - 21:21:42 up 72 days,  9:36,  0 users,  load average: 0.00, 0.03, 0.05
       Tasks: 521 total,   1 running, 520 sleeping,   0 stopped,   0 zombie
       %Cpu(s):  0.2 us,  0.2 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
       KiB Mem : 13191630+total, 12171446+free,  1196368 used,  9005476 buff/cache
       KiB Swap: 12582908 total, 12582908 free,        0 used. 12953688+avail Mem

         PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
       13258 ye53nis   20   0  172732   2620   1664 R  11.1  0.0   0:00.03 top -bcn1 -w512
           1 root      20   0   71788   7548   2584 S   0.0  0.0  35:51.03 /usr/lib/systemd/systemd --switched-root --system --deserialize 22
           2 root      20   0       0      0      0 S   0.0  0.0   0:01.65 [kthreadd]
           3 root      20   0       0      0      0 S   0.0  0.0   0:06.95 [ksoftirqd/0]
           5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 [kworker/0:0H]
           8 root      rt   0       0      0      0 S   0.0  0.0   0:06.58 [migration/0]
           9 root      20   0       0      0      0 S   0.0  0.0   0:00.00 [rcu_bh]
          10 root      20   0       0      0      0 S   0.0  0.0  43:01.62 [rcu_sched]
       (tf) [ye53nis@node128 drmed-git]$
     #+end_example

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       conda list
     #+END_SRC

     #+RESULTS:
     #+begin_example
       # packages in environment at /home/ye53nis/.conda/envs/tf:
       #
       # Name                    Version                   Build  Channel
       _libgcc_mutex             0.1                        main
       _openmp_mutex             4.5                       1_gnu
       absl-py                   1.0.0                    pypi_0    pypi
       alembic                   1.7.6                    pypi_0    pypi
       anyio                     2.2.0            py39h06a4308_1
       argon2-cffi               20.1.0           py39h27cfd23_1
       asteval                   0.9.26                   pypi_0    pypi
       astunparse                1.6.3                    pypi_0    pypi
       async_generator           1.10               pyhd3eb1b0_0
       attrs                     21.4.0             pyhd3eb1b0_0
       babel                     2.9.1              pyhd3eb1b0_0
       backcall                  0.2.0              pyhd3eb1b0_0
       bleach                    4.1.0              pyhd3eb1b0_0
       brotlipy                  0.7.0           py39h27cfd23_1003
       ca-certificates           2021.10.26           h06a4308_2
       cachetools                5.0.0                    pypi_0    pypi
       certifi                   2021.10.8        py39h06a4308_2
       cffi                      1.15.0           py39hd667e15_1
       charset-normalizer        2.0.4              pyhd3eb1b0_0
       click                     8.0.3                    pypi_0    pypi
       cloudpickle               2.0.0                    pypi_0    pypi
       cryptography              36.0.0           py39h9ce1e76_0
       cycler                    0.11.0                   pypi_0    pypi
       cython                    0.29.27                  pypi_0    pypi
       databricks-cli            0.16.4                   pypi_0    pypi
       debugpy                   1.5.1            py39h295c915_0
       decorator                 5.1.1              pyhd3eb1b0_0
       defusedxml                0.7.1              pyhd3eb1b0_0
       docker                    5.0.3                    pypi_0    pypi
       entrypoints               0.3              py39h06a4308_0
       fcsfiles                  2022.2.2                 pypi_0    pypi
       flask                     2.0.2                    pypi_0    pypi
       flatbuffers               2.0                      pypi_0    pypi
       fonttools                 4.29.1                   pypi_0    pypi
       future                    0.18.2                   pypi_0    pypi
       gast                      0.5.3                    pypi_0    pypi
       gitdb                     4.0.9                    pypi_0    pypi
       gitpython                 3.1.26                   pypi_0    pypi
       google-auth               2.6.0                    pypi_0    pypi
       google-auth-oauthlib      0.4.6                    pypi_0    pypi
       google-pasta              0.2.0                    pypi_0    pypi
       greenlet                  1.1.2                    pypi_0    pypi
       grpcio                    1.43.0                   pypi_0    pypi
       gunicorn                  20.1.0                   pypi_0    pypi
       h5py                      3.6.0                    pypi_0    pypi
       idna                      3.3                pyhd3eb1b0_0
       importlib-metadata        4.8.2            py39h06a4308_0
       importlib_metadata        4.8.2                hd3eb1b0_0
       ipykernel                 6.4.1            py39h06a4308_1
       ipython                   7.31.1           py39h06a4308_0
       ipython_genutils          0.2.0              pyhd3eb1b0_1
       itsdangerous              2.0.1                    pypi_0    pypi
       jedi                      0.18.1           py39h06a4308_1
       jinja2                    3.0.2              pyhd3eb1b0_0
       joblib                    1.1.0                    pypi_0    pypi
       json5                     0.9.6              pyhd3eb1b0_0
       jsonschema                3.2.0              pyhd3eb1b0_2
       jupyter_client            7.1.2              pyhd3eb1b0_0
       jupyter_core              4.9.1            py39h06a4308_0
       jupyter_server            1.4.1            py39h06a4308_0
       jupyterlab                3.2.1              pyhd3eb1b0_1
       jupyterlab_pygments       0.1.2                      py_0
       jupyterlab_server         2.10.2             pyhd3eb1b0_1
       keras                     2.8.0                    pypi_0    pypi
       keras-preprocessing       1.1.2                    pypi_0    pypi
       kiwisolver                1.3.2                    pypi_0    pypi
       ld_impl_linux-64          2.35.1               h7274673_9
       libclang                  13.0.0                   pypi_0    pypi
       libffi                    3.3                  he6710b0_2
       libgcc-ng                 9.3.0               h5101ec6_17
       libgomp                   9.3.0               h5101ec6_17
       libsodium                 1.0.18               h7b6447c_0
       libstdcxx-ng              9.3.0               hd4cf53a_17
       lmfit                     1.0.3                    pypi_0    pypi
       mako                      1.1.6                    pypi_0    pypi
       markdown                  3.3.6                    pypi_0    pypi
       markupsafe                2.0.1            py39h27cfd23_0
       matplotlib                3.5.1                    pypi_0    pypi
       matplotlib-inline         0.1.2              pyhd3eb1b0_2
       mistune                   0.8.4           py39h27cfd23_1000
       mlflow                    1.23.1                   pypi_0    pypi
       multipletau               0.3.3                    pypi_0    pypi
       nbclassic                 0.2.6              pyhd3eb1b0_0
       nbclient                  0.5.3              pyhd3eb1b0_0
       nbconvert                 6.3.0            py39h06a4308_0
       nbformat                  5.1.3              pyhd3eb1b0_0
       ncurses                   6.3                  h7f8727e_2
       nest-asyncio              1.5.1              pyhd3eb1b0_0
       notebook                  6.4.6            py39h06a4308_0
       numpy                     1.22.2                   pypi_0    pypi
       oauthlib                  3.2.0                    pypi_0    pypi
       openssl                   1.1.1m               h7f8727e_0
       opt-einsum                3.3.0                    pypi_0    pypi
       packaging                 21.3               pyhd3eb1b0_0
       pandas                    1.4.0                    pypi_0    pypi
       pandocfilters             1.5.0              pyhd3eb1b0_0
       parso                     0.8.3              pyhd3eb1b0_0
       pexpect                   4.8.0              pyhd3eb1b0_3
       pickleshare               0.7.5           pyhd3eb1b0_1003
       pillow                    9.0.1                    pypi_0    pypi
       pip                       21.2.4           py39h06a4308_0
       prometheus-flask-exporter 0.18.7                   pypi_0    pypi
       prometheus_client         0.13.1             pyhd3eb1b0_0
       prompt-toolkit            3.0.20             pyhd3eb1b0_0
       protobuf                  3.19.4                   pypi_0    pypi
       ptyprocess                0.7.0              pyhd3eb1b0_2
       pyasn1                    0.4.8                    pypi_0    pypi
       pyasn1-modules            0.2.8                    pypi_0    pypi
       pycparser                 2.21               pyhd3eb1b0_0
       pygments                  2.11.2             pyhd3eb1b0_0
       pyopenssl                 22.0.0             pyhd3eb1b0_0
       pyparsing                 3.0.4              pyhd3eb1b0_0
       pyrsistent                0.18.0           py39heee7806_0
       pysocks                   1.7.1            py39h06a4308_0
       python                    3.9.7                h12debd9_1
       python-dateutil           2.8.2              pyhd3eb1b0_0
       pytz                      2021.3             pyhd3eb1b0_0
       pyyaml                    6.0                      pypi_0    pypi
       pyzmq                     22.3.0           py39h295c915_2
       querystring-parser        1.2.4                    pypi_0    pypi
       readline                  8.1.2                h7f8727e_1
       requests                  2.27.1             pyhd3eb1b0_0
       requests-oauthlib         1.3.1                    pypi_0    pypi
       rsa                       4.8                      pypi_0    pypi
       scikit-learn              1.0.2                    pypi_0    pypi
       scipy                     1.8.0                    pypi_0    pypi
       seaborn                   0.11.2                   pypi_0    pypi
       send2trash                1.8.0              pyhd3eb1b0_1
       setuptools                58.0.4           py39h06a4308_0
       six                       1.16.0             pyhd3eb1b0_0
       smmap                     5.0.0                    pypi_0    pypi
       sniffio                   1.2.0            py39h06a4308_1
       sqlalchemy                1.4.31                   pypi_0    pypi
       sqlite                    3.37.2               hc218d9a_0
       sqlparse                  0.4.2                    pypi_0    pypi
       tabulate                  0.8.9                    pypi_0    pypi
       tensorboard               2.8.0                    pypi_0    pypi
       tensorboard-data-server   0.6.1                    pypi_0    pypi
       tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
       tensorflow                2.8.0                    pypi_0    pypi
       tensorflow-io-gcs-filesystem 0.24.0                   pypi_0    pypi
       termcolor                 1.1.0                    pypi_0    pypi
       terminado                 0.9.4            py39h06a4308_0
       testpath                  0.5.0              pyhd3eb1b0_0
       tf-estimator-nightly      2.8.0.dev2021122109          pypi_0    pypi
       threadpoolctl             3.1.0                    pypi_0    pypi
       tk                        8.6.11               h1ccaba5_0
       tornado                   6.1              py39h27cfd23_0
       traitlets                 5.1.1              pyhd3eb1b0_0
       typing-extensions         4.0.1                    pypi_0    pypi
       tzdata                    2021e                hda174b7_0
       uncertainties             3.1.6                    pypi_0    pypi
       urllib3                   1.26.8             pyhd3eb1b0_0
       wcwidth                   0.2.5              pyhd3eb1b0_0
       webencodings              0.5.1            py39h06a4308_1
       websocket-client          1.2.3                    pypi_0    pypi
       werkzeug                  2.0.3                    pypi_0    pypi
       wheel                     0.37.1             pyhd3eb1b0_0
       wrapt                     1.13.3                   pypi_0    pypi
       xz                        5.2.5                h7b6447c_0
       zeromq                    4.3.4                h2531618_0
       zipp                      3.7.0              pyhd3eb1b0_0
       zlib                      1.2.11               h7f8727e_4
       (tf) [ye53nis@node128 drmed-git]$
     #+end_example

     #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
       tree ../saves/firstartifact_Nov2020_train_max3sets
       echo --------------------
       tree ../saves/firstartifact_Nov2020_val_max3sets
       echo --------------------
       tree ../saves/firstartifact_Nov2020_train_max2sets
       echo --------------------
       tree ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
       echo --------------------
       tree ../saves/firstartifact_Nov2020_train_max1set
       echo --------------------
       tree ../saves/firstartifact_Nov2020_test
     #+END_SRC

     #+RESULTS:
     #+begin_example
       ../saves/firstartifact_Nov2020_train_max3sets
       ├── 0.069
       │   ├── 0.01
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.069_set002.csv
       │   │   ├── traces_brightclust_Nov2020_D0.069_set003.csv
       │   │   └── traces_brightclust_Nov2020_D0.069_set006.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.069_set009.csv
       ├── 0.08
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.08_set007.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.08_set002.csv
       │   │   ├── traces_brightclust_Nov2020_D0.08_set006.csv
       │   │   └── traces_brightclust_Nov2020_D0.08_set008.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.08_set004.csv
       │       └── traces_brightclust_Nov2020_D0.08_set009.csv
       ├── 0.1
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D0.1_set004.csv
       │   │   ├── traces_brightclust_Nov2020_D0.1_set006.csv
       │   │   └── traces_brightclust_Nov2020_D0.1_set008.csv
       │   ├── 0.1
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.1_set003.csv
       │       └── traces_brightclust_Nov2020_D0.1_set007.csv
       ├── 0.2
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.2_set003.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.2_set001.csv
       │   │   ├── traces_brightclust_Nov2020_D0.2_set004.csv
       │   │   └── traces_brightclust_Nov2020_D0.2_set006.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.2_set009.csv
       │       └── traces_brightclust_Nov2020_D0.2_set010.csv
       ├── 0.4
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D0.4_set004.csv
       │   │   └── traces_brightclust_Nov2020_D0.4_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.4_set002.csv
       │   │   ├── traces_brightclust_Nov2020_D0.4_set003.csv
       │   │   └── traces_brightclust_Nov2020_D0.4_set009.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.4_set006.csv
       │       └── traces_brightclust_Nov2020_D0.4_set007.csv
       ├── 0.6
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.6_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.6_set004.csv
       │   │   ├── traces_brightclust_Nov2020_D0.6_set005.csv
       │   │   └── traces_brightclust_Nov2020_D0.6_set006.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.6_set001.csv
       │       └── traces_brightclust_Nov2020_D0.6_set002.csv
       ├── 10
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D10_set003.csv
       │   │   ├── traces_brightclust_Nov2020_D10_set004.csv
       │   │   └── traces_brightclust_Nov2020_D10_set008.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D10_set006.csv
       │   │   └── traces_brightclust_Nov2020_D10_set007.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D10_set010.csv
       ├── 1.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D1.0_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D1.0_set004.csv
       │   │   ├── traces_brightclust_Nov2020_D1.0_set007.csv
       │   │   └── traces_brightclust_Nov2020_D1.0_set009.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D1.0_set001.csv
       │       ├── traces_brightclust_Nov2020_D1.0_set002.csv
       │       └── traces_brightclust_Nov2020_D1.0_set008.csv
       ├── 3.0
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D3.0_set005.csv
       │   │   ├── traces_brightclust_Nov2020_D3.0_set006.csv
       │   │   └── traces_brightclust_Nov2020_D3.0_set008.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D3.0_set010.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D3.0_set001.csv
       │       ├── traces_brightclust_Nov2020_D3.0_set003.csv
       │       └── traces_brightclust_Nov2020_D3.0_set009.csv
       └── 50
           ├── 0.01
           │   └── traces_brightclust_Nov2020_D50_set006.csv
           ├── 0.1
           │   ├── traces_brightclust_Nov2020_D50_set009.csv
           │   └── traces_brightclust_Nov2020_D50_set010.csv
           └── 1.0
               ├── traces_brightclust_Nov2020_D50_set004.csv
               ├── traces_brightclust_Nov2020_D50_set005.csv
               └── traces_brightclust_Nov2020_D50_set007.csv

       40 directories, 60 files
       (tf) [ye53nis@node128 drmed-git]$ echo --------------------
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_val_max3sets
       ../saves/firstartifact_Nov2020_val_max3sets
       ├── 0.069
       │   ├── 0.01
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.069_set007.csv
       │   │   └── traces_brightclust_Nov2020_D0.069_set008.csv
       │   └── 1.0
       ├── 0.08
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.08_set010.csv
       │   └── 1.0
       ├── 0.1
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D0.1_set009.csv
       │   │   └── traces_brightclust_Nov2020_D0.1_set010.csv
       │   ├── 0.1
       │   └── 1.0
       ├── 0.2
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.2_set008.csv
       │   └── 1.0
       ├── 0.4
       │   ├── 0.01
       │   ├── 0.1
       │   └── 1.0
       ├── 0.6
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.6_set007.csv
       │   └── 1.0
       ├── 10
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D10_set009.csv
       │   ├── 0.1
       │   └── 1.0
       ├── 1.0
       │   ├── 0.01
       │   ├── 0.1
       │   └── 1.0
       ├── 3.0
       │   ├── 0.01
       │   ├── 0.1
       │   └── 1.0
       └── 50
           ├── 0.01
           ├── 0.1
           └── 1.0
               └── traces_brightclust_Nov2020_D50_set008.csv

       40 directories, 9 files
       (tf) [ye53nis@node128 drmed-git]$ echo --------------------
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_train_max2sets
       ../saves/firstartifact_Nov2020_train_max2sets
       ├── 0.069
       │   ├── 0.01
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.069_set002.csv
       │   │   └── traces_brightclust_Nov2020_D0.069_set003.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.069_set009.csv
       ├── 0.08
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.08_set007.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.08_set002.csv
       │   │   └── traces_brightclust_Nov2020_D0.08_set006.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.08_set004.csv
       │       └── traces_brightclust_Nov2020_D0.08_set009.csv
       ├── 0.1
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D0.1_set004.csv
       │   │   └── traces_brightclust_Nov2020_D0.1_set006.csv
       │   ├── 0.1
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.1_set003.csv
       │       └── traces_brightclust_Nov2020_D0.1_set007.csv
       ├── 0.2
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.2_set003.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.2_set001.csv
       │   │   └── traces_brightclust_Nov2020_D0.2_set004.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.2_set009.csv
       │       └── traces_brightclust_Nov2020_D0.2_set010.csv
       ├── 0.4
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D0.4_set004.csv
       │   │   └── traces_brightclust_Nov2020_D0.4_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.4_set002.csv
       │   │   └── traces_brightclust_Nov2020_D0.4_set003.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.4_set006.csv
       │       └── traces_brightclust_Nov2020_D0.4_set007.csv
       ├── 0.6
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.6_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D0.6_set004.csv
       │   │   └── traces_brightclust_Nov2020_D0.6_set005.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D0.6_set001.csv
       │       └── traces_brightclust_Nov2020_D0.6_set002.csv
       ├── 10
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D10_set003.csv
       │   │   └── traces_brightclust_Nov2020_D10_set004.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D10_set006.csv
       │   │   └── traces_brightclust_Nov2020_D10_set007.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D10_set010.csv
       ├── 1.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D1.0_set010.csv
       │   ├── 0.1
       │   │   ├── traces_brightclust_Nov2020_D1.0_set004.csv
       │   │   └── traces_brightclust_Nov2020_D1.0_set007.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D1.0_set001.csv
       │       └── traces_brightclust_Nov2020_D1.0_set002.csv
       ├── 3.0
       │   ├── 0.01
       │   │   ├── traces_brightclust_Nov2020_D3.0_set005.csv
       │   │   └── traces_brightclust_Nov2020_D3.0_set006.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D3.0_set010.csv
       │   └── 1.0
       │       ├── traces_brightclust_Nov2020_D3.0_set001.csv
       │       └── traces_brightclust_Nov2020_D3.0_set003.csv
       └── 50
           ├── 0.01
           │   └── traces_brightclust_Nov2020_D50_set006.csv
           ├── 0.1
           │   ├── traces_brightclust_Nov2020_D50_set009.csv
           │   └── traces_brightclust_Nov2020_D50_set010.csv
           └── 1.0
               ├── traces_brightclust_Nov2020_D50_set004.csv
               └── traces_brightclust_Nov2020_D50_set005.csv

       40 directories, 48 files
       (tf) [ye53nis@node128 drmed-git]$ echo --------------------
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
       ../saves/firstartifact_Nov2020_val_max2sets_SORTEDIN
       ├── 0.069
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.069_set006.csv
       │   └── 1.0
       ├── 0.08
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.08_set008.csv
       │   └── 1.0
       ├── 0.1
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.1_set008.csv
       │   ├── 0.1
       │   └── 1.0
       ├── 0.2
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.2_set006.csv
       │   └── 1.0
       ├── 0.4
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.4_set009.csv
       │   └── 1.0
       ├── 0.6
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.6_set006.csv
       │   └── 1.0
       ├── 10
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D10_set008.csv
       │   ├── 0.1
       │   └── 1.0
       ├── 1.0
       │   ├── 0.01
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D1.0_set009.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D1.0_set008.csv
       ├── 3.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D3.0_set008.csv
       │   ├── 0.1
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D3.0_set009.csv
       └── 50
           ├── 0.01
           ├── 0.1
           └── 1.0
               └── traces_brightclust_Nov2020_D50_set007.csv

       40 directories, 12 files
       (tf) [ye53nis@node128 drmed-git]$ echo --------------------
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_train_max1set
       ../saves/firstartifact_Nov2020_train_max1set
       ├── 0.069
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.069_set002.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.069_set009.csv
       ├── 0.08
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.08_set007.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.08_set002.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.08_set004.csv
       ├── 0.1
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.1_set004.csv
       │   ├── 0.1
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.1_set003.csv
       ├── 0.2
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.2_set003.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.2_set001.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.2_set009.csv
       ├── 0.4
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.4_set004.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.4_set002.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.4_set006.csv
       ├── 0.6
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.6_set010.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.6_set004.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.6_set001.csv
       ├── 10
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D10_set003.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D10_set006.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D10_set010.csv
       ├── 1.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D1.0_set010.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D1.0_set004.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D1.0_set001.csv
       ├── 3.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D3.0_set005.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D3.0_set010.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D3.0_set001.csv
       └── 50
           ├── 0.01
           │   └── traces_brightclust_Nov2020_D50_set006.csv
           ├── 0.1
           │   └── traces_brightclust_Nov2020_D50_set009.csv
           └── 1.0
               └── traces_brightclust_Nov2020_D50_set004.csv

       39 directories, 28 files
       (tf) [ye53nis@node128 drmed-git]$ echo --------------------
       --------------------
       (tf) [ye53nis@node128 drmed-git]$ tree ../saves/firstartifact_Nov2020_test
       ../saves/firstartifact_Nov2020_test
       ├── 0.069
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.069_set005.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.069_set001.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.069_set010.csv
       ├── 0.08
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.08_set005.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.08_set003.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.08_set001.csv
       ├── 0.1
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.1_set002.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.1_set005.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.1_set001.csv
       ├── 0.2
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.2_set002.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.2_set007.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.2_set005.csv
       ├── 0.4
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.4_set008.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.4_set001.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.4_set005.csv
       ├── 0.6
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D0.6_set008.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D0.6_set003.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D0.6_set009.csv
       ├── 10
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D10_set002.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D10_set001.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D10_set005.csv
       ├── 1.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D1.0_set006.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D1.0_set003.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D1.0_set005.csv
       ├── 3.0
       │   ├── 0.01
       │   │   └── traces_brightclust_Nov2020_D3.0_set004.csv
       │   ├── 0.1
       │   │   └── traces_brightclust_Nov2020_D3.0_set007.csv
       │   └── 1.0
       │       └── traces_brightclust_Nov2020_D3.0_set002.csv
       └── 50
           ├── 0.01
           │   └── traces_brightclust_Nov2020_D50_set002.csv
           ├── 0.1
           │   └── traces_brightclust_Nov2020_D50_set003.csv
           └── 1.0
               └── traces_brightclust_Nov2020_D50_set001.csv

       40 directories, 30 files
       (tf) [ye53nis@node128 drmed-git]$
     #+end_example
*** Setup: Show all hyperparameters that worked in =exp-210807-hparams=
   :PROPERTIES:
   :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3
   :END:
   1. get the comparison data of all runs from =exp-210807-hparams= via =git
      restore=
      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        git show 04e9dc3:./data/exp-210807-hparams/mlflow/run1-2_comparison.csv > ./data/exp-220227-unet/mlflow/exp-210807-hparams_comparison.csv
      #+END_SRC

   2. open the file in jupyter, do some processing to only find the best runs,
      and display the relevant hparams (see =exp-210807-hparams= section
      =4. Analyze run 1 and 2= for explanations on the processing)
      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

      #+RESULTS:
      : /beegfs/ye53nis/drmed-git

      #+BEGIN_SRC jupyter-python
        import numpy as np
        import pandas as pd
      #+END_SRC

      #+RESULTS:

      #+BEGIN_SRC jupyter-python
        run1_2 = pd.read_csv('data/exp-220227-unet/mlflow/exp-210807-hparams_comparison.csv', index_col=0)
        run1_2_valauc = run1_2.loc['val_auc'].astype(float)
      #+END_SRC

      #+RESULTS:

      #+BEGIN_SRC jupyter-python
        singles_ls = ['5441e71efe0f4dae868648e7cc795c65']
        run1_2_singles = run1_2.loc[:, singles_ls]
        run1_2_singles.iloc[35:, :] = run1_2_singles.iloc[35:, :].astype(np.float64)
        run1_2 = run1_2.drop(columns=singles_ls)
      #+END_SRC

      #+RESULTS:

      #+BEGIN_SRC jupyter-python
        assert len(run1_2.iloc[35:, :].columns) % 2 == 0
      #+END_SRC

      #+RESULTS:

      #+BEGIN_SRC jupyter-python :pandoc t
        run1_2_doubleparams = pd.DataFrame()
        run1_2_doublemetrics = pd.DataFrame()
        double_cols = []
        for left, right in zip(run1_2.iloc[:, ::2].items(), run1_2.iloc[:, 1::2].items()):
            double_cols.append((left[0], right[0]))
            current_metrics = left[1].iloc[35:].combine(other=right[1].iloc[35:],
                                                        func=(lambda x1, x2: (float(x1) + float(x2)) / 2))
            current_params = left[1].iloc[:35].combine(other=right[1].iloc[:35],
                                                       func=(lambda x1, x2: set((x1, x2)) if x1 != x2 else x1))
            run1_2_doubleparams = pd.concat([run1_2_doubleparams, current_params], axis=1)
            run1_2_doublemetrics = pd.concat([run1_2_doublemetrics, current_metrics], axis=1)

        run1_2_doublemetrics = pd.DataFrame(data=run1_2_doublemetrics.to_numpy(),
                                            index=run1_2.iloc[35:, :].index,
                                            columns=double_cols)

        run1_2_doubleparams = pd.DataFrame(data=run1_2_doubleparams.to_numpy(),
                                           index=run1_2.iloc[:35, :].index,
                                           columns=double_cols)

        run1_2_combimetrics = pd.concat([run1_2_doublemetrics, run1_2_singles.iloc[35:, :]], axis=1)
        run1_2_combiparams = pd.concat([run1_2_doubleparams, run1_2_singles.iloc[:35, :]], axis=1)
        run1_2_mymetrics = run1_2_combimetrics.loc[['val_auc', 'val_recall0.5', 'val_precision0.5']]
        run1_2_myparams = run1_2_combiparams.loc[['hp_batch_size', 'hp_first_filters', 'hp_input_size', 'hp_lr_power', 'hp_lr_start', 'hp_n_levels', 'hp_pool_size', 'hp_scaler']]
        run1_2_my = pd.concat([run1_2_mymetrics, run1_2_myparams], axis=0).T
        # cond1 = run1_2_combimetrics.loc[:, 'val_auc'] > 0.95
        cond2 = run1_2_my.loc[:, 'val_recall0.5'] > 0.85
        cond3 = run1_2_my.loc[:, 'val_precision0.5'] > 0.85

        with pd.option_context('display.max_rows', None, 'display.max_columns', None):
            display(run1_2_my.loc[cond2 & cond3])
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      | Run ID:                                                              | val_auc | val_recall0.5 | val_precision0.5 | hp_batch_size | hp_first_filters | hp_input_size | hp_lr_power |        hp_lr_start | hp_n_levels | hp_pool_size | hp_scaler |
      |----------------------------------------------------------------------+---------+---------------+------------------+---------------+------------------+---------------+-------------+--------------------+-------------+--------------+-----------|
      | (9051e32b87d84f3485b980067addec30, 61ff87bdb89b4e2ba64f8dacc774992d) |   0.981 |        0.8975 |            0.918 |            26 |               44 |         16384 |           1 | 0.0136170138242663 |           7 |            2 | standard  |
      | (93b168c0ff7942c8a908a94129daf973, f243b3b742de4dbcb7ccfbd4244706f8) |   0.976 |         0.893 |            0.852 |            15 |               23 |         16384 |           7 | 0.0305060808685107 |           6 |            4 | quant_g   |
      | (a5b8551144ff46e697a39cd1551e1475, 98cf8cdef9c54b5286e277e75e2ab8c1) |   0.984 |         0.916 |            0.909 |            20 |               78 |         16384 |           4 | 0.0584071108418767 |           4 |            4 | standard  |
      | (00f2635d9fa2463c9a066722163405be, d0a8e1748b194f3290d471b6b44f19f8) |   0.987 |         0.929 |           0.9065 |            28 |                6 |         16384 |           1 | 0.0553313915596308 |           5 |            4 | minmax    |
      | (5604d43c1ece461b8e6eaa0dfb65d6dc, 3612536a77f34f22bc83d1d809140aa6) |  0.9745 |         0.885 |           0.8985 |            20 |              128 |         16384 |           1 |  0.043549707353273 |           3 |            4 | standard  |
      | (7cafab027cdd4fc9bf20a43e989df510, 16dff15d935f45e2a836b1f41b07b4e3) |   0.978 |        0.8905 |            0.891 |            10 |               16 |          8192 |           1 | 0.0627676336651573 |           5 |            4 | robust    |
      | (0e328920e86049928202db95e8cfb7be, bf9d2725eb16462d9a101f0a077ce2b5) |   0.976 |         0.875 |            0.888 |            14 |               16 |         16384 |           5 | 0.0192390310290551 |           9 |            2 | robust    |
      | (3cbd945b62ec4634839372e403f6f377, 458b36a70db843719d202a8eda448f17) |   0.972 |         0.872 |           0.9135 |             9 |               64 |          4096 |           1 | 0.0100697459464075 |           5 |            4 | maxabs    |
      |                                                                      |         |               |                  |               |                  |               |             |                    |             |              |           |
      | (1c954fbc02b747bc813c587ac703c74a, ba49a80c2616407a8f1fe1fd12096fe0) |   0.962 |         0.856 |           0.8585 |            17 |               16 |         16384 |           5 | 0.0101590069352232 |           3 |            4 | l2        |
      :END:

   3. notes on hparams:
      - I used three different input sizes in hparams training (4096, 8192,
        16384). As experimental test data I have got traces which are around
        8000 and traces which are around 32000 time steps. To balance between
        both, I will only use 16384 as an input size.
      - The UNET only excepts input sizes which are exactly the power of 2 and
        > 1024. To deal with that for experimental traces which have a different
        size, I append the median of the trace until it reaches the next biggest
        power of 2. That means in the script below my =input_size= will be
        =14000=, so each trace will be padded with =2384= median values (~15% of
        the input), and the corresponding labels will be =0=.
      - the epoch size used for training will be 100 epochs for each hparam
        configuration

*** Experiment: run training of 9 promising hparam combinations
   1. run training of =(9051e32b87d84f3485b980067addec30,
      61ff87bdb89b4e2ba64f8dacc774992d)= with hparams from above.

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=26 \
               -P first_filters=44 \
               -P input_size=14000 \
               -P lr_start=0.0136170138242663 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=7 \
               -P pool_size=2
      #+END_SRC

      #+RESULTS:
      #+begin_example
        INFO: 'exp-220227-unet' does not exist. Creating a new experiment
        2022/02/27 23:06:17 INFO mlflow.projects.utils: === Created directory /tmp/tmp5u38tprq for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/27 23:06:17 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 26 --input_size 14000 --lr_start 0.0136170138242663 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 7 --first_filters 44 --pool_size 2' in run with ID '484af471c61943fa90e5f78e78a229f0' ===
        2022-02-27 23:06:19.459522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:06:27,328 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-27 23:06:27,329 - train -  Tensorflow version: 2.5.0
        2022-02-27 23:06:27,329 - train -  tf.keras version: 2.5.0
        2022-02-27 23:06:27,329 - train -  Cudnn version: 8
        2022-02-27 23:06:27,329 - train -  Cuda version: 11.2
        2022-02-27 23:06:27.332616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-27 23:06:27.373032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-27 23:06:27.373166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:06:27.382894: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-27 23:06:27.382990: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-27 23:06:27.386881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-27 23:06:27.389946: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-27 23:06:27.399178: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-27 23:06:27.413770: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-27 23:06:27.415902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-27 23:06:27.419520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-27 23:06:27,419 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-27 23:06:27,420 - train -  Setting memory growth successful.
        2022-02-27 23:06:33,649 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-27 23:06:47,474 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-27 23:06:52,553 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-27 23:06:56,374 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-27 23:06:59,968 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-27 23:07:03,508 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-27 23:07:07,092 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-27 23:07:10,718 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-27 23:07:14,433 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-27 23:07:18,054 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-27 23:07:21,398 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-27 23:07:33,241 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-27 23:07:37,082 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-27 23:07:40,911 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-27 23:07:44,813 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-27 23:07:48,436 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-27 23:07:52,998 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-27 23:07:56,536 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-27 23:08:00,088 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-27 23:08:03,661 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-27 23:08:07,253 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-27 23:08:22,306 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-27 23:08:25,939 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-27 23:08:29,797 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-27 23:08:33,419 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-27 23:08:38,026 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-27 23:08:41,552 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-27 23:08:46,334 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-27 23:08:52,449 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-27 23:09:00,390 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-27 23:09:13,802 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-27 23:09:17,690 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-27 23:09:21,264 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-27 23:09:25,460 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-27 23:09:29,041 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-27 23:09:33,185 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-27 23:09:36,927 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-27 23:09:43,792 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-27 23:09:55,806 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-27 23:09:59,340 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-27 23:10:04,195 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-27 23:10:07,769 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-27 23:10:11,494 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-27 23:10:15,480 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-27 23:10:19,534 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-27 23:10:23,308 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-27 23:10:27,088 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-27 23:10:30,870 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-27 23:10:34,365 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-27 23:10:43,346 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-27 23:10:59,488 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-27 23:11:07,159 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-27 23:11:11,824 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-27 23:11:15,330 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-27 23:11:19,613 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-27 23:11:22,985 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-27 23:11:26,571 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-27 23:11:30,142 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-27 23:11:33,712 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-27 23:11:40,154 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-27 23:11:40,374 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-27 23:11:40,463 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-27 23:11:40.616724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-27 23:11:40.620393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-27 23:11:40.624428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-27 23:11:40.624579: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-27 23:11:41.105011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-27 23:11:41.105083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-27 23:11:41.105097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-27 23:11:41.107958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-27 23:11:43,160 - train -  number of examples: 4800
        2022-02-27 23:11:43,526 - train -  number of examples: 1200
        2022-02-27 23:11:46,063 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/27 23:11:46 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='26' for run ID='484
        af471c61943fa90e5f78e78a229f0'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-27 23:11:56.021789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-27 23:11:56.201257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-27 23:12:06.010819: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-27 23:12:06.325533: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-27 23:12:06.806608: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-27 23:12:07.089703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        184/184 [==============================] - 212s 1s/step - loss: 1.1422 - tp0.1: 8390499.0000 - fp0.1: 12828878.0000 - tn0.1: 55341968.0000 - fn0.1: 1819714.0000 - precision0.1: 0.3954 - recall0.1: 0.8218 - tp0.3: 7189476.0000 - fp0.3: 4
        881676.0000 - tn0.3: 63289180.0000 - fn0.3: 3020737.0000 - precision0.3: 0.5956 - recall0.3: 0.7041 - tp0.5: 6041120.0000 - fp0.5: 2184567.0000 - tn0.5: 65986268.0000 - fn0.5: 4169093.0000 - precision0.5: 0.7344 - recall0.5: 0.5917 - tp
        0.7: 4490541.0000 - fp0.7: 712795.0000 - tn0.7: 67458040.0000 - fn0.7: 5719672.0000 - precision0.7: 0.8630 - recall0.7: 0.4398 - tp0.9: 2966847.0000 - fp0.9: 153266.0000 - tn0.9: 68017552.0000 - fn0.9: 7243366.0000 - precision0.9: 0.950
        9 - recall0.9: 0.2906 - accuracy: 0.9189 - auc: 0.8890 - f1: 0.6554 - val_loss: 45.6530 - val_tp0.1: 2695397.0000 - val_fp0.1: 16186602.0000 - val_tn0.1: 695010.0000 - val_fn0.1: 18255.0000 - val_precision0.1: 0.1427 - val_recall0.1: 0.
        9933 - val_tp0.3: 2693432.0000 - val_fp0.3: 16009674.0000 - val_tn0.3: 871938.0000 - val_fn0.3: 20220.0000 - val_precision0.3: 0.1440 - val_recall0.3: 0.9925 - val_tp0.5: 2691511.0000 - val_fp0.5: 15860014.0000 - val_tn0.5: 1021598.0000
         - val_fn0.5: 22141.0000 - val_precision0.5: 0.1451 - val_recall0.5: 0.9918 - val_tp0.7: 2688428.0000 - val_fp0.7: 15650703.0000 - val_tn0.7: 1230909.0000 - val_fn0.7: 25224.0000 - val_precision0.7: 0.1466 - val_recall0.7: 0.9907 - val_
        tp0.9: 2681968.0000 - val_fp0.9: 15334839.0000 - val_tn0.9: 1546773.0000 - val_fn0.9: 31684.0000 - val_precision0.9: 0.1489 - val_recall0.9: 0.9883 - val_accuracy: 0.1895 - val_auc: 0.5616 - val_f1: 0.2531

        ...

        Epoch 100/100
        184/184 [==============================] - 184s 1s/step - loss: 0.0877 - tp0.1: 10015121.0000 - fp0.1: 1833216.0000 - tn0.1: 66390352.0000 - fn0.1: 142350.0000 - precision0.1: 0.8453 - recall0.1: 0.9860 - tp0.3: 9874038.0000 - fp0.3: 10
        86322.0000 - tn0.3: 67137280.0000 - fn0.3: 283433.0000 - precision0.3: 0.9009 - recall0.3: 0.9721 - tp0.5: 9674727.0000 - fp0.5: 664419.0000 - tn0.5: 67559176.0000 - fn0.5: 482744.0000 - precision0.5: 0.9357 - recall0.5: 0.9525 - tp0.7:
         9343030.0000 - fp0.7: 341635.0000 - tn0.7: 67881952.0000 - fn0.7: 814441.0000 - precision0.7: 0.9647 - recall0.7: 0.9198 - tp0.9: 8626370.0000 - fp0.9: 88068.0000 - tn0.9: 68135504.0000 - fn0.9: 1531101.0000 - precision0.9: 0.9899 - re
        call0.9: 0.8493 - accuracy: 0.9854 - auc: 0.9920 - f1: 0.9440 - val_loss: 0.1556 - val_tp0.1: 2623480.0000 - val_fp0.1: 609139.0000 - val_tn0.1: 16273852.0000 - val_fn0.1: 88793.0000 - val_precision0.1: 0.8116 - val_recall0.1: 0.9673 -
        val_tp0.3: 2573475.0000 - val_fp0.3: 375340.0000 - val_tn0.3: 16507651.0000 - val_fn0.3: 138798.0000 - val_precision0.3: 0.8727 - val_recall0.3: 0.9488 - val_tp0.5: 2518254.0000 - val_fp0.5: 251870.0000 - val_tn0.5: 16631121.0000 - val_
        fn0.5: 194019.0000 - val_precision0.5: 0.9091 - val_recall0.5: 0.9285 - val_tp0.7: 2439448.0000 - val_fp0.7: 153092.0000 - val_tn0.7: 16729899.0000 - val_fn0.7: 272825.0000 - val_precision0.7: 0.9409 - val_recall0.7: 0.8994 - val_tp0.9:
         2279822.0000 - val_fp0.9: 61468.0000 - val_tn0.9: 16821524.0000 - val_fn0.9: 432451.0000 - val_precision0.9: 0.9737 - val_recall0.9: 0.8406 - val_accuracy: 0.9772 - val_auc: 0.9814 - val_f1: 0.9187
        2022-02-28 04:24:39.818514: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 04:24:58 INFO mlflow.projects: === Run (ID '484af471c61943fa90e5f78e78a229f0') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =484af471c61943fa90e5f78e78a229f0=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9091 - val_recall0.5: 0.9285 - val_f10.5: 0.9187
        - val_auc: 0.9814
   2. run training of =(93b168c0ff7942c8a908a94129daf973,
      f243b3b742de4dbcb7ccfbd4244706f8)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=15 \
               -P first_filters=23 \
               -P input_size=14000 \
               -P lr_start=0.0305060808685107 \
               -P lr_power=7 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=quant_g \
               -P n_levels=6 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/02/28 14:14:59 INFO mlflow.projects.utils: === Created directory /tmp/tmpjco1jnk_ for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/28 14:15:00 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 15 --input_size 14000 --lr_start 0.0305060808685107 --lr_power 7 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler quant_g --n_levels 6 --first_filters 23 --pool_size 4' in run with ID '0cd2023eeaf745aca0d3e8ad5e1fc653' ===
        2022-02-28 14:15:13.580296: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:15:25,693 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-28 14:15:25,693 - train -  Tensorflow version: 2.5.0
        2022-02-28 14:15:25,693 - train -  tf.keras version: 2.5.0
        2022-02-28 14:15:25,693 - train -  Cudnn version: 8
        2022-02-28 14:15:25,693 - train -  Cuda version: 11.2
        2022-02-28 14:15:25.695839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-28 14:15:25.776740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 14:15:25.776884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:15:25.786987: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 14:15:25.787115: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-28 14:15:25.790205: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-28 14:15:25.791541: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-28 14:15:25.799938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-28 14:15:25.821517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-28 14:15:25.822676: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 14:15:25.826275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 14:15:25,826 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-28 14:15:25,827 - train -  Setting memory growth successful.
        2022-02-28 14:15:33,830 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-28 14:15:46,000 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-28 14:15:50,090 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-28 14:16:02,981 - train -  4/48: /beegfs/ye53nis/saves/first
        artifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-28 14:16:11,106 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-28 14:16:16,436 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-28 14:16:21,251 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-28 14:16:24,785 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-28 14:16:41,395 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-28 14:16:45,170 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-28 14:16:48,894 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-28 14:17:01,362 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-28 14:17:05,972 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-28 14:17:11,392 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-28 14:17:15,150 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-28 14:17:18,880 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-28 14:17:22,858 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-28 14:17:26,879 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-28 14:17:31,181 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-28 14:17:34,897 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-28 14:17:38,846 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-28 14:18:01,434 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-28 14:18:05,125 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-28 14:18:10,548 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-28 14:18:15,933 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-28 14:18:20,727 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-28 14:18:24,064 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-28 14:18:35,979 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-28 14:18:39,881 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-28 14:18:43,394 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-28 14:18:53,160 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-28 14:18:57,332 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-28 14:19:03,503 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-28 14:19:08,665 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-28 14:19:13,327 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-28 14:19:17,293 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-28 14:19:21,119 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-28 14:19:24,804 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-28 14:19:31,451 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-28 14:19:41,863 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-28 14:19:47,487 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-28 14:19:53,197 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-28 14:20:00,405 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-28 14:20:04,607 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-28 14:20:08,353 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-28 14:20:12,307 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-28 14:20:16,444 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-28 14:20:20,213 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-28 14:20:23,834 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-28 14:20:30,953 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-28 14:20:36,797 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-28 14:20:48,524 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-28 14:20:57,745 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-28 14:21:01,411 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-28 14:21:13,337 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-28 14:21:17,317 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-28 14:21:21,005 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-28 14:21:24,834 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-28 14:21:28,718 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-28 14:21:32,087 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-28 14:21:32,293 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-28 14:21:32,383 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-28 14:21:32.540303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-28 14:21:32.542865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 14:21:32.544861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 14:21:32.544960: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 14:21:32.969057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-28 14:21:32.969130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-28 14:21:32.969144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-28 14:21:32.972037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-28 14:21:35,138 - train -  number of examples: 4800
        2022-02-28 14:21:35,561 - train -  number of examples: 1200
        2022-02-28 14:21:37,968 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/28 14:21:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='15' for run ID='0cd
        2023eeaf745aca0d3e8ad5e1fc653'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-28 14:21:47.612006: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-28 14:21:47.786795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-28 14:22:00.556303: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 3118 of 4800
        2022-02-28 14:22:05.887971: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.
        2022-02-28 14:22:05.992991: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 14:22:06.329980: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-28 14:22:06.837590: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 14:22:07.115604: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        320/320 [==============================] - 80s 158ms/step - loss: 0.6557 - tp0.1: 8858269.0000 - fp0.1: 11367531.0000 - tn0.1: 57039588.0000 - fn0.1: 1377794.0000 - precision0.1: 0.4380 - recall0.1: 0.8654 - tp0.3: 8020446.0000 - fp0.3:
         6844078.0000 - tn0.3: 61563052.0000 - fn0.3: 2215617.0000 - precision0.3: 0.5396 - recall0.3: 0.7835 - tp0.5: 6484149.0000 - fp0.5: 3021931.0000 - tn0.5: 65385196.0000 - fn0.5: 3751914.0000 - precision0.5: 0.6821 - recall0.5: 0.6335 -
        tp0.7: 4743137.0000 - fp0.7: 1127848.0000 - tn0.7: 67279296.0000 - fn0.7: 5492926.0000 - precision0.7: 0.8079 - recall0.7: 0.4634 - tp0.9: 2178331.0000 - fp0.9: 182418.0000 - tn0.9: 68224688.0000 - fn0.9: 8057732.0000 - precision0.9: 0.
        9227 - recall0.9: 0.2128 - accuracy: 0.9139 - auc: 0.9007 - f1: 0.6569 - val_loss: 154.4101 - val_tp0.1: 2567299.0000 - val_fp0.1: 15932078.0000 - val_tn0.1: 1006227.0000 - val_fn0.1: 155196.0000 - val_precision0.1: 0.1388 - val_recall0
        .1: 0.9430 - val_tp0.3: 2564050.0000 - val_fp0.3: 15892674.0000 - val_tn0.3: 1045631.0000 - val_fn0.3: 158445.0000 - val_precision0.3: 0.1389 - val_recall0.3: 0.9418 - val_tp0.5: 2561216.0000 - val_fp0.5: 15863898.0000 - val_tn0.5: 1074
        407.0000 - val_fn0.5: 161279.0000 - val_precision0.5: 0.1390 - val_recall0.5: 0.9408 - val_tp0.7: 2556675.0000 - val_fp0.7: 15829841.0000 - val_tn0.7: 1108464.0000 - val_fn0.7: 165820.0000 - val_precision0.7: 0.1391 - val_recall0.7: 0.9
        391 - val_tp0.9: 2546087.0000 - val_fp0.9: 15767476.0000 - val_tn0.9: 1170829.0000 - val_fn0.9: 176408.0000 - val_precision0.9: 0.1390 - val_recall0.9: 0.9352 - val_accuracy: 0.1849 - val_auc: 0.4998 - val_f1: 0.2422

        ...

        Epoch 100/100
        320/320 [==============================] - 46s 145ms/step - loss: 0.1275 - tp0.1: 10018370.0000 - fp0.1: 2700999.0000 - tn0.1: 65706144.0000 - fn0.1: 217693.0000 - precision0.1: 0.7876 - recall0.1: 0.9787 - tp0.3: 9775954.0000 - fp0.3:
        1429847.0000 - tn0.3: 66977260.0000 - fn0.3: 460109.0000 - precision0.3: 0.8724 - recall0.3: 0.9551 - tp0.5: 9497895.0000 - fp0.5: 850165.0000 - tn0.5: 67556944.0000 - fn0.5: 738168.0000 - precision0.5: 0.9178 - recall0.5: 0.9279 - tp0.
        7: 9083449.0000 - fp0.7: 444475.0000 - tn0.7: 67962624.0000 - fn0.7: 1152614.0000 - precision0.7: 0.9534 - recall0.7: 0.8874 - tp0.9: 8160305.0000 - fp0.9: 123032.0000 - tn0.9: 68284080.0000 - fn0.9: 2075758.0000 - precision0.9: 0.9851
        - recall0.9: 0.7972 - accuracy: 0.9798 - auc: 0.9876 - f1: 0.9228 - val_loss: 0.1678 - val_tp0.1: 2639044.0000 - val_fp0.1: 807650.0000 - val_tn0.1: 16130655.0000 - val_fn0.1: 83451.0000 - val_precision0.1: 0.7657 - val_recall0.1: 0.969
        3 - val_tp0.3: 2571140.0000 - val_fp0.3: 452176.0000 - val_tn0.3: 16486129.0000 - val_fn0.3: 151355.0000 - val_precision0.3: 0.8504 - val_recall0.3: 0.9444 - val_tp0.5: 2500729.0000 - val_fp0.5: 291947.0000 - val_tn0.5: 16646358.0000 -
        val_fn0.5: 221766.0000 - val_precision0.5: 0.8955 - val_recall0.5: 0.9185 - val_tp0.7: 2397916.0000 - val_fp0.7: 172157.0000 - val_tn0.7: 16766148.0000 - val_fn0.7: 324579.0000 - val_precision0.7: 0.9330 - val_recall0.7: 0.8808 - val_tp
        0.9: 2174652.0000 - val_fp0.9: 58658.0000 - val_tn0.9: 16879648.0000 - val_fn0.9: 547843.0000 - val_precision0.9: 0.9737 - val_recall0.9: 0.7988 - val_accuracy: 0.9739 - val_auc: 0.9818 - val_f1: 0.9069
        2022-02-28 15:49:04.737117: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 15:49:22 INFO mlflow.projects: === Run (ID '0cd2023eeaf745aca0d3e8ad5e1fc653') succeeded ===
      #+end_example
      - name of run: =0cd2023eeaf745aca0d3e8ad5e1fc653=
      - metrics after 100th epoch:
        - val_precision0.5: 0.8955 - val_recall0.5: 0.9185 - val_f10.5: 0.9069
        - val_auc: 0.9818
   3. run training of =(a5b8551144ff46e697a39cd1551e1475,
      98cf8cdef9c54b5286e277e75e2ab8c1)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=20 \
               -P first_filters=78 \
               -P input_size=14000 \
               -P lr_start=0.0584071108418767 \
               -P lr_power=4 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=4 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/02/28 17:34:45 INFO mlflow.projects.utils: === Created directory /tmp/tmpwue2ujb5 for downloading remote URIs passed to arguments of type 'path' ===
        2022/02/28 17:34:45 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 20 --input_size 14000 --lr_start 0.0584071108418767 --lr_power 4 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 4 --first_filters 78 --pool_size 4' in run with ID 'fe81d71c52404ed790b3a32051258da9' ===
        2022-02-28 17:34:58.034002: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:35:10,330 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-02-28 17:35:10,331 - train -  Tensorflow version: 2.5.0
        2022-02-28 17:35:10,331 - train -  tf.keras version: 2.5.0
        2022-02-28 17:35:10,331 - train -  Cudnn version: 8
        2022-02-28 17:35:10,331 - train -  Cuda version: 11.2
        2022-02-28 17:35:10.333548: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-02-28 17:35:10.391240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 17:35:10.391388: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:35:10.401553: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 17:35:10.401669: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-02-28 17:35:10.405228: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-02-28 17:35:10.407042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-02-28 17:35:10.415485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-02-28 17:35:10.417900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-02-28 17:35:10.419606: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 17:35:10.422879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 17:35:10,423 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-02-28 17:35:10,423 - train -  Setting memory growth successful.
        2022-02-28 17:35:16,324 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-02-28 17:35:30,676 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-02-28 17:35:34,283 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-02-28 17:35:38,780 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-02-28 17:35:43,054 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-02-28 17:35:46,234 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-02-28 17:35:50,337 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-02-28 17:35:53,421 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-02-28 17:35:59,004 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-02-28 17:36:02,669 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-02-28 17:36:06,267 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-02-28 17:36:14,414 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-02-28 17:36:18,640 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-02-28 17:36:21,742 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-02-28 17:36:25,004 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-02-28 17:36:28,518 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-02-28 17:36:31,957 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-02-28 17:36:35,265 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-02-28 17:36:38,670 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-02-28 17:36:42,309 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-02-28 17:36:45,973 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-02-28 17:36:53,886 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-02-28 17:36:57,387 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-02-28 17:37:00,889 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-02-28 17:37:03,901 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-02-28 17:37:08,741 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-02-28 17:37:11,797 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-02-28 17:37:15,549 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-02-28 17:37:19,909 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-02-28 17:37:32,956 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-02-28 17:37:47,613 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-02-28 17:37:51,591 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-02-28 17:37:59,140 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-02-28 17:38:03,933 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-02-28 17:38:07,415 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-02-28 17:38:15,509 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-02-28 17:38:20,075 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-02-28 17:38:24,146 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-02-28 17:38:38,735 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-02-28 17:38:41,894 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-02-28 17:38:45,710 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-02-28 17:38:49,786 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-02-28 17:38:53,505 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-02-28 17:38:58,205 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-02-28 17:39:02,031 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-02-28 17:39:06,190 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-02-28 17:39:09,521 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-02-28 17:39:14,557 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-02-28 17:39:18,060 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-02-28 17:39:31,842 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-02-28 17:39:51,088 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-02-28 17:40:02,789 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-02-28 17:40:06,696 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-02-28 17:40:10,118 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-02-28 17:40:24,593 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-02-28 17:40:28,308 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-02-28 17:40:37,143 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-02-28 17:40:41,060 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-02-28 17:40:59,911 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-02-28 17:41:19,363 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-02-28 17:41:19,570 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-02-28 17:41:19,659 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-02-28 17:41:19.824149: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-02-28 17:41:19.827704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-02-28 17:41:19.831605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-02-28 17:41:19.831748: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-02-28 17:41:20.290008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-02-28 17:41:20.290081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-02-28 17:41:20.290096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-02-28 17:41:20.292984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-02-28 17:41:22,312 - train -  number of examples: 4800
        2022-02-28 17:41:22,698 - train -  number of examples: 1200
        2022-02-28 17:41:26,203 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/02/28 17:41:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='20' for run ID='fe8
        1d71c52404ed790b3a32051258da9'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-02-28 17:41:34.119597: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-02-28 17:41:34.266024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-02-28 17:41:42.993902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-02-28 17:41:43.305956: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-02-28 17:41:43.787015: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-02-28 17:41:44.068827: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        240/240 [==============================] - 146s 532ms/step - loss: 0.8392 - tp0.1: 8747285.0000 - fp0.1: 10445142.0000 - tn0.1: 57962008.0000 - fn0.1: 1488778.0000 - precision0.1: 0.4558 - recall0.1: 0.8546 - tp0.3: 7896000.0000 - fp0.3
        : 5233157.0000 - tn0.3: 63173976.0000 - fn0.3: 2340063.0000 - precision0.3: 0.6014 - recall0.3: 0.7714 - tp0.5: 6575708.0000 - fp0.5: 2263621.0000 - tn0.5: 66143520.0000 - fn0.5: 3660355.0000 - precision0.5: 0.7439 - recall0.5: 0.6424 -
         tp0.7: 5154156.0000 - fp0.7: 920133.0000 - tn0.7: 67487000.0000 - fn0.7: 5081907.0000 - precision0.7: 0.8485 - recall0.7: 0.5035 - tp0.9: 3283109.0000 - fp0.9: 213358.0000 - tn0.9: 68193792.0000 - fn0.9: 6952954.0000 - precision0.9: 0.
        9390 - recall0.9: 0.3207 - accuracy: 0.9247 - auc: 0.9073 - f1: 0.6894 - val_loss: 1.7768 - val_tp0.1: 2543119.0000 - val_fp0.1: 9378664.0000 - val_tn0.1: 7559641.0000 - val_fn0.1: 179376.0000 - val_precision0.1: 0.2133 - val_recall0.1:
         0.9341 - val_tp0.3: 2504900.0000 - val_fp0.3: 7161614.0000 - val_tn0.3: 9776691.0000 - val_fn0.3: 217595.0000 - val_precision0.3: 0.2591 - val_recall0.3: 0.9201 - val_tp0.5: 2470794.0000 - val_fp0.5: 5614724.0000 - val_tn0.5: 11323581.
        0000 - val_fn0.5: 251701.0000 - val_precision0.5: 0.3056 - val_recall0.5: 0.9075 - val_tp0.7: 2416278.0000 - val_fp0.7: 4187348.0000 - val_tn0.7: 12750957.0000 - val_fn0.7: 306217.0000 - val_precision0.7: 0.3659 - val_recall0.7: 0.8875
        - val_tp0.9: 2331726.0000 - val_fp0.9: 2968486.0000 - val_tn0.9: 13969819.0000 - val_fn0.9: 390769.0000 - val_precision0.9: 0.4399 - val_recall0.9: 0.8565 - val_accuracy: 0.7016 - val_auc: 0.8807 - val_f1: 0.4572

        ...

        Epoch 100/100
        240/240 [==============================] - 124s 515ms/step - loss: 0.0941 - tp0.1: 10073753.0000 - fp0.1: 1908290.0000 - tn0.1: 66498824.0000 - fn0.1: 162310.0000 - precision0.1: 0.8407 - recall0.1: 0.9841 - tp0.3: 9929412.0000 - fp0.3:
         1163791.0000 - tn0.3: 67243336.0000 - fn0.3: 306651.0000 - precision0.3: 0.8951 - recall0.3: 0.9700 - tp0.5: 9693885.0000 - fp0.5: 672284.0000 - tn0.5: 67734840.0000 - fn0.5: 542178.0000 - precision0.5: 0.9351 - recall0.5: 0.9470 - tp0
        .7: 9345709.0000 - fp0.7: 339542.0000 - tn0.7: 68067608.0000 - fn0.7: 890354.0000 - precision0.7: 0.9649 - recall0.7: 0.9130 - tp0.9: 8608433.0000 - fp0.9: 86583.0000 - tn0.9: 68320560.0000 - fn0.9: 1627630.0000 - precision0.9: 0.9900 -
         recall0.9: 0.8410 - accuracy: 0.9846 - auc: 0.9912 - f1: 0.9411 - val_loss: 0.1372 - val_tp0.1: 2648989.0000 - val_fp0.1: 600014.0000 - val_tn0.1: 16338291.0000 - val_fn0.1: 73506.0000 - val_precision0.1: 0.8153 - val_recall0.1: 0.9730
         - val_tp0.3: 2604739.0000 - val_fp0.3: 372047.0000 - val_tn0.3: 16566258.0000 - val_fn0.3: 117756.0000 - val_precision0.3: 0.8750 - val_recall0.3: 0.9567 - val_tp0.5: 2542400.0000 - val_fp0.5: 225996.0000 - val_tn0.5: 16712309.0000 - v
        al_fn0.5: 180095.0000 - val_precision0.5: 0.9184 - val_recall0.5: 0.9338 - val_tp0.7: 2459692.0000 - val_fp0.7: 126768.0000 - val_tn0.7: 16811536.0000 - val_fn0.7: 262803.0000 - val_precision0.7: 0.9510 - val_recall0.7: 0.9035 - val_tp0
        .9: 2288921.0000 - val_fp0.9: 43449.0000 - val_tn0.9: 16894856.0000 - val_fn0.9: 433574.0000 - val_precision0.9: 0.9814 - val_recall0.9: 0.8407 - val_accuracy: 0.9793 - val_auc: 0.9849 - val_f1: 0.9260
        2022-02-28 21:13:24.522272: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/02/28 21:13:37 INFO mlflow.projects: === Run (ID 'fe81d71c52404ed790b3a32051258da9') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =fe81d71c52404ed790b3a32051258da9=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9184 - val_recall0.5: 0.9338 - val_f10.5: 0.9260
        - val_auc: 0.9849
   4. run training of =(00f2635d9fa2463c9a066722163405be,
      d0a8e1748b194f3290d471b6b44f19f8)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=28 \
               -P first_filters=6 \
               -P input_size=14000 \
               -P lr_start=0.0553313915596308 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=minmax \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 01:02:32 INFO mlflow.projects.utils: === Created directory /tmp/tmpscsw8dai for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 01:02:32 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 28 --input_size 14000 --lr_start 0.0553313915596308 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler minmax --n_levels 5 --first_filters 6 --pool_size 4' in run with ID 'ff67be0b68e540a9a29a36a2d0c7a5be' ===
        2022-03-01 01:02:49.062309: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:03:02,012 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 01:03:02,013 - train -  Tensorflow version: 2.5.0
        2022-03-01 01:03:02,013 - train -  tf.keras version: 2.5.0
        2022-03-01 01:03:02,013 - train -  Cudnn version: 8
        2022-03-01 01:03:02,013 - train -  Cuda version: 11.2
        2022-03-01 01:03:02.017849: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 01:03:02.070568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 01:03:02.070675: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:03:02.081043: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 01:03:02.081139: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 01:03:02.085346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 01:03:02.088350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 01:03:02.097715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 01:03:02.100867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 01:03:02.103117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 01:03:02.106443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 01:03:02,106 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 01:03:02,107 - train -  Setting memory growth successful.
        2022-03-01 01:03:08,710 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 01:03:17,500 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 01:03:21,523 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 01:03:25,810 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 01:03:29,726 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 01:03:35,702 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 01:03:39,927 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 01:03:44,978 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 01:03:49,851 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 01:03:54,065 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 01:03:57,914 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 01:04:09,148 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 01:04:14,246 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 01:04:17,776 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 01:04:24,334 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 01:04:28,494 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 01:04:31,978 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 01:04:35,535 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 01:04:39,104 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 01:04:42,753 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 01:04:46,786 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 01:04:50,549 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 01:05:10,273 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 01:05:14,332 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 01:05:17,829 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 01:05:29,382 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 01:05:32,892 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 01:05:37,614 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 01:05:41,478 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 01:05:55,816 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 01:06:06,797 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 01:06:10,595 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 01:06:15,368 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 01:06:20,784 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 01:06:26,970 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 01:06:31,521 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 01:06:35,363 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 01:06:39,107 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 01:07:01,475 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 01:07:05,191 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 01:07:08,941 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 01:07:13,043 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 01:07:16,874 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 01:07:20,478 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 01:07:24,571 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 01:07:28,090 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 01:07:31,811 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 01:07:35,574 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 01:07:39,526 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 01:07:49,139 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 01:08:06,079 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 01:08:17,384 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 01:08:21,021 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 01:08:24,646 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 01:08:33,131 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 01:08:37,919 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 01:08:41,923 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 01:08:45,386 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 01:08:50,064 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 01:08:54,537 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 01:08:54,754 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 01:08:54,844 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 01:08:54.997694: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 01:08:55.000062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 01:08:55.002040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 01:08:55.002135: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 01:08:55.428415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 01:08:55.428487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 01:08:55.428501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 01:08:55.431349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 01:08:57,489 - train -  number of examples: 4800
        2022-03-01 01:08:57,859 - train -  number of examples: 1200
        2022-03-01 01:09:00,816 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 01:09:00 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='28' for run ID='ff6
        7be0b68e540a9a29a36a2d0c7a5be'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 01:09:09.470355: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 01:09:09.627221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 01:09:19.253073: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 01:09:19.568134: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 01:09:20.032500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 01:09:20.318967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        171/171 [==============================] - 38s 111ms/step - loss: 0.6328 - tp0.1: 9097064.0000 - fp0.1: 12967912.0000 - tn0.1: 55269208.0000 - fn0.1: 1112405.0000 - precision0.1: 0.4123 - recall0.1: 0.8910 - tp0.3: 8278749.0000 - fp0.3:
         7308225.0000 - tn0.3: 60928896.0000 - fn0.3: 1930720.0000 - precision0.3: 0.5311 - recall0.3: 0.8109 - tp0.5: 6546144.0000 - fp0.5: 2745102.0000 - tn0.5: 65492008.0000 - fn0.5: 3663325.0000 - precision0.5: 0.7045 - recall0.5: 0.6412 -
        tp0.7: 5069917.0000 - fp0.7: 1036309.0000 - tn0.7: 67200816.0000 - fn0.7: 5139552.0000 - precision0.7: 0.8303 - recall0.7: 0.4966 - tp0.9: 2806365.0000 - fp0.9: 200542.0000 - tn0.9: 68036592.0000 - fn0.9: 7403104.0000 - precision0.9: 0.
        9333 - recall0.9: 0.2749 - accuracy: 0.9183 - auc: 0.9138 - f1: 0.6714 - val_loss: 100.5511 - val_tp0.1: 2677947.0000 - val_fp0.1: 16589637.0000 - val_tn0.1: 0.0000e+00 - val_fn0.1: 0.0000e+00 - val_precision0.1: 0.1390 - val_recall0.1:
         1.0000 - val_tp0.3: 2677947.0000 - val_fp0.3: 16589563.0000 - val_tn0.3: 74.0000 - val_fn0.3: 0.0000e+00 - val_precision0.3: 0.1390 - val_recall0.3: 1.0000 - val_tp0.5: 2677947.0000 - val_fp0.5: 16589315.0000 - val_tn0.5: 322.0000 - va
        l_fn0.5: 0.0000e+00 - val_precision0.5: 0.1390 - val_recall0.5: 1.0000 - val_tp0.7: 2677947.0000 - val_fp0.7: 16589042.0000 - val_tn0.7: 595.0000 - val_fn0.7: 0.0000e+00 - val_precision0.7: 0.1390 - val_recall0.7: 1.0000 - val_tp0.9: 26
        77947.0000 - val_fp0.9: 16588561.0000 - val_tn0.9: 1076.0000 - val_fn0.9: 0.0000e+00 - val_precision0.9: 0.1390 - val_recall0.9: 1.0000 - val_accuracy: 0.1390 - val_auc: 0.5001 - val_f1: 0.2441

        ...

        Epoch 100/100
        171/171 [==============================] - 15s 89ms/step - loss: 0.0890 - tp0.1: 10079569.0000 - fp0.1: 1892418.0000 - tn0.1: 66332504.0000 - fn0.1: 142100.0000 - precision0.1: 0.8419 - recall0.1: 0.9861 - tp0.3: 9939857.0000 - fp0.3: 1
        140232.0000 - tn0.3: 67084692.0000 - fn0.3: 281812.0000 - precision0.3: 0.8971 - recall0.3: 0.9724 - tp0.5: 9703286.0000 - fp0.5: 647685.0000 - tn0.5: 67577248.0000 - fn0.5: 518383.0000 - precision0.5: 0.9374 - recall0.5: 0.9493 - tp0.7
        : 9385401.0000 - fp0.7: 340758.0000 - tn0.7: 67884160.0000 - fn0.7: 836268.0000 - precision0.7: 0.9650 - recall0.7: 0.9182 - tp0.9: 8688940.0000 - fp0.9: 89880.0000 - tn0.9: 68135024.0000 - fn0.9: 1532729.0000 - precision0.9: 0.9898 - r
        ecall0.9: 0.8501 - accuracy: 0.9851 - auc: 0.9922 - f1: 0.9433 - val_loss: 0.1286 - val_tp0.1: 2593533.0000 - val_fp0.1: 546329.0000 - val_tn0.1: 16060347.0000 - val_fn0.1: 67375.0000 - val_precision0.1: 0.8260 - val_recall0.1: 0.9747 -
         val_tp0.3: 2548361.0000 - val_fp0.3: 333669.0000 - val_tn0.3: 16273007.0000 - val_fn0.3: 112547.0000 - val_precision0.3: 0.8842 - val_recall0.3: 0.9577 - val_tp0.5: 2492439.0000 - val_fp0.5: 208035.0000 - val_tn0.5: 16398641.0000 - val
        _fn0.5: 168469.0000 - val_precision0.5: 0.9230 - val_recall0.5: 0.9367 - val_tp0.7: 2414912.0000 - val_fp0.7: 119511.0000 - val_tn0.7: 16487165.0000 - val_fn0.7: 245996.0000 - val_precision0.7: 0.9528 - val_recall0.7: 0.9076 - val_tp0.9
        : 2250009.0000 - val_fp0.9: 39723.0000 - val_tn0.9: 16566953.0000 - val_fn0.9: 410899.0000 - val_precision0.9: 0.9827 - val_recall0.9: 0.8456 - val_accuracy: 0.9805 - val_auc: 0.9859 - val_f1: 0.9298
        2022-03-01 01:40:07.449069: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 01:40:21 INFO mlflow.projects: === Run (ID 'ff67be0b68e540a9a29a36a2d0c7a5be') succeeded ===

      #+end_example

      - name of run: =ff67be0b68e540a9a29a36a2d0c7a5be=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9230 - val_recall0.5: 0.9367 - val_f1: 0.9298
        - val_auc: 0.9859
   5. run training of =(5604d43c1ece461b8e6eaa0dfb65d6dc,
      3612536a77f34f22bc83d1d809140aa6)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=20 \
               -P first_filters=128 \
               -P input_size=14000 \
               -P lr_start=0.043549707353273 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=standard \
               -P n_levels=3 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 12:32:44 INFO mlflow.projects.utils: === Created directory /tmp/tmpuaqmbl4a for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 12:32:44 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 20 --input_size 14000 --lr_start 0.043549707353273 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_pa
        th_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler standard --n_levels 3 --first_filters 128 --pool_size 4' in run with ID '19e3e786e1bc4e2b93856f5dc9de8216' ===
        2022-03-01 12:32:58.514798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:33:09,490 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 12:33:09,490 - train -  Tensorflow version: 2.5.0
        2022-03-01 12:33:09,490 - train -  tf.keras version: 2.5.0
        2022-03-01 12:33:09,490 - train -  Cudnn version: 8
        2022-03-01 12:33:09,490 - train -  Cuda version: 11.2
        2022-03-01 12:33:09.493303: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 12:33:09.550241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 12:33:09.550350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:33:09.561190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 12:33:09.561299: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 12:33:09.565126: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 12:33:09.567931: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 12:33:09.576981: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 12:33:09.597335: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 12:33:09.599375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 12:33:09.602568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 12:33:09,602 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 12:33:09,603 - train -  Setting memory growth successful.
        2022-03-01 12:33:15,918 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 12:33:19,510 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 12:33:23,436 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 12:33:27,059 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 12:33:31,773 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 12:33:35,876 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 12:33:39,462 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 12:33:42,942 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 12:33:46,757 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 12:33:51,064 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 12:33:56,528 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 12:34:00,572 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 12:34:04,069 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 12:34:07,965 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 12:34:18,633 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 12:34:21,910 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 12:34:25,641 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 12:34:30,386 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 12:34:34,226 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 12:34:37,740 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 12:34:43,348 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 12:34:46,797 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 12:34:50,435 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 12:34:54,778 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 12:34:58,764 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 12:35:02,693 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 12:35:15,387 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 12:35:19,459 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 12:35:23,164 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 12:35:27,345 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 12:35:30,844 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 12:35:34,995 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 12:35:38,565 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 12:35:43,358 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 12:35:48,209 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 12:35:52,885 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 12:35:57,900 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 12:36:01,708 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 12:36:05,386 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 12:36:09,008 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 12:36:13,039 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 12:36:16,946 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 12:36:20,517 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 12:36:24,115 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 12:36:27,768 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 12:36:32,136 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 12:36:36,005 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 12:36:39,799 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 12:36:43,465 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 12:36:47,166 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 12:36:50,897 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 12:36:56,421 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 12:36:59,926 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 12:37:03,654 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 12:37:07,675 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 12:37:11,784 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 12:37:18,953 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 12:37:22,467 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 12:37:26,203 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 12:37:31,518 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 12:37:31,732 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 12:37:31,822 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 12:37:32.029003: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 12:37:32.031379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 12:37:32.033418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 12:37:32.033500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 12:37:32.469006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 12:37:32.469079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 12:37:32.469093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 12:37:32.471972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 12:37:34,440 - train -  number of examples: 4800
        2022-03-01 12:37:34,767 - train -  number of examples: 1200
        2022-03-01 12:37:36,587 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 12:37:36 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='20' for run ID='19e
        3e786e1bc4e2b93856f5dc9de8216'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 12:37:44.731191: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 12:37:44.863807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 12:37:53.275302: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 12:37:53.580058: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 12:37:54.077952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 12:37:54.363640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        240/240 [==============================] - 220s 838ms/step - loss: 1.1221 - tp0.1: 8540565.0000 - fp0.1: 11192430.0000 - tn0.1: 57214708.0000 - fn0.1: 1695498.0000 - precision0.1: 0.4328 - recall0.1: 0.8344 - tp0.3: 7522117.0000 - fp0.3
        : 4392113.0000 - tn0.3: 64015032.0000 - fn0.3: 2713946.0000 - precision0.3: 0.6314 - recall0.3: 0.7349 - tp0.5: 6672931.0000 - fp0.5: 2324779.0000 - tn0.5: 66082352.0000 - fn0.5: 3563132.0000 - precision0.5: 0.7416 - recall0.5: 0.6519 -
         tp0.7: 5275458.0000 - fp0.7: 916716.0000 - tn0.7: 67490392.0000 - fn0.7: 4960605.0000 - precision0.7: 0.8520 - recall0.7: 0.5154 - tp0.9: 3246371.0000 - fp0.9: 199829.0000 - tn0.9: 68207312.0000 - fn0.9: 6989692.0000 - precision0.9: 0.
        9420 - recall0.9: 0.3172 - accuracy: 0.9251 - auc: 0.9067 - f1: 0.6939 - val_loss: 1.4857 - val_tp0.1: 978503.0000 - val_fp0.1: 435953.0000 - val_tn0.1: 16502352.0000 - val_fn0.1: 1743992.0000 - val_precision0.1: 0.6918 - val_recall0.1:
         0.3594 - val_tp0.3: 873592.0000 - val_fp0.3: 222905.0000 - val_tn0.3: 16715400.0000 - val_fn0.3: 1848903.0000 - val_precision0.3: 0.7967 - val_recall0.3: 0.3209 - val_tp0.5: 816820.0000 - val_fp0.5: 140072.0000 - val_tn0.5: 16798232.00
        00 - val_fn0.5: 1905675.0000 - val_precision0.5: 0.8536 - val_recall0.5: 0.3000 - val_tp0.7: 747818.0000 - val_fp0.7: 84156.0000 - val_tn0.7: 16854148.0000 - val_fn0.7: 1974677.0000 - val_precision0.7: 0.8988 - val_recall0.7: 0.2747 - v
        al_tp0.9: 619063.0000 - val_fp0.9: 32598.0000 - val_tn0.9: 16905708.0000 - val_fn0.9: 2103432.0000 - val_precision0.9: 0.9500 - val_recall0.9: 0.2274 - val_accuracy: 0.8959 - val_auc: 0.7267 - val_f1: 0.4440

        ...

        Epoch 100/100
        240/240 [==============================] - 197s 821ms/step - loss: 0.0929 - tp0.1: 10067403.0000 - fp0.1: 1713493.0000 - tn0.1: 66693648.0000 - fn0.1: 168660.0000 - precision0.1: 0.8546 - recall0.1: 0.9835 - tp0.3: 9949382.0000 - fp0.3:
         1087364.0000 - tn0.3: 67319792.0000 - fn0.3: 286681.0000 - precision0.3: 0.9015 - recall0.3: 0.9720 - tp0.5: 9760046.0000 - fp0.5: 690436.0000 - tn0.5: 67716696.0000 - fn0.5: 476017.0000 - precision0.5: 0.9339 - recall0.5: 0.9535 - tp0
        .7: 9431582.0000 - fp0.7: 374056.0000 - tn0.7: 68033088.0000 - fn0.7: 804481.0000 - precision0.7: 0.9619 - recall0.7: 0.9214 - tp0.9: 8660415.0000 - fp0.9: 112381.0000 - tn0.9: 68294768.0000 - fn0.9: 1575648.0000 - precision0.9: 0.9872
        - recall0.9: 0.8461 - accuracy: 0.9852 - auc: 0.9906 - f1: 0.9436 - val_loss: 0.2611 - val_tp0.1: 2521251.0000 - val_fp0.1: 602159.0000 - val_tn0.1: 16336146.0000 - val_fn0.1: 201244.0000 - val_precision0.1: 0.8072 - val_recall0.1: 0.92
        61 - val_tp0.3: 2463263.0000 - val_fp0.3: 387212.0000 - val_tn0.3: 16551093.0000 - val_fn0.3: 259232.0000 - val_precision0.3: 0.8642 - val_recall0.3: 0.9048 - val_tp0.5: 2406415.0000 - val_fp0.5: 272305.0000 - val_tn0.5: 16666000.0000 -
         val_fn0.5: 316080.0000 - val_precision0.5: 0.8983 - val_recall0.5: 0.8839 - val_tp0.7: 2314277.0000 - val_fp0.7: 168490.0000 - val_tn0.7: 16769815.0000 - val_fn0.7: 408218.0000 - val_precision0.7: 0.9321 - val_recall0.7: 0.8501 - val_t
        p0.9: 2130323.0000 - val_fp0.9: 72929.0000 - val_tn0.9: 16865376.0000 - val_fn0.9: 592172.0000 - val_precision0.9: 0.9669 - val_recall0.9: 0.7825 - val_accuracy: 0.9701 - val_auc: 0.9595 - val_f1: 0.8911
        2022-03-01 18:11:37.935237: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 18:11:48 INFO mlflow.projects: === Run (ID '19e3e786e1bc4e2b93856f5dc9de8216') succeeded ===

      #+end_example

      - name of run: =19e3e786e1bc4e2b93856f5dc9de8216=
      - metrics after 100th epoch:
        - val_precision0.5: 0.8983 - val_recall0.5: 0.8839 - val_f10.5: 0.8911
        - val_auc: 0.9595
   6. run training of =(7cafab027cdd4fc9bf20a43e989df510,
      16dff15d935f45e2a836b1f41b07b4e3)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=10 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0627676336651573 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=robust \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 19:36:22 INFO mlflow.projects.utils: === Created directory /tmp/tmpzbcp4g1j for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 19:36:22 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 10 --input_size 14000 --lr_start 0.0627676336651573 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler robust --n_levels 5 --first_filters 16 --pool_size 4' in run with ID '347669d050f344ad9fb9e480c814f727' ===
        2022-03-01 19:36:34.348943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:36:46,433 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 19:36:46,434 - train -  Tensorflow version: 2.5.0
        2022-03-01 19:36:46,434 - train -  tf.keras version: 2.5.0
        2022-03-01 19:36:46,434 - train -  Cudnn version: 8
        2022-03-01 19:36:46,434 - train -  Cuda version: 11.2
        2022-03-01 19:36:46.437417: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 19:36:46.506267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 19:36:46.506409: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:36:46.516098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 19:36:46.516211: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 19:36:46.519627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 19:36:46.522117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 19:36:46.531350: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 19:36:46.534380: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 19:36:46.536313: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 19:36:46.539533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 19:36:46,539 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 19:36:46,540 - train -  Setting memory growth successful.
        2022-03-01 19:36:53,495 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 19:36:59,518 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 19:37:03,152 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 19:37:06,774 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 19:37:10,319 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 19:37:16,051 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 19:37:20,347 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 19:37:28,839 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 19:37:32,240 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 19:37:36,494 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 19:37:40,435 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 19:37:45,646 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 19:37:49,090 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 19:37:53,145 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 19:37:56,818 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 19:38:00,166 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 19:38:03,643 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 19:38:07,281 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 19:38:10,928 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 19:38:14,614 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 19:38:18,136 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 19:38:21,832 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 19:38:27,731 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 19:38:31,406 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 19:38:34,819 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 19:38:38,249 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 19:38:41,695 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 19:38:45,025 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 19:38:48,758 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 19:38:52,913 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 19:38:56,358 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 19:39:00,987 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 19:39:04,634 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 19:39:08,400 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 19:39:11,867 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 19:39:15,951 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 19:39:19,638 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 19:39:23,207 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 19:39:30,739 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 19:39:34,471 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 19:39:38,619 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 19:39:42,300 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 19:39:45,973 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 19:39:49,635 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 19:39:53,835 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 19:39:57,292 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 19:40:01,084 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 19:40:04,949 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 19:40:08,522 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 19:40:11,907 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 19:40:15,721 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 19:40:19,221 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 19:40:22,982 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 19:40:26,520 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 19:40:30,083 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 19:40:33,515 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 19:40:36,862 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 19:40:40,692 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 19:40:44,478 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 19:40:47,736 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 19:40:47,939 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 19:40:48,032 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 19:40:48.195482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 19:40:48.198562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 19:40:48.200594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 19:40:48.200695: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 19:40:48.635293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 19:40:48.635366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 19:40:48.635382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 19:40:48.638373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 19:40:51,863 - train -  number of examples: 4800
        2022-03-01 19:40:52,254 - train -  number of examples: 1200
        2022-03-01 19:40:54,716 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 19:40:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='10' for run ID='347
        669d050f344ad9fb9e480c814f727'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 19:41:04.464586: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 19:41:04.627492: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 19:41:14.720330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 19:41:15.055044: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 19:41:15.546433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 19:41:15.832893: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        480/480 [==============================] - 60s 82ms/step - loss: 0.5773 - tp0.1: 8880905.0000 - fp0.1: 10094803.0000 - tn0.1: 58312352.0000 - fn0.1: 1355158.0000 - precision0.1: 0.4680 - recall0.1: 0.8676 - tp0.3: 7871045.0000 - fp0.3:
        4514511.0000 - tn0.3: 63892572.0000 - fn0.3: 2365018.0000 - precision0.3: 0.6355 - recall0.3: 0.7690 - tp0.5: 6608273.0000 - fp0.5: 1693677.0000 - tn0.5: 66713460.0000 - fn0.5: 3627790.0000 - precision0.5: 0.7960 - recall0.5: 0.6456 - t
        p0.7: 5575527.0000 - fp0.7: 626556.0000 - tn0.7: 67780600.0000 - fn0.7: 4660536.0000 - precision0.7: 0.8990 - recall0.7: 0.5447 - tp0.9: 4341516.0000 - fp0.9: 163073.0000 - tn0.9: 68244088.0000 - fn0.9: 5894547.0000 - precision0.9: 0.96
        38 - recall0.9: 0.4241 - accuracy: 0.9323 - auc: 0.9124 - f1: 0.7129 - val_loss: 0.6884 - val_tp0.1: 2348236.0000 - val_fp0.1: 3299237.0000 - val_tn0.1: 13639068.0000 - val_fn0.1: 374259.0000 - val_precision0.1: 0.4158 - val_recall0.1:
        0.8625 - val_tp0.3: 2180062.0000 - val_fp0.3: 2146157.0000 - val_tn0.3: 14792148.0000 - val_fn0.3: 542433.0000 - val_precision0.3: 0.5039 - val_recall0.3: 0.8008 - val_tp0.5: 1966718.0000 - val_fp0.5: 1074503.0000 - val_tn0.5: 15863802.
        0000 - val_fn0.5: 755777.0000 - val_precision0.5: 0.6467 - val_recall0.5: 0.7224 - val_tp0.7: 1647155.0000 - val_fp0.7: 270297.0000 - val_tn0.7: 16668008.0000 - val_fn0.7: 1075340.0000 - val_precision0.7: 0.8590 - val_recall0.7: 0.6050
        - val_tp0.9: 1346781.0000 - val_fp0.9: 48532.0000 - val_tn0.9: 16889772.0000 - val_fn0.9: 1375714.0000 - val_precision0.9: 0.9652 - val_recall0.9: 0.4947 - val_accuracy: 0.9069 - val_auc: 0.8983 - val_f1: 0.6824

        ...

        Epoch 100/100
        480/480 [==============================] - 36s 75ms/step - loss: 0.0973 - tp0.1: 10083866.0000 - fp0.1: 2150370.0000 - tn0.1: 66256776.0000 - fn0.1: 152197.0000 - precision0.1: 0.8242 - recall0.1: 0.9851 - tp0.3: 9911194.0000 - fp0.3: 1
        217280.0000 - tn0.3: 67189872.0000 - fn0.3: 324869.0000 - precision0.3: 0.8906 - recall0.3: 0.9683 - tp0.5: 9675199.0000 - fp0.5: 716243.0000 - tn0.5: 67690904.0000 - fn0.5: 560864.0000 - precision0.5: 0.9311 - recall0.5: 0.9452 - tp0.7
        : 9261235.0000 - fp0.7: 330050.0000 - tn0.7: 68077096.0000 - fn0.7: 974828.0000 - precision0.7: 0.9656 - recall0.7: 0.9048 - tp0.9: 8585163.0000 - fp0.9: 94613.0000 - tn0.9: 68312512.0000 - fn0.9: 1650900.0000 - precision0.9: 0.9891 - r
        ecall0.9: 0.8387 - accuracy: 0.9838 - auc: 0.9915 - f1: 0.9381 - val_loss: 0.1400 - val_tp0.1: 2648521.0000 - val_fp0.1: 631749.0000 - val_tn0.1: 16306556.0000 - val_fn0.1: 73974.0000 - val_precision0.1: 0.8074 - val_recall0.1: 0.9728 -
         val_tp0.3: 2586061.0000 - val_fp0.3: 344848.0000 - val_tn0.3: 16593457.0000 - val_fn0.3: 136434.0000 - val_precision0.3: 0.8823 - val_recall0.3: 0.9499 - val_tp0.5: 2514973.0000 - val_fp0.5: 202882.0000 - val_tn0.5: 16735423.0000 - val
        _fn0.5: 207522.0000 - val_precision0.5: 0.9254 - val_recall0.5: 0.9238 - val_tp0.7: 2409626.0000 - val_fp0.7: 97831.0000 - val_tn0.7: 16840474.0000 - val_fn0.7: 312869.0000 - val_precision0.7: 0.9610 - val_recall0.7: 0.8851 - val_tp0.9:
         2228029.0000 - val_fp0.9: 30092.0000 - val_tn0.9: 16908212.0000 - val_fn0.9: 494466.0000 - val_precision0.9: 0.9867 - val_recall0.9: 0.8184 - val_accuracy: 0.9791 - val_auc: 0.9848 - val_f1: 0.9246
        2022-03-01 20:46:33.038541: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/01 20:46:47 INFO mlflow.projects: === Run (ID '347669d050f344ad9fb9e480c814f727') succeeded ===

      #+end_example

      - name of run: =347669d050f344ad9fb9e480c814f727=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9254 - val_recall0.5: 0.9238 - val_f10.5: 0.9246
        - val_auc: 0.9848
   7. run training of =(0e328920e86049928202db95e8cfb7be,
      bf9d2725eb16462d9a101f0a077ce2b5)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=14 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0192390310290551 \
               -P lr_power=5 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=robust \
               -P n_levels=9 \
               -P pool_size=2
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/01 22:12:06 INFO mlflow.projects.utils: === Created directory /tmp/tmpgcmidltj for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/01 22:12:06 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 14 --input_size 14000 --lr_start 0.0192390310290551 --lr_power 5 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler robust --n_levels 9 --first_filters 16 --pool_size 2' in run with ID 'c1204e3a8a1e4c40a35b5b7b1922d1ce' ===
        2022-03-01 22:12:20.335142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:12:33,450 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-01 22:12:33,451 - train -  Tensorflow version: 2.5.0
        2022-03-01 22:12:33,451 - train -  tf.keras version: 2.5.0
        2022-03-01 22:12:33,451 - train -  Cudnn version: 8
        2022-03-01 22:12:33,451 - train -  Cuda version: 11.2
        2022-03-01 22:12:33.453876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-01 22:12:33.508402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 22:12:33.508543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:12:33.518297: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 22:12:33.518392: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-01 22:12:33.521775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-01 22:12:33.523563: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-01 22:12:33.532074: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-01 22:12:33.534870: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-01 22:12:33.536502: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 22:12:33.539631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 22:12:33,539 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-01 22:12:33,540 - train -  Setting memory growth successful.
        2022-03-01 22:12:39,562 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-01 22:12:42,849 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-01 22:12:46,207 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-01 22:12:50,855 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-01 22:12:55,527 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-01 22:12:58,713 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-01 22:13:02,325 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-01 22:13:05,461 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-01 22:13:08,927 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-01 22:13:14,609 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-01 22:13:17,983 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-01 22:13:21,031 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-01 22:13:24,219 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-01 22:13:27,321 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-01 22:13:30,784 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-01 22:13:34,829 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-01 22:13:38,078 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-01 22:13:41,302 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-01 22:13:45,845 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-01 22:13:49,546 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-01 22:13:53,591 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-01 22:13:56,776 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-01 22:14:00,326 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-01 22:14:03,666 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-01 22:14:06,840 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-01 22:14:12,440 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-01 22:14:15,561 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-01 22:14:18,839 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-01 22:14:22,240 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-01 22:14:25,355 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-01 22:14:28,483 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-01 22:14:31,960 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-01 22:14:35,186 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-01 22:14:38,725 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-01 22:14:42,022 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-01 22:14:45,344 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-01 22:14:48,717 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-01 22:14:52,459 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-01 22:14:57,077 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-01 22:15:00,330 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-01 22:15:03,675 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-01 22:15:07,194 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-01 22:15:10,373 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-01 22:15:13,913 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-01 22:15:17,100 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-01 22:15:20,452 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-01 22:15:23,646 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-01 22:15:27,210 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-01 22:15:31,036 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-01 22:15:35,097 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-01 22:15:38,379 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-01 22:15:41,484 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-01 22:15:44,853 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-01 22:15:50,250 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-01 22:15:54,918 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-01 22:15:58,298 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-01 22:16:02,901 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-01 22:16:06,154 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-01 22:16:09,817 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-01 22:16:12,969 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-01 22:16:13,193 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-01 22:16:13,282 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-01 22:16:13.549849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-01 22:16:13.552236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-01 22:16:13.554196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-01 22:16:13.554316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-01 22:16:13.976589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-01 22:16:13.976661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-01 22:16:13.976674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-01 22:16:13.979482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-01 22:16:15,961 - train -  number of examples: 4800
        2022-03-01 22:16:16,380 - train -  number of examples: 1200
        2022-03-01 22:16:19,293 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/01 22:16:19 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='14' for run ID='c12
        04e3a8a1e4c40a35b5b7b1922d1ce'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-01 22:16:30.776559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-01 22:16:30.983303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-01 22:16:42.127026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-01 22:16:42.439526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-01 22:16:42.928881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-01 22:16:43.210835: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        342/342 [==============================] - 124s 292ms/step - loss: 0.7070 - tp0.1: 8568535.0000 - fp0.1: 13083853.0000 - tn0.1: 55158168.0000 - fn0.1: 1636041.0000 - precision0.1: 0.3957 - recall0.1: 0.8397 - tp0.3: 6954119.0000 - fp0.3
        : 4121236.0000 - tn0.3: 64120780.0000 - fn0.3: 3250457.0000 - precision0.3: 0.6279 - recall0.3: 0.6815 - tp0.5: 5914618.0000 - fp0.5: 1373295.0000 - tn0.5: 66868700.0000 - fn0.5: 4289958.0000 - precision0.5: 0.8116 - recall0.5: 0.5796 -
         tp0.7: 5157583.0000 - fp0.7: 495656.0000 - tn0.7: 67746344.0000 - fn0.7: 5046993.0000 - precision0.7: 0.9123 - recall0.7: 0.5054 - tp0.9: 4126657.0000 - fp0.9: 91030.0000 - tn0.9: 68151000.0000 - fn0.9: 6077919.0000 - precision0.9: 0.9
        784 - recall0.9: 0.4044 - accuracy: 0.9278 - auc: 0.8844 - f1: 0.6762 - val_loss: 0.6968 - val_tp0.1: 2338956.0000 - val_fp0.1: 2679424.0000 - val_tn0.1: 14116949.0000 - val_fn0.1: 361631.0000 - val_precision0.1: 0.4661 - val_recall0.1:
         0.8661 - val_tp0.3: 2156286.0000 - val_fp0.3: 1498035.0000 - val_tn0.3: 15298338.0000 - val_fn0.3: 544301.0000 - val_precision0.3: 0.5901 - val_recall0.3: 0.7985 - val_tp0.5: 1886303.0000 - val_fp0.5: 688918.0000 - val_tn0.5: 16107455.
        0000 - val_fn0.5: 814284.0000 - val_precision0.5: 0.7325 - val_recall0.5: 0.6985 - val_tp0.7: 1720047.0000 - val_fp0.7: 358918.0000 - val_tn0.7: 16437455.0000 - val_fn0.7: 980540.0000 - val_precision0.7: 0.8274 - val_recall0.7: 0.6369 -
         val_tp0.9: 1536712.0000 - val_fp0.9: 146022.0000 - val_tn0.9: 16650351.0000 - val_fn0.9: 1163875.0000 - val_precision0.9: 0.9132 - val_recall0.9: 0.5690 - val_accuracy: 0.9229 - val_auc: 0.9057 - val_f1: 0.7151

        ...

        Epoch 100/100
        342/342 [==============================] - 96s 282ms/step - loss: 0.1201 - tp0.1: 9816720.0000 - fp0.1: 2613299.0000 - tn0.1: 65809824.0000 - fn0.1: 206742.0000 - precision0.1: 0.7898 - recall0.1: 0.9794 - tp0.3: 9593189.0000 - fp0.3: 1
        365697.0000 - tn0.3: 67057408.0000 - fn0.3: 430273.0000 - precision0.3: 0.8754 - recall0.3: 0.9571 - tp0.5: 9310282.0000 - fp0.5: 760248.0000 - tn0.5: 67662912.0000 - fn0.5: 713180.0000 - precision0.5: 0.9245 - recall0.5: 0.9288 - tp0.7
        : 8896402.0000 - fp0.7: 359466.0000 - tn0.7: 68063680.0000 - fn0.7: 1127060.0000 - precision0.7: 0.9612 - recall0.7: 0.8876 - tp0.9: 8125429.0000 - fp0.9: 93565.0000 - tn0.9: 68329576.0000 - fn0.9: 1898033.0000 - precision0.9: 0.9886 -
        recall0.9: 0.8106 - accuracy: 0.9812 - auc: 0.9882 - f1: 0.9267 - val_loss: 0.1429 - val_tp0.1: 2631773.0000 - val_fp0.1: 731922.0000 - val_tn0.1: 16067311.0000 - val_fn0.1: 65954.0000 - val_precision0.1: 0.7824 - val_recall0.1: 0.9756
        - val_tp0.3: 2571221.0000 - val_fp0.3: 390541.0000 - val_tn0.3: 16408692.0000 - val_fn0.3: 126506.0000 - val_precision0.3: 0.8681 - val_recall0.3: 0.9531 - val_tp0.5: 2491171.0000 - val_fp0.5: 222824.0000 - val_tn0.5: 16576409.0000 - va
        l_fn0.5: 206556.0000 - val_precision0.5: 0.9179 - val_recall0.5: 0.9234 - val_tp0.7: 2379767.0000 - val_fp0.7: 112408.0000 - val_tn0.7: 16686825.0000 - val_fn0.7: 317960.0000 - val_precision0.7: 0.9549 - val_recall0.7: 0.8821 - val_tp0.
        9: 2166171.0000 - val_fp0.9: 33767.0000 - val_tn0.9: 16765466.0000 - val_fn0.9: 531556.0000 - val_precision0.9: 0.9847 - val_recall0.9: 0.8030 - val_accuracy: 0.9780 -
        2022-03-02 01:02:37.643121: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/02 01:03:00 INFO mlflow.projects: === Run (ID 'c1204e3a8a1e4c40a35b5b7b1922d1ce') succeeded ===
        (tf) [ye53nis@node128 drmed-git]$
      #+end_example

      - name of run: =c1204e3a8a1e4c40a35b5b7b1922d1ce=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9179 - val_recall0.5: 0.9234 - val_f1: 0.9207
        - val_auc: 0.9858
   8. run training of =(3cbd945b62ec4634839372e403f6f377,
      458b36a70db843719d202a8eda448f17)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=9 \
               -P first_filters=64 \
               -P input_size=14000 \
               -P lr_start=0.0100697459464075 \
               -P lr_power=1 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=maxabs \
               -P n_levels=5 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/02 01:11:44 INFO mlflow.projects.utils: === Created directory /tmp/tmpx4epxfnm for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/02 01:11:44 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 9 --input_size 14000 --lr_start 0.0100697459464075 --lr_power 1 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_pa
        th_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler maxabs --n_levels 5 --first_filters 64 --pool_size 4' in run with ID '714af8cd12c1441eac4ca980e8c20070' ===
        2022-03-02 01:11:56.803319: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:12:07,546 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-02 01:12:07,546 - train -  Tensorflow version: 2.5.0
        2022-03-02 01:12:07,546 - train -  tf.keras version: 2.5.0
        2022-03-02 01:12:07,547 - train -  Cudnn version: 8
        2022-03-02 01:12:07,547 - train -  Cuda version: 11.2
        2022-03-02 01:12:07.550455: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-02 01:12:07.628356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-02 01:12:07.628511: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:12:07.638859: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-02 01:12:07.638985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-02 01:12:07.643056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-02 01:12:07.646183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-02 01:12:07.656023: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-02 01:12:07.659075: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-02 01:12:07.661143: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-02 01:12:07.664383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-02 01:12:07,664 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-02 01:12:07,665 - train -  Setting memory growth successful.
        2022-03-02 01:12:13,856 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-02 01:12:17,659 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-02 01:12:21,236 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-02 01:12:24,720 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-02 01:12:27,968 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-02 01:12:31,066 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-02 01:12:34,437 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-02 01:12:37,504 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-02 01:12:42,706 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-02 01:12:46,132 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-02 01:12:49,635 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-02 01:12:53,763 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-02 01:12:57,006 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-02 01:13:00,289 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-02 01:13:03,628 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-02 01:13:07,750 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-02 01:13:11,178 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-02 01:13:14,491 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-02 01:13:17,835 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-02 01:13:21,243 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-02 01:13:24,830 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-02 01:13:28,194 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-02 01:13:31,658 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-02 01:13:35,112 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-02 01:13:38,261 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-02 01:13:41,634 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-02 01:13:44,894 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-02 01:13:48,172 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-02 01:13:51,792 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-02 01:13:55,890 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-02 01:13:59,226 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-02 01:14:03,473 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-02 01:14:06,889 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-02 01:14:11,194 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-02 01:14:14,602 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-02 01:14:18,195 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-02 01:14:23,874 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-02 01:14:27,349 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-02 01:14:30,931 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-02 01:14:39,147 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-02 01:14:42,631 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-02 01:14:46,112 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-02 01:14:49,382 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-02 01:14:54,801 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-02 01:14:58,059 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-02 01:15:01,699 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-02 01:15:04,960 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-02 01:15:08,548 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-02 01:15:11,862 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-02 01:15:15,127 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-02 01:15:18,793 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-02 01:15:24,397 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-02 01:15:27,879 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-02 01:15:31,270 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-02 01:15:34,589 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-02 01:15:38,546 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-02 01:15:42,044 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-02 01:15:45,426 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-02 01:15:49,033 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-02 01:15:52,325 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-02 01:15:52,527 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-02 01:15:52,616 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-02 01:15:52.773335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-02 01:15:52.775655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-02 01:15:52.777670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-02 01:15:52.777752: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-02 01:15:53.202763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-02 01:15:53.202835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-02 01:15:53.202850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-02 01:15:53.205744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-02 01:15:55,214 - train -  number of examples: 4800
        2022-03-02 01:15:55,624 - train -  number of examples: 1200
        2022-03-02 01:15:57,731 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/02 01:15:57 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='9' for run ID='714a
        f8cd12c1441eac4ca980e8c20070'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-02 01:16:06.204044: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-02 01:16:06.363399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-02 01:16:14.227408: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-02 01:16:14.534785: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-02 01:16:15.007638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-02 01:16:15.294778: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        533/533 [==============================] - 129s 209ms/step - loss: 0.9630 - tp0.1: 8826943.0000 - fp0.1: 17028400.0000 - tn0.1: 51333204.0000 - fn0.1: 1405497.0000 - precision0.1: 0.3414 - recall0.1: 0.8626 - tp0.3: 7038448.0000 - fp0.3
        : 7003701.0000 - tn0.3: 61357888.0000 - fn0.3: 3193992.0000 - precision0.3: 0.5012 - recall0.3: 0.6879 - tp0.5: 4980151.0000 - fp0.5: 2201947.0000 - tn0.5: 66159680.0000 - fn0.5: 5252289.0000 - precision0.5: 0.6934 - recall0.5: 0.4867 -
         tp0.7: 3822069.0000 - fp0.7: 917042.0000 - tn0.7: 67444552.0000 - fn0.7: 6410371.0000 - precision0.7: 0.8065 - recall0.7: 0.3735 - tp0.9: 2341770.0000 - fp0.9: 282920.0000 - tn0.9: 68078696.0000 - fn0.9: 7890670.0000 - precision0.9: 0.
        8922 - recall0.9: 0.2289 - accuracy: 0.9052 - auc: 0.8844 - f1: 0.5720 - val_loss: 17.7890 - val_tp0.1: 2710616.0000 - val_fp0.1: 15396795.0000 - val_tn0.1: 1498695.0000 - val_fn0.1: 5542.0000 - val_precision0.1: 0.1497 - val_recall0.1:
         0.9980 - val_tp0.3: 2709922.0000 - val_fp0.3: 15341678.0000 - val_tn0.3: 1553812.0000 - val_fn0.3: 6236.0000 - val_precision0.3: 0.1501 - val_recall0.3: 0.9977 - val_tp0.5: 2709375.0000 - val_fp0.5: 15293665.0000 - val_tn0.5: 1601825.0
        000 - val_fn0.5: 6783.0000 - val_precision0.5: 0.1505 - val_recall0.5: 0.9975 - val_tp0.7: 2708822.0000 - val_fp0.7: 15242876.0000 - val_tn0.7: 1652614.0000 - val_fn0.7: 7336.0000 - val_precision0.7: 0.1509 - val_recall0.7: 0.9973 - val
        _tp0.9: 2707532.0000 - val_fp0.9: 15151973.0000 - val_tn0.9: 1743517.0000 - val_fn0.9: 8626.0000 - val_precision0.9: 0.1516 - val_recall0.9: 0.9968 - val_accuracy: 0.2198 - val_auc: 0.5561 - val_f1: 0.2615

        ...

        Epoch 100/100
        533/533 [==============================] - 108s 202ms/step - loss: 0.0724 - tp0.1: 10196374.0000 - fp0.1: 1589491.0000 - tn0.1: 66701600.0000 - fn0.1: 106580.0000 - precision0.1: 0.8651 - recall0.1: 0.9897 - tp0.3: 10080835.0000 - fp0.3
        : 986714.0000 - tn0.3: 67304368.0000 - fn0.3: 222119.0000 - precision0.3: 0.9108 - recall0.3: 0.9784 - tp0.5: 9895952.0000 - fp0.5: 600682.0000 - tn0.5: 67690432.0000 - fn0.5: 407002.0000 - precision0.5: 0.9428 - recall0.5: 0.9605 - tp0
        .7: 9574784.0000 - fp0.7: 291406.0000 - tn0.7: 67999680.0000 - fn0.7: 728170.0000 - precision0.7: 0.9705 - recall0.7: 0.9293 - tp0.9: 8942531.0000 - fp0.9: 72576.0000 - tn0.9: 68218544.0000 - fn0.9: 1360423.0000 - precision0.9: 0.9919 -
         recall0.9: 0.8680 - accuracy: 0.9872 - auc: 0.9942 - f1: 0.9516 - val_loss: 0.1303 - val_tp0.1: 2631957.0000 - val_fp0.1: 478568.0000 - val_tn0.1: 16426044.0000 - val_fn0.1: 75079.0000 - val_precision0.1: 0.8461 - val_recall0.1: 0.9723
         - val_tp0.3: 2587183.0000 - val_fp0.3: 308683.0000 - val_tn0.3: 16595929.0000 - val_fn0.3: 119853.0000 - val_precision0.3: 0.8934 - val_recall0.3: 0.9557 - val_tp0.5: 2531594.0000 - val_fp0.5: 203214.0000 - val_tn0.5: 16701398.0000 - v
        al_fn0.5: 175442.0000 - val_precision0.5: 0.9257 - val_recall0.5: 0.9352 - val_tp0.7: 2448316.0000 - val_fp0.7: 118418.0000 - val_tn0.7: 16786194.0000 - val_fn0.7: 258720.0000 - val_precision0.7: 0.9539 - val_recall0.7: 0.9044 - val_tp0
        .9: 2283631.0000 - val_fp0.9: 49167.0000 - val_tn0.9: 16855444.0000 - val_fn0.9: 423405.0000 - val_precision0.9: 0.9789 - val_recall0.9: 0.8436 - val_accuracy: 0.9807 - val_auc: 0.9843 - val_f1: 0.9304
        2022-03-02 04:20:37.604740: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/02 04:20:52 INFO mlflow.projects: === Run (ID '714af8cd12c1441eac4ca980e8c20070') succeeded ===

      #+end_example

      - name of run: =714af8cd12c1441eac4ca980e8c20070=
      - metrics after 100th epoch:
        - val_precision0.5: 0.9257 - val_recall0.5: 0.9352 - val_f10.5: 0.9304
        - val_auc: 0.9843
   9. run training of =(3cbd945b62ec4634839372e403f6f377,
      458b36a70db843719d202a8eda448f17)= with hparams from above

      #+BEGIN_SRC tmux :socket ~/.tmux-local-socket-remote-machine :session gpu
        mlflow run . -e main -P fluotracify_path=/beegfs/ye53nis/drmed-git/src/ \
               -P batch_size=17 \
               -P first_filters=16 \
               -P input_size=14000 \
               -P lr_start=0.0101590069352232 \
               -P lr_power=5 \
               -P epochs=100 \
               -P csv_path_train=/beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets \
               -P csv_path_val=/beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN \
               -P scaler=l2 \
               -P n_levels=3 \
               -P pool_size=4
      #+END_SRC

      #+RESULTS:
      #+begin_example
        2022/03/03 14:24:46 INFO mlflow.projects.utils: === Created directory /tmp/tmp7c_e9yu1 for downloading remote URIs passed to arguments of type 'path' ===
        2022/03/03 14:24:46 INFO mlflow.projects.backend.local: === Running command 'source /cluster/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-eaf130b8edd83d20d4f1e0db4286dabd625893fe 1>&2 && python src/fluotracify/train
        ing/train.py --fluotracify_path /beegfs/ye53nis/drmed-git/src --batch_size 17 --input_size 14000 --lr_start 0.0101590069352232 --lr_power 5 --epochs 100 --csv_path_train /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets --csv_p
        ath_val /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN --col_per_example 3 --scaler l2 --n_levels 3 --first_filters 16 --pool_size 4' in run with ID '34a6d207ac594035b1009c330fb67a65' ===
        2022-03-03 14:24:50.057413: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:24:54,004 - train -  Python version: 3.9.6 (default, Jul 30 2021, 16:35:19)
        [GCC 7.5.0]
        2022-03-03 14:24:54,004 - train -  Tensorflow version: 2.5.0
        2022-03-03 14:24:54,004 - train -  tf.keras version: 2.5.0
        2022-03-03 14:24:54,004 - train -  Cudnn version: 8
        2022-03-03 14:24:54,004 - train -  Cuda version: 11.2
        2022-03-03 14:24:54.006301: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
        2022-03-03 14:24:54.030317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-03 14:24:54.030405: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:24:54.038110: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-03 14:24:54.038189: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        2022-03-03 14:24:54.041129: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
        2022-03-03 14:24:54.042988: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
        2022-03-03 14:24:54.050220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
        2022-03-03 14:24:54.052310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
        2022-03-03 14:24:54.053334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-03 14:24:54.056200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-03 14:24:54,056 - train -  GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]. Trying to set memory growth to "True"...
        2022-03-03 14:24:54,056 - train -  Setting memory growth successful.
        2022-03-03 14:25:01,220 - train -  1/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set004.csv
        2022-03-03 14:25:05,184 - train -  2/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set002.csv
        2022-03-03 14:25:08,951 - train -  3/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set001.csv
        2022-03-03 14:25:15,413 - train -  4/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.1/traces_brightclust_Nov2020_D1.0_set007.csv
        2022-03-03 14:25:33,960 - train -  5/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set002.csv
        2022-03-03 14:25:37,427 - train -  6/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/1.0/traces_brightclust_Nov2020_D10_set010.csv
        2022-03-03 14:25:41,118 - train -  7/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set004.csv
        2022-03-03 14:25:49,655 - train -  8/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.1/traces_brightclust_Nov2020_D3.0_set010.csv
        2022-03-03 14:25:54,052 - train -  9/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set009.csv
        2022-03-03 14:25:57,575 - train -  10/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set003.csv
        2022-03-03 14:26:01,255 - train -  11/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/1.0/traces_brightclust_Nov2020_D0.1_set007.csv
        2022-03-03 14:26:04,485 - train -  12/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/1.0/traces_brightclust_Nov2020_D1.0_set001.csv
        2022-03-03 14:26:08,073 - train -  13/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.01/traces_brightclust_Nov2020_D10_set003.csv
        2022-03-03 14:26:11,768 - train -  14/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/1.0/traces_brightclust_Nov2020_D0.6_set002.csv
        2022-03-03 14:26:19,400 - train -  15/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set005.csv
        2022-03-03 14:26:23,640 - train -  16/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/1.0/traces_brightclust_Nov2020_D0.069_set009.csv
        2022-03-03 14:26:27,567 - train -  17/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/1.0/traces_brightclust_Nov2020_D50_set004.csv
        2022-03-03 14:26:31,999 - train -  18/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set010.csv
        2022-03-03 14:26:36,569 - train -  19/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set009.csv
        2022-03-03 14:26:40,326 - train -  20/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/1.0/0.01/traces_brightclust_Nov2020_D1.0_set010.csv
        2022-03-03 14:26:43,920 - train -  21/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set007.csv
        2022-03-03 14:26:48,619 - train -  22/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/1.0/traces_brightclust_Nov2020_D0.2_set010.csv
        2022-03-03 14:26:53,742 - train -  23/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set001.csv
        2022-03-03 14:26:57,605 - train -  24/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set003.csv
        2022-03-03 14:27:01,008 - train -  25/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/1.0/traces_brightclust_Nov2020_D3.0_set003.csv
        2022-03-03 14:27:04,458 - train -  26/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set004.csv
        2022-03-03 14:27:07,860 - train -  27/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set001.csv
        2022-03-03 14:27:11,489 - train -  28/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set005.csv
        2022-03-03 14:27:15,309 - train -  29/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.1/traces_brightclust_Nov2020_D0.08_set006.csv
        2022-03-03 14:27:18,677 - train -  30/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.01/traces_brightclust_Nov2020_D0.4_set004.csv
        2022-03-03 14:27:22,854 - train -  31/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set006.csv
        2022-03-03 14:27:26,667 - train -  32/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.1/traces_brightclust_Nov2020_D0.2_set004.csv
        2022-03-03 14:27:30,369 - train -  33/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set005.csv
        2022-03-03 14:27:34,196 - train -  34/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set003.csv
        2022-03-03 14:27:37,882 - train -  35/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.2/0.01/traces_brightclust_Nov2020_D0.2_set003.csv
        2022-03-03 14:27:41,437 - train -  36/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.01/traces_brightclust_Nov2020_D50_set006.csv
        2022-03-03 14:27:45,344 - train -  37/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.1/traces_brightclust_Nov2020_D0.6_set004.csv
        2022-03-03 14:27:48,979 - train -  38/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/1.0/traces_brightclust_Nov2020_D0.08_set004.csv
        2022-03-03 14:27:52,611 - train -  39/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.6/0.01/traces_brightclust_Nov2020_D0.6_set010.csv
        2022-03-03 14:27:56,754 - train -  40/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/10/0.1/traces_brightclust_Nov2020_D10_set007.csv
        2022-03-03 14:28:00,273 - train -  41/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/1.0/traces_brightclust_Nov2020_D0.4_set006.csv
        2022-03-03 14:28:03,971 - train -  42/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.4/0.1/traces_brightclust_Nov2020_D0.4_set002.csv
        2022-03-03 14:28:07,564 - train -  43/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.1/0.01/traces_brightclust_Nov2020_D0.1_set006.csv
        2022-03-03 14:28:11,272 - train -  44/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/3.0/0.01/traces_brightclust_Nov2020_D3.0_set006.csv
        2022-03-03 14:28:15,163 - train -  45/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set010.csv
        2022-03-03 14:28:18,794 - train -  46/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.08/0.01/traces_brightclust_Nov2020_D0.08_set007.csv
        2022-03-03 14:28:22,428 - train -  47/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/0.069/0.1/traces_brightclust_Nov2020_D0.069_set002.csv
        2022-03-03 14:28:26,334 - train -  48/48: /beegfs/ye53nis/saves/firstartifact_Nov2020_train_max2sets/50/0.1/traces_brightclust_Nov2020_D50_set009.csv
        2022-03-03 14:28:30,056 - train -  1/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/0.1/traces_brightclust_Nov2020_D1.0_set009.csv
        2022-03-03 14:28:33,687 - train -  2/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/50/1.0/traces_brightclust_Nov2020_D50_set007.csv
        2022-03-03 14:28:37,128 - train -  3/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.4/0.1/traces_brightclust_Nov2020_D0.4_set009.csv
        2022-03-03 14:28:40,617 - train -  4/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/1.0/traces_brightclust_Nov2020_D3.0_set009.csv
        2022-03-03 14:28:44,105 - train -  5/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.1/0.01/traces_brightclust_Nov2020_D0.1_set008.csv
        2022-03-03 14:28:47,594 - train -  6/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/10/0.01/traces_brightclust_Nov2020_D10_set008.csv
        2022-03-03 14:28:51,273 - train -  7/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.08/0.1/traces_brightclust_Nov2020_D0.08_set008.csv
        2022-03-03 14:28:56,181 - train -  8/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/1.0/1.0/traces_brightclust_Nov2020_D1.0_set008.csv
        2022-03-03 14:28:59,593 - train -  9/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/3.0/0.01/traces_brightclust_Nov2020_D3.0_set008.csv
        2022-03-03 14:29:03,237 - train -  10/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.2/0.1/traces_brightclust_Nov2020_D0.2_set006.csv
        2022-03-03 14:29:07,571 - train -  11/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.069/0.1/traces_brightclust_Nov2020_D0.069_set006.csv
        2022-03-03 14:29:11,901 - train -  12/12: /beegfs/ye53nis/saves/firstartifact_Nov2020_val_max2sets_SORTEDIN/0.6/0.1/traces_brightclust_Nov2020_D0.6_set006.csv
        2022-03-03 14:29:12,117 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 4800), (16384, 4800), (16384, 4800)]
        2022-03-03 14:29:12,206 - train -  The given DataFrame was split into 3 parts with shapes: [(16384, 1200), (16384, 1200), (16384, 1200)]
        2022-03-03 14:29:12.413198: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operatio
        ns:  AVX2 FMA
        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
        2022-03-03 14:29:12.417391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
        pciBusID: 0000:82:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
        coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
        2022-03-03 14:29:12.419377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
        2022-03-03 14:29:12.419477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
        2022-03-03 14:29:12.833057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
        2022-03-03 14:29:12.833127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
        2022-03-03 14:29:12.833141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
        2022-03-03 14:29:12.835995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, p
        ci bus id: 0000:82:00.0, compute capability: 6.0)
        2022-03-03 14:29:14,768 - train -  number of examples: 4800
        2022-03-03 14:29:15,107 - train -  number of examples: 1200
        2022-03-03 14:29:16,570 - train -  unet: input shape: (None, None, 1), output shape: (None, None, 1)
        2022/03/03 14:29:16 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='batch_size' was already logged with value='17' for run ID='34a
        6d207ac594035b1009c330fb67a65'. Attempted logging new value 'None'.
        Epoch 1/100
        2022-03-03 14:29:23.930177: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
        2022-03-03 14:29:24.066046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199895000 Hz
        2022-03-03 14:29:33.256586: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
        2022-03-03 14:29:33.572296: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101
        2022-03-03 14:29:34.075599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
        2022-03-03 14:29:34.363317: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
        282/282 [==============================] - 45s 98ms/step - loss: 1.0922 - tp0.1: 8529810.0000 - fp0.1: 10393289.0000 - tn0.1: 57940184.0000 - fn0.1: 1681616.0000 - precision0.1: 0.4508 - recall0.1: 0.8353 - tp0.3: 7724105.0000 - fp0.3:
        3960382.0000 - tn0.3: 64373080.0000 - fn0.3: 2487321.0000 - precision0.3: 0.6611 - recall0.3: 0.7564 - tp0.5: 7024685.0000 - fp0.5: 1630985.0000 - tn0.5: 66702492.0000 - fn0.5: 3186741.0000 - precision0.5: 0.8116 - recall0.5: 0.6879 - t
        p0.7: 6159487.0000 - fp0.7: 585291.0000 - tn0.7: 67748208.0000 - fn0.7: 4051939.0000 - precision0.7: 0.9132 - recall0.7: 0.6032 - tp0.9: 4931800.0000 - fp0.9: 143363.0000 - tn0.9: 68190096.0000 - fn0.9: 5279626.0000 - precision0.9: 0.97
        18 - recall0.9: 0.4830 - accuracy: 0.9387 - auc: 0.9142 - f1: 0.7446 - val_loss: 3.2432 - val_tp0.1: 2699606.0000 - val_fp0.1: 16783988.0000 - val_tn0.1: 12739.0000 - val_fn0.1: 627.0000 - val_precision0.1: 0.1386 - val_recall0.1: 0.999
        8 - val_tp0.3: 2697002.0000 - val_fp0.3: 16748206.0000 - val_tn0.3: 48521.0000 - val_fn0.3: 3231.0000 - val_precision0.3: 0.1387 - val_recall0.3: 0.9988 - val_tp0.5: 2695536.0000 - val_fp0.5: 16737605.0000 - val_tn0.5: 59122.0000 - val_
        fn0.5: 4697.0000 - val_precision0.5: 0.1387 - val_recall0.5: 0.9983 - val_tp0.7: 2689329.0000 - val_fp0.7: 16678401.0000 - val_tn0.7: 118326.0000 - val_fn0.7: 10904.0000 - val_precision0.7: 0.1389 - val_recall0.7: 0.9960 - val_tp0.9: 22
        37862.0000 - val_fp0.9: 12480955.0000 - val_tn0.9: 4315772.0000 - val_fn0.9: 462371.0000 - val_precision0.9: 0.1520 - val_recall0.9: 0.8288 - val_accuracy: 0.1413 - val_auc: 0.5907 - val_f1: 0.2436

        ...

        Epoch 100/100
        282/282 [==============================] - 25s 88ms/step - loss: 0.2009 - tp0.1: 9736541.0000 - fp0.1: 3605117.0000 - tn0.1: 64740432.0000 - fn0.1: 462821.0000 - precision0.1: 0.7298 - recall0.1: 0.9546 - tp0.3: 9402084.0000 - fp0.3: 17
        39716.0000 - tn0.3: 66605812.0000 - fn0.3: 797278.0000 - precision0.3: 0.8439 - recall0.3: 0.9218 - tp0.5: 9016887.0000 - fp0.5: 920615.0000 - tn0.5: 67424920.0000 - fn0.5: 1182475.0000 - precision0.5: 0.9074 - recall0.5: 0.8841 - tp0.7
        : 8513773.0000 - fp0.7: 435436.0000 - tn0.7: 67910080.0000 - fn0.7: 1685589.0000 - precision0.7: 0.9513 - recall0.7: 0.8347 - tp0.9: 7585158.0000 - fp0.9: 106557.0000 - tn0.9: 68238992.0000 - fn0.9: 2614204.0000 - precision0.9: 0.9861 -
         recall0.9: 0.7437 - accuracy: 0.9732 - auc: 0.9746 - f1: 0.8956 - val_loss: 0.2670 - val_tp0.1: 2538570.0000 - val_fp0.1: 1039161.0000 - val_tn0.1: 15761772.0000 - val_fn0.1: 157457.0000 - val_precision0.1: 0.7095 - val_recall0.1: 0.94
        16 - val_tp0.3: 2435718.0000 - val_fp0.3: 590706.0000 - val_tn0.3: 16210227.0000 - val_fn0.3: 260309.0000 - val_precision0.3: 0.8048 - val_recall0.3: 0.9034 - val_tp0.5: 2326279.0000 - val_fp0.5: 379342.0000 - val_tn0.5: 16421591.0000 -
         val_fn0.5: 369748.0000 - val_precision0.5: 0.8598 - val_recall0.5: 0.8629 - val_tp0.7: 2189825.0000 - val_fp0.7: 228353.0000 - val_tn0.7: 16572580.0000 - val_fn0.7: 506202.0000 - val_precision0.7: 0.9056 - val_recall0.7: 0.8122 - val_t
        p0.9: 1947380.0000 - val_fp0.9: 92879.0000 - val_tn0.9: 16708054.0000 - val_fn0.9: 748647.0000 - val_precision0.9: 0.9545 - val_recall0.9: 0.7223 - val_accuracy: 0.9616 - val_auc: 0.9652 - val_f1: 0.8613
        2022-03-03 15:16:02.951715: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
        2022/03/03 15:16:13 INFO mlflow.projects: === Run (ID '34a6d207ac594035b1009c330fb67a65') succeeded ===

      #+end_example

      - name of run: =34a6d207ac594035b1009c330fb67a65=
      - metrics after 100th epoch:
        - val_precision0.5: 0.8598 - val_recall0.5: 0.8629 - val_f1: 0.8613
        - val_auc: 0.9652

*** Analysis 1: Check models on simulated test data, show model calibrations
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3
    :END:
    #+BEGIN_SRC jupyter-python
      %cd /beegfs/ye53nis/drmed-git
    #+END_SRC

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git


    #+begin_src jupyter-python
      from pathlib import Path

      import sys
      import mlflow
      import matplotlib.pyplot as plt
      import numpy as np
      import pandas as pd
      import seaborn as sns
      import tensorflow as tf
      print("tf version: ", tf.version.VERSION)
      print("tf.keras version: ", tf.keras.__version__)
      print("mlflow version: ", mlflow.version.VERSION)

      sys.path.append('src/')
      from fluotracify.simulations import (
         import_simulation_from_csv as isfc,
         analyze_simulations as ans,
      )
      from fluotracify.training import build_model as bm, preprocess_data as ppd
      from fluotracify.applications import correlate, plots, correction

      logging.basicConfig(filename="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-03-04_simulations.log",
                          filemode='w', format='%(asctime)s - %(message)s',
                          force=True,
                          level=logging.DEBUG)

      sns.set()
    #+end_src

    #+RESULTS:
    : 2022-03-04 14:27:17.660429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
    : 2022-03-04 14:27:17.660465: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
    : tf version:  2.8.0
    : tf.keras version:  2.8.0
    : mlflow version:  1.23.1

    #+BEGIN_SRC jupyter-python
      import importlib
      importlib.reload(ppd)
      importlib.reload(isfc)
    #+END_SRC

    #+RESULTS:
    : <module 'fluotracify.simulations.import_simulation_from_csv' from '/beegfs/ye53nis/drmed-git/src/fluotracify/simulations/import_simulation_from_csv.py'>

    #+BEGIN_SRC jupyter-python
      col_per_example = 3
      lab_thresh = 0.04
      pred_thresh = 0.5
      artifact = 0
      model_type = 1
      fwhm = 250
      model_ls = ['484af471c61943fa90e5f78e78a229f0', '0cd2023eeaf745aca0d3e8ad5e1fc653', 'fe81d71c52404ed790b3a32051258da9',
                  'ff67be0b68e540a9a29a36a2d0c7a5be', '19e3e786e1bc4e2b93856f5dc9de8216', '347669d050f344ad9fb9e480c814f727',
                  'c1204e3a8a1e4c40a35b5b7b1922d1ce', '714af8cd12c1441eac4ca980e8c20070', '34a6d207ac594035b1009c330fb67a65']

      input_path = '/beegfs/ye53nis/saves/firstartifact_Nov2020_test'
      output_path = "/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-03-01_experimental/"

      dataset, _, nsamples, experiment_params = isfc.import_from_csv(
          folder=input_path,
          header=12,
          frac_train=1,
          col_per_example=col_per_example,
          dropindex=None,
          dropcolumns=None)

      diffrates = experiment_params.loc['diffusion rate of molecules in micrometer^2 / s'].astype(np.float32)
      nmols = experiment_params.loc['number of fast molecules'].astype(np.float32)
      clusters = experiment_params.loc['diffusion rate of clusters in micrometer^2 / s'].astype(np.float32)

      dataset_sep = isfc.separate_data_and_labels(array=dataset,
                                                  nsamples=nsamples,
                                                  col_per_example=col_per_example)

      features = ppd.convert_to_tfds_for_unet(dataset_sep['0'])
      labels_artifact = dataset_sep['1']
      labels_artifact_bool = labels_artifact > lab_thresh
      labels_artifact_bool = ppd.convert_to_tfds_for_unet(labels_artifact_bool)
      labels_puretrace = ppd.convert_to_tfds_for_unet(dataset_sep['2'])

      next(features.as_numpy_iterator())
    #+END_SRC

    #+RESULTS:
    :RESULTS:
    #+begin_example
      2022-03-04 22:05:01,461 - sim import tools - 1/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.069/1.0/traces_brightclust_Nov2020_D0.069_set010.csv
      2022-03-04 22:05:04,158 - sim import tools - 2/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/50/0.1/traces_brightclust_Nov2020_D50_set003.csv
      2022-03-04 22:05:10,238 - sim import tools - 3/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.4/0.1/traces_brightclust_Nov2020_D0.4_set001.csv
      2022-03-04 22:05:12,936 - sim import tools - 4/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.2/0.1/traces_brightclust_Nov2020_D0.2_set007.csv
      2022-03-04 22:05:18,011 - sim import tools - 5/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/3.0/1.0/traces_brightclust_Nov2020_D3.0_set002.csv
      2022-03-04 22:05:21,767 - sim import tools - 6/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/3.0/0.01/traces_brightclust_Nov2020_D3.0_set004.csv
      2022-03-04 22:05:24,424 - sim import tools - 7/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/50/0.01/traces_brightclust_Nov2020_D50_set002.csv
      2022-03-04 22:05:28,343 - sim import tools - 8/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.2/1.0/traces_brightclust_Nov2020_D0.2_set005.csv
      2022-03-04 22:05:31,035 - sim import tools - 9/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.6/1.0/traces_brightclust_Nov2020_D0.6_set009.csv
      2022-03-04 22:05:33,895 - sim import tools - 10/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/10/0.1/traces_brightclust_Nov2020_D10_set001.csv2022-03-04 22:05:36,717 - sim import tools - 11/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.08/1.0/traces_brightclust_Nov2020_D0.08_set001.csv
      2022-03-04 22:05:40,367 - sim import tools - 12/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.6/0.1/traces_brightclust_Nov2020_D0.6_set003.csv
      2022-03-04 22:05:43,363 - sim import tools - 13/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.1/1.0/traces_brightclust_Nov2020_D0.1_set001.csv
      2022-03-04 22:05:50,219 - sim import tools - 14/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.4/1.0/traces_brightclust_Nov2020_D0.4_set005.csv
      2022-03-04 22:05:53,095 - sim import tools - 15/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/10/1.0/traces_brightclust_Nov2020_D10_set005.csv
      2022-03-04 22:05:56,046 - sim import tools - 16/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/1.0/1.0/traces_brightclust_Nov2020_D1.0_set005.csv
      2022-03-04 22:06:04,063 - sim import tools - 17/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.069/0.1/traces_brightclust_Nov2020_D0.069_set001.csv
      2022-03-04 22:06:13,289 - sim import tools - 18/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/50/1.0/traces_brightclust_Nov2020_D50_set001.csv
      2022-03-04 22:06:16,073 - sim import tools - 19/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.1/0.01/traces_brightclust_Nov2020_D0.1_set002.csv
      2022-03-04 22:06:19,494 - sim import tools - 20/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.08/0.1/traces_brightclust_Nov2020_D0.08_set003.csv
      2022-03-04 22:06:22,328 - sim import tools - 21/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/1.0/0.01/traces_brightclust_Nov2020_D1.0_set006.csv
      2022-03-04 22:06:25,247 - sim import tools - 22/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/1.0/0.1/traces_brightclust_Nov2020_D1.0_set003.csv
      2022-03-04 22:06:28,285 - sim import tools - 23/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.2/0.01/traces_brightclust_Nov2020_D0.2_set002.csv
      2022-03-04 22:06:31,188 - sim import tools - 24/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.1/0.1/traces_brightclust_Nov2020_D0.1_set005.csv
      2022-03-04 22:06:38,851 - sim import tools - 25/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/3.0/0.1/traces_brightclust_Nov2020_D3.0_set007.csv
      2022-03-04 22:06:41,893 - sim import tools - 26/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.08/0.01/traces_brightclust_Nov2020_D0.08_set005.csv
      2022-03-04 22:06:44,771 - sim import tools - 27/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.069/0.01/traces_brightclust_Nov2020_D0.069_set005.csv
      2022-03-04 22:06:47,751 - sim import tools - 28/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/10/0.01/traces_brightclust_Nov2020_D10_set002.csv
      2022-03-04 22:06:50,652 - sim import tools - 29/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.6/0.01/traces_brightclust_Nov2020_D0.6_set008.csv
      2022-03-04 22:06:53,573 - sim import tools - 30/30: /beegfs/ye53nis/saves/firstartifact_Nov2020_test/0.4/0.01/traces_brightclust_Nov2020_D0.4_set008.csv
      2022-03-04 22:06:53,849 - sim import tools - The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]
    #+end_example
    : array([[395.06235],
    :        [395.7326 ],
    :        [385.5988 ],
    :        ...,
    :        [472.55148],
    :        [486.6794 ],
    :        [489.89365]], dtype=float32)
    :END:

    #+BEGIN_SRC jupyter-python :pandoc t


    #+END_SRC

    #+RESULTS:
    :RESULTS:
    : 1.0 0.0689999982714653
    # [goto error]
    #+begin_example
      [0;31m---------------------------------------------------------------------------[0m
      [0;31mValueError[0m                                Traceback (most recent call last)
      [0;32m/tmp/ipykernel_404234/1946840430.py[0m in [0;36m<module>[0;34m[0m
      [1;32m      1[0m [0;32mfor[0m [0mi[0m[0;34m,[0m [0;34m([0m[0mc[0m[0;34m,[0m [0md[0m[0;34m)[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0mzip[0m[0;34m([0m[0mclusters[0m[0;34m,[0m [0mdiffrates[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
      [1;32m      2[0m     [0mprint[0m[0;34m([0m[0mc[0m[0;34m,[0m [0md[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
      [0;32m----> 3[0;31m     [0mpreds[0m [0;34m=[0m [0mloaded_model[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mfeatures[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
      [0m[1;32m      4[0m     [0;32mbreak[0m[0;34m[0m[0;34m[0m[0m

      [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py[0m in [0;36merror_handler[0;34m(*args, **kwargs)[0m
      [1;32m     65[0m     [0;32mexcept[0m [0mException[0m [0;32mas[0m [0me[0m[0;34m:[0m  [0;31m# pylint: disable=broad-except[0m[0;34m[0m[0;34m[0m[0m
      [1;32m     66[0m       [0mfiltered_tb[0m [0;34m=[0m [0m_process_traceback_frames[0m[0;34m([0m[0me[0m[0;34m.[0m[0m__traceback__[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
      [0;32m---> 67[0;31m       [0;32mraise[0m [0me[0m[0;34m.[0m[0mwith_traceback[0m[0;34m([0m[0mfiltered_tb[0m[0;34m)[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
      [0m[1;32m     68[0m     [0;32mfinally[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
      [1;32m     69[0m       [0;32mdel[0m [0mfiltered_tb[0m[0;34m[0m[0;34m[0m[0m

      [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py[0m in [0;36mautograph_handler[0;34m(*args, **kwargs)[0m
      [1;32m   1145[0m           [0;32mexcept[0m [0mException[0m [0;32mas[0m [0me[0m[0;34m:[0m  [0;31m# pylint:disable=broad-except[0m[0;34m[0m[0;34m[0m[0m
      [1;32m   1146[0m             [0;32mif[0m [0mhasattr[0m[0;34m([0m[0me[0m[0;34m,[0m [0;34m"ag_error_metadata"[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
      [0;32m-> 1147[0;31m               [0;32mraise[0m [0me[0m[0;34m.[0m[0mag_error_metadata[0m[0;34m.[0m[0mto_exception[0m[0;34m([0m[0me[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
      [0m[1;32m   1148[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
      [1;32m   1149[0m               [0;32mraise[0m[0;34m[0m[0;34m[0m[0m

      [0;31mValueError[0m: in user code:

          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py", line 1801, in predict_function  *
              return step_function(self, iterator)
          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py", line 1790, in step_function  **
              outputs = model.distribute_strategy.run(run_step, args=(data,))
          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py", line 1783, in run_step  **
              outputs = model.predict_step(data)
          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/engine/training.py", line 1751, in predict_step
              return self(x, training=False)
          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
              raise e.with_traceback(filtered_tb) from None
          File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/backend.py", line 6065, in pool2d
              x = tf.compat.v1.nn.max_pool(

          ValueError: Exception encountered when calling layer "mp_encode0" (type MaxPooling1D).

          Negative dimension size caused by subtracting 2 from 1 for '{{node unet_depth7/mp_encode0/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 2, 1, 1], padding="VALID", strides=[1, 2, 1, 1]](unet_depth7/mp_encode0/ExpandDims)' with input shapes: [16384,1,1,44].

          Call arguments received:
            • inputs=tf.Tensor(shape=(16384, 1, 44), dtype=float32)
    #+end_example
    :END:


    - plot transit times stratified after
      1. model used for classification
      2. simulated diffusion time of fast molecules
      3. simulated diffusion time of slow clusters
      #+BEGIN_SRC jupyter-python
        model_ls = {'484af471c61943fa90e5f78e78a229f0': 'standard',
                    '0cd2023eeaf745aca0d3e8ad5e1fc653': 'quant_g',
                    'fe81d71c52404ed790b3a32051258da9': 'standard',
                    'ff67be0b68e540a9a29a36a2d0c7a5be': 'minmax',
                    '19e3e786e1bc4e2b93856f5dc9de8216': 'standard',
                    '347669d050f344ad9fb9e480c814f727': 'robust',
                    'c1204e3a8a1e4c40a35b5b7b1922d1ce': 'robust',
                    '714af8cd12c1441eac4ca980e8c20070': 'maxabs',
                    '34a6d207ac594035b1009c330fb67a65': 'l2'}

        def predict(row):
            return loaded_model(row)


        for m, scaler in model_ls.items():
            print(m, scaler)
            logged_model = Path(f'/beegfs/ye53nis/drmed-git/data/mlruns/10/{m}/artifacts/model')
            loaded_model = mlflow.keras.load_model(logged_model, compile=False)
            loaded_model.compile(loss=bm.binary_ce_dice_loss(),
                                 optimizer=tf.keras.optimizers.Adam(),
                                 metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))
            features_prep = features.map(
                lambda trace: ppd.tfds_scale_trace(trace, scaler))
            preds = features_prep.map(predict)
            break
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      : 484af471c61943fa90e5f78e78a229f0 standard
      : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
      : 2022-03-04 22:59:31,195 - sim import tools - Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.
      # [goto error]
      #+begin_example
        [0;31m---------------------------------------------------------------------------[0m
        [0;31mValueError[0m                                Traceback (most recent call last)
        [0;32m/tmp/ipykernel_404234/1634327075.py[0m in [0;36m<module>[0;34m[0m
        [1;32m     22[0m     features_prep = features.map(
        [1;32m     23[0m         lambda trace: ppd.tfds_scale_trace(trace, scaler))
        [0;32m---> 24[0;31m     [0mpreds[0m [0;34m=[0m [0mfeatures_prep[0m[0;34m.[0m[0mmap[0m[0;34m([0m[0mpredict[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m     25[0m     [0;32mbreak[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py[0m in [0;36mmap[0;34m(self, map_func, num_parallel_calls, deterministic, name)[0m
        [1;32m   2014[0m         warnings.warn("The `deterministic` argument has no effect unless the "
        [1;32m   2015[0m                       "`num_parallel_calls` argument is specified.")
        [0;32m-> 2016[0;31m       [0;32mreturn[0m [0mMapDataset[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mmap_func[0m[0;34m,[0m [0mpreserve_cardinality[0m[0;34m=[0m[0;32mTrue[0m[0;34m,[0m [0mname[0m[0;34m=[0m[0mname[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m   2017[0m     [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   2018[0m       return ParallelMapDataset(

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py[0m in [0;36m__init__[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)[0m
        [1;32m   5189[0m     [0mself[0m[0;34m.[0m[0m_use_inter_op_parallelism[0m [0;34m=[0m [0muse_inter_op_parallelism[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   5190[0m     [0mself[0m[0;34m.[0m[0m_preserve_cardinality[0m [0;34m=[0m [0mpreserve_cardinality[0m[0;34m[0m[0;34m[0m[0m
        [0;32m-> 5191[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(
        [0m[1;32m   5192[0m         [0mmap_func[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   5193[0m         [0mself[0m[0;34m.[0m[0m_transformation_name[0m[0;34m([0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py[0m in [0;36m__init__[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)[0m
        [1;32m    269[0m         [0mfn_factory[0m [0;34m=[0m [0mtrace_tf_function[0m[0;34m([0m[0mdefun_kwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    270[0m [0;34m[0m[0m
        [0;32m--> 271[0;31m     [0mself[0m[0;34m.[0m[0m_function[0m [0;34m=[0m [0mfn_factory[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m    272[0m     [0;31m# There is no graph to add in eager mode.[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    273[0m     [0madd_to_graph[0m [0;34m&=[0m [0;32mnot[0m [0mcontext[0m[0;34m.[0m[0mexecuting_eagerly[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py[0m in [0;36mget_concrete_function[0;34m(self, *args, **kwargs)[0m
        [1;32m   3068[0m          [0;32mor[0m[0;31m [0m[0;31m`[0m[0mtf[0m[0;34m.[0m[0mTensor[0m[0;31m`[0m [0;32mor[0m[0;31m [0m[0;31m`[0m[0mtf[0m[0;34m.[0m[0mTensorSpec[0m[0;31m`[0m[0;34m.[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   3069[0m     """
        [0;32m-> 3070[0;31m     graph_function = self._get_concrete_function_garbage_collected(
        [0m[1;32m   3071[0m         *args, **kwargs)
        [1;32m   3072[0m     [0mgraph_function[0m[0;34m.[0m[0m_garbage_collector[0m[0;34m.[0m[0mrelease[0m[0;34m([0m[0;34m)[0m  [0;31m# pylint: disable=protected-access[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_get_concrete_function_garbage_collected[0;34m(self, *args, **kwargs)[0m
        [1;32m   3034[0m       [0margs[0m[0;34m,[0m [0mkwargs[0m [0;34m=[0m [0;32mNone[0m[0;34m,[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   3035[0m     [0;32mwith[0m [0mself[0m[0;34m.[0m[0m_lock[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [0;32m-> 3036[0;31m       [0mgraph_function[0m[0;34m,[0m [0m_[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_maybe_define_function[0m[0;34m([0m[0margs[0m[0;34m,[0m [0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m   3037[0m       [0mseen_names[0m [0;34m=[0m [0mset[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   3038[0m       captured = object_identity.ObjectIdentitySet(

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_maybe_define_function[0;34m(self, args, kwargs)[0m
        [1;32m   3290[0m [0;34m[0m[0m
        [1;32m   3291[0m           [0mself[0m[0;34m.[0m[0m_function_cache[0m[0;34m.[0m[0madd_call_context[0m[0;34m([0m[0mcache_key[0m[0;34m.[0m[0mcall_context[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0;32m-> 3292[0;31m           [0mgraph_function[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_create_graph_function[0m[0;34m([0m[0margs[0m[0;34m,[0m [0mkwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m   3293[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,
        [1;32m   3294[0m                                    graph_function)

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_create_graph_function[0;34m(self, args, kwargs, override_flat_arg_shapes)[0m
        [1;32m   3128[0m     [0marg_names[0m [0;34m=[0m [0mbase_arg_names[0m [0;34m+[0m [0mmissing_arg_names[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   3129[0m     graph_function = ConcreteFunction(
        [0;32m-> 3130[0;31m         func_graph_module.func_graph_from_py_func(
        [0m[1;32m   3131[0m             [0mself[0m[0;34m.[0m[0m_name[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   3132[0m             [0mself[0m[0;34m.[0m[0m_python_function[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py[0m in [0;36mfunc_graph_from_py_func[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)[0m
        [1;32m   1159[0m         [0m_[0m[0;34m,[0m [0moriginal_func[0m [0;34m=[0m [0mtf_decorator[0m[0;34m.[0m[0munwrap[0m[0;34m([0m[0mpython_func[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [1;32m   1160[0m [0;34m[0m[0m
        [0;32m-> 1161[0;31m       [0mfunc_outputs[0m [0;34m=[0m [0mpython_func[0m[0;34m([0m[0;34m*[0m[0mfunc_args[0m[0;34m,[0m [0;34m**[0m[0mfunc_kwargs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m   1162[0m [0;34m[0m[0m
        [1;32m   1163[0m       [0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py[0m in [0;36mwrapped_fn[0;34m(*args)[0m
        [1;32m    246[0m           attributes=defun_kwargs)
        [1;32m    247[0m       [0;32mdef[0m [0mwrapped_fn[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m)[0m[0;34m:[0m  [0;31m# pylint: disable=missing-docstring[0m[0;34m[0m[0;34m[0m[0m
        [0;32m--> 248[0;31m         [0mret[0m [0;34m=[0m [0mwrapper_helper[0m[0;34m([0m[0;34m*[0m[0margs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m    249[0m         [0mret[0m [0;34m=[0m [0mstructure[0m[0;34m.[0m[0mto_tensor_list[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_output_structure[0m[0;34m,[0m [0mret[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    250[0m         [0;32mreturn[0m [0;34m[[0m[0mops[0m[0;34m.[0m[0mconvert_to_tensor[0m[0;34m([0m[0mt[0m[0;34m)[0m [0;32mfor[0m [0mt[0m [0;32min[0m [0mret[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py[0m in [0;36mwrapper_helper[0;34m(*args)[0m
        [1;32m    175[0m       [0;32mif[0m [0;32mnot[0m [0m_should_unpack[0m[0;34m([0m[0mnested_args[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    176[0m         [0mnested_args[0m [0;34m=[0m [0;34m([0m[0mnested_args[0m[0;34m,[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0;32m--> 177[0;31m       [0mret[0m [0;34m=[0m [0mautograph[0m[0;34m.[0m[0mtf_convert[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_func[0m[0;34m,[0m [0mag_ctx[0m[0;34m)[0m[0;34m([0m[0;34m*[0m[0mnested_args[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m    178[0m       [0;32mif[0m [0m_should_pack[0m[0;34m([0m[0mret[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    179[0m         [0mret[0m [0;34m=[0m [0mtuple[0m[0;34m([0m[0mret[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m

        [0;32m~/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py[0m in [0;36mwrapper[0;34m(*args, **kwargs)[0m
        [1;32m    690[0m       [0;32mexcept[0m [0mException[0m [0;32mas[0m [0me[0m[0;34m:[0m  [0;31m# pylint:disable=broad-except[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    691[0m         [0;32mif[0m [0mhasattr[0m[0;34m([0m[0me[0m[0;34m,[0m [0;34m'ag_error_metadata'[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [0;32m--> 692[0;31m           [0;32mraise[0m [0me[0m[0;34m.[0m[0mag_error_metadata[0m[0;34m.[0m[0mto_exception[0m[0;34m([0m[0me[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
        [0m[1;32m    693[0m         [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
        [1;32m    694[0m           [0;32mraise[0m[0;34m[0m[0;34m[0m[0m

        [0;31mValueError[0m: in user code:

            File "/tmp/ipykernel_404234/1634327075.py", line 12, in predict  *
                return loaded_model(row)
            File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler  **
                raise e.with_traceback(filtered_tb) from None
            File "/home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/keras/backend.py", line 6065, in pool2d
                x = tf.compat.v1.nn.max_pool(

            ValueError: Exception encountered when calling layer "mp_encode0" (type MaxPooling1D).

            Negative dimension size caused by subtracting 2 from 1 for '{{node unet_depth7/mp_encode0/MaxPool}} = MaxPool[T=DT_FLOAT, data_format="NHWC", explicit_paddings=[], ksize=[1, 2, 1, 1], padding="VALID", strides=[1, 2, 1, 1]](unet_depth7/mp_encode0/ExpandDims)' with input shapes: [16384,1,1,44].

            Call arguments received:
              • inputs=tf.Tensor(shape=(16384, 1, 44), dtype=float32)
      #+end_example
      :END:


      #+BEGIN_SRC jupyter-python :pandoc t


      #+END_SRC

      #+RESULTS:
      : 2022-03-04 16:39:10,998 - sim import tools - The given DataFrame was split into 3 parts with shapes: [(16384, 3000), (16384, 3000), (16384, 3000)]


      #+BEGIN_SRC jupyter-python
        clusters
      #+END_SRC

      #+RESULTS:
      #+begin_example
        0     1.00
        1     0.10
        2     0.10
        3     0.10
        4     1.00
        5     0.01
        6     0.01
        7     1.00
        8     1.00
        9     0.10
        10    1.00
        11    0.10
        12    1.00
        13    1.00
        14    1.00
        15    1.00
        16    0.10
        17    1.00
        18    0.01
        19    0.10
        20    0.01
        21    0.10
        22    0.01
        23    0.10
        24    0.10
        25    0.01
        26    0.01
        27    0.01
        28    0.01
        29    0.01
        Name: diffusion rate of clusters in micrometer^2 / s, dtype: float32
      #+end_example


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC


      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

*** Analysis 2: Apply models on experimental data
    :PROPERTIES:
    :header-args:jupyter-python: :session /jpy:localhost#8889:a37e524a-8134-4d8f-b24a-367acaf1bdd3
    :END:
    #+BEGIN_SRC jupyter-python
      %cd /beegfs/ye53nis/drmed-git
    #+END_SRC

    #+RESULTS:
    : /beegfs/ye53nis/drmed-git

    #+BEGIN_SRC jupyter-python
      import logging
      import os
      import sys

      import matplotlib.pyplot as plt
      import numpy as np
      import pandas as pd
      import seaborn as sns

      from pathlib import Path
      from pprint import pprint
      from tensorflow.keras.optimizers import Adam
      from mlflow.keras import load_model

      FLUOTRACIFY_PATH = '/beegfs/ye53nis/drmed-git/src/'
      sys.path.append(FLUOTRACIFY_PATH)
      from fluotracify.applications import corr_fit_object as cfo
      from fluotracify.training import build_model as bm

      logging.basicConfig(filename="/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-03-01_experimental.log",
                          filemode='w', format='%(asctime)s - %(message)s',
                          force=True,
                          level=logging.DEBUG)

      sns.set()
    #+END_SRC

    #+RESULTS:


    #+BEGIN_SRC jupyter-python
      class ParameterClass():
          """Stores parameters for correlation """
          def __init__(self):
              # Where the data is stored.
              self.data = []
              self.objectRef = []
              self.subObjectRef = []
              self.colors = ['blue', 'green', 'red', 'cyan', 'magenta',
                             'yellow', 'black']
              self.numOfLoaded = 0
              # very fast from Ncasc ~ 14 onwards
              self.NcascStart = 0
              self.NcascEnd = 30  # 25
              self.Nsub = 6  # 6
              self.photonLifetimeBin = 10  # used for photon decay
              self.photonCountBin = 1  # used for time series

      data_path = Path("/beegfs/ye53nis/data")
      output_path = "/beegfs/ye53nis/drmed-git/data/exp-220227-unet/2022-03-01_experimental/"
      logged_model = 'file:///beegfs/ye53nis/drmed-git/data/mlruns/10/ff67be0b68e540a9a29a36a2d0c7a5be/artifacts/model'
      par_obj = ParameterClass()

      loaded_model = load_model(logged_model, compile=False)
      loaded_model.compile(loss=bm.binary_ce_dice_loss(),
                           optimizer=Adam(),
                           metrics = bm.unet_metrics([0.1, 0.3, 0.5, 0.7, 0.9]))
    #+END_SRC

    #+RESULTS:
    : 2022-03-01 16:16:29.015686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
    : 2022-03-01 16:16:29.015720: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
    : 2022-03-01 16:16:29.015740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node160): /proc/driver/nvidia/version does not exist
    : 2022-03-01 16:16:29.016040: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    : To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    : WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.

    - check out alexafluor+LUVS
      #+BEGIN_SRC jupyter-python
        path_clean = data_path / '1911DD_atto+LUVs/all_clean_ptu/'
        path_dirty = data_path / '1911DD_atto+LUVs/all_dirty_ptu/'
        files_clean = [path_clean / f for f in os.listdir(path_clean) if f.endswith('.ptu')]
        files_dirty = [path_dirty / f for f in os.listdir(path_dirty) if f.endswith('.ptu')]
        traces = pd.DataFrame()
        predtraces = pd.DataFrame()
        preds = pd.DataFrame()
        corrs = pd.DataFrame()
        mt_bin = 1e-3


        for idx, myfile in enumerate(files_clean):
            ptufile = cfo.PicoObject(myfile, par_obj)
            ptufile.predictTimeSeries(model=loaded_model,
                                      scaler='minmax')
            mt_name = f'us_{ptufile.name}'
            ptufile.getTimeSeries(timeseries_name=mt_name,
                                  photonCountBin=mt_bin)
            ptufile.getPhotonCountingStats(name=mt_name)
            ptufile.predictTimeSeries(model=loaded_model,
                                      scaler='minmax',
                                      name=mt_name)
            for key in list(ptufile.trueTimeArr.keys()):
                ptufile.get_autocorrelation(method='tttr2xfcs', name=key)
            for key in list(ptufile.timeSeries.keys()):
                for k, i in ptufile.timeSeries[key].items():
                    if "PREPRO" in k:
                        if "1.0" in k:
                            predtraces = pd.concat([predtraces, pd.DataFrame(i, columns=[f'{key}_{k}'])],
                                                   axis=1)
                    elif "1.0" in k:
                        traces = pd.concat([traces, pd.DataFrame(i, columns=[f'{key}_{k}'])],
                                           axis=1)
                        preds = pd.concat([preds, pd.DataFrame(data=ptufile.predictions[key][k],
                                                               columns=[f'{key}_{k}'])], axis=1)
                    elif "0.001" in k:
                        ptufile.get_autocorrelation(method='multipletau', name=(key, k))

            for m in ['multipletau', 'tttr2xfcs', 'tttr2xfcs_with_weights']:
                if m in list(ptufile.autoNorm.keys()):
                    for key, item in list(ptufile.autoNorm[m].items()):
                        ptufile.save_autocorrelation(name=key, method=m,
                                                     output_path=output_path)

            if idx > 1:
                break
        predtraces.to_csv(Path(output_path) / 'alexaclean_predtraces.csv')
        traces.to_csv(Path(output_path) / 'alexaclean_traces.csv')
        preds.to_csv(Path(output_path) / 'alexaclean_preds.csv')
      #+END_SRC

      #+RESULTS:


      #+begin_src jupyter-python
        fit_dirty_mt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_multipletau_plot.csv',
                                       index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_dirty_tt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_tttr2xfcs_plot.csv'
                                       , index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_clean_mt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_multipletau_plot.csv'
                                       , index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_clean_tt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_tttr2xfcs_plot.csv'
                                       , index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        corr_dirty_mt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_multipletau_plot.csv',
                                       index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_dirty_tt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_tttr2xfcs_plot.csv'
                                       , index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_clean_mt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_multipletau_plot.csv'
                                       , index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_clean_tt = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_tttr2xfcs_plot.csv'
                                       , index_col=0, usecols=[0, 1, 3, 5], na_values=' ')

        preds_dirty = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_preds.csv', index_col=0)
        predtraces_dirty = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_predtraces.csv', index_col=0)
        traces_dirty = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/dirty/alexadirty_traces.csv', index_col=0)
        preds_clean = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_preds.csv', index_col=0)
        predtraces_clean = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_predtraces.csv', index_col=0)
        traces_clean = pd.read_csv(Path(output_path) / '1911DD_alexafluor488+LUVs/clean/alexaclean_traces.csv', index_col=0)
        fit_clean_mt.columns
      #+end_src

      #+RESULTS:
      : Index(['2022-03-01_multipletau_CH2_BIN0dot001_us_20 nM AF48891_T1082s_1_correlation-CH2_2 fitted model: ',
      :        '2022-03-01_multipletau_CH2_BIN0dot001_us_20 nM AF488129_T1537s_1_correlation-CH2_2 fitted model: ',
      :        '2022-03-01_multipletau_CH2_BIN0dot001_us_20 nM AF488210_T2505s_1_correlation-CH2_2 fitted model: '],
      :       dtype='object')

      #+BEGIN_SRC jupyter-python
        plotdata = zip(traces_dirty.items(), traces_clean.items(), preds_dirty.items(),
                       preds_clean.items(), predtraces_dirty.items(), predtraces_clean.items(),
                       corr_dirty_mt.items(), corr_clean_mt.items(), corr_dirty_tt.items(),
                       corr_clean_tt.items(), fit_dirty_mt.items(), fit_clean_mt.items(),
                       fit_dirty_tt.items(), fit_clean_tt.items())
        c0, c1 = sns.color_palette()[0], sns.color_palette()[1]
        fig = plt.figure(figsize=(16, 20))
        gs = fig.add_gridspec(12, 4)
        for i, ((_, td), (_, tc), (_, prd), (_, pc), (_, ptd), (_, ptc), (_, cdm), (_, ccm), (_, cdt),
                (_, cct), (_, fdm), (_, fcm), (_, fdt), (_, fct)) in enumerate(plotdata):
            ax0 = fig.add_subplot(gs[i*4, 0:2], title=tc.name)
            sns.lineplot(ax=ax0, data=tc)
            ax1 = fig.add_subplot(gs[i*4, 2:4], title=td.name)
            sns.lineplot(ax=ax1, data=td)
            ax2 = fig.add_subplot(gs[i*4+1, 0:2], sharex=ax0)
            sns.lineplot(ax=ax2, x=ptc.index, y=ptc, color=c0)
            sns.lineplot(ax=ax2, x=pc.index, y=pc, color=c1, alpha=0.8)
            ax3 = fig.add_subplot(gs[i*4+1, 2:4], sharex=ax1)
            sns.lineplot(ax=ax3, x=ptd.index, y=ptd)
            sns.lineplot(ax=ax3, x=prd.index, y=prd, color=c1, alpha=0.8)
            ax4 = fig.add_subplot(gs[i*4+2:i*4+4, 0],
                                  title=r'multipletau with $\mu s$ bin')
            sns.lineplot(ax=ax4, x=ccm.index, y=ccm, marker='.')
            sns.lineplot(ax=ax4, x=fcm.index, y=fcm, color=c1, alpha=0.8)
            ax5 = fig.add_subplot(gs[i*4+2:i*4+4, 1],
                                  title='tttr2xfcs on arrival times')
            sns.lineplot(ax=ax5, x=cct.index, y=cct, marker='.')
            sns.lineplot(ax=ax5, x=fct.index, y=fct, color=c1, alpha=0.8)
            ax6 = fig.add_subplot(gs[i*4+2:i*4+4, 2],
                                  title=r'multipletau with $\mu s$ bin', sharey=ax4)
            sns.lineplot(ax=ax6, x=cdm.index, y=cdm, marker='.')
            sns.lineplot(ax=ax6, x=fdm.index, y=fdm, color=c1, alpha=0.8)
            ax7 = fig.add_subplot(gs[i*4+2:i*4+4, 3],
                                  title='tttr2xfcs on arrival times', sharey=ax5)
            sns.lineplot(ax=ax7, x=cdt.index, y=cdt, marker='.')
            sns.lineplot(ax=ax7, x=fdt.index, y=fdt, color=c1, alpha=0.8)
            plt.setp([ax0, ax1], xlabel='time steps [ms]', ylabel='photons [au]')
            plt.setp([ax2, ax3], xlabel='time steps in ms', ylabel='probability of artifact')
            plt.setp([ax4, ax5, ax6, ax7], xscale='log', xlabel=r'$\tau$ [ms]',
                     ylabel=r'Correlation G($\tau$)')
        fig.suptitle('AlexaFluor488 (left) vs AF488 + DiO-LUVs (right)', size=20)
        gs.tight_layout(fig, rect=[0, 0, 1, 0.99])
        plt.show()
      #+END_SRC

      #+RESULTS:
      [[file:./data/exp-220227-unet/jupyter/77bffe681c88956aaa76381a292f60cf7fa7ad06.png]]


    - check out pex5 version 2:
      #+BEGIN_SRC jupyter-python
        path_clean = data_path / '191113_Pex5_2_structured/HsPEX5EGFP 1-100001'
        path_dirty = data_path / '191113_Pex5_2_structured/TbPEX5EGFP 1-10002'
        files_clean = [path_clean / f for f in os.listdir(path_clean) if f.endswith('.ptu')]
        files_dirty = [path_dirty / f for f in os.listdir(path_dirty) if f.endswith('.ptu')]
        traces = pd.DataFrame()
        predtraces = pd.DataFrame()
        preds = pd.DataFrame()
        corrs = pd.DataFrame()
        mt_bin = 1e-3


        for idx, myfile in enumerate(files_dirty):
            ptufile = cfo.PicoObject(myfile, par_obj)
            ptufile.predictTimeSeries(model=loaded_model,
                                      scaler='minmax')
            mt_name = f'us_{ptufile.name}'
            ptufile.getTimeSeries(timeseries_name=mt_name,
                                  photonCountBin=mt_bin)
            ptufile.getPhotonCountingStats(name=mt_name)
            ptufile.predictTimeSeries(model=loaded_model,
                                      scaler='minmax',
                                      name=mt_name)
            for key in list(ptufile.trueTimeArr.keys()):
                ptufile.get_autocorrelation(method='tttr2xfcs', name=key)
            for key in list(ptufile.timeSeries.keys()):
                for k, i in ptufile.timeSeries[key].items():
                    if "PREPRO" in k:
                        if "1.0" in k:
                            predtraces = pd.concat([predtraces, pd.DataFrame(i, columns=[f'{key}_{k}'])],
                                                   axis=1)
                            pass
                    elif "1.0" in k:
                        traces = pd.concat([traces, pd.DataFrame(i, columns=[f'{key}_{k}'])],
                                           axis=1)
                        preds = pd.concat([preds, pd.DataFrame(data=ptufile.predictions[key][k],
                                                               columns=[f'{key}_{k}'])], axis=1)
                    elif "0.001" in k:
                        ptufile.get_autocorrelation(method='multipletau', name=(key, k))

            for m in ['multipletau', 'tttr2xfcs', 'tttr2xfcs_with_weights']:
                if m in list(ptufile.autoNorm.keys()):
                    for key, item in list(ptufile.autoNorm[m].items()):
                        ptufile.save_autocorrelation(name=key, method=m,
                                                     output_path=output_path)
            if idx > 1:
                break
        predtraces.to_csv(Path(output_path) / 'pex2dirty_predtraces.csv')
        traces.to_csv(Path(output_path) / 'pex2dirty_traces.csv')
        preds.to_csv(Path(output_path) / 'pex2dirty_preds.csv')
      #+END_SRC

      #+RESULTS:
      : /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/multipletau/core.py:175: DtypeWarning: Input dtype is not float; casting to np.float_!
      :   warnings.warn("Input dtype is not float; casting to np.float_!",
      : /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/multipletau/core.py:175: DtypeWarning: Input dtype is not float; casting to np.float_!
      :   warnings.warn("Input dtype is not float; casting to np.float_!",
      : /home/ye53nis/.conda/envs/tf/lib/python3.9/site-packages/multipletau/core.py:175: DtypeWarning: Input dtype is not float; casting to np.float_!
      :   warnings.warn("Input dtype is not float; casting to np.float_!",

      #+BEGIN_SRC jupyter-python
        fit_dirty_mt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_multipletau_plot.csv',
                                        index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_dirty_tt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_tttr2xfcs_plot.csv',
                                        index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_clean_mt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_multipletau_plot.csv',
                                        index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        fit_clean_tt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_tttr2xfcs_plot.csv',
                                        index_col=0, usecols=[0, 2, 4, 6], na_values=' ')
        corr_dirty_mt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_multipletau_plot.csv',
                                         index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_dirty_tt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_tttr2xfcs_plot.csv',
                                         index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_clean_mt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_multipletau_plot.csv',
                                         index_col=0, usecols=[0, 1, 3, 5], na_values=' ')
        corr_clean_tt = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_tttr2xfcs_plot.csv',
                                         index_col=0, usecols=[0, 1, 3, 5], na_values=' ')

        preds_dirty = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_preds.csv', index_col=0)
        predtraces_dirty = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_predtraces.csv', index_col=0)
        traces_dirty = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/dirty/pex2dirty_traces.csv', index_col=0)
        preds_clean = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_preds.csv', index_col=0)
        predtraces_clean = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_predtraces.csv', index_col=0)
        traces_clean = pd.read_csv(Path(output_path) / '191113_Pex5_2_structured/clean/pex2clean_traces.csv', index_col=0)
        fit_clean_mt.columns
      #+END_SRC

      #+RESULTS:
      : Index(['2022-03-01_multipletau_CH2_BIN0dot001_us_HsPEX5EGFP 1-1000038_T810s_1_correlation-CH2_2 fitted model: ',
      :        '2022-03-01_multipletau_CH2_BIN0dot001_us_HsPEX5EGFP 1-1000072_T1553s_1_correlation-CH2_2 fitted model: ',
      :        '2022-03-01_multipletau_CH2_BIN0dot001_us_HsPEX5EGFP 1-10000196_T4266s_1_correlation-CH2_2 fitted model: '],
      :       dtype='object')

      #+BEGIN_SRC jupyter-python
        plotdata = zip(traces_dirty.items(), traces_clean.items(), preds_dirty.items(),
                       preds_clean.items(), predtraces_dirty.items(), predtraces_clean.items(),
                       corr_dirty_mt.items(), corr_clean_mt.items(), corr_dirty_tt.items(),
                       corr_clean_tt.items(), fit_dirty_mt.items(), fit_clean_mt.items(),
                       fit_dirty_tt.items(), fit_clean_tt.items())
        fig = plt.figure(figsize=(16, 20))
        gs = fig.add_gridspec(12, 4)
        for i, ((_, td), (_, tc), (_, prd), (_, prc), (_, ptd), (_, ptc), (_, cdm), (_, ccm), (_, cdt),
                (_, cct), (_, fdm), (_, fcm), (_, fdt), (_, fct)) in enumerate(plotdata):
            ax0 = fig.add_subplot(gs[i*4, 0:2], title=tc.name)
            sns.lineplot(ax=ax0, data=tc)
            ax1 = fig.add_subplot(gs[i*4, 2:4], title=td.name)
            sns.lineplot(ax=ax1, data=td)
            ax0.set(xlabel='time steps in ms', ylabel='photons')
            ax1.set(xlabel='time steps in ms', ylabel='photons')
            ax2 = fig.add_subplot(gs[i*4+1, 0:2], sharex=ax0)
            sns.lineplot(ax=ax2, data=ptc, color=sns.color_palette()[0], legend=False)
            sns.lineplot(ax=ax2, data=prc, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax3 = fig.add_subplot(gs[i*4+1, 2:4], sharex=ax1)
            sns.lineplot(ax=ax3, data=ptd, legend=False)
            sns.lineplot(ax=ax3, data=prd, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax2.set(xlabel='time steps in ms', ylabel='probability of artifact')
            ax3.set(xlabel='time steps in ms', ylabel='probability of artifact')
            ax4 = fig.add_subplot(gs[i*4+2:i*4+4, 0], title='multipletau w/ us bin')
            sns.lineplot(ax=ax4, data=ccm, marker='.', legend=False)
            sns.lineplot(ax=ax4, data=fcm, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax5 = fig.add_subplot(gs[i*4+2:i*4+4, 1], title='tttr2xfcs on arrival times')
            sns.lineplot(ax=ax5, data=cct, marker='.', legend=False)
            sns.lineplot(ax=ax5, data=fct, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax4.set(xscale='log', xlabel='tau in ms', ylabel='Correlation G(tau)')
            ax5.set(xscale='log', xlabel='tau in ms', ylabel='Correlation G(tau)')
            ax6 = fig.add_subplot(gs[i*4+2:i*4+4, 2], title='multipletau w/ us bin', sharey=ax4)
            sns.lineplot(ax=ax6, data=cdm, marker='.', legend=False)
            sns.lineplot(ax=ax6, data=fdm, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax7 = fig.add_subplot(gs[i*4+2:i*4+4, 3], title='tttr2xfcs on arrival times', sharey=ax5)
            sns.lineplot(ax=ax7, data=cdt, marker='.', legend=False)
            sns.lineplot(ax=ax7, data=fdt, color=sns.color_palette()[1], alpha=0.8, legend=False)
            ax6.set(xscale='log', xlabel='tau in ms', ylabel='Correlation G(tau)')
            ax7.set(xscale='log', xlabel='tau in ms', ylabel='Correlation G(tau)')
        fig.suptitle('HsPEX5-eGFP (left) vs TbPEX5-eGFP (right) - 13.11.2019', size=20)
        gs.tight_layout(fig, rect=[0, 0, 1, 0.99])
        plt.show()
      #+END_SRC

      #+RESULTS:
      :RESULTS:
      #+begin_example
        0 TbPEX5EGFP 1-1000223_T4859s_1_CH2_BIN1.0 Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,
                        9,
                    ...
                    19989, 19990, 19991, 19992, 19993, 19994, 19995, 19996, 19997,
                    19998],
                   dtype='int64', length=19999)
        1 TbPEX5EGFP 1-1000177_T3852s_1_CH2_BIN1.0 Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,
                        9,
                    ...
                    19989, 19990, 19991, 19992, 19993, 19994, 19995, 19996, 19997,
                    19998],
                   dtype='int64', length=19999)2 TbPEX5EGFP 1-1000238_T5189s_1_CH2_BIN1.0 Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,
             9,
         ...
         19989, 19990, 19991, 19992, 19993, 19994, 19995, 19996, 19997,
         19998],
        dtype='int64', length=19999)
      #+end_example
      [[file:./data/exp-220227-unet/jupyter/e9594ffc40d7318f79985a65eb4f9c2348507e63.png]]
      :END:

      #+BEGIN_SRC jupyter-python
        plt.plot(range(0, 10))
      #+END_SRC

      #+RESULTS:
      :RESULTS:
          | <matplotlib.lines.Line2D | at | 0x2b3cb0e2b490> |
      [[file:./data/exp-220227-unet/jupyter/cf2194e07f0219b14e52f9057bee92f5ff6c13cb.png]]
      :END:

      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC

      #+BEGIN_SRC jupyter-python
        %cd /beegfs/ye53nis/drmed-git
      #+END_SRC
